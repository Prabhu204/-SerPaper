[
{"title": "Battery State of Charge Modeling for Solar PV Array using Polynomial Regression", "author": "Siddhi Vinayak Pandey, Jeet Patel, Harsh S. Dhiman", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this manuscript, we have investigated the response of the State of Charge (SoC) and the open-circuit voltage across the dynamic battery model under the variable voltage and current during the charging cycle of the battery. These variable input voltage and current have been obtained using the variable irradiance and surface temperature of a Solar PV array which is connected as an input of the dynamic battery model to store the energy within it. In order to match the Simulation result with reality, these variable irradiance and surface temperature of Solar PV Array with respect to time has been simulated. After forming and storing the energy within the dynamic battery model; the SoC of the battery has been estimated using the Kalman filter approach. After the successful estimation of SoC; the Open Circuit Voltage (OCV) and State of Charge (SoC) have been plotted using the polynomial regression technique. The regression plots between the OCV and SoC have been drawn for the polynomial degree of 2, 3,4, and 5. Results reveal that R$^2$ keeps increasing as we increase the degrees of regression. Simultaneously the value of RMSE keeps decreasing as we increase the degree of the polynomial regression.", "pdf_url": "https://arxiv.org/pdf/2008.09038", "subject": "Systems and Control (eess.SY)"},
{"title": "Exposures Exposed: A Measurement and User Study to Assess Mobile Data Privacy in Context", "author": "Evita Bakopoulou, Anastasia Shuba, Athina Markopoulou", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Mobile devices have access to personal, potentially sensitive data, and there is a large number of mobile applications and third-party libraries that transmit this information over the network to remote servers (including app developer servers and third party servers). In this paper, we are interested in better understanding of not just the extent of personally identifiable information (PII) exposure, but also its context i.e., functionality of the app, destination server, encryption used, etc.) and the risk perceived by mobile users today. To that end we take two steps. First, we perform a measurement study: we collect a new dataset via manual and automatic testing and capture the exposure of 16 PII types from 400 most popular Android apps. We analyze these exposures and provide insights into the extent and patterns of mobile apps sharing PII, which can be later used for prediction and prevention. Second, we perform a user study with 220 participants on Amazon Mechanical Turk: we summarize the results of the measurement study in categories, present them in a realistic context, and assess users' understanding, concern, and willingness to take action. To the best of our knowledge, our user study is the first to collect and analyze user input in such fine granularity and on actual (not just potential or permitted) privacy exposures on mobile devices. Although many users did not initially understand the full implications of their PII being exposed, after being better informed through the study, they became appreciative and interested in better privacy practices.", "pdf_url": "https://arxiv.org/pdf/2008.08973", "subject": "Cryptography and Security (cs.CR)"},
{"title": "State Observation of LTV Systems with Delayed Measurements: A Parameter Estimation-based Approach", "author": "Alexey Bobtsov, Nikolay Nikolaev, Romeo Ortega, Denis Efimov", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this paper we address the problem of state observation of linear time-varying systems with delayed measurements, which has attracted the attention of many researchers|see [7] and references therein. We show that, adopting the parameter estimationbased approach proposed in [3,4], we can provide a very simple solution to the problem with reduced prior knowledge.", "pdf_url": "https://arxiv.org/pdf/2008.08913", "subject": "Systems and Control (eess.SY)"},
{"title": "Complete the Missing Half: Augmenting Aggregation Filtering with Diversification for Graph Convolutional Networks", "author": "Sitao Luan, Mingde Zhao, Chenqing Hua, Xiao-Wen Chang, Doina Precup", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The core operation of Graph Neural Networks (GNNs) is the aggregation enabled by the graph Laplacian or message passing, which filters the neighborhood information of the nodes. Though effective for various tasks, they are the potentially problematic factor of all GNN methods, as they force the node representations to be similar, making the nodes gradually lose their identity and become indistinguishable. In this paper, we augment the aggregation operations with their dual, i.e. diversification operators that make the node more distinct and preserve the identity. Such augmentation replaces the aggregation with a two-pass filtering process that, in theory, is beneficial for enriching the node representations. In practice, the two-pass filters can be easily patched on existing GNN methods with diverse training strategies, including spectral and spatial (message passing) methods. When patched on baselines, we observe the significant performance boost on 8 node and graph classification tasks.", "pdf_url": "https://arxiv.org/pdf/2008.08844", "subject": "Machine Learning (cs.LG)"},
{"title": "Reliable Traffic Monitoring Mechanisms Based on Blockchain in Vehicular Networks", "author": "Jianxiong Guo, Xingjian Ding, Weili Wu", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The real-time traffic monitoring is a fundamental mission in a smart city to understand traffic conditions and avoid dangerous incidents. In this paper, we propose a reliable and efficient traffic monitoring system that integrates blockchain and the Internet of vehicles technologies effectively. It can crowdsource its tasks of traffic information collection to vehicles that run on the road instead of installing cameras in every corner. First, we design a lightweight blockchain-based information trading framework to model the interactions between traffic administration and vehicles. It guarantees reliability, efficiency, and security during executing trading. Second, we define the utility functions for the entities in this system and come up with a budgeted auction mechanism that motivates vehicles to undertake the collection tasks actively. In our algorithm, it not only ensures that the total payment to the selected vehicles does not exceed a given budget, but also maintains the truthfulness of auction process that avoids some vehicles to offer unreal bids for getting greater utilities. Finally, we conduct a group of numerical simulations to evaluate the reliability of our trading framework and performance of our algorithms, whose results demonstrate their correctness and efficiency perfectly.", "pdf_url": "https://arxiv.org/pdf/2008.08761", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Prescriptive Business Process Monitoring for Recommending Next Best Actions", "author": "Sven Weinzierl, Sebastian Dunzer, Sandra Zilker, Martin Matzner", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Predictive business process monitoring (PBPM) techniques predict future process behaviour based on historical event log data to improve operational business processes. Concerning the next activity prediction, recent PBPM techniques use state-of-the-art deep neural networks (DNNs) to learn predictive models for producing more accurate predictions in running process instances. Even though organisations measure process performance by key performance indicators (KPIs), the DNN`s learning procedure is not directly affected by them. Therefore, the resulting next most likely activity predictions can be less beneficial in practice. Prescriptive business process monitoring (PrBPM) approaches assess predictions regarding their impact on the process performance (typically measured by KPIs) to prevent undesired process activities by raising alarms or recommending actions. However, none of these approaches recommends actual process activities as actions that are optimised according to a given KPI. We present a PrBPM technique that transforms the next most likely activities into the next best actions regarding a given KPI. Thereby, our technique uses business process simulation to ensure the control-flow conformance of the recommended actions. Based on our evaluation with two real-life event logs, we show that our technique`s next best actions can outperform next activity predictions regarding the optimisation of a KPI and the distance from the actual process instances.", "pdf_url": "https://arxiv.org/pdf/2008.08693", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Markov Chain-Based Stochastic Strategies for Robotic Surveillance", "author": "Xiaoming Duan, Francesco Bullo", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This article surveys recent advancements of strategy designs for persistent robotic surveillance tasks with the focus on stochastic approaches. The problem describes how mobile robots stochastically patrol a graph in an efficient way where the efficiency is defined with respect to relevant underlying performance metrics. We first start by reviewing the basics of Markov chains, which is the primary motion model for stochastic robotic surveillance. Then two main criteria regarding the speed and unpredictability of surveillance strategies are discussed. The central objects that appear throughout the treatment is the hitting times of Markov chains, their distributions and expectations. We formulate various optimization problems based on the concerned metrics in different scenarios and establish their respective properties.", "pdf_url": "https://arxiv.org/pdf/2008.09050", "subject": "Optimization and Control (math.OC)"},
{"title": "Ensemble learning reveals dissimilarity between rare-earth transition metal binary alloys with respect to the Curie temperature", "author": "Duong-Nguyen Nguyen, Tien-Lam Pham, Viet-Cuong Nguyen, Hiori Kino, Takashi Miyake, Hieu-Chi Dam", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We propose a data-driven method to extract dissimilarity between materials, with respect to a given target physical property. The technique is based on an ensemble method with Kernel ridge regression as the predicting model; multiple random subset sampling of the materials is done to generate prediction models and the corresponding contributions of the reference training materials in detail. The distribution of the predicted values for each material can be approximated by a Gaussian mixture model. The reference training materials contributed to the prediction model that accurately predicts the physical property value of a specific material, are considered to be similar to that material, or vice versa. Evaluations using synthesized data demonstrate that the proposed method can effectively measure the dissimilarity between data instances. An application of the analysis method on the data of Curie temperature (TC) of binary 3d transition metal 4f rare earth binary alloys also reveals meaningful results on the relations between the materials. The proposed method can be considered as a potential tool for obtaining a deeper understanding of the structure of data, with respect to a target property, in particular.", "pdf_url": "https://arxiv.org/pdf/2008.08818", "subject": "Machine Learning (stat.ML)"},
{"title": "UoB at SemEval-2020 Task 12: Boosting BERT with Corpus Level Information", "author": "Wah Meng Lim, Harish Tayyar Madabushi", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Pre-trained language model word representation, such as BERT, have been extremely successful in several Natural Language Processing tasks significantly improving on the state-of-the-art. This can largely be attributed to their ability to better capture semantic information contained within a sentence. Several tasks, however, can benefit from information available at a corpus level, such as Term Frequency-Inverse Document Frequency (TF-IDF). In this work we test the effectiveness of integrating this information with BERT on the task of identifying abuse on social media and show that integrating this information with BERT does indeed significantly improve performance. We participate in Sub-Task A (abuse detection) wherein we achieve a score within two points of the top performing team and in Sub-Task B (target detection) wherein we are ranked 4 of the 44 participating teams.", "pdf_url": "https://arxiv.org/pdf/2008.08547", "subject": "Computation and Language (cs.CL)"},
{"title": "MineNav: An Expandable Synthetic Dataset Based on Minecraft for Aircraft Visual Navigation", "author": "Dali Wang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We propose a simply method to generate high quality synthetic dataset based on open-source game Minecraft includes rendered image, Depth map, surface normal map, and 6-dof camera trajectory. This dataset has a perfect ground-truth generated by plug-in program, and thanks for the large game's community, there is an extremely large number of 3D open-world environment, users can find suitable scenes for shooting and build data sets through it and they can also build scenes in-game. as such, We don't need to worry about manual over fitting caused by too small datasets. what's more, there is also a shader community which We can use to minimize data bias between rendered images and real-images as little as possible. Last but not least, we now provide three tools to generate the data for depth prediction ,surface normal prediction and visual odometry, user can also develop the plug-in module for other vision task like segmentation or optical flow prediction.", "pdf_url": "https://arxiv.org/pdf/2008.08454", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Robust Instance-Optimal Recovery of Sparse Signals at Unknown Noise Levels", "author": "Hendrik Bernd Petersen, Peter Jung", "pub_date": "Submitted on 19 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "We consider the problem of sparse signal recovery from noisy measurements. Many of frequently used recovery methods rely on some sort of tuning depending on either noise or signal parameters. If no estimates for either of them are available, the noisy recovery problem is significantly harder. The square root LASSO and the least absolute deviation LASSO are known to be noise-blind, in the sense that the tuning parameter can be chosen independent on the noise and the signal. We generalize those recovery methods to the rLASSO and give a recovery guarantee once the tuning parameter is above a threshold. Moreover we analyze the effect of mistuning on a theoretic level and prove the optimality of our recovery guarantee. Further, for Gaussian matrices we give a refined analysis of the threshold of the tuning parameter and proof a new relation of the tuning parameter on the dimensions. Indeed, for a certain amount of measurements the tuning parameter becomes independent on the sparsity. Finally, we verify that the least absolute deviation LASSO can be used with random walk matrices of uniformly at random chosen left regular biparitite graphs.", "pdf_url": "https://arxiv.org/pdf/2008.08385", "subject": "Information Theory (cs.IT)"},
{"title": "Towards Lightweight Lane Detection by Optimizing Spatial Embedding", "author": "Seokwoo Jung, Sungha Choi, Mohammad Azam Khan, Jaegul Choo", "pub_date": "Submitted on 19 Aug 2020", "abstract": "A number of lane detection methods depend on a proposal-free instance segmentation because of its adaptability to flexible object shape, occlusion, and real-time application. This paper addresses the problem that pixel embedding in proposal-free instance segmentation based lane detection is difficult to optimize. A translation invariance of convolution, which is one of the supposed strengths, causes challenges in optimizing pixel embedding. In this work, we propose a lane detection method based on proposal-free instance segmentation, directly optimizing spatial embedding of pixels using image coordinate. Our proposed method allows the post-processing step for center localization and optimizes clustering in an end-to-end manner. The proposed method enables real-time lane detection through the simplicity of post-processing and the adoption of a lightweight backbone. Our proposed method demonstrates competitive performance on public lane detection datasets.", "pdf_url": "https://arxiv.org/pdf/2008.08311", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Weakly Supervised Learning with Region and Box-level Annotations for Salient Instance Segmentation", "author": "Jialun Pei, He Tang, Chuanbo Chen", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Salient instance segmentation is a new challenging task that received widespread attention in saliency detection area. Due to the limited scale of the existing dataset and the high mask annotations cost, it is difficult to train a salient instance neural network completely. In this paper, we appeal to train a salient instance segmentation framework by a weakly supervised source without resorting to laborious labeling. We present a cyclic global context salient instance segmentation network (CGCNet), which is supervised by the combination of the binary salient regions and bounding boxes from the existing saliency detection datasets. For a precise pixel-level location, a global feature refining layer is introduced that dilates the context features of each salient instance to the global context in the image. Meanwhile, a labeling updating scheme is embedded in the proposed framework to online update the weak annotations for next iteration. Experiment results demonstrate that the proposed end-to-end network trained by weakly supervised annotations can be competitive to the existing fully supervised salient instance segmentation methods. Without bells and whistles, our proposed method achieves a mask AP of 57.13%, which outperforms the best fully supervised methods and establishes new states of the art for weakly supervised salient instance segmentation.", "pdf_url": "https://arxiv.org/pdf/2008.08246", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Uncertainty-aware Self-supervised 3D Data Association", "author": "Jianren Wang, Siddharth Ancha, Yi-Ting Chen, David Held", "pub_date": "Submitted on 18 Aug 2020", "abstract": "3D object trackers usually require training on large amounts of annotated data that is expensive and time-consuming to collect. Instead, we propose leveraging vast unlabeled datasets by self-supervised metric learning of 3D object trackers, with a focus on data association. Large scale annotations for unlabeled data are cheaply obtained by automatic object detection and association across frames. We show how these self-supervised annotations can be used in a principled manner to learn point-cloud embeddings that are effective for 3D tracking. We estimate and incorporate uncertainty in self-supervised tracking to learn more robust embeddings, without needing any labeled data. We design embeddings to differentiate objects across frames, and learn them using uncertainty-aware self-supervised training. Finally, we demonstrate their ability to perform accurate data association across frames, towards effective and accurate 3D tracking. Project videos and code are at .", "pdf_url": "https://arxiv.org/pdf/2008.08173", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Covid-19 infodemic reveals new tipping point epidemiology and a revised $R$ formula", "author": "N.F. Johnson, N. Velasquez, O.K. Jha, H. Niyazi, R. Leahy, N. Johnson Restrepo, R. Sear, P. Manrique, Y. Lupu, P. Devkota, S. Wuchty", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Many governments have managed to control their COVID-19 outbreak with a simple message: keep the effective '$R$ number' $R<1$ to prevent widespread contagion and flatten the curve. This raises the question whether a similar policy could control dangerous online 'infodemics' of information, misinformation and disinformation. Here we show, using multi-platform data from the COVID-19 infodemic, that its online spreading instead encompasses a different dynamical regime where communities and users within and across independent platforms, sporadically form temporary active links on similar timescales to the viral spreading. This allows material that might have died out, to evolve and even mutate. This has enabled niche networks that were already successfully spreading hate and anti-vaccination material, to rapidly become global super-spreaders of narratives featuring fake COVID-19 treatments, anti-Asian sentiment and conspiracy theories. We derive new tools that incorporate these coupled social-viral dynamics, including an online $R$, to help prevent infodemic spreading at all scales: from spreading across platforms (e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community, or topic. By accounting for similar social and viral timescales, the same mathematical theory also offers a quantitative description of other unconventional infection profiles such as rumors spreading in financial markets and colds spreading in schools.", "pdf_url": "https://arxiv.org/pdf/2008.08513", "subject": "Physics and Society (physics.soc-ph)"},
{"title": "Augmenting Neural Differential Equations to Model Unknown Dynamical Systems with Incomplete State Information", "author": "Robert Strauss", "pub_date": "Submitted on 19 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "Neural Ordinary Differential Equations replace the right-hand side of a conventional ODE with a neural net, which by virtue of the universal approximation theorem, can be trained to the representation of any function. When we do not know the function itself, but have state trajectories (time evolution) of the ODE system we can still train the neural net to learn the representation of the underlying but unknown ODE. However if the state of the system is incompletely known then the right-hand side of the ODE cannot be calculated. The derivatives to propagate the system are unavailable. We show that a specially augmented Neural ODE can learn the system when given incomplete state information. As a worked example we apply neural ODEs to the Lotka-Voltera problem of 3 species, rabbits, wolves, and bears. We show that even when the data for the bear time series is removed the remaining time series of the rabbits and wolves is sufficient to learn the dynamical system despite the missing the incomplete state information. This is surprising since a conventional ODE system cannot output the correct derivatives without the full state as the input. We implement augmented neural ODEs and differential equation solvers in the julia programming language.", "pdf_url": "https://arxiv.org/pdf/2008.08226", "subject": "Neurons and Cognition (q-bio.NC)"},
{"title": "On dropping the first Sobol' point", "author": "Art B. Owen", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Quasi-Monte Carlo (QMC) points are a substitute for plain Monte Carlo (MC) points that greatly improve integration accuracy under mild assumptions on the problem. Because QMC can give errors that are $o(1/n)$ as $n\\to\\infty$, changing even one point can change the estimate by an amount much larger than the error would have been and worsen the convergence rate. As a result, certain practices that fit quite naturally and intuitively with MC points are very detrimental to QMC performance. These include thinning, burn-in, and taking sample sizes such as powers of $10$, other than the ones for which the QMC points were designed. This article looks at the effects of a common practice in which one skips the first point of a Sobol' sequence. The retained points ordinarily fail to be a digital net and when scrambling is applied, skipping over the first point can increase the numerical error by a factor proportional to $\\sqrt{n}$ where $n$ is the number of function evaluations used.", "pdf_url": "https://arxiv.org/pdf/2008.08051", "subject": "Numerical Analysis (math.NA)"},
{"title": "Communicative Reinforcement Learning Agents for Landmark Detection in Brain Images", "author": "Guy Leroy, Daniel Rueckert, Amir Alansary", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Accurate detection of anatomical landmarks is an essential step in several medical imaging tasks. We propose a novel communicative multi-agent reinforcement learning (C-MARL) system to automatically detect landmarks in 3D brain images. C-MARL enables the agents to learn explicit communication channels, as well as implicit communication signals by sharing certain weights of the architecture among all the agents. The proposed approach is evaluated on two brain imaging datasets from adult magnetic resonance imaging (MRI) and fetal ultrasound scans. Our experiments show that involving multiple cooperating agents by learning their communication with each other outperforms previous approaches using single agents.", "pdf_url": "https://arxiv.org/pdf/2008.08055", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Benchmarking network fabrics for data distributed training of deep neural networks", "author": "Siddharth Samsi, Andrew Prout, Michael Jones, Andrew Kirby, Bill Arcand, Bill Bergeron, David Bestor, Chansup Byun, Vijay Gadepally, Michael Houle, Matthew Hubbell, Anna Klein, Peter Michaleas, Lauren Milechin, Julie Mullen, Antonio Rosa, Charles Yee, Albert Reuther, Jeremy Kepner", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Artificial Intelligence/Machine Learning applications require the training of complex models on large amounts of labelled data. The large computational requirements for training deep models have necessitated the development of new methods for faster training. One such approach is the data parallel approach, where the training data is distributed across multiple compute nodes. This approach is simple to implement and supported by most of the commonly used machine learning frameworks. The data parallel approach leverages MPI for communicating gradients across all nodes. In this paper, we examine the effects of using different physical hardware interconnects and network-related software primitives for enabling data distributed deep learning. We compare the effect of using GPUDirect and NCCL on Ethernet and OmniPath fabrics. Our results show that using Ethernet-based networking in shared HPC systems does not have a significant effect on the training times for commonly used deep neural network architectures or traditional HPC applications such as Computational Fluid Dynamics.", "pdf_url": "https://arxiv.org/pdf/2008.08057", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "When Hardness of Approximation Meets Hardness of Learning", "author": "Eran Malach, Shai Shalev-Shwartz", "pub_date": "Submitted on 18 Aug 2020", "abstract": "A supervised learning algorithm has access to a distribution of labeled examples, and needs to return a function (hypothesis) that correctly labels the examples. The hypothesis of the learner is taken from some fixed class of functions (e.g., linear classifiers, neural networks etc.). A failure of the learning algorithm can occur due to two possible reasons: wrong choice of hypothesis class (hardness of approximation), or failure to find the best function within the hypothesis class (hardness of learning). Although both approximation and learnability are important for the success of the algorithm, they are typically studied separately. In this work, we show a single hardness property that implies both hardness of approximation using linear classes and shallow networks, and hardness of learning using correlation queries and gradient-descent. This allows us to obtain new results on hardness of approximation and learnability of parity functions, DNF formulas and $AC^0$ circuits.", "pdf_url": "https://arxiv.org/pdf/2008.08059", "subject": "Machine Learning (cs.LG)"},
{"title": "Personalized Deep Learning for Ventricular Arrhythmias Detection on Medical IoT Systems", "author": "Zhenge Jia, Zhepeng Wang, Feng Hong, Lichuan Ping, Yiyu Shi, Jingtong Hu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Life-threatening ventricular arrhythmias (VA) are the leading cause of sudden cardiac death (SCD), which is the most significant cause of natural death in the US. The implantable cardioverter defibrillator (ICD) is a small device implanted to patients under high risk of SCD as a preventive treatment. The ICD continuously monitors the intracardiac rhythm and delivers shock when detecting the life-threatening VA. Traditional methods detect VA by setting criteria on the detected rhythm. However, those methods suffer from a high inappropriate shock rate and require a regular follow-up to optimize criteria parameters for each ICD recipient. To ameliorate the challenges, we propose the personalized computing framework for deep learning based VA detection on medical IoT systems. The system consists of intracardiac and surface rhythm monitors, and the cloud platform for data uploading, diagnosis, and CNN model personalization. We equip the system with real-time inference on both intracardiac and surface rhythm monitors. To improve the detection accuracy, we enable the monitors to detect VA collaboratively by proposing the cooperative inference. We also introduce the CNN personalization for each patient based on the computing framework to tackle the unlabeled and limited rhythm data problem. When compared with the traditional detection algorithm, the proposed method achieves comparable accuracy on VA rhythm detection and 6.6% reduction in inappropriate shock rate, while the average inference latency is kept at 71ms.", "pdf_url": "https://arxiv.org/pdf/2008.08060", "subject": "Machine Learning (cs.LG)"},
{"title": "Compute, Time and Energy Characterization of Encoder-Decoder Networks with Automatic Mixed Precision Training", "author": "Siddharth Samsi, Michael Jones, Mark M. Veillette", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Deep neural networks have shown great success in many diverse fields. The training of these networks can take significant amounts of time, compute and energy. As datasets get larger and models become more complex, the exploration of model architectures becomes prohibitive. In this paper we examine the compute, energy and time costs of training a UNet based deep neural network for the problem of predicting short term weather forecasts (called precipitation Nowcasting). By leveraging a combination of data distributed and mixed-precision training, we explore the design space for this problem. We also show that larger models with better performance come at a potentially incremental cost if appropriate optimizations are used. We show that it is possible to achieve a significant improvement in training time by leveraging mixed-precision training without sacrificing model performance. Additionally, we find that a 1549% increase in the number of trainable parameters for a network comes at a relatively smaller 63.22% increase in energy usage for a UNet with 4 encoding layers.", "pdf_url": "https://arxiv.org/pdf/2008.08062", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "AB3DMOT: A Baseline for 3D Multi-Object Tracking and New Evaluation Metrics", "author": "Xinshuo Weng, Jianren Wang, David Held, Kris Kitani", "pub_date": "Submitted on 18 Aug 2020", "abstract": "3D multi-object tracking (MOT) is essential to applications such as autonomous driving. Recent work focuses on developing accurate systems giving less attention to computational cost and system complexity. In contrast, this work proposes a simple real-time 3D MOT system with strong performance. Our system first obtains 3D detections from a LiDAR point cloud. Then, a straightforward combination of a 3D Kalman filter and the Hungarian algorithm is used for state estimation and data association. Additionally, 3D MOT datasets such as KITTI evaluate MOT methods in 2D space and standardized 3D MOT evaluation tools are missing for a fair comparison of 3D MOT methods. We propose a new 3D MOT evaluation tool along with three new metrics to comprehensively evaluate 3D MOT methods. We show that, our proposed method achieves strong 3D MOT performance on KITTI and runs at a rate of $207.4$ FPS on the KITTI dataset, achieving the fastest speed among modern 3D MOT systems. Our code is publicly available at .", "pdf_url": "https://arxiv.org/pdf/2008.08063", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Embedded Fracture Model for Coupled Flow and Geomechanics", "author": "I. Shovkun, T. Garipov, H. A. Tchelepi", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Fluid injection and production cause changes in reservoir pressure, which result in deformations in the subsurface. This phenomenon is particularly important in reservoirs with abundant fractures and faults because the induced slip and opening of the fractures may significantly alter their hydraulic properties. Modeling strongly coupled poro-mechanical processes in naturally fractured reservoirs is a challenging problem. The Discrete Fracture Model (DFM) is a state-of-art method for modeling coupled flow and mechanics in fractured reservoirs. This method requires constructing computational grids that comform to fractures, which is very challenging in complex 3D settings. The objective of this study is to develop a numerical method that does not require gridding near fractures and can efficiently model hydromechanical interactions in fractured reservoirs. We utilize formulations based on the Strong Discontinuity Approach (SDA) for mechanics and Embedded Discrete Fracture Model (EDFM) for flow. We first present a mathematical formulation and emphasize the kinematic aspects of fracture slip and opening. We then introduce a series of mechanical tests that investigate the spatial convergence of the model and compare its accuracy with the Discrete Fracture Model (DFM). We finally consider a synthetic coupled case of a reservoir with several fractures and compare the performance of the SDA and DFM methods. Our results indicate super-linear spatial convergence of the proposed SDA algorithm. Numerical simulations confirm the applicability of the proposed method to modeling the coupling effects in subsurface applications.", "pdf_url": "https://arxiv.org/pdf/2008.08064", "subject": "Computational Engineering, Finance, and Science (cs.CE)"},
{"title": "Energy-Optimal Control of a Submarine-Launched Cruise Missile", "author": "Semih K\u00f6kl\u00fccan, M. Kemal Leblebicio\u011flu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "A typical mission profile of submarine-launched cruise missiles begins with the launch phase which covers the motion of the missile from the launch to the water-exit and continues with the boost phase which lasts from the water-exit to the beginning of the cruise phase. In order to achieve the desired range of the launch and boost phases, efficient utilization of available energy which carries the missile to the beginning of the cruise phase is necessary. For this purpose, this study presents a new approach for energy-optimal control of the underwater and air motion of a submarine-launched cruise missile. In this approach, the aforementioned problem is modeled and solved as a minimum-effort optimal control problem. Then, the effects of initial and final conditions on energy need are investigated, and the optimal conditions that result with the minimum energy need are determined. Prior to the guidance and control design steps, six degrees of freedom (6 DOF) motion equations are derived and the hydrodynamic and aerodynamic parameters are retrieved. The nonlinear 6 DOF motion model is simplified and linearized before minimum-effort optimal control design part. Results of the designed guidance and control strategies are presented through the nonlinear 6 DOF simulations. Finally, some comments are made and future studies are mentioned based on theoretical and simulation studies.", "pdf_url": "https://arxiv.org/pdf/2008.08068", "subject": "Systems and Control (eess.SY)"},
{"title": "Robust Mean Estimation on Highly Incomplete Data with Arbitrary Outliers", "author": "Lunjia Hu, Omer Reingold", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "We study the problem of robustly estimating the mean of a $d$-dimensional distribution given $N$ examples, where $\\varepsilon N$ examples may be arbitrarily corrupted and most coordinates of every example may be missing. Assuming each coordinate appears in a constant factor more than $\\varepsilon N$ examples, we show algorithms that estimate the mean of the distribution with information-theoretically optimal dimension-independent error guarantees in nearly-linear time $\\widetilde O(Nd)$. Our results extend recent work on computationally-efficient robust estimation to a more widely applicable incomplete-data setting.", "pdf_url": "https://arxiv.org/pdf/2008.08071", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "AssembleNet++: Assembling Modality Representations via Attention Connections", "author": "Michael S. Ryoo, AJ Piergiovanni, Juhana Kangaspunta, Anelia Angelova", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We create a family of powerful video models which are able to: (i) learn interactions between semantic object information and raw appearance and motion features, and (ii) deploy attention in order to better learn the importance of features at each convolutional block of the network. A new network component named peer-attention is introduced, which dynamically learns the attention weights using another block or input modality. Even without pre-training, our models outperform the previous work on standard public activity recognition datasets with continuous videos, establishing new state-of-the-art. We also confirm that our findings of having neural connections from the object modality and the use of peer-attention is generally applicable for different existing architectures, improving their performances. We name our model explicitly as AssembleNet++. The code will be available at:", "pdf_url": "https://arxiv.org/pdf/2008.08072", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Identification of the K-most Vulnerable Entities in a Smart Grid System", "author": "Sohini Roy, Arunabha Sen", "pub_date": "Submitted on 18 Aug 2020", "abstract": "A smart grid system can be considered as a multi-layered network with power network in one layer and communication network in the other. The entities in both the layers exhibit complex intra-and-interdependencies between them. A reliable decision making by the smart grid operator is contingent upon correct analysis of such dependencies between its entities and also on accurate identification of the most critical entities in the system. The Modified Implicative Interdependency Model (MIIM) [1] successfully captures such dependencies using multi-valued Boolean Logic based equations called Interdependency Relations (IDRs) after most of the existing models made failed attempts in doing that. In this paper, for any given integer K, this model is used to identify the K-most vulnerable entities in a smart grid, failure of which can maximize the network damage. Owing to the problem being NP complete, an Integer Linear Programming (ILP) based solution is given here. Validation of the model [1] and the results of the ILP based solution is done by simulating a smart grid system of IEEE 14-Bus using MATPOWER and Java Network Simulator (JNS). Simulation results prove that not only the model MIIM [1] is correct but also it can predict the network damage for failure of K-most vulnerable entities more accurately than its predecessor Implicative Interdependency Model (IIM) [2].", "pdf_url": "https://arxiv.org/pdf/2008.08074", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Deploying Lifelong Open-Domain Dialogue Learning", "author": "Kurt Shuster, Jack Urbanek, Emily Dinan, Arthur Szlam, Jason Weston", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Much of NLP research has focused on crowdsourced static datasets and the supervised learning paradigm of training once and then evaluating test performance. As argued in de Vries et al. (2020), crowdsourced data has the issues of lack of naturalness and relevance to real-world use cases, while the static dataset paradigm does not allow for a model to learn from its experiences of using language (Silver et al., 2013). In contrast, one might hope for machine learning systems that become more useful as they interact with people. In this work, we build and deploy a role-playing game, whereby human players converse with learning agents situated in an open-domain fantasy world. We show that by training models on the conversations they have with humans in the game the models progressively improve, as measured by automatic metrics and online engagement scores. This learning is shown to be more efficient than crowdsourced data when applied to conversations with real users, as well as being far cheaper to collect.", "pdf_url": "https://arxiv.org/pdf/2008.08076", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Non-convex Min-Max Optimization: Applications, Challenges, and Recent Theoretical Advances", "author": "Meisam Razaviyayn, Tianjian Huang, Songtao Lu, Maher Nouiehed, Maziar Sanjabi, Mingyi Hong", "pub_date": "Submitted on 15 Jun 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "The min-max optimization problem, also known as the saddle point problem, is a classical optimization problem which is also studied in the context of zero-sum games. Given a class of objective functions, the goal is to find a value for the argument which leads to a small objective value even for the worst case function in the given class. Min-max optimization problems have recently become very popular in a wide range of signal and data processing applications such as fair beamforming, training generative adversarial networks (GANs), and robust machine learning, to just name a few. The overarching goal of this article is to provide a survey of recent advances for an important subclass of min-max problem, where the minimization and maximization problems can be non-convex and/or non-concave. In particular, we will first present a number of applications to showcase the importance of such min-max problems; then we discuss key theoretical challenges, and provide a selective review of some exciting recent theoretical and algorithmic advances in tackling non-convex min-max problems. Finally, we will point out open questions and future research directions.", "pdf_url": "https://arxiv.org/pdf/2006.08141", "subject": "Optimization and Control (math.OC)"},
{"title": "mlr3proba: Machine Learning Survival Analysis in R", "author": "Raphael Sonabend, Franz J. Kir\u00e1ly, Andreas Bender, Bernd Bischl, Michel Lang", "pub_date": "Submitted on 18 Aug 2020", "abstract": "As machine learning has become increasingly popular over the last few decades, so too has the number of machine learning interfaces for implementing these models. However, no consistent interface for evaluation and modelling of survival analysis has emerged despite its vital importance in many fields, including medicine, economics, and engineering. \\texttt{mlr3proba} is part of the \\texttt{mlr3} ecosystem of machine learning packages for R and facilitates \\texttt{mlr3}'s general model tuning and benchmarking by providing a multitude of performance measures and learners for survival analysis with a clean and systematic infrastructure for their evaluation. \\texttt{mlr3proba} provides a comprehensive machine learning interface for survival analysis, which allows survival modelling to finally be up to the state-of-art.", "pdf_url": "https://arxiv.org/pdf/2008.08080", "subject": "Computation (stat.CO)"},
{"title": "Complementary Language Model and Parallel Bi-LRNN for False Trigger Mitigation", "author": "Rishika Agarwal, Xiaochuan Niu, Pranay Dighe, Srikanth Vishnubhotla, Sameer Badaskar, Devang Naik", "pub_date": "Submitted on 18 Aug 2020", "abstract": "False triggers in voice assistants are unintended invocations of the assistant, which not only degrade the user experience but may also compromise privacy. False trigger mitigation (FTM) is a process to detect the false trigger events and respond appropriately to the user. In this paper, we propose a novel solution to the FTM problem by introducing a parallel ASR decoding process with a special language model trained from \"out-of-domain\" data sources. Such language model is complementary to the existing language model optimized for the assistant task. A bidirectional lattice RNN (Bi-LRNN) classifier trained from the lattices generated by the complementary language model shows a $38.34\\%$ relative reduction of the false trigger (FT) rate at the fixed rate of $0.4\\%$ false suppression (FS) of correct invocations, compared to the current Bi-LRNN model. In addition, we propose to train a parallel Bi-LRNN model based on the decoding lattices from both language models, and examine various ways of implementation. The resulting model leads to further reduction in the false trigger rate by $10.8\\%$.", "pdf_url": "https://arxiv.org/pdf/2008.08113", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Review of Machine Learning Algorithms for Brain Stroke Diagnosis and Prognosis by EEG Analysis", "author": "Mohammad-Parsa Hosseini, Cecilia Hemingway, Jerard Madamba, Alexander McKee, Natalie Ploof, Jennifer Schuman, Elliot Voss", "pub_date": "Submitted on 6 Aug 2020", "abstract": "Currently, strokes are the leading cause of adult disability in the United States. Traditional treatment and rehabilitation options such as physical therapy and tissue plasminogen activator are limited in their effectiveness and ability to restore mobility and function to the patient. As a result, there exists an opportunity to greatly improve the treatment for strokes. Machine learning, specifically techniques that utilize Brain-Computer Interfaces (BCIs) to help the patient either restore neurologic pathways or effectively communicate with an electronic prosthetic, show promising results when applied to both stroke diagnosis and rehabilitation. In this review, sources that design and implement BCIs for treatment of stroke patients are evaluated and categorized based on their successful applications for stroke diagnosis or stroke rehabilitation. The various machine learning techniques and algorithms that are addressed and combined with BCI technology show that the use of BCIs for stroke treatment is a promising and rapidly expanding field.", "pdf_url": "https://arxiv.org/pdf/2008.08118", "subject": "Signal Processing (eess.SP)"},
{"title": "Abelian Closures of Infinite Binary Words", "author": "Svetlana Puzynina, Markus A. Whiteland", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Two finite words $u$ and $v$ are called Abelian equivalent if each letter occurs equally many times in both $u$ and $v$. The abelian closure $\\mathcal{A}(\\mathbf{x})$ of (the shift orbit closure of) an infinite word $\\mathbf{x}$ is the set of infinite words $\\mathbf{y}$ such that, for each factor $u$ of $\\mathbf{y}$, there exists a factor $v$ of $\\mathbf{x}$ which is abelian equivalent to $u$. The notion of an abelian closure gives a characterization of Sturmian words: among binary uniformly recurrent words, Sturmian words are exactly those words for which $\\mathcal{A}(\\mathbf{x})$ equals the shift orbit closure $\\Omega(\\mathbf{x})$. In this paper we show that, contrary to larger alphabets, the abelian closure of a uniformly recurrent aperiodic binary word which is not Sturmian contains infinitely many minimal subshifts.", "pdf_url": "https://arxiv.org/pdf/2008.08125", "subject": "Combinatorics (math.CO)"},
{"title": "PRNU Estimation from Encoded Videos Using Block-Based Weighting", "author": "Enes Altinisik, Kasim Tasdemir, Husrev Taha Sencar", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Estimating the photo-response non-uniformity (PRNU) of an imaging sensor from videos is a challenging task due to complications created by several processing steps in the camera imaging pipeline. Among these steps, video coding is one of the most disruptive to PRNU estimation because of its lossy nature. Since videos are always stored in a compressed format, the ability to cope with disruptive effects of encoding is central to reliable attribution. In this work, by focusing on the block-based operation of widely used video coding standards, we present an improved approach to PRNU estimation that exploits this behavior. To this purpose, several PRNU weighting schemes that utilize block-level parameters, such as encoding block type, quantization strength, and rate-distortion values, are proposed and compared. Our results show that the use of the coding rate and the distortion introduced to a block serve as better estimators for the strength of PRNU with almost three times improvement in the matching statistic at low to medium coding bitrates as compared to the basic estimation method developed for photos.", "pdf_url": "https://arxiv.org/pdf/2008.08138", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Physics-informed machine learning for the COVID-19 pandemic: Adherence to social distancing and short-term predictions for eight countries", "author": "G. D. Barmparis, G. P. Tsironis", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The spread of COVID-19 during the initial phase of the first half of 2020 was curtailed to a larger or lesser extent through measures of social distancing imposed by most countries. In this work, we link directly, through machine learning techniques, infection data at a country level to a single number that signifies social distancing effectiveness. We assume that the standard SIR model gives a reasonable description of the dynamics of spreading, and thus the social distancing aspect can be modeled through time-dependent infection rates that are imposed externally. We use an exponential ansatz to analyze the SIR model, find an exact solution for the time-independent infection rate, and derive a simple first-order differential equation for the time-dependent infection rate as a function of the infected population. Using infected number data from the \"first wave\" of the infection from eight countries, and through physics-informed machine learning, we extract the degree of linear dependence in social distancing that led to the specific infections. We find that in the two extremes are Greece, with the highest decay slope on one side, and the US on the other with a practically flat \"decay\". The hierarchy of slopes is compatible with the effectiveness of the pandemic containment in each country. Finally, we train our network with data after the end of the analyzed period, and we make week-long predictions for the current phase of the infection that appear to be very close to the actual infection values.", "pdf_url": "https://arxiv.org/pdf/2008.08162", "subject": "Populations and Evolution (q-bio.PE)"},
{"title": "Accelerated Zeroth-Order Momentum Methods from Mini to Minimax Optimization", "author": "Feihu Huang, Shangqian Gao, Jian Pei, Heng Huang", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In the paper, we propose a new accelerated zeroth-order momentum (Acc-ZOM) method to solve the non-convex stochastic mini-optimization problems. We prove that the Acc-ZOM method achieves a lower query complexity of $O(d^{3/4}\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point, which improves the best known result by a factor of $O(d^{1/4})$ where $d$ denotes the parameter dimension. The Acc-ZOM does not require any batches compared to the large batches required in the existing zeroth-order stochastic algorithms. Further, we extend the Acc-ZOM method to solve the non-convex stochastic minimax-optimization problems and propose an accelerated zeroth-order momentum descent ascent (Acc-ZOMDA) method. We prove that the Acc-ZOMDA method reaches the best know query complexity of $\\tilde{O}(\\kappa_y^3(d_1+d_2)^{3/2}\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point, where $d_1$ and $d_2$ denote dimensions of the mini and max optimization parameters respectively and $\\kappa_y$ is condition number. In particular, our theoretical result does not rely on large batches required in the existing methods. Moreover, we propose a momentum-based accelerated framework for the minimax-optimization problems. At the same time, we present an accelerated momentum descent ascent (Acc-MDA) method for solving the white-box minimax problems, and prove that it achieves the best known gradient complexity of $\\tilde{O}(\\kappa_y^3\\epsilon^{-3})$ without large batches. Extensive experimental results on the black-box adversarial attack to deep neural networks (DNNs) and poisoning attack demonstrate the efficiency of our algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.08170", "subject": "Optimization and Control (math.OC)"},
{"title": "Non-Canonical Hamiltonian Monte Carlo", "author": "James A. Brofos, Roy R. Lederman", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Hamiltonian Monte Carlo is typically based on the assumption of an underlying canonical symplectic structure. Numerical integrators designed for the canonical structure are incompatible with motion generated by non-canonical dynamics. These non-canonical dynamics, motivated by examples in physics and symplectic geometry, correspond to techniques such as preconditioning which are routinely used to improve algorithmic performance. Indeed, recently, a special case of non-canonical structure, magnetic Hamiltonian Monte Carlo, was demonstrated to provide advantageous sampling properties. We present a framework for Hamiltonian Monte Carlo using non-canonical symplectic structures. Our experimental results demonstrate sampling advantages associated to Hamiltonian Monte Carlo with non-canonical structure. To summarize our contributions: (i) we develop non-canonical HMC from foundations in symplectic geomtry; (ii) we construct an HMC procedure using implicit integration that satisfies the detailed balance; (iii) we propose to accelerate the sampling using an {\\em approximate} explicit methodology; (iv) we study two novel, randomly-generated non-canonical structures: magnetic momentum and the coupled magnet structure, with implicit and explicit integration.", "pdf_url": "https://arxiv.org/pdf/2008.08191", "subject": "Machine Learning (stat.ML)"},
{"title": "BraggNN: Fast X-ray Bragg Peak Analysis Using Deep Learning", "author": "Zhengchun Liu, Hemant Sharma, Jun-Sang Park, Peter Kenesei, Jonathan Almer, Rajkumar Kettimuthu, Ian Foster", "pub_date": "Submitted on 18 Aug 2020", "abstract": "X-ray diffraction based microscopy techniques such as high energy diffraction microscopy rely on knowledge of position of diffraction peaks with high resolution. These positions are typically computed by fitting the observed intensities in detector data to a theoretical peak shape such as pseudo-Voigt. As experiments become more complex and detector technologies evolve, the computational cost of such peak shape fitting becomes the biggest hurdle to the rapid analysis required for real-time feedback for experiments. To this end, this paper proposes BraggNN, a machine learning-based method that can localize Bragg peak much more rapidly than conventional pseudo-Voigt peak fitting. When applied to our test dataset, BraggNN gives errors of less than 0.29 and 0.57 voxels, relative to conventional method, for 75% and 95% of the peaks, respectively. When applied to a real experiment dataset, a 3D reconstruction using peak positions located by BraggNN yields an average grain position difference of 17 micrometer and size difference of 1.3 micrometer as compared to the results obtained when the reconstruction used peaks from conventional 2D pseudo-Voigt fitting. Recent advances in deep learning method implementations and special-purpose model inference accelerators allow BraggNN to deliver enormous performance improvements relative to the conventional method, running, for example, more than 200 times faster than a conventional method when using a GPU card with out-of-the-box software.", "pdf_url": "https://arxiv.org/pdf/2008.08198", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Joint Channel Assignment and Power Allocation for Multi-UAV Communication", "author": "Lingyun Zhou, Xihan Chen, Mingyi Hong, Shi Jin, Qingjiang Shi", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Unmanned aerial vehicle (UAV) swarm has emerged as a promising novel paradigm to achieve better coverage and higher capacity for future wireless network by exploiting the more favorable line-of-sight (LoS) propagation. To reap the potential gains of UAV swarm, the remote control signal sent by ground control unit (GCU) is essential, whereas the control signal quality are susceptible in practice due to the effect of the adjacent channel interference (ACI) and the external interference (EI) from radiation sources distributed across the region. To tackle these challenges, this paper considers priority-aware resource coordination in a multi-UAV communication system, where multiple UAVs are controlled by a GCU to perform certain tasks with a pre-defined trajectory. Specifically, we maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the UAVs by jointly optimizing channel assignment and power allocation strategy under stringent resource availability constraints. According to the intensity of ACI, we consider the corresponding problem in two scenarios, i.e., Null-ACI and ACI systems. By virtue of the particular problem structure in Null-ACI case, we first recast the formulation into an equivalent yet more tractable form and obtain the global optimal solution via Hungarian algorithm. For general ACI systems, we develop an efficient iterative algorithm for its solution based on the smooth approximation and alternating optimization methods. Extensive simulation results demonstrate that the proposed algorithms can significantly enhance the minimum SINR among all the UAVs and adapt the allocation of communication resources to diverse mission priority.", "pdf_url": "https://arxiv.org/pdf/2008.08212", "subject": "Signal Processing (eess.SP)"},
{"title": "Monte Carlo construction of cubature on Wiener space", "author": "Satoshi Hayakawa, Ken'ichiro Tanaka", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In this paper, we investigate application of mathematical optimization to construction of a cubature formula on Wiener space, which is a weak approximation method of stochastic differential equations introduced by Lyons and Victoir (Cubature on Wiener Space, Proc. R. Soc. Lond. A 460, 169--198). After giving a brief review of the cubature theory on Wiener space, we show that a cubature formula of general dimension and degree can be obtained through a Monte Carlo sampling and linear programming. This paper also includes an extension of stochastic Tchakaloff's theorem, which technically yields the proof of our main result.", "pdf_url": "https://arxiv.org/pdf/2008.08219", "subject": "Probability (math.PR)"},
{"title": "Long-Term Effect Estimation with Surrogate Representation", "author": "Lu Cheng, Ruocheng Guo, Huan Liu", "pub_date": "Submitted on 19 Aug 2020", "abstract": "There are many scenarios where short- and long-term causal effects of an intervention are different. For example, low-quality ads may increase short-term ad clicks but decrease the long-term revenue via reduced clicks; search engines measured by inappropriate performance metrics may increase search query shares in a short-term but not long-term. This work therefore studies the long-term effect where the outcome of primary interest, or primary outcome, takes months or even years to accumulate. The observational study of long-term effect presents unique challenges. First, the confounding bias causes large estimation error and variance, which can further accumulate towards the prediction of primary outcomes. Second, short-term outcomes are often directly used as the proxy of the primary outcome, i.e., the surrogate. Notwithstanding its simplicity, this method entails the strong surrogacy assumption that is often impractical. To tackle these challenges, we propose to build connections between long-term causal inference and sequential models in machine learning. This enables us to learn surrogate representations that account for the temporal unconfoundedness and circumvent the stringent surrogacy assumption by conditioning on time-varying confounders in the latent space. Experimental results show that the proposed framework outperforms the state-of-the-art.", "pdf_url": "https://arxiv.org/pdf/2008.08236", "subject": "Applications (stat.AP)"},
{"title": "LIRA: Lifelong Image Restoration from Unknown Blended Distortions", "author": "Jianzhao Liu, Jianxin Lin, Xin Li, Wei Zhou, Sen Liu, Zhibo Chen", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Most existing image restoration networks are designed in a disposable way and catastrophically forget previously learned distortions when trained on a new distortion removal task. To alleviate this problem, we raise the novel lifelong image restoration problem for blended distortions. We first design a base fork-join model in which multiple pre-trained expert models specializing in individual distortion removal task work cooperatively and adaptively to handle blended distortions. When the input is degraded by a new distortion, inspired by adult neurogenesis in human memory system, we develop a neural growing strategy where the previously trained model can incorporate a new expert branch and continually accumulate new knowledge without interfering with learned knowledge. Experimental results show that the proposed approach can not only achieve state-of-the-art performance on blended distortions removal tasks in both PSNR/SSIM metrics, but also maintain old expertise while learning new restoration tasks.", "pdf_url": "https://arxiv.org/pdf/2008.08242", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Enhanced MRI Reconstruction Network using Neural Architecture Search", "author": "Qiaoying Huang, Dong Yang, Yikun Xian, Pengxiang Wu, Jingru Yi, Hui Qu, Dimitris Metaxas", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The accurate reconstruction of under-sampled magnetic resonance imaging (MRI) data using modern deep learning technology, requires significant effort to design the necessary complex neural network architectures. The cascaded network architecture for MRI reconstruction has been widely used, while it suffers from the \"vanishing gradient\" problem when the network becomes deep. In addition, homogeneous architecture degrades the representation capacity of the network. In this work, we present an enhanced MRI reconstruction network using a residual in residual basic block. For each cell in the basic block, we use the differentiable neural architecture search (NAS) technique to automatically choose the optimal operation among eight variants of the dense block. This new heterogeneous network is evaluated on two publicly available datasets and outperforms all current state-of-the-art methods, which demonstrates the effectiveness of our proposed method.", "pdf_url": "https://arxiv.org/pdf/2008.08248", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Spatio-temporal relationships between rainfall and convective clouds during Indian Monsoon through a discrete lens", "author": "Arjun Sharma, Adway Mitra, Vishal Vasan, Rama Govindarajan", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The Indian monsoon, a multi-variable process causing heavy rains during June-September every year, is very heterogeneous in space and time. We study the relationship between rainfall and Outgoing Longwave Radiation (OLR, convective cloud cover) for monsoon between 2004-2010. To identify, classify and visualize spatial patterns of rainfall and OLR we use a discrete and spatio-temporally coherent representation of the data, created using a statistical model based on Markov Random Field. Our approach clusters the days with similar spatial distributions of rainfall and OLR into a small number of spatial patterns. We find that eight daily spatial patterns each in rainfall and OLR, and seven joint patterns of rainfall and OLR, describe over 90\\% of all days. Through these patterns, we find that OLR generally has a strong negative correlation with precipitation, but with significant spatial variations. In particular, peninsular India (except west coast) is under significant convective cloud cover over a majority of days but remains rainless. We also find that much of the monsoon rainfall co-occurs with low OLR, but some amount of rainfall in Eastern and North-western India in June occurs on OLR days, presumably from shallow clouds. To study day-to-day variations of both quantities, we identify spatial patterns in the temporal gradients computed from the observations. We find that changes in convective cloud activity across India most commonly occur due to the establishment of a north-south OLR gradient which persists for 1-2 days and shifts the convective cloud cover from light to deep or vice versa. Such changes are also accompanied by changes in the spatial distribution of precipitation. The present work thus provides a highly reduced description of the complex spatial patterns and their day-to-day variations, and could form a useful tool for future simplified descriptions of this process.", "pdf_url": "https://arxiv.org/pdf/2008.08251", "subject": "Atmospheric and Oceanic Physics (physics.ao-ph)"},
{"title": "Intelligent Radio Signal Processing: A Contemporary Survey", "author": "Quoc-Viet Pham, Nhan Thanh Nguyen, Thien Huynh-The, Long Bao Le, Kyungchun Lee, Won-Joo Hwang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Intelligent signal processing for wireless communications is a vital task in modern wireless systems, but it faces new challenges because of network heterogeneity, diverse service requirements, a massive number of connections, and various radio characteristics. Owing to recent advancements in big data and computing technologies, artificial intelligence (AI) has become a useful tool for radio signal processing and has enabled the realization of intelligent radio signal processing. This survey covers four intelligent signal processing topics for the wireless physical layer, including modulation classification, signal detection, beamforming, and channel estimation. In particular, each theme is presented in a dedicated section, starting with the most fundamental principles, followed by a review of up-to-date studies and a summary. To provide the necessary background, we first present a brief overview of AI techniques such as machine learning, deep learning, and federated learning. Finally, we highlight a number of research challenges and future directions in the area of intelligent radio signal processing. We expect this survey to be a good source of information for anyone interested in intelligent radio signal processing, and the perspectives we provide therein will stimulate many more novel ideas and contributions in the future.", "pdf_url": "https://arxiv.org/pdf/2008.08264", "subject": "Signal Processing (eess.SP)"},
{"title": "DONet: Dual Objective Networks for Skin Lesion Segmentation", "author": "Yaxiong Wang, Yunchao Wei, Xueming Qian, Li Zhu, Yi Yang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Skin lesion segmentation is a crucial step in the computer-aided diagnosis of dermoscopic images. In the last few years, deep learning based semantic segmentation methods have significantly advanced the skin lesion segmentation results. However, the current performance is still unsatisfactory due to some challenging factors such as large variety of lesion scale and ambiguous difference between lesion region and background. In this paper, we propose a simple yet effective framework, named Dual Objective Networks (DONet), to improve the skin lesion segmentation. Our DONet adopts two symmetric decoders to produce different predictions for approaching different objectives. Concretely, the two objectives are actually defined by different loss functions. In this way, the two decoders are encouraged to produce differentiated probability maps to match different optimization targets, resulting in complementary predictions accordingly. The complementary information learned by these two objectives are further aggregated together to make the final prediction, by which the uncertainty existing in segmentation maps can be significantly alleviated. Besides, to address the challenge of large variety of lesion scales and shapes in dermoscopic images, we additionally propose a recurrent context encoding module (RCEM) to model the complex correlation among skin lesions, where the features with different scale contexts are efficiently integrated to form a more robust representation. Extensive experiments on two popular benchmarks well demonstrate the effectiveness of the proposed DONet. In particular, our DONet achieves 0.881 and 0.931 dice score on ISIC 2018 and $\\text{PH}^2$, respectively. Code will be made public available.", "pdf_url": "https://arxiv.org/pdf/2008.08278", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Axiomatic (and Non-Axiomatic) Mathematics", "author": "Saeed Salehi", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Axiomatizing mathematical structures and theories is an objective of Mathematical Logic. Some axiomatic systems are nowadays mere definitions, such as the axioms of Group Theory; but some systems are much deeper, such as the axioms of Complete Ordered Fields with which Real Analysis starts. Groups abound in mathematical sciences, while by Dedekind's theorem there exists only one complete ordered field, up to isomorphism. Cayley's theorem in Abstract Algebra implies that the axioms of group theory completely axiomatize the class of permutation sets that are closed under composition and inversion. In this article, we survey some old and new results on the first-order axiomatizability of various mathematical structures. We will also review identities over addition, multiplication, and exponentiation that hold in the set of positive real numbers.", "pdf_url": "https://arxiv.org/pdf/2008.08283", "subject": "Logic (math.LO)"},
{"title": "Counting embeddings of rooted trees into families of rooted trees", "author": "Bernhard Gittenberger, Zbigniew Golebiewski, Isabella Larcher, Malgorzata Sulkowska", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The number of embeddings of a partially ordered set $S$ in a partially ordered set $T$ is the number of subposets of $T$ isomorphic to $S$. If both, $S$ and $T$, have only one unique maximal element, we define good embeddings as those in which the maximal elements of $S$ and $T$ overlap. We investigate the number of good and all embeddings of a rooted poset $S$ in the family of all binary trees on $n$ elements considering two cases: plane (when the order of descendants matters) and non-plane. Furthermore, we study the number of embeddings of a rooted poset $S$ in the family of all planted plane trees of size $n$. We derive the asymptotic behaviour of good and all embeddings in all cases and we prove that the ratio of good embeddings to all is of the order $\\Theta(1/\\sqrt{n})$ in all cases, where we provide the exact constants. Furthermore, we show that this ratio is non-decreasing with $S$ in the plane binary case and asymptotically non-decreasing with $S$ in the non-plane binary case and in the planted plane case. Finally, we comment on the case when $S$ is disconnected.", "pdf_url": "https://arxiv.org/pdf/2008.08312", "subject": "Combinatorics (math.CO)"},
{"title": "Structure Learning in Inverse Ising Problems Using $\\ell_2$-Regularized Linear Estimator", "author": "Xiangming Meng, Tomoyuki Obuchi, Yoshiyuki Kabashima", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Inferring interaction parameters from observed data is a ubiquitous requirement in various fields of science and engineering. Recent studies have shown that the pseudolikelihood (PL) method is highly effective in meeting this requirement even though the maximum likelihood method is computationally intractable when used directly. To the best of our knowledge, most existing studies assume that the postulated model used in the inference stage covers the true model that generates the data. However, such an assumption does not necessarily hold in practical situations. From this perspective, we discuss the utility of the PL method in model mismatch cases. Specifically, we examine the inference performance of the PL method when $\\ell_2$-regularized (ridge) linear regression is applied to data generated from sparse Boltzmann machines of Ising spins using methods of statistical mechanics. Our analysis indicates that despite the model mismatch, one can perfectly identify the network topology using naive linear regression without regularization when the dataset size $M$ is greater than the number of Ising spins, $N$. Further, even when $M < N$, perfect identification is possible using a two-stage estimator with much better quantitative performance compared to naive usage of the PL method. Results of extensive numerical experiments support our findings.", "pdf_url": "https://arxiv.org/pdf/2008.08342", "subject": "Disordered Systems and Neural Networks (cond-mat.dis-nn)"},
{"title": "The Neighborhood Polynomial of Chordal Graphs", "author": "Helena Bergold, Winfried Hochst\u00e4ttler, Uwe Mayer", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The neighborhood polynomial of a graph $G$ is the generating function of subsets of vertices in $G$ that have a common neighbor. In this paper we study the neighborhood polynomial and the complexity of its computation for chordal graphs. We will show that it is \\NP-hard to compute the neighborhood polynomial on general chordal graphs. Furthermore we will introduce a parameter for chordal graphs called anchor width and an algorithm to compute the neighborhood polynomial which runs in polynomial time if the anchor width is polynomially bounded. Finally we will show that we can bound the anchor width for chordal comparability graphs and chordal graphs with bounded leafage. The leafage of a chordal graphs is the minimum number of leaves in the host tree of a subtree representation. In particular, interval graphs have leafage at most 2. This shows that the anchor width of interval graphs is at most quadratic.", "pdf_url": "https://arxiv.org/pdf/2008.08349", "subject": "Combinatorics (math.CO)"},
{"title": "Deep Controllable Backlight Dimming", "author": "Lvyin Duan, Demetris Marnerides, Alan Chalmers, Zhichun Lei, Kurt Debattista", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Dual-panel displays require local dimming algorithms in order to reproduce content with high fidelity and high dynamic range. In this work, a novel deep learning based local dimming method is proposed for rendering HDR images on dual-panel HDR displays. The method uses a Convolutional Neural Network to predict backlight values, using as input the HDR image that is to be displayed. The model is designed and trained via a controllable power parameter that allows a user to trade off between power and quality. The proposed method is evaluated against six other methods on a test set of 105 HDR images, using a variety of quantitative quality metrics. Results demonstrate improved display quality and better power consumption when using the proposed method compared to the best alternatives.", "pdf_url": "https://arxiv.org/pdf/2008.08352", "subject": "Image and Video Processing (eess.IV)"},
{"title": "On the Notion of a Generalized Mapping on Multiset Spaces", "author": "Athar Kharal, Mansoor H. Alshehri, Nasser Bin Turki, Faisal Z. Duraihem", "pub_date": "Submitted on 19 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "This work presents a generalized notion of multiset mapping thus resolving a long standing obstacle in structural study of multiset processing. It has been shown that the mapping defined herein can model a vast array of notions as special cases and also handels diverse situations in multiset rewriting transformations. Specifically, this paper unifies and generalizes the works of Parikh(1966), Hickman(1980), Khomenko(2003) and Nazmul(2013).", "pdf_url": "https://arxiv.org/pdf/2008.08381", "subject": "Logic (math.LO)"},
{"title": "Kernelized Stein Discrepancy Tests of Goodness-of-fit for Time-to-Event Data", "author": "Fernandez Tamara, Rivera Nicolas, Xu Wenkai, Gretton Arthur", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Survival Analysis and Reliability Theory are concerned with the analysis of time-to-event data, in which observations correspond to waiting times until an event of interest such as death from a particular disease or failure of a component in a mechanical system. This type of data is unique due to the presence of censoring, a type of missing data that occurs when we do not observe the actual time of the event of interest but, instead, we have access to an approximation for it given by random interval in which the observation is known to belong. Most traditional methods are not designed to deal with censoring, and thus we need to adapt them to censored time-to-event data. In this paper, we focus on non-parametric goodness-of-fit testing procedures based on combining the Stein's method and kernelized discrepancies. While for uncensored data, there is a natural way of implementing a kernelized Stein discrepancy test, for censored data there are several options, each of them with different advantages and disadvantages. In this paper, we propose a collection of kernelized Stein discrepancy tests for time-to-event data, and we study each of them theoretically and empirically; our experimental results show that our proposed methods perform better than existing tests, including previous tests based on a kernelized maximum mean discrepancy.", "pdf_url": "https://arxiv.org/pdf/2008.08397", "subject": "Machine Learning (stat.ML)"},
{"title": "Improving predictions of Bayesian neural networks via local linearization", "author": "Alexander Immer, Maciej Korzepa, Matthias Bauer", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In this paper we argue that in Bayesian deep learning, the frequently utilized generalized Gauss-Newton (GGN) approximation should be understood as a modification of the underlying probabilistic model and should be considered separately from further approximate inference techniques. Applying the GGN approximation turns a BNN into a locally linearized generalized linear model or, equivalently, a Gaussian process. Because we then use this linearized model for inference, we should also predict using this modified likelihood rather than the original BNN likelihood. This formulation extends previous results to general likelihoods and alleviates underfitting behaviour observed e.g. by Ritter et al. (2018). We demonstrate our approach on several UCI classification datasets as well as CIFAR10.", "pdf_url": "https://arxiv.org/pdf/2008.08400", "subject": "Machine Learning (stat.ML)"},
{"title": "HpRNet : Incorporating Residual Noise Modeling for Violin in a Variational Parametric Synthesizer", "author": "Krishna Subramani, Preeti Rao", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Generative Models for Audio Synthesis have been gaining momentum in the last few years. More recently, parametric representations of the audio signal have been incorporated to facilitate better musical control of the synthesized output. In this work, we investigate a parametric model for violin tones, in particular the generative modeling of the residual bow noise to make for more natural tone quality. To aid in our analysis, we introduce a dataset of Carnatic Violin Recordings where bow noise is an integral part of the playing style of higher pitched notes in specific gestural contexts. We obtain insights about each of the harmonic and residual components of the signal, as well as their interdependence, via observations on the latent space derived in the course of variational encoding of the spectral envelopes of the sustained sounds.", "pdf_url": "https://arxiv.org/pdf/2008.08405", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Augmenting Geometric Graphs with Matchings", "author": "Alexander Pilz, Jonathan Rollin, Lena Schlipf, Andr\u00e9 Schulz", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We study noncrossing geometric graphs and their disjoint compatible geometric matchings. Given a cycle (a polygon) P we want to draw a set of pairwise disjoint straight-line edges with endpoints on the vertices of P such that these new edges neither cross nor contain any edge of the polygon. We prove NP-completeness of deciding whether there is such a perfect matching. For any n-vertex polygon, with n > 3, we show that such a matching with less than n/7 edges is not maximal, that is, it can be extended by another compatible matching edge. We also construct polygons with maximal compatible matchings with n/7 edges, demonstrating the tightness of this bound. Tight bounds on the size of a minimal maximal compatible matching are also obtained for the families of d-regular geometric graphs for each d in {0,1,2}. Finally we consider a related problem. We prove that it is NP-complete to decide whether a noncrossing geometric graph G admits a set of compatible noncrossing edges such that G together with these edges has minimum degree five.", "pdf_url": "https://arxiv.org/pdf/2008.08413", "subject": "Combinatorics (math.CO)"},
{"title": "Improving Blind Spot Denoising for Microscopy", "author": "Anna S. Goncharova, Alf Honigmann, Florian Jug, Alexander Krull", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Many microscopy applications are limited by the total amount of usable light and are consequently challenged by the resulting levels of noise in the acquired images. This problem is often addressed via (supervised) deep learning based denoising. Recently, by making assumptions about the noise statistics, self-supervised methods have emerged. Such methods are trained directly on the images that are to be denoised and do not require additional paired training data. While achieving remarkable results, self-supervised methods can produce high-frequency artifacts and achieve inferior results compared to supervised approaches. Here we present a novel way to improve the quality of self-supervised denoising. Considering that light microscopy images are usually diffraction-limited, we propose to include this knowledge in the denoising process. We assume the clean image to be the result of a convolution with a point spread function (PSF) and explicitly include this operation at the end of our neural network. As a consequence, we are able to eliminate high-frequency artifacts and achieve self-supervised results that are very close to the ones achieved with traditional supervised methods.", "pdf_url": "https://arxiv.org/pdf/2008.08414", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Virus Transmission Risk in Urban Rail Systems: A Microscopic Simulation-based Analysis of Spatio-temporal Characteristics", "author": "Jiali Zhou, Haris N. Koutsopoulos", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Transmission risk of air-borne diseases in public transportation systems is a concern. The paper proposes a modified Wells-Riley model for risk analysis in public transportation systems to capture the passenger flow characteristics, including spatial and temporal patterns in terms of number of boarding, alighting passengers, and number of infectors. The model is utilized to assess overall risk as a function of OD flows, actual operations, and factors such as mask wearing, and ventilation. The model is integrated with a microscopic simulation model of subway operations (SimMETRO). Using actual data from a subway system, a case study explores the impact of different factors on transmission risk, including mask-wearing, ventilation rates, infectiousness levels of disease and carrier rates. In general, mask-wearing and ventilation are effective under various demand levels, infectiousness levels, and carrier rates. Mask-wearing is more effective in mitigating risks. Impacts from operations and service frequency are also evaluated, emphasizing the importance of maintaining reliable, frequent operations in lowering transmission risks. Risk spatial patterns are also explored, highlighting locations of higher risk.", "pdf_url": "https://arxiv.org/pdf/2008.08448", "subject": "Populations and Evolution (q-bio.PE)"},
{"title": "Shallow Water Moment models for bedload transport problems", "author": "Jos\u00e9 Garres-D\u00edaz, Manuel J. Castro D\u00edaz, Julian Koellermeier, Tom\u00e1s Morales de Luna", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this work a simple but accurate shallow model for bedload sediment transport is proposed. The model is based on applying the moment approach to the Shallow Water Exner model, making it possible to recover the vertical structure of the flow. This approach allows us to obtain a better approximation of the fluid velocity close to the bottom, which is the relevant velocity for the sediment transport. A general Shallow Water Exner moment model allowing for polynomial velocity profiles of arbitrary order is obtained. A regularization ensures hyperbolicity and easy computation of the eigenvalues. The system is solved by means of an adapted IFCP scheme proposed here. The improvement of this IFCP type scheme is based on the approximation of the eigenvalue associated to the sediment transport. Numerical tests are presented which deal with large and short time scales. The proposed model allows to obtain the vertical structure of the fluid, which results in a better description on the bedload transport of the sediment layer.", "pdf_url": "https://arxiv.org/pdf/2008.08449", "subject": "Fluid Dynamics (physics.flu-dyn)"},
{"title": "Axioms for Defeat in Democratic Elections", "author": "Wesley H. Holliday, Eric Pacuit", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We propose six axioms concerning when one candidate should defeat another in a democratic election involving two or more candidates. Five of the axioms are widely satisfied by known voting procedures. The sixth axiom is a weakening of Kenneth Arrow's famous condition of the Independence of Irrelevant Alternatives (IIA). We call this weakening Coherent IIA. We prove that the five axioms plus Coherent IIA single out a voting procedure studied in our recent work: Split Cycle. In particular, Split Cycle is the most resolute voting procedure satisfying the six axioms for democratic defeat. In addition, we analyze how Split Cycle escapes Arrow's Impossibility Theorem and related impossibility results.", "pdf_url": "https://arxiv.org/pdf/2008.08451", "subject": "Theoretical Economics (econ.TH)"},
{"title": "On the inverse Potts functional for single-image super-resolution problems", "author": "Pasquale Cascarano, Luca Calatroni, Elena Loli Piccolomini", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We consider a variational model for single-image super-resolution based on the assumption that the image gradient of the target image is sparse. To promote jump sparsity, we use an isotropic and anisotropic $\\ell^{0}$ inverse Potts gradient regularisation term combined with a quadratic data fidelity, similarly as studied in [1] for general problems in signal recovery. For the numerical realisation of the model, we consider a converging ADMM algorithm. Differently from [1], [2], where approximate graph cuts and dynamic programming techniques were used for solving the non-convex substeps in the case of multivariate data, the proposed splitting allows to compute explicitly their solution by means of hard-thresholding and standard conjugate-gradient solvers. We compare quantitatively our results with several convex, nonconvex and deep-learning-based approaches for several synthetic and real-world data. Our numerical results show that combining super-resolution with gradient sparsity is particularly helpful for object detection and labelling tasks (such as QR scanning and land-cover classification), for which our results are shown to improve the classification precision of standard clustering algorithms and state-of-the art deep architectures [3].", "pdf_url": "https://arxiv.org/pdf/2008.08470", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Data-Driven Solvers for Strongly Nonlinear Material Response", "author": "Armin Galetzka, Dimitrios Loukrezis, Herbert De Gersem", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This work presents a data-driven magnetostatic finite-element solver that is specifically well-suited to cope with strongly nonlinear material responses. The data-driven computing framework is essentially a multiobjective optimization procedure matching the material operation points as closely as possible to given material data while obeying Maxwell's equations. Here, the framework is extended with heterogeneous (local) weighting factors - one per finite element - equilibrating the goal function locally according to the material behavior. This modification allows the data-driven solver to capture sharp gradients in the constitutive law of strongly nonlinear materials, which constitute problematic cases for standard data-driven solvers with a homogeneous (global) weighting factor, hindering their efficiency and accuracy. The local weighting factors are embedded in the distance-minimizing data-driven algorithm used for noiseless data, likewise for the maximum entropy data-driven algorithm used for noisy data. Numerical experiments based on a quadrupole magnet model with a soft magnetic material show that the proposed modification results in major improvements in terms of solution accuracy and solver efficiency. For the case of noiseless data, local weighting factors improve the convergence of the data-driven solver by orders of magnitude. When noisy data are considered, the convergence rate of the data-driven solver is doubled.", "pdf_url": "https://arxiv.org/pdf/2008.08482", "subject": "Computational Physics (physics.comp-ph)"},
{"title": "Correcting Data Imbalance for Semi-Supervised Covid-19 Detection Using X-ray Chest Images", "author": "Saul Calderon-Ramirez, Shengxiang-Yang, Armaghan Moemeni, David Elizondo, Simon Colreavy-Donnelly, Luis Fernando Chavarria-Estrada, Miguel A. Molina-Cabello", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The Corona Virus (COVID-19) is an internationalpandemic that has quickly propagated throughout the world. The application of deep learning for image classification of chest X-ray images of Covid-19 patients, could become a novel pre-diagnostic detection methodology. However, deep learning architectures require large labelled datasets. This is often a limitation when the subject of research is relatively new as in the case of the virus outbreak, where dealing with small labelled datasets is a challenge. Moreover, in the context of a new highly infectious disease, the datasets are also highly imbalanced,with few observations from positive cases of the new disease. In this work we evaluate the performance of the semi-supervised deep learning architecture known as MixMatch using a very limited number of labelled observations and highly imbalanced labelled dataset. We propose a simple approach for correcting data imbalance, re-weight each observationin the loss function, giving a higher weight to the observationscorresponding to the under-represented class. For unlabelled observations, we propose the usage of the pseudo and augmentedlabels calculated by MixMatch to choose the appropriate weight. The MixMatch method combined with the proposed pseudo-label based balance correction improved classification accuracy by up to 10%, with respect to the non balanced MixMatch algorithm, with statistical significance. We tested our proposed approach with several available datasets using 10, 15 and 20 labelledobservations. Additionally, a new dataset is included among thetested datasets, composed of chest X-ray images of Costa Rican adult patients", "pdf_url": "https://arxiv.org/pdf/2008.08496", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Fractional hypergraph isomorphism and fractional invariants", "author": "Flavia Bonomo-Braberman, Dora Tilli", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Fractional graph isomorphism is the linear relaxation of an integer programming formulation of graph isomorphism. It preserves some invariants of graphs, like degree sequences and equitable partitions, but it does not preserve others like connectivity, clique and independence numbers, chromatic number, vertex and edge cover numbers, matching number, domination and total domination numbers. In this work, we extend the concept of fractional graph isomorphism to hypergraphs, and give an alternative characterization, analogous to one of those that are known for graphs. With this new concept we prove that the fractional packing, covering, matching and transversal numbers on hypergraphs are invariant under fractional hypergraph isomorphism. As a consequence, fractional matching, vertex and edge cover, independence, domination and total domination numbers are invariant under fractional graph isomorphism. This is not the case of fractional chromatic, clique, and clique cover numbers. In this way, most of the classical fractional parameters are classified with respect to their invariance under fractional graph isomorphism.", "pdf_url": "https://arxiv.org/pdf/2008.08499", "subject": "Combinatorics (math.CO)"},
{"title": "Building Halo Merger Trees from the Q Continuum Simulation", "author": "Esteban Rangel, Nicholas Frontiere, Salman Habib, Katrin Heitmann, Wei-keng Liao, Ankit Agrawal, Alok Choudhary", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Cosmological N-body simulations rank among the most computationally intensive efforts today. A key challenge is the analysis of structure, substructure, and the merger history for many billions of compact particle clusters, called halos. Effectively representing the merging history of halos is essential for many galaxy formation models used to generate synthetic sky catalogs, an important application of modern cosmological simulations. Generating realistic mock catalogs requires computing the halo formation history from simulations with large volumes and billions of halos over many time steps, taking hundreds of terabytes of analysis data. We present fast parallel algorithms for producing halo merger trees and tracking halo substructure from a single-level, density-based clustering algorithm. Merger trees are created from analyzing the halo-particle membership function in adjacent snapshots, and substructure is identified by tracking the \"cores\" of merging halos -- sets of particles near the halo center. Core tracking is performed after creating merger trees and uses the relationships found during tree construction to associate substructures with hosts. The algorithms are implemented with MPI and evaluated on a Cray XK7 supercomputer using up to 16,384 processes on data from HACC, a modern cosmological simulation framework. We present results for creating merger trees from 101 analysis snapshots taken from the Q Continuum, a large volume, high mass resolution, cosmological simulation evolving half a trillion particles.", "pdf_url": "https://arxiv.org/pdf/2008.08519", "subject": "Cosmology and Nongalactic Astrophysics (astro-ph.CO)"},
{"title": "\"Name that manufacturer\". Relating image acquisition bias with task complexity when training deep learning models: experiments on head CT", "author": "Giorgio Pietro Biondetti, Romane Gauriau, Christopher P. Bridge, Charles Lu, Katherine P. Andriole", "pub_date": "Submitted on 19 Aug 2020", "abstract": "As interest in applying machine learning techniques for medical images continues to grow at a rapid pace, models are starting to be developed and deployed for clinical applications. In the clinical AI model development lifecycle (described by Lu et al. [1]), a crucial phase for machine learning scientists and clinicians is the proper design and collection of the data cohort. The ability to recognize various forms of biases and distribution shifts in the dataset is critical at this step. While it remains difficult to account for all potential sources of bias, techniques can be developed to identify specific types of bias in order to mitigate their impact. In this work we analyze how the distribution of scanner manufacturers in a dataset can contribute to the overall bias of deep learning models. We evaluate convolutional neural networks (CNN) for both classification and segmentation tasks, specifically two state-of-the-art models: ResNet [2] for classification and U-Net [3] for segmentation. We demonstrate that CNNs can learn to distinguish the imaging scanner manufacturer and that this bias can substantially impact model performance for both classification and segmentation tasks. By creating an original synthesis dataset of brain data mimicking the presence of more or less subtle lesions we also show that this bias is related to the difficulty of the task. Recognition of such bias is critical to develop robust, generalizable models that will be crucial for clinical applications in real-world data distributions.", "pdf_url": "https://arxiv.org/pdf/2008.08525", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Blur-Attention: A boosting mechanism for non-uniform blurred image restoration", "author": "Xiaoguang Li, Feifan Yang, Kin Man Lam, Li Zhuo, Jiafeng Li", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Dynamic scene deblurring is a challenging problem in computer vision. It is difficult to accurately estimate the spatially varying blur kernel by traditional methods. Data-driven-based methods usually employ kernel-free end-to-end mapping schemes, which are apt to overlook the kernel estimation. To address this issue, we propose a blur-attention module to dynamically capture the spatially varying features of non-uniform blurred images. The module consists of a DenseBlock unit and a spatial attention unit with multi-pooling feature fusion, which can effectively extract complex spatially varying blur features. We design a multi-level residual connection structure to connect multiple blur-attention modules to form a blur-attention network. By introducing the blur-attention network into a conditional generation adversarial framework, we propose an end-to-end blind motion deblurring method, namely Blur-Attention-GAN (BAG), for a single image. Our method can adaptively select the weights of the extracted features according to the spatially varying blur features, and dynamically restore the images. Experimental results show that the deblurring capability of our method achieved outstanding objective performance in terms of PSNR, SSIM, and subjective visual quality. Furthermore, by visualizing the features extracted by the blur-attention module, comprehensive discussions are provided on its effectiveness.", "pdf_url": "https://arxiv.org/pdf/2008.08526", "subject": "Image and Video Processing (eess.IV)"},
{"title": "A Unified Evaluation of Two-Candidate Ballot-Polling Election Auditing Methods", "author": "Zhuoqun Huang, Ronald L. Rivest, Philip B. Stark, Vanessa Teague, Damjan Vukcevic", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Counting votes is complex and error-prone. Several statistical methods have been developed to assess election accuracy by manually inspecting randomly selected physical ballots. Two 'principled' methods are risk-limiting audits (RLAs) and Bayesian audits (BAs). RLAs use frequentist statistical inference while BAs are based on Bayesian inference. Until recently, the two have been thought of as fundamentally different. We present results that unify and shed light upon 'ballot-polling' RLAs and BAs (which only require the ability to sample uniformly at random from all cast ballot cards) for two-candidate plurality contests, the are building blocks for auditing more complex social choice functions, including some preferential voting systems. We highlight the connections between the methods and explore their performance. First, building on a previous demonstration of the mathematical equivalence of classical and Bayesian approaches, we show that BAs, suitably calibrated, are risk-limiting. Second, we compare the efficiency of the methods across a wide range of contest sizes and margins, focusing on the distribution of sample sizes required to attain a given risk limit. Third, we outline several ways to improve performance and show how the mathematical equivalence explains the improvements.", "pdf_url": "https://arxiv.org/pdf/2008.08536", "subject": "Applications (stat.AP)"},
{"title": "Slide-free MUSE Microscopy to H&E Histology Modality Conversion via Unpaired Image-to-Image Translation GAN Models", "author": "Tanishq Abraham, Andrew Shaw, Daniel O'Connor, Austin Todd, Richard Levenson", "pub_date": "Submitted on 19 Aug 2020", "abstract": "MUSE is a novel slide-free imaging technique for histological examination of tissues that can serve as an alternative to traditional histology. In order to bridge the gap between MUSE and traditional histology, we aim to convert MUSE images to resemble authentic hematoxylin- and eosin-stained (H&E) images. We evaluated four models: a non-machine-learning-based color-mapping unmixing-based tool, CycleGAN, DualGAN, and GANILLA. CycleGAN and GANILLA provided visually compelling results that appropriately transferred H&E style and preserved MUSE content. Based on training an automated critic on real and generated H&E images, we determined that CycleGAN demonstrated the best performance. We have also found that MUSE color inversion may be a necessary step for accurate modality conversion to H&E. We believe that our MUSE-to-H&E model can help improve adoption of novel slide-free methods by bridging a perceptual gap between MUSE imaging and traditional histology.", "pdf_url": "https://arxiv.org/pdf/2008.08579", "subject": "Image and Video Processing (eess.IV)"},
{"title": "On the Numerical Solution of Nonlinear Eigenvalue Problems for the Monge-Amp\u00e8re Operator", "author": "Roland Glowinski, Shingyu Leung, Hao Liu, Jianliang Qian", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this article, we report the results we obtained when investigating the numerical solution of some nonlinear eigenvalue problems for the Monge-Amp\u00e8re operator $v\\rightarrow \\det \\mathbf{D}^2 v$. The methodology we employ relies on the following ingredients: (i) A divergence formulation of the eigenvalue problems under consideration. (ii) The time discretization by operator-splitting of an initial value problem (a kind of gradient flow) associated with each eigenvalue problem. (iii) A finite element approximation relying on spaces of continuous piecewise affine functions. To validate the above methodology, we applied it to the solution of problems with known exact solutions: The results we obtained suggest convergence to the exact solution when the space discretization step $h\\rightarrow 0$. We considered also test problems with no known exact solutions.", "pdf_url": "https://arxiv.org/pdf/2008.08103", "subject": "Numerical Analysis (math.NA)"},
{"title": "Splitting methods for solution decomposition in nonstationary problems", "author": "Yalchin Efendiev, Petr N. Vabishchevich", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In approximating solutions of nonstationary problems, various approaches are used to compute the solution at a new time level from a number of simpler (sub-)problems. Among these approaches are splitting methods. Standard splitting schemes are based on one or another additive splitting of the operator into \"simpler\" operators that are more convenient/easier for the computer implementation and use inhomogeneous (explicitly-implicit) time approximations. In this paper, a new class of splitting schemes is proposed that is characterized by an additive representation of the solution instead of the operator corresponding to the problem (called problem operator). A specific feature of the proposed splitting is that the resulting coupled equations for individual solution components consist of the time derivatives of the solution components. The proposed approaches are motivated by various applications, including multiscale methods, domain decomposition, and so on, where spatially local problems are solved and used to compute the solution. Unconditionally stable splitting schemes are constructed for a first-order evolution equation, which is considered in a finite-dimensional Hilbert space. In our splitting algorithms, we consider the decomposition of both the main operator of the system and the operator at the time derivative. Our goal is to provide a general framework that combines temporal splitting algorithms and spatial decomposition and its analysis. Applications of the framework will be studied separately.", "pdf_url": "https://arxiv.org/pdf/2008.08111", "subject": "Numerical Analysis (math.NA)"},
{"title": "A Theory Building Study of Enterprise Architecture Practices and Benefits", "author": "Ralph Foorthuis, Marlies van Steenbergen, Sjaak Brinkkemper, Wiel Bruls", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Academics and practitioners have made various claims regarding the benefits that Enterprise Architecture (EA) delivers for both individual projects and the organization as a whole. At the same time, there is a lack of explanatory theory regarding how EA delivers these benefits. Moreover, EA practices and benefits have not been extensively investigated by empirical research, with especially quantitative studies on the topic being few and far between. This paper therefore presents the statistical findings of a theory-building survey study (n=293). The resulting PLS model is a synthesis of current implicit and fragmented theory, and shows how EA practices and intermediate benefits jointly work to help the organization reap benefits for both the organization and its projects. The model shows that EA and EA practices do not deliver benefits directly, but operate through intermediate results, most notably compliance with EA and architectural insight. Furthermore, the research identifies the EA practices that have a major impact on these results, the most important being compliance assessments, management propagation of EA, and different types of knowledge exchange. The results also demonstrate that projects play an important role in obtaining benefits from EA, but that they generally benefit less than the organization as a whole.", "pdf_url": "https://arxiv.org/pdf/2008.08112", "subject": "Computers and Society (cs.CY)"},
{"title": "Commonsense Knowledge in Wikidata", "author": "Filip Ilievski, Pedro Szekely, Daniel Schwabe", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Wikidata and Wikipedia have been proven useful for reason-ing in natural language applications, like question answering or entitylinking. Yet, no existing work has studied the potential of Wikidata for commonsense reasoning. This paper investigates whether Wikidata con-tains commonsense knowledge which is complementary to existing commonsense sources. Starting from a definition of common sense, we devise three guiding principles, and apply them to generate a commonsense subgraph of Wikidata (Wikidata-CS). Within our approach, we map the relations of Wikidata to ConceptNet, which we also leverage to integrate Wikidata-CS into an existing consolidated commonsense graph. Our experiments reveal that: 1) albeit Wikidata-CS represents a small portion of Wikidata, it is an indicator that Wikidata contains relevant commonsense knowledge, which can be mapped to 15 ConceptNet relations; 2) the overlap between Wikidata-CS and other commonsense sources is low, motivating the value of knowledge integration; 3) Wikidata-CS has been evolving over time at a slightly slower rate compared to the overall Wikidata, indicating a possible lack of focus on commonsense knowledge. Based on these findings, we propose three recommended actions to improve the coverage and quality of Wikidata-CS further.", "pdf_url": "https://arxiv.org/pdf/2008.08114", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Category Level Object Pose Estimation via Neural Analysis-by-Synthesis", "author": "Xu Chen, Zijian Dong, Jie Song, Andreas Geiger, Otmar Hilliges", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Many object pose estimation algorithms rely on the analysis-by-synthesis framework which requires explicit representations of individual object instances. In this paper we combine a gradient-based fitting procedure with a parametric neural image synthesis module that is capable of implicitly representing the appearance, shape and pose of entire object categories, thus rendering the need for explicit CAD models per object instance unnecessary. The image synthesis network is designed to efficiently span the pose configuration space so that model capacity can be used to capture the shape and local appearance (i.e., texture) variations jointly. At inference time the synthesized images are compared to the target via an appearance based loss and the error signal is backpropagated through the network to the input parameters. Keeping the network parameters fixed, this allows for iterative optimization of the object pose, shape and appearance in a joint manner and we experimentally show that the method can recover orientation of objects with high accuracy from 2D images alone. When provided with depth measurements, to overcome scale ambiguities, the method can accurately recover the full 6DOF pose successfully.", "pdf_url": "https://arxiv.org/pdf/2008.08145", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Robust Handwriting Recognition with Limited and Noisy Data", "author": "Hai Pham, Amrith Setlur, Saket Dingliwal, Tzu-Hsiang Lin, Barnabas Poczos, Kang Huang, Zhuo Li, Jae Lim, Collin McCormack, Tam Vu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Despite the advent of deep learning in computer vision, the general handwriting recognition problem is far from solved. Most existing approaches focus on handwriting datasets that have clearly written text and carefully segmented labels. In this paper, we instead focus on learning handwritten characters from maintenance logs, a constrained setting where data is very limited and noisy. We break the problem into two consecutive stages of word segmentation and word recognition respectively and utilize data augmentation techniques to train both stages. Extensive comparisons with popular baselines for scene-text detection and word recognition show that our system achieves a lower error rate and is more suited to handle noisy and difficult documents", "pdf_url": "https://arxiv.org/pdf/2008.08148", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Hyperbolicity-Preserving and Well-Balanced Stochastic Galerkin Method for Shallow Water Equations", "author": "Dihan Dai, Yekaterina Epshteyn, Akil Narayan", "pub_date": "Submitted on 18 Aug 2020", "abstract": "A stochastic Galerkin formulation for a stochastic system of balanced or conservation laws may fail to preserve hyperbolicity of the original system. In this work, we develop hyperbolicity-preserving stochastic Galerkin formulation for the one-dimensional shallow water equations by carefully selecting the polynomial chaos expansion of the nonlinear $q^2/h$ term in terms of the polynomial chaos expansions of the conserved variables. In addition, in an arbitrary finite stochastic dimension, we establish a sufficient condition to guarantee hyperbolicity of the stochastic Galerkin system through a finite number of conditions at stochastic quadrature points. Further, we develop a well-balanced central-upwind scheme for the stochastic shallow water model and derive the associated hyperbolicty-preserving CFL-type condition. The performance of the developed method is illustrated on a number of challenging numerical tests.", "pdf_url": "https://arxiv.org/pdf/2008.08154", "subject": "Numerical Analysis (math.NA)"},
{"title": "Heteroscedastic Uncertainty for Robust Generative Latent Dynamics", "author": "Oliver Limoyo, Bryan Chan, Filip Mari\u0107, Brandon Wagstaff, Rupam Mahmood, Jonathan Kelly", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Learning or identifying dynamics from a sequence of high-dimensional observations is a difficult challenge in many domains, including reinforcement learning and control. The problem has recently been studied from a generative perspective through latent dynamics: high-dimensional observations are embedded into a lower-dimensional space in which the dynamics can be learned. Despite some successes, latent dynamics models have not yet been applied to real-world robotic systems where learned representations must be robust to a variety of perceptual confounds and noise sources not seen during training. In this paper, we present a method to jointly learn a latent state representation and the associated dynamics that is amenable for long-term planning and closed-loop control under perceptually difficult conditions. As our main contribution, we describe how our representation is able to capture a notion of heteroscedastic or input-specific uncertainty at test time by detecting novel or out-of-distribution (OOD) inputs. We present results from prediction and control experiments on two image-based tasks: a simulated pendulum balancing task and a real-world robotic manipulator reaching task. We demonstrate that our model produces significantly more accurate predictions and exhibits improved control performance, compared to a model that assumes homoscedastic uncertainty only, in the presence of varying degrees of input degradation.", "pdf_url": "https://arxiv.org/pdf/2008.08157", "subject": "Robotics (cs.RO)"},
{"title": "Intelligent Reflecting Surface Assisted MISO Downlink: Channel Estimation and Asymptotic Analysis", "author": "Bayan Al-Nahhas, Qurrat-Ul-Ain Nadeem, Anas Chaaban", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This work makes the preliminary contribution of studying the asymptotic performance of a multi-user intelligent reflecting surface (IRS) assisted-multiple-input single-output (MISO) downlink system under imperfect CSI. We first extend the existing least squares (LS) ON/OFF channel estimation protocol to a multi-user system, where we derive minimum mean squared error (MMSE) estimates of all IRS-assisted channels over multiple sub-phases. We also consider a low-complexity direct estimation (DE) scheme, where the BS obtains the MMSE estimate of the overall channel in a single sub-phase. Under both protocols, the BS implements maximum ratio transmission (MRT) precoding while the IRS design is studied in the large system limit, where we derive deterministic equivalents of the signal-to-interference-plus-noise ratio (SINR) and the sum-rate. The derived asymptotic expressions, which depend only on channel statistics, reveal that under Rayleigh fading IRS-to-users channels, the IRS phase-shift values do not play a significant role in improving the sum-rate but the IRS still provides an array gain. Simulation results confirm the accuracy of the derived deterministic equivalents and show that under Rayleigh fading, the IRS gains are more significant in noise-limited scenarios. We also conclude that the DE of the overall channel yields better performance when considering large systems.", "pdf_url": "https://arxiv.org/pdf/2008.08160", "subject": "Information Theory (cs.IT)"},
{"title": "Fingerprinting Search Keywords over HTTPS at Scale", "author": "Junhua Yan, Hasan Faik Alan, Jasleen Kaur", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The possibility of fingerprinting the search keywords issued by a user on popular web search engines is a significant threat to user privacy. This threat has received surprisingly little attention in the network traffic analysis literature. In this work, we consider the problem of keyword fingerprinting of HTTPS traffic -- we study the impact of several factors, including client platform diversity, choice of search engine, feature sets as well as classification frameworks. We conduct both closed-world and open-world evaluations using nearly 4 million search queries collected over a period of three months. Our analysis reveals several insights into the threat of keyword fingerprinting in modern HTTPS traffic.", "pdf_url": "https://arxiv.org/pdf/2008.08161", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Characterizing Stage-Aware Writing Assistance in Collaborative Document Authoring", "author": "Bahareh Sarrafzadeh, Sujay Kumar Jauhar, Michael Gamon, Edward Lank, Ryen White", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Writing is a complex non-linear process that begins with a mental model of intent, and progresses through an outline of ideas, to words on paper (and their subsequent refinement). Despite past research in understanding writing, Web-scale consumer and enterprise collaborative digital writing environments are yet to greatly benefit from intelligent systems that understand the stages of document evolution, providing opportune assistance based on authors' situated actions and context. In this paper, we present three studies that explore temporal stages of document authoring. We first survey information workers at a large technology company about their writing habits and preferences, concluding that writers do in fact conceptually progress through several distinct phases while authoring documents. We also explore, qualitatively, how writing stages are linked to document lifespan. We supplement these qualitative findings with an analysis of the longitudinal user interaction logs of a popular digital writing platform over several million documents. Finally, as a first step towards facilitating an intelligent digital writing assistant, we conduct a preliminary investigation into the utility of user interaction log data for predicting the temporal stage of a document. Our results support the benefit of tools tailored to writing stages, identify primary tasks associated with these stages, and show that it is possible to predict stages from anonymous interaction logs. Together, these results argue for the benefit and feasibility of more tailored digital writing assistance.", "pdf_url": "https://arxiv.org/pdf/2008.08165", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Clustering and Analysis of Vulnerabilities Present in Different Robot Types", "author": "Chinwe Ekenna, Bharvee Acharya", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Due to the new advancements in automation using Artificial Intelligence, Robotics and Internet of Things it has become crucial to pay attention to possible vulnerabilities in order to avoid cyber attack and hijacking that can occur which can be catastrophic. There have been many consequences of disasters due to vulnerabilities in Robotics, these vulnerabilities need to be analyzed to target the severe ones before they cause cataclysm. This paper aims to highlight the areas and severity of each type of vulnerability by analyzing issues categorized under the type of vulnerability. This we achieve by careful analysis of the data and application of information retrieval techniques like Term Frequency - Inverse Document Frequency, dimension reduction techniques like Principal Component Analysis and Clustering using Machine Learning techniques like K-means. By performing this analysis, the severity of robotic issues in different domains and the severity of the issue based on type of issue is detected.", "pdf_url": "https://arxiv.org/pdf/2008.08166", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Learning to Generate Diverse Dance Motions with Transformer", "author": "Jiaman Li, Yihang Yin, Hang Chu, Yi Zhou, Tingwu Wang, Sanja Fidler, Hao Li", "pub_date": "Submitted on 18 Aug 2020", "abstract": "With the ongoing pandemic, virtual concerts and live events using digitized performances of musicians are getting traction on massive multiplayer online worlds. However, well choreographed dance movements are extremely complex to animate and would involve an expensive and tedious production process. In addition to the use of complex motion capture systems, it typically requires a collaborative effort between animators, dancers, and choreographers. We introduce a complete system for dance motion synthesis, which can generate complex and highly diverse dance sequences given an input music sequence. As motion capture data is limited for the range of dance motions and styles, we introduce a massive dance motion data set that is created from YouTube videos. We also present a novel two-stream motion transformer generative model, which can generate motion sequences with high flexibility. We also introduce new evaluation metrics for the quality of synthesized dance motions, and demonstrate that our system can outperform state-of-the-art methods. Our system provides high-quality animations suitable for large crowds for virtual concerts and can also be used as reference for professional animation pipelines. Most importantly, we show that vast online videos can be effective in training dance motion models.", "pdf_url": "https://arxiv.org/pdf/2008.08171", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Error-correcting Codes for Noisy Duplication Channels", "author": "Yuanyuan Tang, Farzad Farnoud", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Because of its high data density and longevity, DNA is emerging as a promising candidate for satisfying increasing data storage needs. Compared to conventional storage media, however, data stored in DNA is subject to a wider range of errors resulting from various processes involved in the data storage pipeline. In this paper, we consider correcting duplication errors for both exact and noisy tandem duplications of a given length k. An exact duplication inserts a copy of a substring of length k of the sequence immediately after that substring, e.g., ACGT to ACGACGT, where k = 3, while a noisy duplication inserts a copy suffering from substitution noise, e.g., ACGT to ACGATGT. Specifically, we design codes that can correct any number of exact duplication and one noisy duplication errors, where in the noisy duplication case the copy is at Hamming distance 1 from the original. Our constructions rely upon recovering the duplication root of the stored codeword. We characterize the ways in which duplication errors manifest in the root of affected sequences and design efficient codes for correcting these error patterns. We show that the proposed construction is asymptotically optimal, in the sense that it has the same asymptotic rate as optimal codes correcting exact duplications only.", "pdf_url": "https://arxiv.org/pdf/2008.08174", "subject": "Information Theory (cs.IT)"},
{"title": "Scalable Combinatorial Bayesian Optimization with Tractable Statistical models", "author": "Aryan Deshwal, Syrine Belakaria, Janardhan Rao Doppa", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We study the problem of optimizing expensive blackbox functions over combinatorial spaces (e.g., sets, sequences, trees, and graphs). BOCS (Baptista and Poloczek, 2018) is a state-of-the-art Bayesian optimization method for tractable statistical models, which performs semi-definite programming based acquisition function optimization (AFO) to select the next structure for evaluation. Unfortunately, BOCS scales poorly for large number of binary and/or categorical variables. Based on recent advances in submodular relaxation (Ito and Fujimaki, 2016) for solving Binary Quadratic Programs, we study an approach referred as Parametrized Submodular Relaxation (PSR) towards the goal of improving the scalability and accuracy of solving AFO problems for BOCS model. PSR approach relies on two key ideas. First, reformulation of AFO problem as submodular relaxation with some unknown parameters, which can be solved efficiently using minimum graph cut algorithms. Second, construction of an optimization problem to estimate the unknown parameters with close approximation to the true objective. Experiments on diverse benchmark problems show significant improvements with PSR for BOCS model. The source code is available at .", "pdf_url": "https://arxiv.org/pdf/2008.08177", "subject": "Machine Learning (cs.LG)"},
{"title": "Discovering Multi-Hardware Mobile Models via Architecture Search", "author": "Grace Chu, Okan Arikan, Gabriel Bender, Weijun Wang, Achille Brighton, Pieter-Jan Kindermans, Hanxiao Liu, Berkin Akin, Suyog Gupta, Andrew Howard", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Developing efficient models for mobile phones or other on-device deployments has been a popular topic in both industry and academia. In such scenarios, it is often convenient to deploy the same model on a diverse set of hardware devices owned by different end users to minimize the costs of development, deployment and maintenance. Despite the importance, designing a single neural network that can perform well on multiple devices is difficult as each device has its own specialty and restrictions: A model optimized for one device may not perform well on another. While most existing work proposes different models optimized for each single hardware, this paper is the first which explores the problem of finding a single model that performs well on multiple hardware. Specifically, we leverage architecture search to help us find the best model, where given a set of diverse hardware to optimize for, we first introduce a multi-hardware search space that is compatible with all examined hardware. Then, to measure the performance of a neural network over multiple hardware, we propose metrics that can characterize the overall latency performance in an average case and worst case scenario. With the multi-hardware search space and new metrics applied to Pixel4 CPU, GPU, DSP and EdgeTPU, we found models that perform on par or better than state-of-the-art (SOTA) models on each of our target accelerators and generalize well on many un-targeted hardware. Comparing with single-hardware searches, multi-hardware search gives a better trade-off between computation cost and model performance.", "pdf_url": "https://arxiv.org/pdf/2008.08178", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Semantic Product Search for Matching Structured Product Catalogs in E-Commerce", "author": "Jason Ingyu Choi, Surya Kallumadi, Bhaskar Mitra, Eugene Agichtein, Faizan Javed", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Retrieving all semantically relevant products from the product catalog is an important problem in E-commerce. Compared to web documents, product catalogs are more structured and sparse due to multi-instance fields that encode heterogeneous aspects of products (e.g. brand name and product dimensions). In this paper, we propose a new semantic product search algorithm that learns to represent and aggregate multi-instance fields into a document representation using state of the art transformers as encoders. Our experiments investigate two aspects of the proposed approach: (1) effectiveness of field representations and structured matching; (2) effectiveness of adding lexical features to semantic search. After training our models using user click logs from a well-known E-commerce platform, we show that our results provide useful insights for improving product search. Lastly, we present a detailed error analysis to show which types of queries benefited the most by fielded representations and structured matching.", "pdf_url": "https://arxiv.org/pdf/2008.08180", "subject": "Information Retrieval (cs.IR)"},
{"title": "A Jumping Mining Attack and Solution", "author": "Muchuang Hu, Jiahui Chen, Wensheng Gan, Chien-Ming Chen", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Mining is the important part of the blockchain used the proof of work (PoW) on its consensus, looking for the matching block through testing a number of hash calculations. In order to attract more hash computing power, the miner who finds the proper block can obtain some rewards. Actually, these hash calculations ensure that the data of the blockchain is not easily tampered. Thus, the incentive mechanism for mining affects the security of the blockchain directly. This paper presents an approach to attack against the difficulty adjustment algorithm (abbreviated as DAA) used in blockchain mining, which has a direct impact on miners' earnings. In this method, the attack miner jumps between different blockchains to get more benefits than the honest miner who keep mining on only one blockchain. We build a probabilistic model to simulate the time to obtain the next block at different hash computing power called hashrate. Based on this model, we analyze the DAAs of the major cryptocurrencies, including Bitcoin, Bitcoin Cash, Zcash, and Bitcoin Gold. We further verify the effectiveness of this attack called jumping mining through simulation experiments, and also get the characters for the attack in the public block data of Bitcoin Gold. Finally, we give an improved DAA scheme against this attack. Extensive experiments are provided to support the efficiency of our designed scheme.", "pdf_url": "https://arxiv.org/pdf/2008.08184", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Prevalence of Neural Collapse during the terminal phase of deep learning training", "author": "Vardan Papyan, X.Y. Han, David L. Donoho", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Modern practice for training classification deepnets involves a Terminal Phase of Training (TPT), which begins at the epoch where training error first vanishes; During TPT, the training error stays effectively zero while training loss is pushed towards zero. Direct measurements of TPT, for three prototypical deepnet architectures and across seven canonical classification datasets, expose a pervasive inductive bias we call Neural Collapse, involving four deeply interconnected phenomena: (NC1) Cross-example within-class variability of last-layer training activations collapses to zero, as the individual activations themselves collapse to their class-means; (NC2) The class-means collapse to the vertices of a Simplex Equiangular Tight Frame (ETF); (NC3) Up to rescaling, the last-layer classifiers collapse to the class-means, or in other words to the Simplex ETF, i.e. to a self-dual configuration; (NC4) For a given activation, the classifier's decision collapses to simply choosing whichever class has the closest train class-mean, i.e. the Nearest Class Center (NCC) decision rule. The symmetric and very simple geometry induced by the TPT confers important benefits, including better generalization performance, better robustness, and better interpretability.", "pdf_url": "https://arxiv.org/pdf/2008.08186", "subject": "Machine Learning (cs.LG)"},
{"title": "Learning Tuple Compatibility for Conditional OutfitRecommendation", "author": "Xuewen Yang, Dongliang Xie, Xin Wang, Jiangbo Yuan, Wanying Ding, Pengyun Yan", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Outfit recommendation requires the answers of some challenging outfit compatibility questions such as 'Which pair of boots and school bag go well with my jeans and sweater?'. It is more complicated than conventional similarity search, and needs to consider not only visual aesthetics but also the intrinsic fine-grained and multi-category nature of fashion items. Some existing approaches solve the problem through sequential models or learning pair-wise distances between items. However, most of them only consider coarse category information in defining fashion compatibility while neglecting the fine-grained category information often desired in practical applications. To better define the fashion compatibility and more flexibly meet different needs, we propose a novel problem of learning compatibility among multiple tuples (each consisting of an item and category pair), and recommending fashion items following the category choices from customers. Our contributions include: 1) Designing a Mixed Category Attention Net (MCAN) which integrates both fine-grained and coarse category information into recommendation and learns the compatibility among fashion tuples. MCAN can explicitly and effectively generate diverse and controllable recommendations based on need. 2) Contributing a new dataset IQON, which follows eastern culture and can be used to test the generalization of recommendation systems. Our extensive experiments on a reference dataset Polyvore and our dataset IQON demonstrate that our method significantly outperforms state-of-the-art recommendation methods.", "pdf_url": "https://arxiv.org/pdf/2008.08189", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Discovering High Utility-Occupancy Patterns from Uncertain Data", "author": "Chien-Ming Chen, Lili Chen, Wensheng Gan, Lina Qiu, Weiping Ding", "pub_date": "Submitted on 18 Aug 2020", "abstract": "It is widely known that there is a lot of useful information hidden in big data, leading to a new saying that \"data is money.\" Thus, it is prevalent for individuals to mine crucial information for utilization in many real-world applications. In the past, studies have considered frequency. Unfortunately, doing so neglects other aspects, such as utility, interest, or risk. Thus, it is sensible to discover high-utility itemsets (HUIs) in transaction databases while utilizing not only the quantity but also the predefined utility. To find patterns that can represent the supporting transaction, a recent study was conducted to mine high utility-occupancy patterns whose contribution to the utility of the entire transaction is greater than a certain value. Moreover, in realistic applications, patterns may not exist in transactions but be connected to an existence probability. In this paper, a novel algorithm, called High-Utility-Occupancy Pattern Mining in Uncertain databases (UHUOPM), is proposed. The patterns found by the algorithm are called Potential High Utility Occupancy Patterns (PHUOPs). This algorithm divides user preferences into three factors, including support, probability, and utility occupancy. To reduce memory cost and time consumption and to prune the search space in the algorithm as mentioned above, probability-utility-occupancy list (PUO-list) and probability-frequency-utility table (PFU-table) are used, which assist in providing the downward closure property. Furthermore, an original tree structure, called support count tree (SC-tree), is constructed as the search space of the algorithm. Finally, substantial experiments were conducted to evaluate the performance of proposed UHUOPM algorithm on both real-life and synthetic datasets, particularly in terms of effectiveness and efficiency.", "pdf_url": "https://arxiv.org/pdf/2008.08190", "subject": "Databases (cs.DB)"},
{"title": "EXCLUVIS: A MATLAB GUI Software for Comparative Study of Clustering and Visualization of Gene Expression Data", "author": "Sudip Poddar, Anirban Mukhopadhyay", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Clustering is a popular data mining technique that aims to partition an input space into multiple homogeneous regions. There exist several clustering algorithms in the literature. The performance of a clustering algorithm depends on its input parameters which can substantially affect the behavior of the algorithm. Cluster validity indices determine the partitioning that best fits the underlying data. In bioinformatics, microarray gene expression technology has made it possible to measure the gene expression levels of thousands of genes simultaneously. Many genomic studies, which aim to analyze the functions of some genes, highly rely on some clustering technique for grouping similarly expressed genes in one cluster or partitioning tissue samples based on similar expression values of genes. In this work, an application package called EXCLUVIS (gene EXpression data CLUstering and VISualization) has been developed using MATLAB Graphical User Interface (GUI) environment for analyzing the performances of different clustering algorithms on gene expression datasets. In this application package, the user needs to select a number of parameters such as internal validity indices, external validity indices and number of clusters from the active windows for evaluating the performance of the clustering algorithms. EXCLUVIS compares the performances of K-means, fuzzy C-means, hierarchical clustering and multiobjective evolutionary clustering algorithms. Heatmap and cluster profile plots are used for visualizing the results. EXCLUVIS allows the users to easily find the goodness of clustering solutions as well as provides visual representations of the clustering outcomes.", "pdf_url": "https://arxiv.org/pdf/2008.08193", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "PC-U Net: Learning to Jointly Reconstruct and Segment the Cardiac Walls in 3D from CT Data", "author": "Meng Ye, Qiaoying Huang, Dong Yang, Pengxiang Wu, Jingru Yi, Leon Axel, Dimitris Metaxas", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The 3D volumetric shape of the heart's left ventricle (LV) myocardium (MYO) wall provides important information for diagnosis of cardiac disease and invasive procedure navigation. Many cardiac image segmentation methods have relied on detection of region-of-interest as a pre-requisite for shape segmentation and modeling. With segmentation results, a 3D surface mesh and a corresponding point cloud of the segmented cardiac volume can be reconstructed for further analyses. Although state-of-the-art methods (e.g., U-Net) have achieved decent performance on cardiac image segmentation in terms of accuracy, these segmentation results can still suffer from imaging artifacts and noise, which will lead to inaccurate shape modeling results. In this paper, we propose a PC-U net that jointly reconstructs the point cloud of the LV MYO wall directly from volumes of 2D CT slices and generates its segmentation masks from the predicted 3D point cloud. Extensive experimental results show that by incorporating a shape prior from the point cloud, the segmentation masks are more accurate than the state-of-the-art U-Net results in terms of Dice's coefficient and Hausdorff distance.The proposed joint learning framework of our PC-U net is beneficial for automatic cardiac image analysis tasks because it can obtain simultaneously the 3D shape and segmentation of the LV MYO walls.", "pdf_url": "https://arxiv.org/pdf/2008.08194", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Data Driven Optimization of Inter-Frequency Mobility Parameters for Emerging Multi-band Networks", "author": "Muhammad Umar Bin Farooq, Marvin Manalastas, Waseem Raza, Aneeqa Ijaz, Syed Muhammad Asad Zaidi, Adnan Abu-Dayya, Ali Imran", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Densification and multi-band operation in 5G and beyond pose an unprecedented challenge for mobility management, particularly for inter-frequency handovers. The challenge is aggravated by the fact that the impact of key inter-frequency mobility parameters, namely A5 time to trigger (TTT), A5 threshold1 and A5 threshold2 on the system's performance is not fully understood. These parameters are fixed to a gold standard value or adjusted through hit and trial. This paper presents a first study to analyze and optimize A5 parameters for jointly maximizing two key performance indicators (KPIs): Reference signal received power (RSRP) and handover success rate (HOSR). As analytical modeling cannot capture the system-level complexity, a data driven approach is used. By developing XGBoost based model, that outperforms other models in terms of accuracy, we first analyze the concurrent impact of the three parameters on the two KPIs. The results reveal three key insights: 1) there exist optimal parameter values for each KPI; 2) these optimal values do not necessarily belong to the current gold standard; 3) the optimal parameter values for the two KPIs do not overlap. We then leverage the Sobol variance-based sensitivity analysis to draw some insights which can be used to avoid the parametric conflict while jointly maximizing both KPIs. We formulate the joint RSRP and HOSR optimization problem, show that it is non-convex and solve it using the genetic algorithm (GA). Comparison with the brute force-based results show that the proposed data driven GA-aided solution is 48x faster with negligible loss in optimality.", "pdf_url": "https://arxiv.org/pdf/2008.08200", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Mediating Community-AI Interaction through Situated Explanation: The Case of AI-Led Moderation", "author": "Yubo Kou, Xinning Gui", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Artificial intelligence (AI) has become prevalent in our everyday technologies and impacts both individuals and communities. The explainable AI (XAI) scholarship has explored the philosophical nature of explanation and technical explanations, which are usually driven by experts in lab settings and can be challenging for laypersons to understand. In addition, existing XAI research tends to focus on the individual level. Little is known about how people understand and explain AI-led decisions in the community context. Drawing from XAI and activity theory, a foundational HCI theory, we theorize how explanation is situated in a community's shared values, norms, knowledge, and practices, and how situated explanation mediates community-AI interaction. We then present a case study of AI-led moderation, where community members collectively develop explanations of AI-led decisions, most of which are automated punishments. Lastly, we discuss the implications of this framework at the intersection of CSCW, HCI, and XAI.", "pdf_url": "https://arxiv.org/pdf/2008.08202", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "An Algebraic-Topological Approach to Processing Cross-Blockchain Transactions", "author": "Dongfang Zhao", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The state-of-the-art techniques for processing cross-blockchain transactions take a simple centralized approach: when the assets on blockchain $X$, say $X$-coins, are exchanged with the assets on blockchain $Y$---the $Y$-coins, those $X$-coins need to be exchanged to a \"middle\" medium (such as Bitcoin) that is then exchanged to $Y$-coins. If there are more than two parties involved in a single global transaction, the global transaction is split into multiple local two-party transactions, each of which follows the above central-exchange protocol. Unfortunately, the atomicity of the global transaction is violated with the central-exchange approach: those local two-party transactions, once committed, cannot be rolled back if the global transaction decides to abort. In a more general sense, the graph-based model of (two-party) transactions can hardly be extended to an arbitrary number of parties in a cross-blockchain transaction. %from why to how In this paper, we introduce a higher-level abstraction of cross-blockchain transactions. We adopt the \\textit{abstract simplicial complex}, an extensively-studied mathematical object in algebraic topology, to represent an arbitrary number of parties involved in the blockchain transactions. Essentially, each party in the global transaction is modeled as a vertex and the global transaction among $n+1$ ($n \\in \\mathbb{Z}$, $n > 0$) parties compose a $n$-dimensional simplex. While this higher-level abstraction seems plausibly trivial, we will show how this simple extension leads to a new line of modeling methods and protocols for better processing cross-blockchain transactions.", "pdf_url": "https://arxiv.org/pdf/2008.08208", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "DeepHandMesh: A Weakly-supervised Deep Encoder-Decoder Framework for High-fidelity Hand Mesh Modeling", "author": "Gyeongsik Moon, Takaaki Shiratori, Kyoung Mu Lee", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Human hands play a central role in interacting with other people and objects. For realistic replication of such hand motions, high-fidelity hand meshes have to be reconstructed. In this study, we firstly propose DeepHandMesh, a weakly-supervised deep encoder-decoder framework for high-fidelity hand mesh modeling. We design our system to be trained in an end-to-end and weakly-supervised manner; therefore, it does not require groundtruth meshes. Instead, it relies on weaker supervisions such as 3D joint coordinates and multi-view depth maps, which are easier to get than groundtruth meshes and do not dependent on the mesh topology. Although the proposed DeepHandMesh is trained in a weakly-supervised way, it provides significantly more realistic hand mesh than previous fully-supervised hand models. Our newly introduced penetration avoidance loss further improves results by replicating physical interaction between hand parts. Finally, we demonstrate that our system can also be applied successfully to the 3D hand mesh estimation from general images. Our hand model, dataset, and codes are publicly available at .", "pdf_url": "https://arxiv.org/pdf/2008.08213", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Stereo Plane SLAM Based on Intersecting Lines", "author": "Xiaoyu Zhang, Wei Wang, Xianyu Qi, Ziwei Liao", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Plane feature is a kind of stable landmark to reduce drift error in SLAM system. It is easy and fast to extract planes from dense point cloud, which is commonly acquired from RGB-D camera or lidar. But for stereo camera, it is hard to compute dense point cloud accurately and efficiently. In this paper, we propose a novel method to compute plane parameters from intersecting lines extracted for stereo image. The plane features commonly exist on the surface of man-made objects and structure, which have regular shape and straight edge lines. In 3D space, two intersecting lines can determine such a plane. Thus we extract line segments from both stereo left and right image. By stereo matching, we compute the endpoints and line directions in 3D space, and then the planes can be computed. Adding such computed plane features in stereo SLAM system reduces the drift error and refines the performance. We test our proposed system on public datasets and demonstrate its robust and accurate estimation results, compared with state-of-the-art SLAM systems.", "pdf_url": "https://arxiv.org/pdf/2008.08218", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Open Source Iris Recognition Hardware and Software with Presentation Attack Detection", "author": "Zhaoyuan Fang, Adam Czajka", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper proposes the first known to us open source hardware and software iris recognition system with presentation attack detection (PAD), which can be easily assembled for about 75 USD using Raspberry Pi board and a few peripherals. The primary goal of this work is to offer a low-cost baseline for spoof-resistant iris recognition, which may (a) stimulate research in iris PAD and allow for easy prototyping of secure iris recognition systems, (b) offer a low-cost secure iris recognition alternative to more sophisticated systems, and (c) serve as an educational platform. We propose a lightweight image complexity-guided convolutional network for fast and accurate iris segmentation, domain-specific human-inspired Binarized Statistical Image Features (BSIF) to build an iris template, and to combine 2D (iris texture) and 3D (photometric stereo-based) features for PAD. The proposed iris recognition runs in about 3.2 seconds and the proposed PAD runs in about 4.5 seconds on Raspberry Pi 3B+. The hardware specifications and all source codes of the entire pipeline are made available along with this paper.", "pdf_url": "https://arxiv.org/pdf/2008.08220", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Machine Learning for Reliability Engineering and Safety Applications: Review of Current Status and Future Opportunities", "author": "Zhaoyi Xu, Joseph Homer Saleh", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Machine learning (ML) pervades an increasing number of academic disciplines and industries. Its impact is profound, and several fields have been fundamentally altered by it, autonomy and computer vision for example; reliability engineering and safety will undoubtedly follow suit. There is already a large but fragmented literature on ML for reliability and safety applications, and it can be overwhelming to navigate and integrate into a coherent whole. In this work, we facilitate this task by providing a synthesis of, and a roadmap to this ever-expanding analytical landscape and highlighting its major landmarks and pathways. We first provide an overview of the different ML categories and sub-categories or tasks, and we note several of the corresponding models and algorithms. We then look back and review the use of ML in reliability and safety applications. We examine several publications in each category/sub-category, and we include a short discussion on the use of Deep Learning to highlight its growing popularity and distinctive advantages. Finally, we look ahead and outline several promising future opportunities for leveraging ML in service of advancing reliability and safety considerations. Overall, we argue that ML is capable of providing novel insights and opportunities to solve important challenges in reliability and safety applications. It is also capable of teasing out more accurate insights from accident datasets than with traditional analysis tools, and this in turn can lead to better informed decision-making and more effective accident prevention.", "pdf_url": "https://arxiv.org/pdf/2008.08221", "subject": "Machine Learning (cs.LG)"},
{"title": "Structure-preserving function approximation via convex optimization", "author": "Vidhi Zala, Robert M. Kirby, Akil Narayan", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Approximations of functions with finite data often do not respect certain \"structural\" properties of the functions. For example, if a given function is non-negative, a polynomial approximation of the function is not necessarily also non-negative. We propose a formalism and algorithms for preserving certain types of such structure in function approximation. In particular, we consider structure corresponding to a convex constraint on the approximant (for which positivity is one example). The approximation problem then converts into a convex feasibility problem, but the feasible set is relatively complicated so that standard convex feasibility algorithms cannot be directly applied. We propose and discuss different algorithms for solving this problem. One of the features of our machinery is flexibility: relatively complicated constraints, such as simultaneously enforcing positivity, monotonicity, and convexity, are fairly straightforward to implement. We demonstrate the success of our algorithm on several problems in univariate function approximation.", "pdf_url": "https://arxiv.org/pdf/2008.08223", "subject": "Numerical Analysis (math.NA)"},
{"title": "Victim or Perpetrator? Analysis of Violent Characters Portrayals from Movie Scripts", "author": "Victor R Martinez, Krishna Somendapalli, Karan Singla, Anil Ramanakrishna, Yalda T. Uhls, Shrikanth Narayanan", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Violent content in the media can influence viewers' perception of the society. For example, frequent depictions of certain demographics as victims or perpetrators of violence can shape stereotyped attitudes. We propose that computational methods can aid in the large-scale analysis of violence in movies. The method we develop characterizes aspects of violent content solely from the language used in the scripts. Thus, our method is applicable to a movie in the earlier stages of content creation even before it is produced. This is complementary to previous works which rely on audio or video post production. In this work, we identify stereotypes in character roles (i.e., victim, perpetrator and narrator) based on the demographics of the actor casted for that role. Our results highlight two significant differences in the frequency of portrayals as well as the demographics of the interaction between victims and perpetrators : (1) female characters appear more often as victims, and (2) perpetrators are more likely to be White if the victim is Black or Latino. To date, we are the first to show that language used in movie scripts is a strong indicator of violent content, and that there are systematic portrayals of certain demographics as victims and perpetrators in a large dataset. This offers novel computational tools to assist in creating awareness of representations in storytelling", "pdf_url": "https://arxiv.org/pdf/2008.08225", "subject": "Computation and Language (cs.CL)"},
{"title": "Kinematic Resolutions of Redundant Robot Manipulators using Integration-Enhanced RNNs", "author": "Lingdong Kong", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Recently, a time-varying quadratic programming (QP) framework that describes the tracking operations of redundant robot manipulators is introduced to handle the kinematic resolutions of many robot control tasks. Based on the generalization of such a time-varying QP framework, two schemes, i.e., the Repetitive Motion Scheme and the Hybrid Torque Scheme, are proposed. However, measurement noises are unavoidable when a redundant robot manipulator is executing a tracking task. To solve this problem, a novel integration-enhanced recurrent neural network (IE-RNN) is proposed in this paper. Associating with the aforementioned two schemes, the tracking task can be accurately completed by IE-RNN. Both theoretical analyses and simulations results prove that the residual errors of IE-RNN can converge to zero under different kinds of measurement noises. Moreover, practical experiments are elaborately made to verify the excellent convergence and strong robustness properties of the proposed IE-RNN.", "pdf_url": "https://arxiv.org/pdf/2008.08228", "subject": "Systems and Control (eess.SY)"},
{"title": "On the condition number of the total least squares problem with linear equality constraint", "author": "Qiaohua Liu, Zhigang Jia", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper is devoted to the condition number of the total least squares problem with linear equality constraint (TLSE). With novel techniques, closed formulae for the normwise, mixed and componentwise condition numbers of the TLSE problem are derived. Compact expressions and upper bounds for these condition numbers are also given to avoid the costly Kronecker product-based operations. Explicit condition number expressions and perturbation bound for the TLS problem can be recovered from our estimates. For random TLSE problems, numerical experiments illustrate the sharpness of the estimates based on normwise condition numbers, while for sparse and badly scaled matrices, the estimates based on mixed and componentwise condition numbers are much tighter.", "pdf_url": "https://arxiv.org/pdf/2008.08233", "subject": "Numerical Analysis (math.NA)"},
{"title": "Assessing the Effectiveness of Using Live Interactions and Feedback to Increase Engagement in Online Learning", "author": "Beth Porter, Burcin Bozkaya", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In-person instruction for professional development or other types of workplace training provides a social environment and immediate feedback mechanisms that typically ensure all participants are successful. Online, self-paced instruction lacks these mechanisms and relies on the motivation and persistence of each individual learner, often resulting in low completion rates. In this study, we studied the effect of introducing enabling tools and live feedback into an online learning experience on learner performance in the course, persistence in the course, and election to complete supplemental readings and assignments. The findings from our experiments show positive correlations with strong statistical significance between live interactions and all performance measures studied.", "pdf_url": "https://arxiv.org/pdf/2008.08241", "subject": "Computers and Society (cs.CY)"},
{"title": "Enabling Remote Whole-Body Control with 5G Edge Computing", "author": "Huaijiang Zhu, Manali Sharma, Kai Pfeiffer, Marco Mezzavilla, Jia Shen, Sundeep Rangan, Ludovic Righetti", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Real-world applications require light-weight, energy-efficient, fully autonomous robots. Yet, increasing autonomy is oftentimes synonymous with escalating computational requirements. It might thus be desirable to offload intensive computation--not only sensing and planning, but also low-level whole-body control--to remote servers in order to reduce on-board computational needs. Fifth Generation (5G) wireless cellular technology, with its low latency and high bandwidth capabilities, has the potential to unlock cloud-based high performance control of complex robots. However, state-of-the-art control algorithms for legged robots can only tolerate very low control delays, which even ultra-low latency 5G edge computing can sometimes fail to achieve. In this work, we investigate the problem of cloud-based whole-body control of legged robots over a 5G link. We propose a novel approach that consists of a standard optimization-based controller on the network edge and a local linear, approximately optimal controller that significantly reduces on-board computational needs while increasing robustness to delay and possible loss of communication. Simulation experiments on humanoid balancing and walking tasks that includes a realistic 5G communication model demonstrate significant improvement of the reliability of robot locomotion under jitter and delays likely to experienced in 5G wireless links.", "pdf_url": "https://arxiv.org/pdf/2008.08243", "subject": "Robotics (cs.RO)"},
{"title": "Formalizing and Verifying Decentralized Systems with Extended Concurrent Separation Logic", "author": "Yepeng Ding, Hiroyuki Sato", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Decentralized techniques are becoming crucial and ubiquitous with the rapid advancement of distributed ledger technologies such as the blockchain. Numerous decentralized systems have been developed to address security and privacy issues with great dependability and reliability via these techniques. Meanwhile, formalization and verification of the decentralized systems is the key to ensuring correctness of the design and security properties of the implementation. In this paper, we propose a novel method of formalizing and verifying decentralized systems with a kind of extended concurrent separation logic. Our logic extends the standard concurrent separation logic with new features including communication encapsulation, environment perception, and node-level reasoning, which enhances modularity and expressiveness. Besides, we develop our logic with unitarity and compatibility to facilitate implementation. Furthermore, we demonstrate the effectiveness and versatility of our method by applying our logic to formalize and verify critical techniques in decentralized systems including the consensus mechanism and the smart contract.", "pdf_url": "https://arxiv.org/pdf/2008.08245", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Leveraging Historical Interaction Data for Improving Conversational Recommender System", "author": "Kun Zhou, Wayne Xin Zhao, Hui Wang, Sirui Wang, Fuzheng Zhang, Zhongyuan Wang, Ji-Rong Wen", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Recently, conversational recommender system (CRS) has become an emerging and practical research topic. Most of the existing CRS methods focus on learning effective preference representations for users from conversation data alone. While, we take a new perspective to leverage historical interaction data for improving CRS. For this purpose, we propose a novel pre-training approach to integrating both item-based preference sequence (from historical interaction data) and attribute-based preference sequence (from conversation data) via pre-training methods. We carefully design two pre-training tasks to enhance information fusion between item- and attribute-based preference. To improve the learning performance, we further develop an effective negative sample generator which can produce high-quality negative samples. Experiment results on two real-world datasets have demonstrated the effectiveness of our approach for improving CRS.", "pdf_url": "https://arxiv.org/pdf/2008.08247", "subject": "Information Retrieval (cs.IR)"},
{"title": "The Strong Convergence and Stability of Explicit Approximations for Nonlinear Stochastic Delay Differential Equations", "author": "Guoting Song, Junhao Hu, Shuaibin Gao, Xiaoyue Li", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper focuses on explicit approximations for nonlinear stochastic delay differential equations (SDDEs). Under the weakly local Lipschitz and some suitable conditions, a generic truncated Euler-Maruyama (TEM) scheme for SDDEs is proposed, which numerical solutions are bounded and converge to the exact solutions in qth moment for q>0. Furthermore, the 1/2 order convergent rate is yielded. Under the Khasminskii-type condition, a more precise TEM scheme is given, which numerical solutions are exponential stable in mean square and P-1. Finally, several numerical experiments are carried out to illustrate our results.", "pdf_url": "https://arxiv.org/pdf/2008.08249", "subject": "Numerical Analysis (math.NA)"},
{"title": "Face Anti-Spoofing Via Disentangled Representation Learning", "author": "Ke-Yue Zhang, Taiping Yao, Jian Zhang, Ying Tai, Shouhong Ding, Jilin Li, Feiyue Huang, Haichuan Song, Lizhuang Ma", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Face anti-spoofing is crucial to security of face recognition systems. Previous approaches focus on developing discriminative models based on the features extracted from images, which may be still entangled between spoof patterns and real persons. In this paper, motivated by the disentangled representation learning, we propose a novel perspective of face anti-spoofing that disentangles the liveness features and content features from images, and the liveness features is further used for classification. We also put forward a Convolutional Neural Network (CNN) architecture with the process of disentanglement and combination of low-level and high-level supervision to improve the generalization capabilities. We evaluate our method on public benchmark datasets and extensive experimental results demonstrate the effectiveness of our method against the state-of-the-art competitors. Finally, we further visualize some results to help understand the effect and advantage of disentanglement.", "pdf_url": "https://arxiv.org/pdf/2008.08250", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Threshy: Supporting Safe Usage of Intelligent Web Services", "author": "Alex Cummaudo, Scott Barnett, Rajesh Vasa, John Grundy", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Increased popularity of `intelligent' web services provides end-users with machine-learnt functionality at little effort to developers. However, these services require a decision threshold to be set which is dependent on problem-specific data. Developers lack a systematic approach for evaluating intelligent services and existing evaluation tools are predominantly targeted at data scientists for pre-development evaluation. This paper presents a workflow and supporting tool, Threshy, to help software developers select a decision threshold suited to their problem domain. Unlike existing tools, Threshy is designed to operate in multiple workflows including pre-development, pre-release, and support. Threshy is designed for tuning the confidence scores returned by intelligent web services and does not deal with hyper-parameter optimisation used in ML models. Additionally, it considers the financial impacts of false positives. Threshold configuration files exported by Threshy can be integrated into client applications and monitoring infrastructure. Demo: .", "pdf_url": "https://arxiv.org/pdf/2008.08252", "subject": "Software Engineering (cs.SE)"},
{"title": "A Color Elastica Model for Vector-Valued Image Regularization", "author": "Hao Liu, Xue-Cheng Tai, Ron Kimmel, Roland Glowinski", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Models related to the Euler's Elastica energy have proven to be very useful for many applications, including image processing and high energy physics. Extending the Elastica models to color images and multi-channel data is challenging, as numerical solvers for these geometric models are difficult to find. In the past, the Polyakov action from high energy physics has been successfully applied for color image processing. Like the single channel Euler's elastica model and the total variation (TV) models, measures that require high order derivatives could help when considering image formation models that minimize elastic properties, in one way or another. Here, we introduce an addition to the Polyakov action for color images that minimizes the color manifold curvature, that is computed by applying of the Laplace-Beltrami operator to the color image channels. When applied to gray scale images, while selecting appropriate scaling between space and color, the proposed model reduces to minimizing the Euler's Elastica operating on the image level sets. Finding a minimizer for the proposed nonlinear geometric model is the challenge we address in this paper. Specifically, we present an operator-splitting method to minimize the proposed functional. The nonlinearity is decoupled by introducing three vector-valued and matrix-valued variables. The problem is then converted into solving for the steady state of an associated initial-value problem. The initial-value problem is time-split into three fractional steps, such that each sub-problem has a closed form solution, or can be solved by fast algorithms. The efficiency, and robustness of the proposed method are demonstrated by systematic numerical experiments.", "pdf_url": "https://arxiv.org/pdf/2008.08255", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment Retrieval in Videos", "author": "Zhu Zhang, Zhijie Lin, Zhou Zhao, Jieming Zhu, Xiuqiang He", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Video moment retrieval aims to localize the target moment in an video according to the given sentence. The weak-supervised setting only provides the video-level sentence annotations during training. Most existing weak-supervised methods apply a MIL-based framework to develop inter-sample confrontment, but ignore the intra-sample confrontment between moments with semantically similar contents. Thus, these methods fail to distinguish the target moment from plausible negative moments. In this paper, we propose a novel Regularized Two-Branch Proposal Network to simultaneously consider the inter-sample and intra-sample confrontments. Concretely, we first devise a language-aware filter to generate an enhanced video stream and a suppressed video stream. We then design the sharable two-branch proposal module to generate positive proposals from the enhanced stream and plausible negative proposals from the suppressed one for sufficient confrontment. Further, we apply the proposal regularization to stabilize the training process and improve model performance. The extensive experiments show the effectiveness of our method. Our code is released at here.", "pdf_url": "https://arxiv.org/pdf/2008.08257", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Learning Connectivity of Neural Networks from a Topological Perspective", "author": "Kun Yuan, Quanquan Li, Jing Shao, Junjie Yan", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Seeking effective neural networks is a critical and practical field in deep learning. Besides designing the depth, type of convolution, normalization, and nonlinearities, the topological connectivity of neural networks is also important. Previous principles of rule-based modular design simplify the difficulty of building an effective architecture, but constrain the possible topologies in limited spaces. In this paper, we attempt to optimize the connectivity in neural networks. We propose a topological perspective to represent a network into a complete graph for analysis, where nodes carry out aggregation and transformation of features, and edges determine the flow of information. By assigning learnable parameters to the edges which reflect the magnitude of connections, the learning process can be performed in a differentiable manner. We further attach auxiliary sparsity constraint to the distribution of connectedness, which promotes the learned topology focus on critical connections. This learning process is compatible with existing networks and owns adaptability to larger search spaces and different tasks. Quantitative results of experiments reflect the learned connectivity is superior to traditional rule-based ones, such as random, residual, and complete. In addition, it obtains significant improvements in image classification and object detection without introducing excessive computation burden.", "pdf_url": "https://arxiv.org/pdf/2008.08261", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Quarantines as a Targeted Immunization Strategy", "author": "Jessica Hoffmann, Matt Jordan, Constantine Caramanis", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In the context of the recent COVID-19 outbreak, quarantine has been used to \"flatten the curve\" and slow the spread of the this paper, we show that this is not the only benefit of quarantine for the mitigation of an SIR epidemic spreading on a graph. Indeed, we theoretically prove that nodes of high-degree are disproportionately in the Removed state after a first wave of infection, which has very positive consequences. In particular, powerlaw graphs do not retain their structure after a few waves of infection, which implies second and third waves may be of much smaller amplitude than the first wave. We propose an opening and closing strategy aiming at immunizing the graph while infecting the minimum number of individuals, while guaranteeing the population is now robust to future infections. We experimentally verify our results on simulated networks.", "pdf_url": "https://arxiv.org/pdf/2008.08262", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Problem of robotic precision cutting of the geometrically complex shape from an irregular honeycomb grid", "author": "M.V. Kubrikov, M.V. Saramud, M.V Karaseva", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The article considers solving the problem of precision cutting of honeycomb blocks. The urgency of using arbitrary shapes application cutting from honey-comb blocks made of modern composite materials is substantiated. The problem is to obtain a cut of the given shape from honeycomb blocks. The complexity of this problem is in the irregular pattern of honeycomb blocks and the presence of double edges, which forces an operator to scan each block before cutting. It is necessary to take into account such restrictions as the place and angle of the cut and size of the knife, its angle when cutting and the geometry of cells. For this problem solving, a robotic complex has been developed. It includes a device for scanning the geometry of a honeycomb block, software for cutting automation and a cutting device itself. The software takes into account all restrictions on the choice of the location and angle of the operating mechanism. It helps to obtain the highest quality cut and a cut shape with the best strength characteristics. An actu-ating device has been developed and implemented for both scanning and cutting of honeycomb blocks directly. The necessary tests were carried out on real alu-minum honeycomb blocks. Some technical solutions are used in the cutting de-vice to improve the quality of cutting honeycomb blocks. The tests have shown the effectiveness of the proposed complex. Robotic planar cutting made it possi-ble to obtain precise cutting with a high degree of repeatability.", "pdf_url": "https://arxiv.org/pdf/2008.08265", "subject": "Robotics (cs.RO)"},
{"title": "Compiling ONNX Neural Network Models Using MLIR", "author": "Tung D. Le, Gheorghe-Teodor Bercea, Tong Chen, Alexandre E. Eichenberger, Haruki Imai, Tian Jin, Kiyokuni Kawachiya, Yasushi Negishi, Kevin O'Brien", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Deep neural network models are becoming popular and have used in various tasks such as computer vision, speech recognition, and natural language processing. It is often the case that the training phase of a model is executed in one environment, while the inference phase is executed in another environment. This is because the optimization characteristics for each phase significantly differ. Therefore, it is critical to efficiently compile a trained model for inferencing on different environments. To represent neural network models, users often use Open Neural Network Exchange (ONNX) which is an open standard format for machine learning interoperability. We are developing a compiler for rewriting a model in ONNX into a standalone binary that is executable on different target hardwares such as x86 machines, IBM Power Systems, and IBM System Z. The compiler was written using Multi-level Intermediate Representation (MLIR), a modern compiler infrastructure. In particular, we introduce two internal representations: ONNX IR for representing ONNX operators, and Kernel IR for efficiently lowering ONNX operators into LLVM bitcode. In this paper, we will discuss the overall structure of our compiler and give some practical examples of converting ONNX operators and models. We also cover several issues related to endianness. Our framework is publicly available as an open source project under the ONNX project.", "pdf_url": "https://arxiv.org/pdf/2008.08272", "subject": "Programming Languages (cs.PL)"},
{"title": "MEANTIME: Mixture of Attention Mechanisms with Multi-temporal Embeddings for Sequential Recommendation", "author": "Sung Min Cho, Eunhyeok Park, Sungjoo Yoo", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Recently, self-attention based models have achieved state-of-the-art performance in sequential recommendation task. Following the custom from language processing, most of these models rely on a simple positional embedding to exploit the sequential nature of the user's history. However, there are some limitations regarding the current approaches. First, sequential recommendation is different from language processing in that timestamp information is available. Previous models have not made good use of it to extract additional contextual information. Second, using a simple embedding scheme can lead to information bottleneck since the same embedding has to represent all possible contextual biases. Third, since previous models use the same positional embedding in each attention head, they can wastefully learn overlapping patterns. To address these limitations, we propose MEANTIME (MixturE of AtteNTIon mechanisms with Multi-temporal Embeddings) which employs multiple types of temporal embeddings designed to capture various patterns from the user's behavior sequence, and an attention structure that fully leverages such diversity. Experiments on real-world data show that our proposed method outperforms current state-of-the-art sequential recommendation methods, and we provide an extensive ablation study to analyze how the model gains from the diverse positional information.", "pdf_url": "https://arxiv.org/pdf/2008.08273", "subject": "Machine Learning (cs.LG)"},
{"title": "CCA: Exploring the Possibility of Contextual Camouflage Attack on Object Detection", "author": "Shengnan Hu, Yang Zhang, Sumit Laha, Ankit Sharma, Hassan Foroosh", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Deep neural network based object detection hasbecome the cornerstone of many real-world applications. Alongwith this success comes concerns about its vulnerability tomalicious attacks. To gain more insight into this issue, we proposea contextual camouflage attack (CCA for short) algorithm to in-fluence the performance of object detectors. In this paper, we usean evolutionary search strategy and adversarial machine learningin interactions with a photo-realistic simulated environment tofind camouflage patterns that are effective over a huge varietyof object locations, camera poses, and lighting conditions. Theproposed camouflages are validated effective to most of the state-of-the-art object detectors.", "pdf_url": "https://arxiv.org/pdf/2008.08281", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Multiscale Snapshots: Visual Analysis of Temporal Summaries in Dynamic Graphs", "author": "Eren Cakmak, Udo Schlegel, Dominik J\u00e4ckle, Daniel Keim, Tobias Schreck", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The overview-driven visual analysis of large-scale dynamic graphs poses a major challenge. We propose Multiscale Snapshots, a visual analytics approach to analyze temporal summaries of dynamic graphs at multiple temporal scales. First, we recursively generate temporal summaries to abstract overlapping sequences of graphs into compact snapshots. Second, we apply graph embeddings to the snapshots to learn low-dimensional representations of each sequence of graphs to speed up specific analytical tasks (e.g., similarity search). Third, we visualize the evolving data from a coarse to fine-granular snapshots to semi-automatically analyze temporal states, trends, and outliers. The approach enables to discover similar temporal summaries (e.g., recurring states), reduces the temporal data to speed up automatic analysis, and to explore both structural and temporal properties of a dynamic graph. We demonstrate the usefulness of our approach by a quantitative evaluation and the application to a real-world dataset.", "pdf_url": "https://arxiv.org/pdf/2008.08282", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Channel-wise Hessian Aware trace-Weighted Quantization of Neural Networks", "author": "Xu Qian, Victor Li, Crews Darren", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Second-order information has proven to be very effective in determining the redundancy of neural network weights and activations. Recent paper proposes to use Hessian traces of weights and activations for mixed-precision quantization and achieves state-of-the-art results. However, prior works only focus on selecting bits for each layer while the redundancy of different channels within a layer also differ a lot. This is mainly because the complexity of determining bits for each channel is too high for original methods. Here, we introduce Channel-wise Hessian Aware trace-Weighted Quantization (CW-HAWQ). CW-HAWQ uses Hessian trace to determine the relative sensitivity order of different channels of activations and weights. What's more, CW-HAWQ proposes to use deep Reinforcement learning (DRL) Deep Deterministic Policy Gradient (DDPG)-based agent to find the optimal ratios of different quantization bits and assign bits to channels according to the Hessian trace order. The number of states in CW-HAWQ is much smaller compared with traditional AutoML based mix-precision methods since we only need to search ratios for the quantization bits. Compare CW-HAWQ with state-of-the-art shows that we can achieve better results for multiple networks.", "pdf_url": "https://arxiv.org/pdf/2008.08284", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Scalable Blocking for Very Large Databases", "author": "Andrew Borthwick, Stephen Ash, Bin Pang, Shehzad Qureshi, Timothy Jones", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In the field of database deduplication, the goal is to find approximately matching records within a database. Blocking is a typical stage in this process that involves cheaply finding candidate pairs of records that are potential matches for further processing. We present here Hashed Dynamic Blocking, a new approach to blocking designed to address datasets larger than those studied in most prior work. Hashed Dynamic Blocking (HDB) extends Dynamic Blocking, which leverages the insight that rare matching values and rare intersections of values are predictive of a matching relationship. We also present a novel use of Locality Sensitive Hashing (LSH) to build blocking key values for huge databases with a convenient configuration to control the trade-off between precision and recall. HDB achieves massive scale by minimizing data movement, using compact block representation, and greedily pruning ineffective candidate blocks using a Count-min Sketch approximate counting data structure. We benchmark the algorithm by focusing on real-world datasets in excess of one million rows, demonstrating that the algorithm displays linear time complexity scaling in this range. Furthermore, we execute HDB on a 530 million row industrial dataset, detecting 68 billion candidate pairs in less than three hours at a cost of $307 on a major cloud service.", "pdf_url": "https://arxiv.org/pdf/2008.08285", "subject": "Databases (cs.DB)"},
{"title": "Noncoherent OOK Symbol Detection with Supervised-Learning Approach for BCC", "author": "Jihoon Cha, Junil Choi, David J. Love", "pub_date": "Submitted on 19 Aug 2020", "abstract": "There has been a continuing demand for improving the accuracy and ease of use of medical devices used on or around the human body. Communication is critical to medical applications, and wireless body area networks (WBANs) have the potential to revolutionize diagnosis. Despite its importance, WBAN technology is still in its infancy and requires much research. We consider body channel communication (BCC), which uses the whole body as well as the skin as a medium for communication. BCC is sensitive to the body's natural circulation and movement, which requires a noncoherent model for wireless communication. To accurately handle practical applications for electronic devices working on or inside a human body, we configure a realistic system model for BCC with on-off keying (OOK) modulation. We propose novel detection techniques for OOK symbols and improve the performance by exploiting distributed reception and supervised-learning approaches. Numerical results show that the proposed techniques are valid for noncoherent OOK transmissions for BCC.", "pdf_url": "https://arxiv.org/pdf/2008.08286", "subject": "Information Theory (cs.IT)"},
{"title": "Parameterized Algorithms for Queue Layouts", "author": "Sujoy Bhore, Robert Ganian, Fabrizio Montecchiani, Martin N\u00f6llenburg", "pub_date": "Submitted on 19 Aug 2020", "abstract": "An $h$-queue layout of a graph $G$ consists of a linear order of its vertices and a partition of its edges into $h$ queues, such that no two independent edges of the same queue nest. The minimum $h$ such that $G$ admits an $h$-queue layout is the queue number of $G$. We present two fixed-parameter tractable algorithms that exploit structural properties of graphs to compute optimal queue layouts. As our first result, we show that deciding whether a graph $G$ has queue number $1$ and computing a corresponding layout is fixed-parameter tractable when parameterized by the treedepth of $G$. Our second result then uses a more restrictive parameter, the vertex cover number, to solve the problem for arbitrary $h$.", "pdf_url": "https://arxiv.org/pdf/2008.08288", "subject": "Computational Geometry (cs.CG)"},
{"title": "Restructuring, Pruning, and Adjustment of Deep Models for Parallel Distributed Inference", "author": "Afshin Abdi, Saeed Rashidi, Faramarz Fekri, Tushar Krishna", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Using multiple nodes and parallel computing algorithms has become a principal tool to improve training and execution times of deep neural networks as well as effective collective intelligence in sensor networks. In this paper, we consider the parallel implementation of an already-trained deep model on multiple processing nodes (a.k.a. workers) where the deep model is divided into several parallel sub-models, each of which is executed by a worker. Since latency due to synchronization and data transfer among workers negatively impacts the performance of the parallel implementation, it is desirable to have minimum interdependency among parallel sub-models. To achieve this goal, we propose to rearrange the neurons in the neural network and partition them (without changing the general topology of the neural network), such that the interdependency among sub-models is minimized under the computations and communications constraints of the workers. We propose RePurpose, a layer-wise model restructuring and pruning technique that guarantees the performance of the overall parallelized model. To efficiently apply RePurpose, we propose an approach based on $\\ell_0$ optimization and the Munkres assignment algorithm. We show that, compared to the existing methods, RePurpose significantly improves the efficiency of the distributed inference via parallel implementation, both in terms of communication and computational complexity.", "pdf_url": "https://arxiv.org/pdf/2008.08289", "subject": "Machine Learning (cs.LG)"},
{"title": "Attribute Prototype Network for Zero-Shot Learning", "author": "Wenjia Xu, Yongqin Xian, Jiuniu Wang, Bernt Schiele, Zeynep Akata", "pub_date": "Submitted on 19 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "From the beginning of zero-shot learning research, visual attributes have been shown to play an important role. In order to better transfer attribute-based knowledge from known to unknown classes, we argue that an image representation with integrated attribute localization ability would be beneficial for zero-shot learning. To this end, we propose a novel zero-shot representation learning framework that jointly learns discriminative global and local features using only class-level attributes. While a visual-semantic embedding layer learns global features, local features are learned through an attribute prototype network that simultaneously regresses and decorrelates attributes from intermediate features. We show that our locality augmented image representations achieve a new state-of-the-art on three zero-shot learning benchmarks. As an additional benefit, our model points to the visual evidence of the attributes in an image, e.g. for the CUB dataset, confirming the improved attribute localization ability of our image representation. The code will be publicaly available at .", "pdf_url": "https://arxiv.org/pdf/2008.08290", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "End-to-End Predictions-Based Resource Management Framework for Supercomputer Jobs", "author": "Swetha Hariharan, Prakash Murali, Abhishek Pasari, Sathish Vadhiyar", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Job submissions of parallel applications to production supercomputer systems will have to be carefully tuned in terms of the job submission parameters to obtain minimum response times. In this work, we have developed an end-to-end resource management framework that uses predictions of queue waiting and execution times to minimize response times of user jobs submitted to supercomputer systems. Our method for predicting queue waiting times adaptively chooses a prediction method based on the cluster structure of similar jobs. Our strategy for execution time predictions dynamically learns the impact of load on execution times and uses this to predict a set of execution time ranges for the target job. We have developed two resource management techniques that employ these predictions, one that selects the number of processors for execution and the other that also dynamically changes the job submission time. Using workload simulations of large supercomputer traces, we show large-scale improvements in predictions and reductions in response times over existing techniques and baseline strategies.", "pdf_url": "https://arxiv.org/pdf/2008.08292", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "TNT: Target-driveN Trajectory Prediction", "author": "Hang Zhao, Jiyang Gao, Tian Lan, Chen Sun, Benjamin Sapp, Balakrishnan Varadarajan, Yue Shen, Yi Shen, Yuning Chai, Cordelia Schmid, Congcong Li, Dragomir Anguelov", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Predicting the future behavior of moving agents is essential for real world applications. It is challenging as the intent of the agent and the corresponding behavior is unknown and intrinsically multimodal. Our key insight is that for prediction within a moderate time horizon, the future modes can be effectively captured by a set of target states. This leads to our target-driven trajectory prediction (TNT) framework. TNT has three stages which are trained end-to-end. It first predicts an agent's potential target states $T$ steps into the future, by encoding its interactions with the environment and the other agents. TNT then generates trajectory state sequences conditioned on targets. A final stage estimates trajectory likelihoods and a final compact set of trajectory predictions is selected. This is in contrast to previous work which models agent intents as latent variables, and relies on test-time sampling to generate diverse trajectories. We benchmark TNT on trajectory prediction of vehicles and pedestrians, where we outperform state-of-the-art on Argoverse Forecasting, INTERACTION, Stanford Drone and an in-house Pedestrian-at-Intersection dataset.", "pdf_url": "https://arxiv.org/pdf/2008.08294", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Deep Relighting Networks for Image Light Source Manipulation", "author": "Li-Wen Wang, Wan-Chi Siu, Zhi-Song Liu, Chu-Tak Li, Daniel P.K. Lun", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Manipulating the light source of given images is an interesting task and useful in various applications, including photography and cinematography. Existing methods usually require additional information like the geometric structure of the scene, which may not be available for most images. In this paper, we formulate the single image relighting task and propose a novel Deep Relighting Network (DRN) with three parts: 1) scene reconversion, which aims to reveal the primary scene structure through a deep auto-encoder network, 2) shadow prior estimation, to predict light effect from the new light direction through adversarial learning, and 3) re-renderer, to combine the primary structure with the reconstructed shadow view to form the required estimation under the target light source. Experimental results show that the proposed method outperforms other possible methods, both qualitatively and quantitatively. Specifically, the proposed DRN has achieved the best PSNR in the \"AIM2020 - Any to one relighting challenge\" of the 2020 ECCV conference.", "pdf_url": "https://arxiv.org/pdf/2008.08298", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Using Sampling Strategy to Assist Consensus Sequence Analysis", "author": "Zhichao Xu, Shuhong Chen", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Consensus Sequences of event logs are often used in process mining to quickly grasp the core sequence of events to be performed in a process, or to represent the backbone of the process for doing other analyses. However, it is still not clear how many traces are enough to properly represent the underlying process. In this paper, we propose a novel sampling strategy to determine the number of traces necessary to produce a representative consensus sequence. We show how to estimate the difference between the predefined Expert Model and the real processes carried out. This difference level can be used as reference for domain experts to adjust the Expert Model. In addition, we apply this strategy to several real-world workflow activity datasets as a case study. We show a sample curve fitting task to help readers better understand our proposed methodology.", "pdf_url": "https://arxiv.org/pdf/2008.08300", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "E-commerce Recommendation with Weighted Expected Utility", "author": "Zhichao Xu, Yi Han, Yongfeng Zhang, Qingyao Ai", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Different from shopping at retail stores, consumers on e-commerce platforms usually cannot touch or try products before purchasing, which means that they have to make decisions when they are uncertain about the outcome (e.g., satisfaction level) of purchasing a product. To study people's preferences, economics researchers have proposed the hypothesis of Expected Utility (EU) that models the subject value associated with an individual's choice as the statistical expectations of that individual's valuations of the outcomes of this choice. Despite its success in studies of game theory and decision theory, the effectiveness of EU, however, is mostly unknown in e-commerce recommendation systems. Previous research on e-commerce recommendation interprets the utility of purchase decisions either as a function of the consumed quantity of the product or as the gain of sellers/buyers in the monetary sense. As most consumers just purchase one unit of a product at a time and most alternatives have similar prices, such modeling of purchase utility is likely to be inaccurate in practice. In this paper, we interpret purchase utility as the satisfaction level a consumer gets from a product and propose a recommendation framework using EU to model consumers' behavioral patterns. We assume that consumer estimates the expected utilities of all the alternatives and choose products with maximum expected utility for each purchase. To deal with the potential psychological biases of each consumer, we introduce the usage of Probability Weight Function (PWF) and design our algorithm based on Weighted Expected Utility (WEU). Empirical study on real-world e-commerce datasets shows that our proposed ranking-based recommendation framework achieves statistically significant improvement against both classical Collaborative Filtering/Latent Factor Models and state-of-the-art deep models in top-K recommendation.", "pdf_url": "https://arxiv.org/pdf/2008.08302", "subject": "Information Retrieval (cs.IR)"},
{"title": "FinChat: Corpus and evaluation setup for Finnish chat conversations on everyday topics", "author": "Katri Leino, Juho Leinonen, Mittul Singh, Sami Virpioja, Mikko Kurimo", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Creating open-domain chatbots requires large amounts of conversational data and related benchmark tasks to evaluate them. Standardized evaluation tasks are crucial for creating automatic evaluation metrics for model development; otherwise, comparing the models would require resource-expensive human evaluation. While chatbot challenges have recently managed to provide a plethora of such resources for English, resources in other languages are not yet available. In this work, we provide a starting point for Finnish open-domain chatbot research. We describe our collection efforts to create the Finnish chat conversation corpus FinChat, which is made available publicly. FinChat includes unscripted conversations on seven topics from people of different ages. Using this corpus, we also construct a retrieval-based evaluation task for Finnish chatbot development. We observe that off-the-shelf chatbot models trained on conversational corpora do not perform better than chance at choosing the right answer based on automatic metrics, while humans can do the same task almost perfectly. Similarly, in a human evaluation, responses to questions from the evaluation set generated by the chatbots are predominantly marked as incoherent. Thus, FinChat provides a challenging evaluation set, meant to encourage chatbot development in Finnish.", "pdf_url": "https://arxiv.org/pdf/2008.08315", "subject": "Computation and Language (cs.CL)"},
{"title": "Data-Independent Structured Pruning of Neural Networks via Coresets", "author": "Ben Mussay, Daniel Feldman, Samson Zhou, Vladimir Braverman, Margarita Osadchy", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Model compression is crucial for deployment of neural networks on devices with limited computational and memory resources. Many different methods show comparable accuracy of the compressed model and similar compression rates. However, the majority of the compression methods are based on heuristics and offer no worst-case guarantees on the trade-off between the compression rate and the approximation error for an arbitrarily new sample. We propose the first efficient structured pruning algorithm with a provable trade-off between its compression rate and the approximation error for any future test sample. Our method is based on the coreset framework and it approximates the output of a layer of neurons/filters by a coreset of neurons/filters in the previous layer and discards the rest. We apply this framework in a layer-by-layer fashion from the bottom to the top. Unlike previous works, our coreset is data independent, meaning that it provably guarantees the accuracy of the function for any input $x\\in \\mathbb{R}^d$, including an adversarial one.", "pdf_url": "https://arxiv.org/pdf/2008.08316", "subject": "Machine Learning (cs.LG)"},
{"title": "Organizing Virtual Conferences through Mirrors: The ACM e-Energy 2020 Experience", "author": "Dan Wang, Arun Vishwanath, Ramesh Sitaraman, Iven Mareels", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The emergence of the world-wide COVID-19 pandemic has forced academic conferences to be held entirely in a virtual manner. While prior studies have advocated the merits of virtual conferences in terms of energy and cost savings, organizers are increasingly facing the prospect of planning and executing them systematically, in order to deliver a rich conference-attending-experience for all participants. Starting from March 2020, tens of conferences have been held virtually. Past conferences have revealed numerous challenges, from budget planning, to selecting the supporting virtual platforms. Among these, two special challenges were identified: 1) how to deliver talks to geo-distributed attendees and 2) how to stimulate social interactions among attendees. These are the two important goals of an academic conference. In this paper, we advocate a mirror program approach for academic conferences. More specifically, the conference program is executed in multiple parallel (mirrored) programs, so that each mirror program can fit a different time zone. This can effectively address the first challenge.", "pdf_url": "https://arxiv.org/pdf/2008.08318", "subject": "Computers and Society (cs.CY)"},
{"title": "Flux-stability for conservation laws with discontinuous flux and convergence rates of the front tracking method", "author": "Adrian Montgomery Ruf", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We prove that adapted entropy solutions of scalar conservation laws with discontinuous flux are stable with respect to changes in the flux under the assumption that the flux is strictly monotone in u and the spatial dependency is piecewise constant with finitely many discontinuities. We use this stability result to prove a convergence rate for the front tracking method -- a numerical method which is widely used in the field of conservation laws with discontinuous flux. To the best of our knowledge, both of these results are the first of their kind in the literature on conservation laws with discontinuous flux. We also present numerical experiments verifying the convergence rate results and comparing numerical solutions computed with the front tracking method to finite volume approximations.", "pdf_url": "https://arxiv.org/pdf/2008.08320", "subject": "Numerical Analysis (math.NA)"},
{"title": "FrankMocap: Fast Monocular 3D Hand and Body Motion Capture by Regression and Integration", "author": "Yu Rong, Takaaki Shiratori, Hanbyul Joo", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Although the essential nuance of human motion is often conveyed as a combination of body movements and hand gestures, the existing monocular motion capture approaches mostly focus on either body motion capture only ignoring hand parts or hand motion capture only without considering body motion. In this paper, we present FrankMocap, a motion capture system that can estimate both 3D hand and body motion from in-the-wild monocular inputs with faster speed (9.5 fps) and better accuracy than previous work. Our method works in near real-time (9.5 fps) and produces 3D body and hand motion capture outputs as a unified parametric model structure. Our method aims to capture 3D body and hand motion simultaneously from challenging in-the-wild monocular videos. To construct FrankMocap, we build the state-of-the-art monocular 3D \"hand\" motion capture method by taking the hand part of the whole body parametric model (SMPL-X). Our 3D hand motion capture output can be efficiently integrated to monocular body motion capture output, producing whole body motion results in a unified parrametric model structure. We demonstrate the state-of-the-art performance of our hand motion capture system in public benchmarks, and show the high quality of our whole body motion capture result in various challenging real-world scenes, including a live demo scenario.", "pdf_url": "https://arxiv.org/pdf/2008.08324", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Second-order accurate TVD numerical methods for nonlocal nonlinear conservation laws", "author": "Ulrik Skre Fjordholm, Adrian Montgomery Ruf", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We present a second-order accurate numerical method for a class of nonlocal nonlinear conservation laws called the \"nonlocal pair-interaction model\" which was recently introduced by Du, Huang, and LeFloch. Our numerical method uses second-order accurate reconstruction-based schemes for local conservation laws in conjunction with appropriate numerical integration. We show that the resulting method is total variation diminishing (TVD) and converges towards a weak solution. In fact, in contrast to local conservation laws, our second-order reconstruction-based method converges towards the unique entropy solution provided that the nonlocal interaction kernel satisfies a certain growth condition near zero. Furthermore, as the nonlocal horizon parameter in our method approaches zero we recover a well-known second-order method for local conservation laws. In addition, we answer several questions from the paper from Du, Huang, and LeFloch concerning regularity of solutions. In particular, we prove that any discontinuity present in a weak solution must be stationary and that, if the interaction kernel satisfies a certain growth condition, then weak solutions are unique. We present a series of numerical experiments in which we investigate the accuracy of our second-order scheme, demonstrate shock formation in the nonlocal pair-interaction model, and examine how the regularity of the solution depends on the choice of flux function.", "pdf_url": "https://arxiv.org/pdf/2008.08326", "subject": "Numerical Analysis (math.NA)"},
{"title": "An Adjoint Optimization Approach to Network Topology and Discrete Pipe Size Design for District Heating Networks", "author": "Maarten Blommaert, Yannick Wack, Martine Baelmans", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This article deals with the problem of finding the best topology, pipe diameter choices, and operation parameters for district heating networks. We introduce an alternative adjoint-based numerical optimization strategy that aims at enabling large-scale nonlinear thermal network optimization. This allows the optimal design tool to start from a bottom-up transport-based district heating network model. We introduce a proof-of-concept design formulation that optimizes the network for minimal investment cost and pumping power, while keeping the heat supplied to the consumers within a thermal comfort range of 5 %. Several challenges in applying the adjoint optimization strategy to district heating network design are overcome in this paper. First, we avoid a strong computational cost scaling with the network size by introducing a constraint aggregation strategy. Secondly, we present a numerical continuation strategy that gradually forces the continuous optimization method towards discrete design variable choices. As such, network topology and discrete pipe size choices are determined simultaneously. Finally, we employ the algorithm for the design of a fictitious but realistically-sized district heating network with 160 consumers. Starting from a uniform distribution of 15 cm wide piping throughout the network, the novel algorithm finds a network lay-out that reduces piping investment by 23 % and pump-related costs by a factor of 14 in less than an hour on a standard laptop. Moreover, the importance of embedding a non-linear transport model is clear from a temperature-induced variation in the consumer flow rates of 72 %.", "pdf_url": "https://arxiv.org/pdf/2008.08328", "subject": "Computational Engineering, Finance, and Science (cs.CE)"},
{"title": "Toward Smart Security Enhancement of Federated Learning Networks", "author": "Junjie Tan, Ying-Chang Liang, Nguyen Cong Luong, Dusit Niyato", "pub_date": "Submitted on 19 Aug 2020", "abstract": "As traditional centralized learning networks (CLNs) are facing increasing challenges in terms of privacy preservation, communication overheads, and scalability, federated learning networks (FLNs) have been proposed as a promising alternative paradigm to support the training of machine learning (ML) models. In contrast to the centralized data storage and processing in CLNs, FLNs exploit a number of edge devices (EDs) to store data and perform training distributively. In this way, the EDs in FLNs can keep training data locally, which preserves privacy and reduces communication overheads. However, since the model training within FLNs relies on the contribution of all EDs, the training process can be disrupted if some of the EDs upload incorrect or falsified training results, i.e., poisoning attacks. In this paper, we review the vulnerabilities of FLNs, and particularly give an overview of poisoning attacks and mainstream countermeasures. Nevertheless, the existing countermeasures can only provide passive protection and fail to consider the training fees paid for the contributions of the EDs, resulting in a unnecessarily high training cost. Hence, we present a smart security enhancement framework for FLNs. In particular, a verify-before-aggregate (VBA) procedure is developed to identify and remove the non-benign training results from the EDs. Afterward, deep reinforcement learning (DRL) is applied to learn the behaving patterns of the EDs and to actively select the EDs that can provide benign training results and charge low training fees. Simulation results reveal that the proposed framework can protect FLNs effectively and efficiently.", "pdf_url": "https://arxiv.org/pdf/2008.08330", "subject": "Cryptography and Security (cs.CR)"},
{"title": "CFAD: Coarse-to-Fine Action Detector for Spatiotemporal Action Localization", "author": "Yuxi Li, Weiyao Lin, John See, Ning Xu, Shugong Xu, Ke Yan, Cong Yang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Most current pipelines for spatio-temporal action localization connect frame-wise or clip-wise detection results to generate action proposals, where only local information is exploited and the efficiency is hindered by dense per-frame localization. In this paper, we propose Coarse-to-Fine Action Detector (CFAD),an original end-to-end trainable framework for efficient spatio-temporal action localization. The CFAD introduces a new paradigm that first estimates coarse spatio-temporal action tubes from video streams, and then refines the tubes' location based on key timestamps. This concept is implemented by two key components, the Coarse and Refine Modules in our framework. The parameterized modeling of long temporal information in the Coarse Module helps obtain accurate initial tube estimation, while the Refine Module selectively adjusts the tube location under the guidance of key timestamps. Against other methods, theproposed CFAD achieves competitive results on action detection benchmarks of UCF101-24, UCFSports and JHMDB-21 with inference speed that is 3.3x faster than the nearest competitors.", "pdf_url": "https://arxiv.org/pdf/2008.08332", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Towards Class-incremental Object Detection with Nearest Mean of Exemplars", "author": "Sheng Ren, Yan He, Neal N. Xiong, Kehua Guo", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Object detection has been widely used in the field of Internet, and deep learning plays a very important role in object detection. However, the existing object detection methods need to be trained in the static setting, which requires obtaining all the data at one time, and it does not support training in the way of class-incremental. In this paper, an object detection framework named class-incremental object detection (CIOD) is proposed. CIOD divides object detection into two stages. Firstly, the traditional OpenCV cascade classifier is improved in the object candidate box generation stage to meet the needs of class increment. Secondly, we use the concept of prototype vector on the basis of deep learning to train a classifier based on class-incremental to identify the generated object candidate box, so as to extract the real object box. A large number of experiments on CIOD have been carried out to verify that CIOD can detect the object in the way of class-incremental and can control the training time and memory capacity.", "pdf_url": "https://arxiv.org/pdf/2008.08336", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Survey of HTTPS Traffic and Services Identification Approaches", "author": "Wazen M. Shbair, Thibault Cholez, Jerome Francois, Isabelle Chrisment", "pub_date": "Submitted on 19 Aug 2020", "abstract": "HTTPS is quickly rising alongside the need of Internet users to benefit from security and privacy when accessing the Web, and it becomes the predominant application protocol on the Internet. This migration towards a secure Web using HTTPS comes with important challenges related to the management of HTTPS traffic to guarantee basic network properties such as security, QoS, reliability, etc. But encryption undermines the effectiveness of standard monitoring techniques and makes it difficult for ISPs and network administrators to properly identify and manage the services behind HTTPS traffic. This survey details the techniques used to monitor HTTPS traffic, from the most basic level of protocol identification (TLS, HTTPS), to the finest identification of precise services. We show that protocol identification is well mastered while more precise levels keep being challenging despite recent advances. We also describe practical solutions that lead us to discuss the trade-off between security and privacy and the research directions to guarantee both of them.", "pdf_url": "https://arxiv.org/pdf/2008.08339", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Deep Volumetric Ambient Occlusion", "author": "Dominik Engel, Timo Ropinski", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We present a novel deep learning based technique for volumetric ambient occlusion in the context of direct volume rendering. Our proposed Deep Volumetric Ambient Occlusion (DVAO) approach can predict per-voxel ambient occlusion in volumetric data sets, while considering global information provided through the transfer function. The proposed neural network only needs to be executed upon change of this global information, and thus supports real-time volume interaction. Accordingly, we demonstrate DVAOs ability to predict volumetric ambient occlusion, such that it can be applied interactively within direct volume rendering. To achieve the best possible results, we propose and analyze a variety of transfer function representations and injection strategies for deep neural networks. Based on the obtained results we also give recommendations applicable in similar volume learning scenarios. Lastly, we show that DVAO generalizes to a variety of modalities, despite being trained on computed tomography data only.", "pdf_url": "https://arxiv.org/pdf/2008.08345", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Early Identification of Services in HTTPS Traffic", "author": "Wazen M. Shbair, Thibault Cholez, Jerome Francois, Isabelle Chrisment", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Traffic monitoring is essential for network management tasks that ensure security and QoS. However, the continuous increase of HTTPS traffic undermines the effectiveness of current service-level monitoring that can only rely on unreliable parameters from the TLS handshake (X.509 certificate, SNI) or must decrypt the traffic. We propose a new machine learning-based method to identify HTTPS services without decryption. By extracting statistical features on TLS handshake packets and on a small number of application data packets, we can identify HTTPS services very early in the session. Extensive experiments performed over a significant and open dataset show that our method offers a good accuracy and a prototype implementation confirms that the early identification of HTTPS services is satisfied.", "pdf_url": "https://arxiv.org/pdf/2008.08350", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Multiplex Graph Association Rules for Link Prediction", "author": "Michele Coscia, Michael Szell", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Multiplex networks allow us to study a variety of complex systems where nodes connect to each other in multiple ways, for example friend, family, and co-worker relations in social networks. Link prediction is the branch of network analysis allowing us to forecast the future status of a network: which new connections are the most likely to appear in the future? In multiplex link prediction we also ask: of which type? Because this last question is unanswerable with classical link prediction, here we investigate the use of graph association rules to inform multiplex link prediction. We derive such rules by identifying all frequent patterns in a network via multiplex graph mining, and then score each unobserved link's likelihood by finding the occurrences of each rule in the original network. Association rules add new abilities to multiplex link prediction: to predict new node arrivals, to consider higher order structures with four or more nodes, and to be memory efficient. In our experiments, we show that, exploiting graph association rules, we are able to achieve a prediction performance close to an ideal ensemble classifier. Further, we perform a case study on a signed multiplex network, showing how graph association rules can provide valuable insights to extend social balance theory.", "pdf_url": "https://arxiv.org/pdf/2008.08351", "subject": "Social and Information Networks (cs.SI)"},
{"title": "DECE: Decision Explorer with Counterfactual Explanations for Machine Learning Models", "author": "Furui Cheng, Yao Ming, Huamin Qu", "pub_date": "Submitted on 19 Aug 2020", "abstract": "With machine learning models being increasingly applied to various decision-making scenarios, people have spent growing efforts to make machine learning models more transparent and explainable. Among various explanation techniques, counterfactual explanations have the advantages of being human-friendly and actionable -- a counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input. Besides, counterfactual explanations can also serve as efficient probes to the models' decisions. In this work, we exploit the potential of counterfactual explanations to understand and explore the behavior of machine learning models. We design DECE, an interactive visualization system that helps understand and explore a model's decisions on individual instances and data subsets, supporting users ranging from decision-subjects to model developers. DECE supports exploratory analysis of model decisions by combining the strengths of counterfactual explanations at instance- and subgroup-levels. We also introduce a set of interactions that enable users to customize the generation of counterfactual explanations to find more actionable ones that can suit their needs. Through three use cases and an expert interview, we demonstrate the effectiveness of DECE in supporting decision exploration tasks and instance explanations.", "pdf_url": "https://arxiv.org/pdf/2008.08353", "subject": "Machine Learning (cs.LG)"},
{"title": "Berlin: A Quantitative View of the Structure of Institutional Scientific Collaborations", "author": "Aliakbar Akbaritabar", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper examines the structure of scientific collaborations in a large European metropolitan area. It aims to identify strategic coalitions among organizations in Berlin as a specific case with high institutional and sectoral diversity. By adopting a global, regional and organization based approach we provide a quantitative, exploratory and macro view of this diversity. We use publications data with at least one organization located in Berlin from 1996-2017. We further investigate four members of the Berlin University Alliance (BUA) through their self-represented research profiles comparing it with empirical results of OECD disciplines. Using a bipartite network modeling framework, we are able to move beyond the uncontested trend towards team science and increasing internationalization. Our results show that BUA members shape the structure of scientific collaborations in the region. However, they are not collaborating cohesively in all disciplines. Larger divides exist in some disciplines e.g., Agricultural Sciences and Humanities. Only Medical and Health Sciences have cohesive intraregional collaborations which signals the success of regional cooperation established in 2003. We explain possible underlying factors shaping the observed trends and sectoral and intra-regional groupings. A major methodological contribution of this paper is evaluating coverage and accuracy of different organization name disambiguation techniques.", "pdf_url": "https://arxiv.org/pdf/2008.08355", "subject": "Digital Libraries (cs.DL)"},
{"title": "Query Twice: Dual Mixture Attention Meta Learning for Video Summarization", "author": "Junyan Wang, Yang Bai, Yang Long, Bingzhang Hu, Zhenhua Chai, Yu Guan, Xiaolin Wei", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Video summarization aims to select representative frames to retain high-level information, which is usually solved by predicting the segment-wise importance score via a softmax function. However, softmax function suffers in retaining high-rank representations for complex visual or sequential information, which is known as the Softmax Bottleneck problem. In this paper, we propose a novel framework named Dual Mixture Attention (DMASum) model with Meta Learning for video summarization that tackles the softmax bottleneck problem, where the Mixture of Attention layer (MoA) effectively increases the model capacity by employing twice self-query attention that can capture the second-order changes in addition to the initial query-key attention, and a novel Single Frame Meta Learning rule is then introduced to achieve more generalization to small datasets with limited training sources. Furthermore, the DMASum significantly exploits both visual and sequential attention that connects local key-frame and global attention in an accumulative way. We adopt the new evaluation protocol on two public datasets, SumMe, and TVSum. Both qualitative and quantitative experiments manifest significant improvements over the state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2008.08360", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Experts and authorities receive disproportionate attention on Twitter during the COVID-19 crisis", "author": "Kristina Gligori\u0107, Manoel Horta Ribeiro, Martin M\u00fcller, Olesia Altunina, Maxime Peyrard, Marcel Salath\u00e9, Giovanni Colavizza, Robert West", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Timely access to accurate information is crucial during the COVID-19 pandemic. Prompted by key stakeholders' cautioning against an \"infodemic\", we study information sharing on Twitter from January through May 2020. We observe an overall surge in the volume of general as well as COVID-19-related tweets around peak lockdown in March/April 2020. With respect to engagement (retweets and likes), accounts related to healthcare, science, government and politics received by far the largest boosts, whereas accounts related to religion and sports saw a relative decrease in engagement. While the threat of an \"infodemic\" remains, our results show that social media also provide a platform for experts and public authorities to be widely heard during a global crisis.", "pdf_url": "https://arxiv.org/pdf/2008.08364", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Disjoint Shortest Paths with Congestion on DAGs", "author": "Saeed Akhoondian Amiri", "pub_date": "Submitted on 19 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "In the $k$-Disjoint Shortest Paths problem, a set of source terminal pairs of vertices $\\{(s_i,t_i)\\mid 1\\le i\\le k\\}$ is given and we are asked to find paths $P_1,\\ldots,P_k$ such that each path $P_i$ is a shortest path from $s_i$ to $t_i$ and every vertex of the graph routes at most one of such paths. We introduce a relaxation of the problem, namely, $k$-Disjonit Shortest Paths with Congestion-$c$ where every vertex is allowed to route up to $c$ paths. In this work we provide a simple algorithm to solve the $k$-Disjonit Shortest Paths with Congestion-$c$ problem in time $f(k) n^{O(k-c)}$ on DAGs. Along this way, we significantly simplify the argument that is used in the previous work for $k$-Disjoint Paths with Congestion-$c$ by Amiri et al. We also discuss the hardness of problem and open problems in this area.", "pdf_url": "https://arxiv.org/pdf/2008.08368", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Virtual Adversarial Training in Feature Space to Improve Unsupervised Video Domain Adaptation", "author": "Artjoms Gorpincenko, Geoffrey French, Michal Mackiewicz", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Virtual Adversarial Training has recently seen a lot of success in semi-supervised learning, as well as unsupervised Domain Adaptation. However, so far it has been used on input samples in the pixel space, whereas we propose to apply it directly to feature vectors. We also discuss the unstable behaviour of entropy minimization and Decision-Boundary Iterative Refinement Training With a Teacher in Domain Adaptation, and suggest substitutes that achieve similar behaviour. By adding the aforementioned techniques to the state of the art model TA$^3$N, we either maintain competitive results or outperform prior art in multiple unsupervised video Domain Adaptation tasks", "pdf_url": "https://arxiv.org/pdf/2008.08369", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Coordinated Behavior on Social Media in 2019 UK General Election", "author": "Leonardo Nizzoli, Serena Tardelli, Marco Avvenuti, Stefano Cresci, Maurizio Tesconi", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Coordinated online behaviors are an important part of information and influence operations, as they allow a more effective disinformation's spread. Most studies on coordinated behaviors involved manual investigations and the few existing computational approaches make bold assumptions or oversimplify the problem to make it tractable. Here, we propose a new network-based framework for uncovering and studying coordinated behaviors on social media. Our proposal extends existing systems and goes beyond limiting binary classifications of coordinated and uncoordinated behaviors. It allows to uncover different patterns of coordination and to estimate the degree of coordination that characterizes different communities. We apply our framework to a dataset collected during the 2019 UK General Election, detecting and characterizing coordinated communities that participated in the electoral debate. Our work conveys both theoretical and practical implications, and provides more nuanced and fine-grained results for studying online manipulation.", "pdf_url": "https://arxiv.org/pdf/2008.08370", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Holy Tweets: Exploring the Sharing of Quran on Twitter", "author": "Norah Abokhodair, Abdelrahim Elmadany, Walid Magdy", "pub_date": "Submitted on 19 Aug 2020", "abstract": "While social media offer users a platform for self-expression, identity exploration, and community management, among other functions, they also offer space for religious practice and expression. In this paper, we explore social media spaces as they subtend new forms of religious experiences and rituals. We present a mixed-method study to understand the practice of sharing Quran verses on Arabic Twitter in their cultural context by combining a quantitative analysis of the most shared Quran verses, the topics covered by these verses, and the modalities of sharing, with a qualitative study of users' goals. This analysis of a set of 2.6 million tweets containing Quran verses demonstrates that online religious expression in the form of sharing Quran verses both extends offline religious life and supports new forms of religious expression including goals such as doing good deeds, giving charity, holding memorials, and showing solidarity. By analysing the responses on a survey, we found that our Arab Muslim respondents conceptualize social media platforms as everlasting, at least beyond their lifetimes, where they consider them to be effective for certain religious practices, such as reciting Quran, supplication (dua), and ceaseless charity. Our quantitative analysis of the most shared verses of the Quran underlines this commitment to religious expression as an act of worship, highlighting topics such as the hereafter, God's mercy, and sharia law. We note that verses on topics such as jihad are shared much less often, contradicting some media representation of Muslim social media use and practice.", "pdf_url": "https://arxiv.org/pdf/2008.08372", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Efficient Graph Minors Theory and Parameterized Algorithms for (Planar) Disjoint Paths", "author": "Daniel Lokshtanov, Saket Saurabh, Meirav Zehavi", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In the Disjoint Paths problem, the input consists of an $n$-vertex graph $G$ and a collection of $k$ vertex pairs, $\\{(s_i,t_i)\\}_{i=1}^k$, and the objective is to determine whether there exists a collection $\\{P_i\\}_{i=1}^k$ of $k$ pairwise vertex-disjoint paths in $G$ where the end-vertices of $P_i$ are $s_i$ and $t_i$. This problem was shown to admit an $f(k)n^3$-time algorithm by Robertson and Seymour (Graph Minors XIII, The Disjoint Paths Problem, JCTB). In modern terminology, this means that Disjoint Paths is fixed parameter tractable (FPT) with respect to $k$. Remarkably, the above algorithm for Disjoint Paths is a cornerstone of the entire Graph Minors Theory, and conceptually vital to the $g(k)n^3$-time algorithm for Minor Testing (given two undirected graphs, $G$ and $H$ on $n$ and $k$ vertices, respectively, determine whether $G$ contains $H$ as a minor). In this semi-survey, we will first give an exposition of the Graph Minors Theory with emphasis on efficiency from the viewpoint of Parameterized Complexity. Secondly, we will review the state of the art with respect to the Disjoint Paths and Planar Disjoint Paths problems. Lastly, we will discuss the main ideas behind a new algorithm that combines treewidth reduction and an algebraic approach to solve Planar Disjoint Paths in time $2^{k^{O(1)}}n^{O(1)}$ (for undirected graphs).", "pdf_url": "https://arxiv.org/pdf/2008.08373", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Addressing Neural Network Robustness with Mixup and Targeted Labeling Adversarial Training", "author": "Alfred Laugros, Alice Caplier, Matthieu Ospici", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Despite their performance, Artificial Neural Networks are not reliable enough for most of industrial applications. They are sensitive to noises, rotations, blurs and adversarial examples. There is a need to build defenses that protect against a wide range of perturbations, covering the most traditional common corruptions and adversarial examples. We propose a new data augmentation strategy called M-TLAT and designed to address robustness in a broad sense. Our approach combines the Mixup augmentation and a new adversarial training algorithm called Targeted Labeling Adversarial Training (TLAT). The idea of TLAT is to interpolate the target labels of adversarial examples with the ground-truth labels. We show that M-TLAT can increase the robustness of image classifiers towards nineteen common corruptions and five adversarial attacks, without reducing the accuracy on clean samples.", "pdf_url": "https://arxiv.org/pdf/2008.08384", "subject": "Machine Learning (cs.LG)"},
{"title": "ReLU activated Multi-Layer Neural Networks trained with Mixed Integer Linear Programs", "author": "Steffen Goebbels", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper is a case study to demonstrate that, in principle, multi-layer feedforward Neural Networks activated by ReLU functions can be iteratively trained with Mixed Integer Linear Programs. To this end, two simple networks were trained with a backpropagation-like algorithm on the MNIST dataset that contains handwritten digits.", "pdf_url": "https://arxiv.org/pdf/2008.08386", "subject": "Machine Learning (cs.LG)"},
{"title": "Robust RGB-based 6-DoF Pose Estimation without Real Pose Annotations", "author": "Zhigang Li, Yinlin Hu, Mathieu Salzmann, Xiangyang Ji", "pub_date": "Submitted on 19 Aug 2020", "abstract": "While much progress has been made in 6-DoF object pose estimation from a single RGB image, the current leading approaches heavily rely on real-annotation data. As such, they remain sensitive to severe occlusions, because covering all possible occlusions with annotated data is intractable. In this paper, we introduce an approach to robustly and accurately estimate the 6-DoF pose in challenging conditions and without using any real pose annotations. To this end, we leverage the intuition that the poses predicted by a network from an image and from its counterpart synthetically altered to mimic occlusion should be consistent, and translate this to a self-supervised loss function. Our experiments on LINEMOD, Occluded-LINEMOD, YCB and new Randomization LINEMOD dataset evidence the robustness of our approach. We achieve state of the art performance on LINEMOD, and OccludedLINEMOD in without real-pose setting, even outperforming methods that rely on real annotations during training on Occluded-LINEMOD.", "pdf_url": "https://arxiv.org/pdf/2008.08391", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "On CCZ-equivalence of the inverse function", "author": "Lukas K\u00f6lsch", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The inverse function $x \\mapsto x^{-1}$ on $\\mathbb{F}_{2^n}$ is one of the most studied functions in cryptography due to its widespread use as an S-box in block ciphers like AES. In this paper, we show that, if $n\\geq 5$, every function that is CCZ-equivalent to the inverse function is already EA-equivalent to it. This confirms a conjecture by Budaghyan, Calderini and Villa. We also prove that every permutation that is CCZ-equivalent to the inverse function is already affine equivalent to it. The majority of the paper is devoted to proving that there are no permutation polynomials of the form $L_1(x^{-1})+L_2(x)$ over $\\mathbb{F}_{2^n}$ if $n\\geq 5$, where $L_1,L_2$ are nonzero linear functions. In the proof, we combine Kloosterman sums, quadratic forms and tools from additive combinatorics.", "pdf_url": "https://arxiv.org/pdf/2008.08398", "subject": "Information Theory (cs.IT)"},
{"title": "Trace-based Debloat for Java Bytecode", "author": "C\u00e9sar Soto-Valero, Thomas Durieux, Nicolas Harrand, Benoit Baudry", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Software bloat is code that is packaged in an application but is actually not used and not necessary to run the application. The presence of bloat is an issue for software security, for performance, and for maintenance. In recent years, several works have proposed techniques to detect and remove software bloat. In this paper, we introduce a novel technique to debloat Java bytecode through dynamic analysis, which we call trace-based debloat. We have developed JDBL, a tool that automates the collection of accurate execution traces and the debloating process. Given a Java project and a workload, JDBL generates a debloated version of the project that is syntactically correct and preserves the original behavior, modulo the workload. We evaluate the feasibility and the effectiveness of trace-based debloat with 395 open-source Java libraries for a total 10M+ lines of code. We demonstrate that our approach significantly reduces the size of these libraries while preserving the functionalities needed by their clients.", "pdf_url": "https://arxiv.org/pdf/2008.08401", "subject": "Software Engineering (cs.SE)"},
{"title": "Instance-Aware Graph Convolutional Network for Multi-Label Classification", "author": "Yun Wang, Tong Zhang, Zhen Cui, Chunyan Xu, Jian Yang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Graph convolutional neural network (GCN) has effectively boosted the multi-label image recognition task by introducing label dependencies based on statistical label co-occurrence of data. However, in previous methods, label correlation is computed based on statistical information of data and therefore the same for all samples, and this makes graph inference on labels insufficient to handle huge variations among numerous image instances. In this paper, we propose an instance-aware graph convolutional neural network (IA-GCN) framework for multi-label classification. As a whole, two fused branches of sub-networks are involved in the framework: a global branch modeling the whole image and a region-based branch exploring dependencies among regions of interests (ROIs). For label diffusion of instance-awareness in graph convolution, rather than using the statistical label correlation alone, an image-dependent label correlation matrix (LCM), fusing both the statistical LCM and an individual one of each image instance, is constructed for graph inference on labels to inject adaptive information of label-awareness into the learned features of the model. Specifically, the individual LCM of each image is obtained by mining the label dependencies based on the scores of labels about detected ROIs. In this process, considering the contribution differences of ROIs to multi-label classification, variational inference is introduced to learn adaptive scaling factors for those ROIs by considering their complex distribution. Finally, extensive experiments on MS-COCO and VOC datasets show that our proposed approach outperforms existing state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2008.08407", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Early RTL Analysis for SCA Vulnerability in Fuzzy Extractors of Memory-Based PUF Enabled Devices", "author": "Xinhui Lai, Maksim Jenihhin, Georgios Selimis, Sven Goossens, Roel Maes, Kolin Paul", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Physical Unclonable Functions (PUFs) are gaining attention in the cryptography community because of the ability to efficiently harness the intrinsic variability in the manufacturing process. However, this means that they are noisy devices and require error correction mechanisms, e.g., by employing Fuzzy Extractors (FEs). Recent works demonstrated that applying FEs for error correction may enable new opportunities to break the PUFs if no countermeasures are taken. In this paper, we address an attack model on FEs hardware implementations and provide a solution for early identification of the timing Side-Channel Attack (SCA) vulnerabilities which can be exploited by physical fault injection. The significance of this work stems from the fact that FEs are an essential building block in the implementations of PUF-enabled devices. The information leaked through the timing side-channel during the error correction process can reveal the FE input data and thereby can endanger revealing secrets. Therefore, it is very important to identify the potential leakages early in the process during RTL design. Experimental results based on RTL analysis of several Bose-Chaudhuri-Hocquenghem (BCH) and Reed-Solomon decoders for PUF-enabled devices with FEs demonstrate the feasibility of the proposed methodology.", "pdf_url": "https://arxiv.org/pdf/2008.08409", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Inheritance of Convexity for the $\\tilde{\\mathcal{P}}_{\\min}$-Restricted Game", "author": "Alexandre Skoda", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We consider a restricted game on weighted graphs associated with minimum partitions. We replace in the classical definition of Myerson restricted game the connected components of any subgraph by the sub-components obtained with a specific partition $\\tilde{\\mathcal{P}}_{\\min}$. This partition relies on the same principle as the partition $\\mathcal{P}_{\\min}$ introduced by Grabisch and Skoda (2012) but restricted to connected coalitions. More precisely, this new partition $\\tilde{\\mathcal{P}}_{\\min}$ is induced by the deletion of the minimum weight edges in each connected component associated with a coalition. We provide a characterization of the graphs satisfying inheritance of convexity from the underlying game to the restricted game associated with $\\tilde{\\mathcal{P}}_{\\min}$.", "pdf_url": "https://arxiv.org/pdf/2008.08410", "subject": "Discrete Mathematics (cs.DM)"},
{"title": "Survey on Cryptocurrency Networking: Context, State-of-the-Art, Challenges", "author": "Maya Dotan, Yvonne-Anne Pignolet, Stefan Schmid, Saar Tochner, Aviv Zohar", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Cryptocurrencies such as Bitcoin are realized using distributed systems and hence critically rely on the performance and security of the interconnecting network. The requirements on these networks and their usage, however can differ significantly from traditional communication networks, with implications on all layers of the protocol stack. This paper is motivated by these differences, and in particular by the observation that many fundamental design aspects of these networks are not well-understood today. In order to support the networking community to contribute to this emerging application domain, we present a structured overview of the field, from topology and neighbor discovery to block and transaction propagation. In particular, we provide the context, highlighting differences and commonalities with traditional networks, review the state-of-the-art, and identify open research challenges. Our paper can hence also be seen as a call-to-arms to improve the foundation on top of which cryptocurrencies are built.", "pdf_url": "https://arxiv.org/pdf/2008.08412", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Competitive Analysis for Two Variants of Online Metric Matching Problem", "author": "Shuichi Miyazaki, Makoto Satake", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In this paper, we study two variants of the online metric matching problem. The first problem is the online metric matching problem where all the servers are placed at one of two positions in the metric space. We show that a simple greedy algorithm achieves the competitive ratio of 3 and give a matching lower bound. The second problem is the online facility assignment problem on a line, where servers have capacities, servers and requests are placed on 1-dimensional line, and the distances between any two consecutive servers are the same. We show lower bounds 3, 11/3 and 4 on the competitive ratio when the numbers of servers are 3, 4 and 5, respectively.", "pdf_url": "https://arxiv.org/pdf/2008.08415", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Gradually Applying Weakly Supervised and Active Learning for Mass Detection in Breast Ultrasound Images", "author": "JooYeol Yun, JungWoo Oh, IlDong Yun", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We propose a method for effectively utilizing weakly annotated image data in an object detection tasks of breast ultrasound images. Given the problem setting where a small, strongly annotated dataset and a large, weakly annotated dataset with no bounding box information are available, training an object detection model becomes a non-trivial problem. We suggest a controlled weight for handling the effect of weakly annotated images in a two stage object detection model. We~also present a subsequent active learning scheme for safely assigning weakly annotated images a strong annotation using the trained model. Experimental results showed a 24\\% point increase in correct localization (CorLoc) measure, which is the ratio of correctly localized and classified images, by assigning the properly controlled weight. Performing active learning after a model is trained showed an additional increase in CorLoc. We tested the proposed method on the Stanford Dog datasets to assure that it can be applied to general cases, where strong annotations are insufficient to obtain resembling results. The presented method showed that higher performance is achievable with lesser annotation effort.", "pdf_url": "https://arxiv.org/pdf/2008.08416", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Modular Subset Sum, Dynamic Strings, and Zero-Sum Sets", "author": "Jean Cardinal, John Iacono", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The modular subset sum problem consists of deciding, given a modulus $m$, a multiset $S$ of $n$ integers in $0..m$, and a target integer $t$, whether there exists a subset of $S$ with elements summing to $t \\pmod{m}$, and to report such a set if it exists. We give a simple $O(m \\log m)$-time with high probability (w.h.p.) algorithm for the modular subset sum problem. This builds on and improves on a previous $\\tilde{O}(m)$ w.h.p. algorithm from Axiotis, Backurs, Jin, Tzamos, and Wu (SODA 19). Our method utilizes the ADT of the dynamic strings structure of Gawrychowski et. al (SODA 18). However, as this structure is rather complicated we present a much simpler alternative which we call the Data Dependent Tree. As an application, we consider the computational version of a fundamental theorem in zero-sum Ramsey theory. The Erd\u0151s-Ginzburg-Ziv Theorem states that a multiset of $2n - 1$ integers always contains a subset of cardinality exactly $n$ whose values sum to a multiple of $n$. We give an algorithm for finding such a subset in time $O(n \\log n)$ w.h.p. which improves on an $O(n^2)$ algorithm due to Del Lungo, Marini, and Mori (Disc. Math. 09).", "pdf_url": "https://arxiv.org/pdf/2008.08417", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Anchor-free Small-scale Multispectral Pedestrian Detection", "author": "Alexander Wolpert, Michael Teutsch, M. Saquib Sarfraz, Rainer Stiefelhagen", "pub_date": "Submitted on 19 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "Multispectral images consisting of aligned visual-optical (VIS) and thermal infrared (IR) image pairs are well-suited for practical applications like autonomous driving or visual surveillance. Such data can be used to increase the performance of pedestrian detection especially for weakly illuminated, small-scaled, or partially occluded instances. The current state-of-the-art is based on variants of Faster R-CNN and thus passes through two stages: a proposal generator network with handcrafted anchor boxes for object localization and a classification network for verifying the object category. In this paper we propose a method for effective and efficient multispectral fusion of the two modalities in an adapted single-stage anchor-free base architecture. We aim at learning pedestrian representations based on object center and scale rather than direct bounding box predictions. In this way, we can both simplify the network architecture and achieve higher detection performance, especially for pedestrians under occlusion or at low object resolution. In addition, we provide a study on well-suited multispectral data augmentation techniques that improve the commonly used augmentations. The results show our method's effectiveness in detecting small-scaled pedestrians. We achieve 5.68% log-average miss rate in comparison to the best current state-of-the-art of 7.49% (25% improvement) on the challenging KAIST Multispectral Pedestrian Detection Benchmark. Code:", "pdf_url": "https://arxiv.org/pdf/2008.08418", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "AutoSimulate: (Quickly) Learning Synthetic Data Generation", "author": "Harkirat Singh Behl, At\u0131l\u0131m G\u00fcne\u015f Baydin, Ran Gal, Philip H.S. Torr, Vibhav Vineet", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Simulation is increasingly being used for generating large labelled datasets in many machine learning problems. Recent methods have focused on adjusting simulator parameters with the goal of maximising accuracy on a validation task, usually relying on REINFORCE-like gradient estimators. However these approaches are very expensive as they treat the entire data generation, model training, and validation pipeline as a black-box and require multiple costly objective evaluations at each iteration. We propose an efficient alternative for optimal synthetic data generation, based on a novel differentiable approximation of the objective. This allows us to optimize the simulator, which may be non-differentiable, requiring only one objective evaluation at each iteration with a little overhead. We demonstrate on a state-of-the-art photorealistic renderer that the proposed method finds the optimal data distribution faster (up to $50\\times$), with significantly reduced training data generation (up to $30\\times$) and better accuracy ($+8.7\\%$) on real-world test datasets than previous methods.", "pdf_url": "https://arxiv.org/pdf/2008.08424", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Detection Probability in a Molecular Communication via Diffusion System with Multiple Fully-absorbing Receivers", "author": "Nithin V. Sabu, Abhishek K. Gupta", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In this letter, we consider a 3D molecular communication via diffusion system (MCvDS) with a single point transmitter and multiple fully-absorbing spherical receivers whose centers are distributed as a Poisson point process (PPP) in the medium. We derive the probability that a transmitted molecule hits any of the receivers within time t. We consider both degradable and non-degradable molecules. We verify the analysis using particle-based simulation. The framework can be used for various applications, e.g., to derive event detection probability for systems where the IMs are transmitted to convey the occurrence of a particular event to trigger reactions at receivers or can be used as channel models for such systems.", "pdf_url": "https://arxiv.org/pdf/2008.08425", "subject": "Information Theory (cs.IT)"},
{"title": "On the Approximation Lower Bound for Neural Nets with Random Weights", "author": "Sho Sonoda, Ming Li, Feilong Cao, Changqin Huang, Yu Guang Wang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "A random net is a shallow neural network where the hidden layer is frozen with random assignment and the output layer is trained by convex optimization. Using random weights for a hidden layer is an effective method to avoid the inevitable non-convexity in standard gradient descent learning. It has recently been adopted in the study of deep learning theory. Here, we investigate the expressive power of random nets. We show that, despite the well-known fact that a shallow neural network is a universal approximator, a random net cannot achieve zero approximation error even for smooth functions. In particular, we prove that for a class of smooth functions, if the proposal distribution is compactly supported, then a lower bound is positive. Based on the ridgelet analysis and harmonic analysis for neural networks, the proof uses the Plancherel theorem and an estimate for the truncated tail of the parameter distribution. We corroborate our theoretical results with various simulation studies, and generally two main take-home messages are offered: (i) Not any distribution for selecting random weights is feasible to build a universal approximator; (ii) A suitable assignment of random weights exists but to some degree is associated with the complexity of the target function.", "pdf_url": "https://arxiv.org/pdf/2008.08427", "subject": "Machine Learning (cs.LG)"},
{"title": "Generating Categories for Sets of Entities", "author": "Shuo Zhang, Krisztian Balog, Jamie Callan", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Category systems are central components of knowledge bases, as they provide a hierarchical grouping of semantically related concepts and entities. They are a unique and valuable resource that is utilized in a broad range of information access tasks. To aid knowledge editors in the manual process of expanding a category system, this paper presents a method of generating categories for sets of entities. First, we employ neural abstractive summarization models to generate candidate categories. Next, the location within the hierarchy is identified for each candidate. Finally, structure-, content-, and hierarchy-based features are used to rank candidates to identify by the most promising ones (measured in terms of specificity, hierarchy, and importance). We develop a test collection based on Wikipedia categories and demonstrate the effectiveness of the proposed approach.", "pdf_url": "https://arxiv.org/pdf/2008.08428", "subject": "Information Retrieval (cs.IR)"},
{"title": "Deep Neural Networks for automatic extraction of features in time series satellite images", "author": "Gael Kamdem De Teyou, Yuliya Tarabalka, Isabelle Manighetti, Rafael Almar, Sebastien Tripod", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Many earth observation programs such as Landsat, Sentinel, SPOT, and Pleiades produce huge volume of medium to high resolution multi-spectral images every day that can be organized in time series. In this work, we exploit both temporal and spatial information provided by these images to generate land cover maps. For this purpose, we combine a fully convolutional neural network with a convolutional long short-term memory. Implementation details of the proposed spatio-temporal neural network architecture are provided. Experimental results show that the temporal information provided by time series images allows increasing the accuracy of land cover classification, thus producing up-to-date maps that can help in identifying changes on earth.", "pdf_url": "https://arxiv.org/pdf/2008.08432", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Unsupervised Cross-domain Image Classification by Distance Metric Guided Feature Alignment", "author": "Qingjie Meng, Daniel Rueckert, Bernhard Kainz", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Learning deep neural networks that are generalizable across different domains remains a challenge due to the problem of domain shift. Unsupervised domain adaptation is a promising avenue which transfers knowledge from a source domain to a target domain without using any labels in the target domain. Contemporary techniques focus on extracting domain-invariant features using domain adversarial training. However, these techniques neglect to learn discriminative class boundaries in the latent representation space on a target domain and yield limited adaptation performance. To address this problem, we propose distance metric guided feature alignment (MetFA) to extract discriminative as well as domain-invariant features on both source and target domains. The proposed MetFA method explicitly and directly learns the latent representation without using domain adversarial training. Our model integrates class distribution alignment to transfer semantic knowledge from a source domain to a target domain. We evaluate the proposed method on fetal ultrasound datasets for cross-device image classification. Experimental results demonstrate that the proposed method outperforms the state-of-the-art and enables model generalization.", "pdf_url": "https://arxiv.org/pdf/2008.08433", "subject": "Machine Learning (cs.LG)"},
{"title": "BabelEnconding at SemEval-2020 Task 3: Contextual Similarity as a Combination of Multilingualism and Language Models", "author": "Lucas R. C. Pessutto, Tiago de Melo, Viviane P. Moreira, Altigran da Silva", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper describes the system submitted by our team (BabelEnconding) to SemEval-2020 Task 3: Predicting the Graded Effect of Context in Word Similarity. We propose an approach that relies on translation and multilingual language models in order to compute the contextual similarity between pairs of words. Our hypothesis is that evidence from additional languages can leverage the correlation with the human generated scores. BabelEnconding was applied to both subtasks and ranked among the top-3 in six out of eight task/language combinations and was the highest scoring system three times.", "pdf_url": "https://arxiv.org/pdf/2008.08439", "subject": "Computation and Language (cs.CL)"},
{"title": "Learning Attribute-Based and Relationship-Based Access Control Policies with Unknown Values", "author": "Thang Bui, Scott D. Stoller", "pub_date": "Submitted on 19 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "Attribute-Based Access Control (ABAC) and Relationship-based access control (ReBAC) provide a high level of expressiveness and flexibility that promote security and information sharing, by allowing policies to be expressed in terms of attributes of and chains of relationships between entities. Algorithms for learning ABAC and ReBAC policies from legacy access control information have the potential to significantly reduce the cost of migration to ABAC or ReBAC. This paper presents the first algorithms for mining ABAC and ReBAC policies from access control lists (ACLs) and incomplete information about entities, where the values of some attributes of some entities are unknown. We show that the core of this problem can be viewed as learning a concise three-valued logic formula from a set of labeled feature vectors containing unknowns, and we give the first algorithm (to the best of our knowledge) for that problem.", "pdf_url": "https://arxiv.org/pdf/2008.08444", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Domain-specific Communication Optimization for Distributed DNN Training", "author": "Hao Wang, Jingrong Chen, Xinchen Wan, Han Tian, Jiacheng Xia, Gaoxiong Zeng, Weiyan Wang, Kai Chen, Wei Bai, Junchen Jiang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Communication overhead poses an important obstacle to distributed DNN training and draws increasing attention in recent years. Despite continuous efforts, prior solutions such as gradient compression/reduction, compute/communication overlapping and layer-wise flow scheduling, etc., are still coarse-grained and insufficient for an efficient distributed training especially when the network is under pressure. We present DLCP, a novel solution exploiting the domain-specific properties of deep learning to optimize communication overhead of DNN training in a fine-grained manner. At its heart, DLCP comprises of several key innovations beyond prior work: e.g., it exploits {\\em bounded loss tolerance} of SGD-based training to improve tail communication latency which cannot be avoided purely through gradient compression. It then performs fine-grained packet-level prioritization and dropping, as opposed to flow-level scheduling, based on layers and magnitudes of gradients to further speedup model convergence without affecting accuracy. In addition, it leverages inter-packet order-independency to perform per-packet load balancing without causing classical re-ordering issues. DLCP works with both Parameter Server and collective communication routines. We have implemented DLCP with commodity switches, integrated it with various training frameworks including TensorFlow, MXNet and PyTorch, and deployed it in our small-scale testbed with 10 Nvidia V100 GPUs. Our testbed experiments and large-scale simulations show that DLCP delivers up to $84.3\\%$ additional training acceleration over the best existing solutions.", "pdf_url": "https://arxiv.org/pdf/2008.08445", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "A Maximum Independent Set Method for Scheduling Earth Observing Satellite Constellations", "author": "Duncan Eddy, Mykel J. Kochenderfer", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Operating Earth observing satellites requires efficient planning methods that coordinate activities of multiple spacecraft. The satellite task planning problem entails selecting actions that best satisfy mission objectives for autonomous execution. Task scheduling is often performed by human operators assisted by heuristic or rule-based planning tools. This approach does not efficiently scale to multiple assets as heuristics frequently fail to properly coordinate actions of multiple vehicles over long horizons. Additionally, the problem becomes more difficult to solve for large constellations as the complexity of the problem scales exponentially in the number of requested observations and linearly in the number of spacecraft. It is expected that new commercial optical and radar imaging constellations will require automated planning methods to meet stated responsiveness and throughput objectives. This paper introduces a new approach for solving the satellite scheduling problem by generating an infeasibility-based graph representation of the problem and finding a maximal independent set of vertices for the graph. The approach is tested on a scenarios of up to 10,000 requested imaging locations for the Skysat constellation of optical satellites as well as simulated constellations of up to 24 satellites. Performance is compared with contemporary graph-traversal and mixed-integer linear programming approaches. Empirical results demonstrate improvements in both the solution time along with the number of scheduled collections beyond baseline methods. For large problems, the maximum independent set approach is able find a feasible schedule with 8% more collections in 75% less time.", "pdf_url": "https://arxiv.org/pdf/2008.08446", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "SegCodeNet: Color-Coded Segmentation Masks for Activity Detection from Wearable Cameras", "author": "Asif Shahriyar Sushmit, Partho Ghosh, Md.Abrar Istiak, Nayeeb Rashid, Ahsan Habib Akash, Taufiq Hasan", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Activity detection from first-person videos (FPV) captured using a wearable camera is an active research field with potential applications in many sectors, including healthcare, law enforcement, and rehabilitation. State-of-the-art methods use optical flow-based hybrid techniques that rely on features derived from the motion of objects from consecutive frames. In this work, we developed a two-stream network, the \\emph{SegCodeNet}, that uses a network branch containing video-streams with color-coded semantic segmentation masks of relevant objects in addition to the original RGB video-stream. We also include a stream-wise attention gating that prioritizes between the two streams and a frame-wise attention module that prioritizes the video frames that contain relevant features. Experiments are conducted on an FPV dataset containing $18$ activity classes in office environments. In comparison to a single-stream network, the proposed two-stream method achieves an absolute improvement of $14.366\\%$ and $10.324\\%$ for averaged F1 score and accuracy, respectively, when average results are compared for three different frame sizes $224\\times224$, $112\\times112$, and $64\\times64$. The proposed method provides significant performance gains for lower-resolution images with absolute improvements of $17\\%$ and $26\\%$ in F1 score for input dimensions of $112\\times112$ and $64\\times64$, respectively. The best performance is achieved for a frame size of $224\\times224$ yielding an F1 score and accuracy of $90.176\\%$ and $90.799\\%$ which outperforms the state-of-the-art Inflated 3D ConvNet (I3D) \\cite{carreira2017quo} method by an absolute margin of $4.529\\%$ and $2.419\\%$, respectively.", "pdf_url": "https://arxiv.org/pdf/2008.08452", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Statistical CSI based Design for Intelligent Reflecting Surface Assisted MISO Systems", "author": "Xiaoling Hu, Junwei Wang, Caijun Zhong", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper considers an intelligent reflecting surface (IRS) aided multiple-input single-output communication system, where statistical channel state information (CSI) is exploited for transmit beamforming and IRS beamforming. A tight upper bound is derived for the ergodic capacity of the system. Based on which, the joint optimization of transmit beam and IRS beam are studied. Depending on whether a line-of-sight path exists between the access point and user, two different cases, namely, Rician fading and Rayleigh fading, are separately treated. Specifically, for the Rician fading case, an iterative algorithm is proposed, which is guaranteed to converge. For the Rayleigh fading case, closed-form designs are obtained for the transmit beam and IRS beam. Simulation results show the proposed beamforming scheme achieves similar performance as the benchmark algorithm requiring instantaneous CSI.", "pdf_url": "https://arxiv.org/pdf/2008.08453", "subject": "Information Theory (cs.IT)"},
{"title": "Designing inverse dynamic controller with integral action for motion planning of surgical robot in the presence of bounded disturbances", "author": "AA. Ghavifekr, MA Badamchizadeh, G Alizadeh, A Arjmandi", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Robotic laparoscopic grasper is a surgical tool with minimal invasion. In this robot, achieve goals like precise tracking, stability and disturbance rejection are very important. In this paper, first the stages of modeling and simulating of laparoscopic robot will be discussed and the reasons for selecting the appropriate materials for different parts of proposed practical robot will be explained. Inverse dynamic controller with integral action is applied to improve the accuracy of tracking procedure for a surgical manipulator to track a specified reference signal in the presence of tremor that is modeled as constant bounded disturbance. Based on the disturbance rejection scheme, tracking controller is constructed which is asymptotically stabilizing in the sense of Lyapunov. It is shown that how under proper assumptions; the selected schemes succeed in achieving disturbance rejection at the input of a nonlinear system. Computer simulation results demonstrate that accurate trajectory tracking can be achieved by using the proposed controller.", "pdf_url": "https://arxiv.org/pdf/2008.08456", "subject": "Systems and Control (eess.SY)"},
{"title": "Reconfigurable Intelligent Surfaces Aided Multi-Cell NOMA Networks: A Stochastic Geometry Model", "author": "Chao Zhang, Wenqiang Yi, Yuanwei Liu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "By activating blocked users and altering successive interference cancellation (SIC) sequences, reconfigurable intelligent surfaces (RISs) become promising for enhancing non-orthogonal multiple access (NOMA) systems. The downlink RIS-aided NOMA networks are investigated via stochastic geometry. We first introduce the unique path loss model for RIS reflecting channels. Then, we evaluate the angle distributions based on a Poisson cluster process (PCP) model, which theoretically demonstrates that the angles of incidence and reflection are uniformly distributed. Additionally, we derive closed-form analytical and asymptotic expressions for coverage probabilities of the paired NOMA users. Lastly, we derive the analytical expressions of the ergodic rate for both of the paired NOMA users and calculate the asymptotic expressions for the typical user. The analytical results indicate that 1) the achievable rates reach an upper limit when the length of RIS increases; 2) exploiting RISs can enhance the path loss intercept to improve the performance without influencing the bandwidth. Our results show that 1) RIS-aided NOMA networks have superior performance than the conventional NOMA networks, and 2) the SIC order in NOMA systems can be altered since RISs are able to change the channel quality of NOMA users.", "pdf_url": "https://arxiv.org/pdf/2008.08457", "subject": "Information Theory (cs.IT)"},
{"title": "Relevance of Rotationally Equivariant Convolutions for Predicting Molecular Properties", "author": "Benjamin Kurt Miller, Mario Geiger, Tess E. Smidt, Frank No\u00e9", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Equivariant neural networks (ENNs) are graph neural networks embedded in $\\mathbb{R}^3$ and are well suited for predicting molecular properties. The ENN library e3nn has customizable convolutions, which can be designed to depend only on distances between points, or also on angular features, making them rotationally invariant, or equivariant, respectively. This paper studies the practical value of including angular dependencies for molecular property prediction using the QM9 data set. We find that for fixed network depth, adding angular features improves the accuracy on most targets. For most, but not all, molecular properties, distance-only e3nns (L0Nets) can compensate by increasing convolutional layer depth. Our angular-feature e3nn (L1Net) architecture beats previous state-of-the-art results on the global electronic properties dipole moment, isotropic polarizability, and electronic spatial extent.", "pdf_url": "https://arxiv.org/pdf/2008.08461", "subject": "Machine Learning (cs.LG)"},
{"title": "CosyPose: Consistent multi-view multi-object 6D pose estimation", "author": "Yann Labb\u00e9, Justin Carpentier, Mathieu Aubry, Josef Sivic", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We introduce an approach for recovering the 6D pose of multiple known objects in a scene captured by a set of input images with unknown camera viewpoints. First, we present a single-view single-object 6D pose estimation method, which we use to generate 6D object pose hypotheses. Second, we develop a robust method for matching individual 6D object pose hypotheses across different input images in order to jointly estimate camera viewpoints and 6D poses of all objects in a single consistent scene. Our approach explicitly handles object symmetries, does not require depth measurements, is robust to missing or incorrect object hypotheses, and automatically recovers the number of objects in the scene. Third, we develop a method for global scene refinement given multiple object hypotheses and their correspondences across views. This is achieved by solving an object-level bundle adjustment problem that refines the poses of cameras and objects to minimize the reprojection error in all views. We demonstrate that the proposed method, dubbed CosyPose, outperforms current state-of-the-art results for single-view and multi-view 6D object pose estimation by a large margin on two challenging benchmarks: the YCB-Video and T-LESS datasets. Code and pre-trained models are available on the project webpage .", "pdf_url": "https://arxiv.org/pdf/2008.08465", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Cross-Domain Identification for Thermal-to-Visible Face Recognition", "author": "Cedric Nimpa Fondje, Shuowen Hu, Nathaniel J. Short, Benjamin S. Riggan", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Recent advances in domain adaptation, especially those applied to heterogeneous facial recognition, typically rely upon restrictive Euclidean loss functions (e.g., $L_2$ norm) which perform best when images from two different domains (e.g., visible and thermal) are co-registered and temporally synchronized. This paper proposes a novel domain adaptation framework that combines a new feature mapping sub-network with existing deep feature models, which are based on modified network architectures (e.g., VGG16 or Resnet50). This framework is optimized by introducing new cross-domain identity and domain invariance loss functions for thermal-to-visible face recognition, which alleviates the requirement for precisely co-registered and synchronized imagery. We provide extensive analysis of both features and loss functions used, and compare the proposed domain adaptation framework with state-of-the-art feature based domain adaptation models on a difficult dataset containing facial imagery collected at varying ranges, poses, and expressions. Moreover, we analyze the viability of the proposed framework for more challenging tasks, such as non-frontal thermal-to-visible face recognition.", "pdf_url": "https://arxiv.org/pdf/2008.08473", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Human Body Model Fitting by Learned Gradient Descent", "author": "Jie Song, Xu Chen, Otmar Hilliges", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We propose a novel algorithm for the fitting of 3D human shape to images. Combining the accuracy and refinement capabilities of iterative gradient-based optimization techniques with the robustness of deep neural networks, we propose a gradient descent algorithm that leverages a neural network to predict the parameter update rule for each iteration. This per-parameter and state-aware update guides the optimizer towards a good solution in very few steps, converging in typically few steps. During training our approach only requires MoCap data of human poses, parametrized via SMPL. From this data the network learns a subspace of valid poses and shapes in which optimization is performed much more efficiently. The approach does not require any hard to acquire image-to-3D correspondences. At test time we only optimize the 2D joint re-projection error without the need for any further priors or regularization terms. We show empirically that this algorithm is fast (avg. 120ms convergence), robust to initialization and dataset, and achieves state-of-the-art results on public evaluation datasets including the challenging 3DPW in-the-wild benchmark (improvement over SMPLify 45%) and also approaches using image-to-3D correspondences", "pdf_url": "https://arxiv.org/pdf/2008.08474", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "NASCaps: A Framework for Neural Architecture Search to Optimize the Accuracy and Hardware Efficiency of Convolutional Capsule Networks", "author": "Alberto Marchisio, Andrea Massa, Vojtech Mrazek, Beatrice Bussolino, Maurizio Martina, Muhammad Shafique", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Deep Neural Networks (DNNs) have made significant improvements to reach the desired accuracy to be employed in a wide variety of Machine Learning (ML) applications. Recently the Google Brain's team demonstrated the ability of Capsule Networks (CapsNets) to encode and learn spatial correlations between different input features, thereby obtaining superior learning capabilities compared to traditional (i.e., non-capsule based) DNNs. However, designing CapsNets using conventional methods is a tedious job and incurs significant training effort. Recent studies have shown that powerful methods to automatically select the best/optimal DNN model configuration for a given set of applications and a training dataset are based on the Neural Architecture Search (NAS) algorithms. Moreover, due to their extreme computational and memory requirements, DNNs are employed using the specialized hardware accelerators in IoT-Edge/CPS devices. In this paper, we propose NASCaps, an automated framework for the hardware-aware NAS of different types of DNNs, covering both traditional convolutional DNNs and CapsNets. We study the efficacy of deploying a multi-objective Genetic Algorithm (e.g., based on the NSGA-II algorithm). The proposed framework can jointly optimize the network accuracy and the corresponding hardware efficiency, expressed in terms of energy, memory, and latency of a given hardware accelerator executing the DNN inference. Besides supporting the traditional DNN layers, our framework is the first to model and supports the specialized capsule layers and dynamic routing in the NAS-flow. We evaluate our framework on different datasets, generating different network configurations, and demonstrate the tradeoffs between the different output metrics. We will open-source the complete framework and configurations of the Pareto-optimal architectures at .", "pdf_url": "https://arxiv.org/pdf/2008.08476", "subject": "Machine Learning (cs.LG)"},
{"title": "Evaluating the Performance of NVIDIA's A100 Ampere GPU for Sparse Linear Algebra Computations", "author": "Yuhsiang Mike Tsai, Terry Cojean, Hartwig Anzt", "pub_date": "Submitted on 19 Aug 2020", "abstract": "GPU accelerators have become an important backbone for scientific high performance computing, and the performance advances obtained from adopting new GPU hardware are significant. In this paper we take a first look at NVIDIA's newest server line GPU, the A100 architecture part of the Ampere generation. Specifically, we assess its performance for sparse linear algebra operations that form the backbone of many scientific applications and assess the performance improvements over its predecessor.", "pdf_url": "https://arxiv.org/pdf/2008.08478", "subject": "Mathematical Software (cs.MS)"},
{"title": "Simple Counting and Sampling Algorithms for Graphs with Bounded Pathwidth", "author": "Christine T. Cheng, Will Rosenbaum", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In this paper, we consider the problem of counting and sampling structures in graphs. We define a class of \"edge universal labeling problems\"---which include proper $k$-colorings, independent sets, and downsets---and describe simple algorithms for counting and uniformly sampling valid labelings of graphs, assuming a path decomposition is given. Thus, we show that several well-studied counting and sampling problems are fixed parameter tractable (FPT) when parameterized by the pathwidth of the input graph. We discuss connections to counting and sampling problems for distributive lattices and, in particular, we give a new FPT algorithm for exactly counting and uniformly sampling stable matchings.", "pdf_url": "https://arxiv.org/pdf/2008.08479", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Stable Matchings with Restricted Preferences: Structure and Complexity", "author": "Christine T. Cheng, Will Rosenbaum", "pub_date": "Submitted on 19 Aug 2020", "abstract": "It is well known that every stable matching instance $I$ has a \\emph{rotation poset} $R(I)$ that can be computed efficiently and the downsets of $R(I)$ are in one-to-one correspondence with the stable matchings of $I$. Furthermore, for every poset $P$, an instance $I(P)$ can be constructed efficiently so that the rotation poset of $I(P)$ is isomorphic to $P$. In this case, we say that $I(P)$ \\emph{realizes} $P$. Many researchers exploit the rotation poset of an instance to develop fast algorithms or to establish the hardness of stable matching problems. To make the problem of sampling stable matchings more tractable, Bhatnagar et al. [SODA 2008] introduced stable matching instances whose preference lists are restricted but nevertheless model situations that arise in practice. In this paper, we study four such parameterized restrictions; our goal is to characterize the rotation posets that arise from these models: $k$-bounded, $k$-attribute, $(k_1, k_2)$-list, $k$-range. We prove that there is a constant $k$ so that \\emph{every} rotation poset is realized by some instance in the first three models for some fixed constant $k$. We describe efficient algorithms for constructing such instances given the Hasse diagram of a poset. As a consequence, the fundamental problem of counting stable matchings remains $\\#$BIS-complete even for these restricted instances. For $k$-range preferences, we show that a poset $P$ is realizable if and only if the Hasse diagram of $P$ has pathwidth bounded by functions of $k$. Using this characterization, we show that the following problems are fixed parameter tractable when parametrized by the range of the instance: exactly counting and uniformly sampling stable matchings, finding median, sex-equal, and balanced stable matchings.", "pdf_url": "https://arxiv.org/pdf/2008.08480", "subject": "Discrete Mathematics (cs.DM)"},
{"title": "A Finite Volume Method for Continuum Limit Equations of Nonlocally Interacting Active Chiral Particles", "author": "Nikita Kruk, Jos\u00e9 A. Carrillo, Heinz Koeppl", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The continuum description of active particle systems is an efficient instrument to analyze a finite size particle dynamics in the limit of a large number of particles. However, it is often the case that such equations appear as nonlinear integro-differential equations and purely analytical treatment becomes quite limited. We propose a general framework of finite volume methods (FVMs) to numerically solve partial differential equations (PDEs) of the continuum limit of nonlocally interacting chiral active particle systems confined to two dimensions. We demonstrate the performance of the method on spatially homogeneous problems, where the comparison to analytical results is available, and on general spatially inhomogeneous equations, where pattern formation is predicted by kinetic theory. We numerically investigate phase transitions of particular problems in both spatially homogeneous and inhomogeneous regimes and report the existence of different first and second order transitions.", "pdf_url": "https://arxiv.org/pdf/2008.08493", "subject": "Numerical Analysis (math.NA)"},
{"title": "Reinforcement Learning for Low-Thrust Trajectory Design of Interplanetary Missions", "author": "Alessandro Zavoli, Lorenzo Federici", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper investigates the use of Reinforcement Learning for the robust design of low-thrust interplanetary trajectories in presence of severe disturbances, modeled alternatively as Gaussian additive process noise, observation noise, control actuation errors on thrust magnitude and direction, and possibly multiple missed thrust events. The optimal control problem is recast as a time-discrete Markov Decision Process to comply with the standard formulation of reinforcement learning. An open-source implementation of the state-of-the-art algorithm Proximal Policy Optimization is adopted to carry out the training process of a deep neural network, used to map the spacecraft (observed) states to the optimal control policy. The resulting Guidance and Control Network provides both a robust nominal trajectory and the associated closed-loop guidance law. Numerical results are presented for a typical Earth-Mars mission. First, in order to validate the proposed approach, the solution found in a (deterministic) unperturbed scenario is compared with the optimal one provided by an indirect technique. Then, the robustness and optimality of the obtained closed-loop guidance laws is assessed by means of Monte Carlo campaigns performed in the considered uncertain scenarios. These preliminary results open up new horizons for the use of reinforcement learning in the robust design of interplanetary missions.", "pdf_url": "https://arxiv.org/pdf/2008.08501", "subject": "Machine Learning (cs.LG)"},
{"title": "Learning Trailer Moments in Full-Length Movies", "author": "Lezi Wang, Dong Liu, Rohit Puri, Dimitris N. Metaxas", "pub_date": "Submitted on 19 Aug 2020", "abstract": "A movie's key moments stand out of the screenplay to grab an audience's attention and make movie browsing efficient. But a lack of annotations makes the existing approaches not applicable to movie key moment detection. To get rid of human annotations, we leverage the officially-released trailers as the weak supervision to learn a model that can detect the key moments from full-length movies. We introduce a novel ranking network that utilizes the Co-Attention between movies and trailers as guidance to generate the training pairs, where the moments highly corrected with trailers are expected to be scored higher than the uncorrelated moments. Additionally, we propose a Contrastive Attention module to enhance the feature representations such that the comparative contrast between features of the key and non-key moments are maximized. We construct the first movie-trailer dataset, and the proposed Co-Attention assisted ranking network shows superior performance even over the supervised approach. The effectiveness of our Contrastive Attention module is also demonstrated by the performance improvement over the state-of-the-art on the public benchmarks.", "pdf_url": "https://arxiv.org/pdf/2008.08502", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Novel Results on the Number of Runs of the Burrows-Wheeler-Transform", "author": "Sara Giuliani, Shunsuke Inenaga, Zsuzsanna Lipt\u00e1k, Nicola Prezza, Marinella Sciortino, Anna Toffanello", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The Burrows-Wheeler-Transform (BWT), a reversible string transformation, is one of the fundamental components of many current data structures in string processing. It is central in data compression, as well as in efficient query algorithms for sequence data, such as webpages, genomic and other biological sequences, or indeed any textual data. The BWT lends itself well to compression because its number of equal-letter-runs (usually referred to as $r$) is often considerably lower than that of the original string; in particular, it is well suited for strings with many repeated factors. In fact, much attention has been paid to the $r$ parameter as measure of repetitiveness, especially to evaluate the performance in terms of both space and time of compressed indexing data structures. In this paper, we investigate $\\rho(v)$, the ratio of $r$ and of the number of runs of the BWT of the reverse of $v$. Kempa and Kociumaka [FOCS 2020] gave the first non-trivial upper bound as $\\rho(v) = O(\\log^2(n))$, for any string $v$ of length $n$. However, nothing is known about the tightness of this upper bound. We present infinite families of binary strings for which $\\rho(v) = \\Theta(\\log n)$ holds, thus giving the first non-trivial lower bound on $\\rho(n)$, the maximum over all strings of length $n$. Our results suggest that $r$ is not an ideal measure of the repetitiveness of the string, since the number of repeated factors is invariant between the string and its reverse. We believe that there is a more intricate relationship between the number of runs of the BWT and the string's combinatorial properties.", "pdf_url": "https://arxiv.org/pdf/2008.08506", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Quality tetrahedral mesh generation with HXT", "author": "C\u00e9lestin Marot, Jean-Fran\u00e7ois Remacle", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We proposed, in a recent paper ( ), a fast 3D parallel Delaunay kernel for tetrahedral mesh generation. This kernel was however incomplete in the sense that it lacked the necessary mesh improvement tools. The present paper builds on that previous work and proposes a fast parallel mesh improvement stage that delivers high-quality tetrahedral meshes compared to alternative open-source mesh generators. Our mesh improvement toolkit includes edge removal and improved Laplacian smoothing as well as a brand new operator called the Growing SPR Cavity, which can be regarded as the mother of all flips. The paper describes the workflow of the new mesh improvement schedule, as well as the details of the implementation. The result of this research is a series of open-source scalable software components, called HXT, whose overall efficiency is demonstrated on practical examples by means of a detailed comparative benchmark with two open-source mesh generators: Gmsh and TetGen.", "pdf_url": "https://arxiv.org/pdf/2008.08508", "subject": "Computational Geometry (cs.CG)"},
{"title": "FIRM: An Intelligent Fine-Grained Resource Management Framework for SLO-Oriented Microservices", "author": "Haoran Qiu, Subho S. Banerjee, Saurabh Jha, Zbigniew T. Kalbarczyk, Ravishankar K. Iyer", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Modern user-facing, latency-sensitive web services include numerous distributed, intercommunicating microservices that promise to simplify software development and operation. However, multiplexing compute-resources across microservices is still challenging in production because contention for shared resources can cause latency spikes that violate the service-level objectives (SLOs) of user requests. This paper presents FIRM, an intelligent fine-grained resource management framework for predictable sharing of resources across microservices to drive up overall utilization. FIRM leverages online telemetry data and machine-learning methods to adaptively (a) detect/localize microservices that cause SLO-violations, (b) identify low-level resources in contention, and (c) take actions to mitigate SLO-violations by dynamic reprovisioning. Experiments across four microservice benchmarks demonstrate that FIRM reduces SLO violations by up to 16x while reducing the overall requested CPU limit by up to 62%. Moreover, FIRM improves performance predictability by reducing tail latencies by up to 11x.", "pdf_url": "https://arxiv.org/pdf/2008.08509", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Automated Machine Learning -- a brief review at the end of the early years", "author": "Hugo Jair Escalante", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Automated machine learning (AutoML) is the sub-field of machine learning that aims at automating, to some extend, all stages of the design of a machine learning system. In the context of supervised learning, AutoML is concerned with feature extraction, pre processing, model design and post processing. Major contributions and achievements in AutoML have been taking place during the recent decade. We are therefore in perfect timing to look back and realize what we have learned. This chapter aims to summarize the main findings in the early years of AutoML. More specifically, in this chapter an introduction to AutoML for supervised learning is provided and an historical review of progress in this field is presented. Likewise, the main paradigms of AutoML are described and research opportunities are outlined.", "pdf_url": "https://arxiv.org/pdf/2008.08516", "subject": "Machine Learning (cs.LG)"},
{"title": "Demand Forecasting using Long Short-Term Memory Neural Networks", "author": "Marta Go\u0142\u0105bek, Robin Senge, Rainer Neumann", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In this paper we investigate to what extent long short-term memory neural networks (LSTMs) are suitable for demand forecasting in the e-grocery retail sector. For this purpose, univariate as well as multivariate LSTM-based models were developed and tested for 100 fast-moving consumer goods in the context of a master's thesis. On average, the developed models showed better results for food products than the comparative models from both statistical and machine learning families. Solely in the area of beverages random forest and linear regression achieved slightly better results. This outcome suggests that LSTMs can be used for demand forecasting at product level. The performance of the models presented here goes beyond the current state of research, as can be seen from the evaluations based on a data set that unfortunately has not been publicly available to date.", "pdf_url": "https://arxiv.org/pdf/2008.08522", "subject": "Machine Learning (cs.LG)"},
{"title": "Scene Text Detection with Selected Anchor", "author": "Anna Zhu, Hang Du, Shengwu Xiong", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Object proposal technique with dense anchoring scheme for scene text detection were applied frequently to achieve high recall. It results in the significant improvement in accuracy but waste of computational searching, regression and classification. In this paper, we propose an anchor selection-based region proposal network (AS-RPN) using effective selected anchors instead of dense anchors to extract text proposals. The center, scales, aspect ratios and orientations of anchors are learnable instead of fixing, which leads to high recall and greatly reduced numbers of anchors. By replacing the anchor-based RPN in Faster RCNN, the AS-RPN-based Faster RCNN can achieve comparable performance with previous state-of-the-art text detecting approaches on standard benchmarks, including COCO-Text, ICDAR2013, ICDAR2015 and MSRA-TD500 when using single-scale and single model (ResNet50) testing only.", "pdf_url": "https://arxiv.org/pdf/2008.08523", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Tractable Inference in Credal Sentential Decision Diagrams", "author": "Lilith Mattei, Alessandro Antonucci, Denis Deratani Mau\u00e1, Alessandro Facchini, Julissa Villanueva Llerena", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Probabilistic sentential decision diagrams are logic circuits where the inputs of disjunctive gates are annotated by probability values. They allow for a compact representation of joint probability mass functions defined over sets of Boolean variables, that are also consistent with the logical constraints defined by the circuit. The probabilities in such a model are usually learned from a set of observations. This leads to overconfident and prior-dependent inferences when data are scarce, unreliable or conflicting. In this work, we develop the credal sentential decision diagrams, a generalisation of their probabilistic counterpart that allows for replacing the local probabilities with (so-called credal) sets of mass functions. These models induce a joint credal set over the set of Boolean variables, that sharply assigns probability zero to states inconsistent with the logical constraints. Three inference algorithms are derived for these models, these allow to compute: (i) the lower and upper probabilities of an observation for an arbitrary number of variables; (ii) the lower and upper conditional probabilities for the state of a single variable given an observation; (iii) whether or not all the probabilistic sentential decision diagrams compatible with the credal specification have the same most probable explanation of a given set of variables given an observation of the other variables. These inferences are tractable, as all the three algorithms, based on bottom-up traversal with local linear programming tasks on the disjunctive gates, can be solved in polynomial time with respect to the circuit size. For a first empirical validation, we consider a simple application based on noisy seven-segment display images. The credal models are observed to properly distinguish between easy and hard-to-detect instances and outperform other generative models not able to cope with logical constraints.", "pdf_url": "https://arxiv.org/pdf/2008.08524", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Black Re-ID: A Head-shoulder Descriptor for the Challenging Problem of Person Re-Identification", "author": "Boqiang Xu, Lingxiao He, Xingyu Liao, Wu Liu, Zhenan Sun, Tao Mei", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Person re-identification (Re-ID) aims at retrieving an input person image from a set of images captured by multiple cameras. Although recent Re-ID methods have made great success, most of them extract features in terms of the attributes of clothing (e.g., color, texture). However, it is common for people to wear black clothes or be captured by surveillance systems in low light illumination, in which cases the attributes of the clothing are severely missing. We call this problem the Black Re-ID problem. To solve this problem, rather than relying on the clothing information, we propose to exploit head-shoulder features to assist person Re-ID. The head-shoulder adaptive attention network (HAA) is proposed to learn the head-shoulder feature and an innovative ensemble method is designed to enhance the generalization of our model. Given the input person image, the ensemble method would focus on the head-shoulder feature by assigning a larger weight if the individual insides the image is in black clothing. Due to the lack of a suitable benchmark dataset for studying the Black Re-ID problem, we also contribute the first Black-reID dataset, which contains 1274 identities in training set. Extensive evaluations on the Black-reID, Market1501 and DukeMTMC-reID datasets show that our model achieves the best result compared with the state-of-the-art Re-ID methods on both Black and conventional Re-ID problems. Furthermore, our method is also proved to be effective in dealing with person Re-ID in similar clothing. Our code and dataset are avaliable on .", "pdf_url": "https://arxiv.org/pdf/2008.08528", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "The Transpension Type: Technical Report", "author": "Andreas Nuyts", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The purpose of these notes is to give a categorical semantics for the transpension type (Nuyts and Devriese, Transpension: The Right Adjoint to the Pi-type, pre-print, 2020), which is right adjoint to a potentially substructural dependent function type. In section 2 we discuss some prerequisites. In section 3, we define multipliers and discuss their properties. In section 4, we study how multipliers lift from base categories to presheaf categories. In section 5, we explain how typical presheaf modalities can be used in the presence of the transpension type. In section 6, we study commutation properties of prior modalities, substitution modalities and multiplier modalities.", "pdf_url": "https://arxiv.org/pdf/2008.08530", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "Transpension: The Right Adjoint to the Pi-type", "author": "Andreas Nuyts, Dominique Devriese", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Presheaf models of dependent type theory have been successfully applied to model HoTT, parametricity, and directed, guarded and nominal type theory. There has been considerable interest in internalizing aspects of these presheaf models, either to make the resulting language more expressive, or in order to carry out further reasoning internally, allowing greater abstraction and sometimes automated verification. While the constructions of presheaf models largely follow a common pattern, approaches towards internalization do not. Throughout the literature, various internal presheaf operators ($\\surd$, $\\Phi/\\mathsf{extent}$, $\\Psi/\\mathsf{Gel}$, $\\mathsf{Glue}$, $\\mathsf{Weld}$, $\\mathsf{mill}$, the strictness axiom and locally fresh names) can be found and little is known about their relative expressivenes. Moreover, some of these require that variables whose type is a shape (representable presheaf, e.g. an interval) be used affinely. We propose a novel type former, the transpension type, which is right adjoint to universal quantification over a shape. Its structure resembles a dependent version of the suspension type in HoTT. We give general typing rules and a presheaf semantics in terms of base category functors dubbed multipliers. Structural rules for shape variables and certain aspects of the transpension type depend on characteristics of the multiplier. We demonstrate how the transpension type and the strictness axiom can be combined to implement all and improve some of the aforementioned internalization operators (without formal claim in the case of locally fresh names).", "pdf_url": "https://arxiv.org/pdf/2008.08533", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "STAR: Sparse Trained Articulated Human Body Regressor", "author": "Ahmed A. A. Osman, Timo Bolkart, Michael J. Black", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The SMPL body model is widely used for the estimation, synthesis, and analysis of 3D human pose and shape. While popular, we show that SMPL has several limitations and introduce STAR, which is quantitatively and qualitatively superior to SMPL. First, SMPL has a huge number of parameters resulting from its use of global blend shapes. These dense pose-corrective offsets relate every vertex on the mesh to all the joints in the kinematic tree, capturing spurious long-range correlations. To address this, we define per-joint pose correctives and learn the subset of mesh vertices that are influenced by each joint movement. This sparse formulation results in more realistic deformations and significantly reduces the number of model parameters to 20% of SMPL. When trained on the same data as SMPL, STAR generalizes better despite having many fewer parameters. Second, SMPL factors pose-dependent deformations from body shape while, in reality, people with different shapes deform differently. Consequently, we learn shape-dependent pose-corrective blend shapes that depend on both body pose and BMI. Third, we show that the shape space of SMPL is not rich enough to capture the variation in the human population. We address this by training STAR with an additional 10,000 scans of male and female subjects, and show that this results in better model generalization. STAR is compact, generalizes better to new bodies and is a drop-in replacement for SMPL. STAR is publicly available for research purposes at .", "pdf_url": "https://arxiv.org/pdf/2008.08535", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Survey of Knowledge-based Sequential Decision Making under Uncertainty", "author": "Shiqi Zhang, Mohan Sridharan", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Reasoning with declarative knowledge (RDK) and sequential decision-making (SDM) are two key research areas in artificial intelligence. RDK methods reason with declarative domain knowledge, including commonsense knowledge, that is either provided a priori or acquired over time, while SDM methods (probabilistic planning and reinforcement learning) seek to compute action policies that maximize the expected cumulative utility over a time horizon; both classes of methods reason in the presence of uncertainty. Despite the rich literature in these two areas, researchers have not fully explored their complementary strengths. In this paper, we survey algorithms that leverage RDK methods while making sequential decisions under uncertainty. We discuss significant developments, open problems, and directions for future work.", "pdf_url": "https://arxiv.org/pdf/2008.08548", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Popularity Bias in Recommendation: A Multi-stakeholder Perspective", "author": "Himan Abdollahpouri", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Traditionally, especially in academic research in recommender systems, the focus has been solely on the satisfaction of the end-user. While user satisfaction has, indeed, been associated with the success of the business, it is not the only factor. In many recommendation domains, there are other stakeholders whose needs should be taken into account in the recommendation generation and evaluation. In this dissertation, I describe the notion of multi-stakeholder recommendation. In particular, I study one of the most important challenges in recommendation research, popularity bias, from a multi-stakeholder perspective since, as I show later in this dissertation, it impacts different stakeholders in a recommender system. Popularity bias is a well-known phenomenon in recommender systems where popular items are recommended even more frequently than their popularity would warrant, amplifying long-tail effects already present in many recommendation domains. Prior research has examined various approaches for mitigating popularity bias and enhancing the recommendation of long-tail items overall. The effectiveness of these approaches, however, has not been assessed in multi-stakeholder environments. In this dissertation, I study the impact of popularity bias in recommender systems from a multi-stakeholder perspective. In addition, I propose several algorithms each approaching the popularity bias mitigation from a different angle and compare their performances using several metrics with some other state-of-the-art approaches in the literature. I show that, often, the standard evaluation measures of popularity bias mitigation in the literature do not reflect the real picture of an algorithm's performance when it is evaluated from a multi-stakeholder point of view.", "pdf_url": "https://arxiv.org/pdf/2008.08551", "subject": "Information Retrieval (cs.IR)"},
{"title": "No-reference Quality Assessment with Unsupervised Domain Adaptation", "author": "Baoliang Chen, Haoliang Li, Hongfei Fan, Shiqi Wang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Quality assessment driven by machine learning generally relies on the strong assumption that the training and testing data share very close scene statistics, lacking the adaptation capacity to the content in other domains. In this paper, we quest the capability of transferring the quality of natural scene to the images that are not acquired by optical cameras (e.g., screen content images, SCIs), rooted in the widely accepted view that the human visual system has adapted and evolved through the perception of natural environment. Here we develop the first unsupervised domain adaptation based no reference quality assessment method, under the reasonable assumption that there are abundant subjective ratings of natural images (NIs). In general, it is a non-trivial task to directly transfer the quality prediction model from NIs to a new type of content (i.e., SCIs) that holds dramatically different statistical characteristics. Inspired by the transferability of pair-wise relationship, the proposed quality measure operates based on the philosophy of learning to rank. To reduce the domain gap, we introduce two complementary losses which explicitly regularize the feature space of ranking in a progressive manner. For feature discrepancy minimization, the maximum mean discrepancy (MMD) is imposed on the extracted ranking features of NIs and SCIs. For feature discriminatory capability enhancement, we propose a center based loss to rectify the classifier and improve its prediction capability not only for source domain (NI) but also the target domain (SCI). Experiments show that our method can achieve higher performance on different source-target settings based on a light-weight convolution neural network. The proposed method also sheds light on learning quality assessment measures for unseen application-specific content without the cumbersome and costing subjective evaluations.", "pdf_url": "https://arxiv.org/pdf/2008.08561", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Physically-Constrained Transfer Learning through Shared Abundance Space for Hyperspectral Image Classification", "author": "Ying Qu, Razieh Kaviani Baghbaderani, Wei Li, Lianru Gao, Hairong Qi", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Hyperspectral image (HSI) classification is one of the most active research topics and has achieved promising results boosted by the recent development of deep learning. However, most state-of-the-art approaches tend to perform poorly when the training and testing images are on different domains, e.g., source domain and target domain, respectively, due to the spectral variability caused by different acquisition conditions. Transfer learning-based methods address this problem by pre-training in the source domain and fine-tuning on the target domain. Nonetheless, a considerable amount of data on the target domain has to be labeled and non-negligible computational resources are required to retrain the whole network. In this paper, we propose a new transfer learning scheme to bridge the gap between the source and target domains by projecting the HSI data from the source and target domains into a shared abundance space based on their own physical characteristics. In this way, the domain discrepancy would be largely reduced such that the model trained on the source domain could be applied on the target domain without extra efforts for data labeling or network retraining. The proposed method is referred to as physically-constrained transfer learning through shared abundance space (PCTL-SAS). Extensive experimental results demonstrate the superiority of the proposed method as compared to the state-of-the-art. The success of this endeavor would largely facilitate the deployment of HSI classification for real-world sensing scenarios.", "pdf_url": "https://arxiv.org/pdf/2008.08563", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Analog Lagrange Coded Computing", "author": "Mahdi Soleymani, Hessam Mahdavifar, A. Salman Avestimehr", "pub_date": "Submitted on 19 Aug 2020", "abstract": "A distributed computing scenario is considered, where the computational power of a set of worker nodes is used to perform a certain computation task over a dataset that is dispersed among the workers. Lagrange coded computing (LCC), proposed by Yu et al., leverages the well-known Lagrange polynomial to perform polynomial evaluation of the dataset in such a scenario in an efficient parallel fashion while keeping the privacy of data amidst possible collusion of workers. This solution relies on quantizing the data into a finite field, so that Shamir's secret sharing, as one of its main building blocks, can be employed. Such a solution, however, is not properly scalable with the size of dataset, mainly due to computation overflows. To address such a critical issue, we propose a novel extension of LCC to the analog domain, referred to as analog LCC (ALCC). All the operations in the proposed ALCC protocol are done over the infinite fields of R/C but for practical implementations floating-point numbers are used. We characterize the privacy of data in ALCC, against any subset of colluding workers up to a certain size, in terms of the distinguishing security (DS) and the mutual information security (MIS) metrics. Also, the accuracy of outcome is characterized in a practical setting assuming operations are performed using floating-point numbers. Consequently, a fundamental trade-off between the accuracy of the outcome of ALCC and its privacy level is observed and is numerically evaluated. Moreover, we implement the proposed scheme to perform matrix-matrix multiplication over a batch of matrices. It is observed that ALCC is superior compared to the state-of-the-art LCC, implemented using fixed-point numbers, assuming both schemes use an equal number of bits to represent data symbols.", "pdf_url": "https://arxiv.org/pdf/2008.08565", "subject": "Information Theory (cs.IT)"},
{"title": "Transformer based Multilingual document Embedding model", "author": "Wei Li, Brian Mak", "pub_date": "Submitted on 19 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "One of the current state-of-the-art multilingual document embedding model LASER is based on the bidirectional LSTM neural machine translation model. This paper presents a transformer-based sentence/document embedding model, T-LASER, which makes three significant improvements. Firstly, the BiLSTM layers is replaced by the attention-based transformer layers, which is more capable of learning sequential patterns in longer texts. Secondly, due to the absence of recurrence, T-LASER enables faster parallel computations in the encoder to generate the text embedding. Thirdly, we augment the NMT translation loss function with an additional novel distance constraint loss. This distance constraint loss would further bring the embeddings of parallel sentences close together in the vector space; we call the T-LASER model trained with distance constraint, cT-LASER. Our cT-LASER model significantly outperforms both BiLSTM-based LASER and the simpler transformer-based T-LASER.", "pdf_url": "https://arxiv.org/pdf/2008.08567", "subject": "Computation and Language (cs.CL)"},
{"title": "Every Pixel Matters: Center-aware Feature Alignment for Domain Adaptive Object Detector", "author": "Cheng-Chun Hsu, Yi-Hsuan Tsai, Yen-Yu Lin, Ming-Hsuan Yang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "A domain adaptive object detector aims to adapt itself to unseen domains that may contain variations of object appearance, viewpoints or backgrounds. Most existing methods adopt feature alignment either on the image level or instance level. However, image-level alignment on global features may tangle foreground/background pixels at the same time, while instance-level alignment using proposals may suffer from the background noise. Different from existing solutions, we propose a domain adaptation framework that accounts for each pixel via predicting pixel-wise objectness and centerness. Specifically, the proposed method carries out center-aware alignment by paying more attention to foreground pixels, hence achieving better adaptation across domains. We demonstrate our method on numerous adaptation settings with extensive experimental results and show favorable performance against existing state-of-the-art algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.08574", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Simple Deterministic Algorithm for Edge Connectivity", "author": "Thatchaphol Saranurak", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We show a deterministic algorithm for computing edge connectivity of a simple graph with $m$ edges in $m^{1+o(1)}$ time. Although the fastest deterministic algorithm by Henzinger, Rao, and Wang [SODA'17] has a faster running time of $O(m\\log^{2}m\\log\\log m)$, we believe that our algorithm is conceptually simpler. The key tool for this simplication is the expander decomposition. We exploit it in a very straightforward way compared to how it has been previously used in the literature.", "pdf_url": "https://arxiv.org/pdf/2008.08575", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Large Associative Memory Problem in Neurobiology and Machine Learning", "author": "Dmitry Krotov, John Hopfield", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Dense Associative Memories or modern Hopfield networks permit storage and reliable retrieval of an exponentially large (in the dimension of feature space) number of memories. At the same time, their naive implementation is non-biological, since it seemingly requires the existence of many-body synaptic junctions between the neurons. We show that these models are effective descriptions of a more microscopic (written in terms of biological degrees of freedom) theory that has additional (hidden) neurons and only requires two-body interactions between them. For this reason our proposed microscopic theory is a valid model of large associative memory with a degree of biological plausibility. The dynamics of our network and its reduced dimensional equivalent both minimize energy (Lyapunov) functions. When certain dynamical variables (hidden neurons) are integrated out from our microscopic theory, one can recover many of the models that were previously discussed in the literature, e.g. the model presented in ''Hopfield Networks is All You Need'' paper. We also provide an alternative derivation of the energy function and the update rule proposed in the aforementioned paper and clarify the relationships between various models of this class.", "pdf_url": "https://arxiv.org/pdf/2008.06996", "subject": "Neurons and Cognition (q-bio.NC)"},
{"title": "Matchings, hypergraphs, association schemes, and semidefinite optimization", "author": "Yu Hin Au, Nathan Lindzey, Levent Tun\u00e7el", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We utilize association schemes to analyze the quality of semidefinite programming (SDP) based convex relaxations of integral packing and covering polyhedra determined by matchings in hypergraphs. As a by-product of our approach, we obtain bounds on the clique and stability numbers of some regular graphs reminiscent of classical bounds by Delsarte and Hoffman. We determine exactly or provide bounds on the performance of Lov\u00e1sz-Schrijver SDP hierarchy, and illustrate the usefulness of obtaining commutative subschemes from non-commutative schemes via contraction in this context.", "pdf_url": "https://arxiv.org/pdf/2008.08628", "subject": "Combinatorics (math.CO)"},
{"title": "SODEN: A Scalable Continuous-Time Survival Model through Ordinary Differential Equation Networks", "author": "Weijing Tang, Jiaqi Ma, Qiaozhu Mei, Ji Zhu", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In this paper, we propose a flexible model for survival analysis using neural networks along with scalable optimization algorithms. One key technical challenge for directly applying maximum likelihood estimation (MLE) to censored data is that evaluating the objective function and its gradients with respect to model parameters requires the calculation of integrals. To address this challenge, we recognize that the MLE for censored data can be viewed as a differential-equation constrained optimization problem, a novel perspective. Following this connection, we model the distribution of event time through an ordinary differential equation and utilize efficient ODE solvers and adjoint sensitivity analysis to numerically evaluate the likelihood and the gradients. Using this approach, we are able to 1) provide a broad family of continuous-time survival distributions without strong structural assumptions, 2) obtain powerful feature representations using neural networks, and 3) allow efficient estimation of the model in large-scale applications using stochastic gradient descent. Through both simulation studies and real-world data examples, we demonstrate the effectiveness of the proposed method in comparison to existing state-of-the-art deep learning survival analysis models.", "pdf_url": "https://arxiv.org/pdf/2008.08637", "subject": "Machine Learning (stat.ML)"},
{"title": "Context-aware Goodness of Pronunciation for Computer-Assisted Pronunciation Training", "author": "Jiatong Shi, Nan Huo, Qin Jin", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Mispronunciation detection is an essential component of the Computer-Assisted Pronunciation Training (CAPT) systems. State-of-the-art mispronunciation detection models use Deep Neural Networks (DNN) for acoustic modeling, and a Goodness of Pronunciation (GOP) based algorithm for pronunciation scoring. However, GOP based scoring models have two major limitations: i.e., (i) They depend on forced alignment which splits the speech into phonetic segments and independently use them for scoring, which neglects the transitions between phonemes within the segment; (ii) They only focus on phonetic segments, which fails to consider the context effects across phonemes (such as liaison, omission, incomplete plosive sound, etc.). In this work, we propose the Context-aware Goodness of Pronunciation (CaGOP) scoring model. Particularly, two factors namely the transition factor and the duration factor are injected into CaGOP scoring. The transition factor identifies the transitions between phonemes and applies them to weight the frame-wise GOP. Moreover, a self-attention based phonetic duration modeling is proposed to introduce the duration factor into the scoring model. The proposed scoring model significantly outperforms baselines, achieving 20% and 12% relative improvement over the GOP model on the phoneme-level and sentence-level mispronunciation detection respectively.", "pdf_url": "https://arxiv.org/pdf/2008.08647", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "A new role for circuit expansion for learning in neural networks", "author": "Julia Steinberg, Madhu Advani, Haim Sompolinsky", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Many sensory pathways in the brain rely on sparsely active populations of neurons downstream from the input stimuli. The biological reason for the occurrence of expanded structure in the brain is unclear, but may be because expansion can increase the expressive power of a neural network. In this work, we show that expanding a neural network can improve its generalization performance even in cases in which the expanded structure is pruned after the learning period. To study this setting we use a teacher-student framework where a perceptron teacher network generates labels which are corrupted with small amounts of noise. We then train a student network that is structurally matched to the teacher and can achieve optimal accuracy if given the teacher's synaptic weights. We find that sparse expansion of the input of a student perceptron network both increases its capacity and improves the generalization performance of the network when learning a noisy rule from a teacher perceptron when these expansions are pruned after learning. We find similar behavior when the expanded units are stochastic and uncorrelated with the input and analyze this network in the mean field limit. We show by solving the mean field equations that the generalization error of the stochastic expanded student network continues to drop as the size of the network increases. The improvement in generalization performance occurs despite the increased complexity of the student network relative to the teacher it is trying to learn. We show that this effect is closely related to the addition of slack variables in artificial neural networks and suggest possible implications for artificial and biological neural networks.", "pdf_url": "https://arxiv.org/pdf/2008.08653", "subject": "Disordered Systems and Neural Networks (cond-mat.dis-nn)"},
{"title": "Inner Cell Mass and Trophectoderm Segmentation in Human Blastocyst Images using Deep Neural Network", "author": "Md Yousuf Harun, Thomas Huang, Aaron T. Ohta", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Embryo quality assessment based on morphological attributes is important for achieving higher pregnancy rates from in vitro fertilization (IVF). The accurate segmentation of the embryo's inner cell mass (ICM) and trophectoderm epithelium (TE) is important, as these parameters can help to predict the embryo viability and live birth potential. However, segmentation of the ICM and TE is difficult due to variations in their shape and similarities in their textures, both with each other and with their surroundings. To tackle this problem, a deep neural network (DNN) based segmentation approach was implemented. The DNN can identify the ICM region with 99.1% accuracy, 94.9% precision, 93.8% recall, a 94.3% Dice Coefficient, and a 89.3% Jaccard Index. It can extract the TE region with 98.3% accuracy, 91.8% precision, 93.2% recall, a 92.5% Dice Coefficient, and a 85.3% Jaccard Index.", "pdf_url": "https://arxiv.org/pdf/2008.08676", "subject": "Image and Video Processing (eess.IV)"},
{"title": "On directed analogues of expander and hyperfinite graph sequences", "author": "Endre Cs\u00f3ka, \u0141ukasz Grabowski", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We introduce and study analogues of expander and hyperfinite graph sequences in the context of directed acyclic graphs, which we call \"extender\" and \"hypershallow\" graph sequences, respectively. Our main result is a probabilistic construction of non-hypershallow graph sequences.", "pdf_url": "https://arxiv.org/pdf/2008.08680", "subject": "Combinatorics (math.CO)"},
{"title": "Self-Supervised Ultrasound to MRI Fetal Brain Image Synthesis", "author": "Jianbo Jiao, Ana I.L. Namburete, Aris T. Papageorghiou, J. Alison Noble", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Fetal brain magnetic resonance imaging (MRI) offers exquisite images of the developing brain but is not suitable for second-trimester anomaly screening, for which ultrasound (US) is employed. Although expert sonographers are adept at reading US images, MR images which closely resemble anatomical images are much easier for non-experts to interpret. Thus in this paper we propose to generate MR-like images directly from clinical US images. In medical image analysis such a capability is potentially useful as well, for instance for automatic US-MRI registration and fusion. The proposed model is end-to-end trainable and self-supervised without any external annotations. Specifically, based on an assumption that the US and MRI data share a similar anatomical latent space, we first utilise a network to extract the shared latent features, which are then used for MRI synthesis. Since paired data is unavailable for our study (and rare in practice), pixel-level constraints are infeasible to apply. We instead propose to enforce the distributions to be statistically indistinguishable, by adversarial learning in both the image domain and feature space. To regularise the anatomical structures between US and MRI during synthesis, we further propose an adversarial structural constraint. A new cross-modal attention technique is proposed to utilise non-local spatial information, by encouraging multi-modal knowledge fusion and propagation. We extend the approach to consider the case where 3D auxiliary information (e.g., 3D neighbours and a 3D location index) from volumetric data is also available, and show that this improves image synthesis. The proposed approach is evaluated quantitatively and qualitatively with comparison to real fetal MR images and other approaches to synthesis, demonstrating its feasibility of synthesising realistic MR images.", "pdf_url": "https://arxiv.org/pdf/2008.08698", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Minimum discrepancy principle strategy for choosing $k$ in $k$-NN regression", "author": "Yaroslav Averyanov, Alain Celisse", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper presents a novel data-driven strategy to choose the hyperparameter $k$ in the $k$-NN regression estimator. We treat the problem of choosing the hyperparameter as an iterative procedure (over $k$) and propose using an easily implemented in practice strategy based on the idea of early stopping and the minimum discrepancy principle. This estimation strategy is proven to be minimax optimal, under the fixed-design assumption on covariates, over different smoothness function classes, for instance, the Lipschitz functions class on a bounded domain. After that, the novel strategy shows consistent simulations results on artificial and real-world data sets in comparison to other model selection strategies such as the Hold-out method.", "pdf_url": "https://arxiv.org/pdf/2008.08718", "subject": "Machine Learning (stat.ML)"},
{"title": "iPhantom: a framework for automated creation of individualized computational phantoms and its application to CT organ dosimetry", "author": "Wanyi Fu, Shobhit Sharma, Ehsan Abadi, Alexandros-Stavros Iliopoulos, Qi Wang, Joseph Y. Lo, Xiaobai Sun, William P. Segars, Ehsan Samei", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Objective: This study aims to develop and validate a novel framework, iPhantom, for automated creation of patient-specific phantoms or digital-twins (DT) using patient medical images. The framework is applied to assess radiation dose to radiosensitive organs in CT imaging of individual patients. Method: From patient CT images, iPhantom segments selected anchor organs (e.g. liver, bones, pancreas) using a learning-based model developed for multi-organ CT segmentation. Organs challenging to segment (e.g. intestines) are incorporated from a matched phantom template, using a diffeomorphic registration model developed for multi-organ phantom-voxels. The resulting full-patient phantoms are used to assess organ doses during routine CT exams. Result: iPhantom was validated on both the XCAT (n=50) and an independent clinical (n=10) dataset with similar accuracy. iPhantom precisely predicted all organ locations with good accuracy of Dice Similarity Coefficients (DSC) >0.6 for anchor organs and DSC of 0.3-0.9 for all other organs. iPhantom showed less than 10% dose errors for the majority of organs, which was notably superior to the state-of-the-art baseline method (20-35% dose errors). Conclusion: iPhantom enables automated and accurate creation of patient-specific phantoms and, for the first time, provides sufficient and automated patient-specific dose estimates for CT dosimetry. Significance: The new framework brings the creation and application of CHPs to the level of individual CHPs through automation, achieving a wider and precise organ localization, paving the way for clinical monitoring, and personalized optimization, and large-scale research.", "pdf_url": "https://arxiv.org/pdf/2008.08730", "subject": "Medical Physics (physics.med-ph)"},
{"title": "Optimal Network Compression", "author": "Hamed Amini, Zachary Feinstein", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper introduces a formulation of the optimal network compression problem for financial systems. This general formulation is presented for different levels of network compression or rerouting allowed from the initial interbank network. We prove that this problem is, generically, NP-hard. We focus on objective functions generated by systemic risk measures under systematic shocks to the financial network. We conclude by studying the optimal compression problem for specific networks; this permits us to study the so-called robust fragility of certain network topologies more generally as well as the potential benefits and costs of network compression.", "pdf_url": "https://arxiv.org/pdf/2008.08733", "subject": "Risk Management (q-fin.RM)"},
{"title": "On Lower Bounds for Standard and Robust Gaussian Process Bandit Optimization", "author": "Xu Cai, Jonathan Scarlett", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this paper, we consider algorithm-independent lower bounds for the problem of black-box optimization of functions having a bounded norm is some Reproducing Kernel Hilbert Space (RKHS), which can be viewed as a non-Bayesian Gaussian process bandit problem. In the standard noisy setting, we provide a novel proof technique for deriving lower bounds on the regret, with benefits including simplicity, versatility, and an improved dependence on the error probability. In a robust setting in which every sampled point may be perturbed by a suitably-constrained adversary, we provide a novel lower bound for deterministic strategies, demonstrating an inevitable joint dependence of the cumulative regret on the corruption level and the time horizon, in contrast with existing lower bounds that only characterize the individual dependencies. Furthermore, in a distinct robust setting in which the final point is perturbed by an adversary, we strengthen an existing lower bound that only holds for target success probabilities very close to one, by allowing for arbitrary success probabilities in $(0,1)$.", "pdf_url": "https://arxiv.org/pdf/2008.08757", "subject": "Machine Learning (stat.ML)"},
{"title": "Positionality-Weighted Aggregation Methods on Cumulative Voting", "author": "Takeshi Kato, Yasuhiro Asa, Misa Owa", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The issue in solving social problems is how to respect minority opinions, which are often ignored in general majority rules. To build consensus on pluralistic values and make social choices in consideration of minority opinions, we propose aggregation methods that give weighting to the minority's positionality on cardinal cumulative voting. Based on quadratic and linear voting, we formulated three weighted aggregation methods that differ in the ratio of votes to cumulative points and the weighting of the minority to all members, and calculated the frequency distributions of the aggregation results, assuming that the distributions of votes follow normal distributions. From these calculation results, we found that minority opinions are likely to be reflected as weighting increases proportionally in two of the above three methods. This means that Sen and Gotoh's idea of considering the social position of unfortunate people on ordinal ranking, that welfare economics considers under an axiomatic approach, was shown by weighting the minority's positionality on cardinal voting. In addition, we can know the contents such as the number and positionality of the minority from the analysis of the aggregation results. It will be useful for promoting mutual understanding between the majority and minority by visualizing the contents of the proposed aggregation methods interactively in the consensus-building process. With the further development of information technology, the consensus building on cardinal choices based on big data will be necessary. We would like to use the proposed aggregation methods for making social choices for pluralistic values such as social, environmental, and economic.", "pdf_url": "https://arxiv.org/pdf/2008.08759", "subject": "General Economics (econ.GN)"},
{"title": "Single Image Super-Resolution via a Holistic Attention Network", "author": "Ben Niu, Weilei Wen, Wenqi Ren, Xiangde Zhang, Lianping Yang, Shuzhen Wang, Kaihao Zhang, Xiaochun Cao, Haifeng Shen", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Informative features play a crucial role in the single image super-resolution task. Channel attention has been demonstrated to be effective for preserving information-rich features in each layer. However, channel attention treats each convolution layer as a separate process that misses the correlation among different layers. To address this problem, we propose a new holistic attention network (HAN), which consists of a layer attention module (LAM) and a channel-spatial attention module (CSAM), to model the holistic interdependencies among layers, channels, and positions. Specifically, the proposed LAM adaptively emphasizes hierarchical features by considering correlations among layers. Meanwhile, CSAM learns the confidence at all the positions of each channel to selectively capture more informative features. Extensive experiments demonstrate that the proposed HAN performs favorably against the state-of-the-art single image super-resolution approaches.", "pdf_url": "https://arxiv.org/pdf/2008.08767", "subject": "Image and Video Processing (eess.IV)"},
{"title": "A simple 7/3-approximation algorithm for feedback vertex set in tournaments", "author": "Manuel Aprile, Matthew Drescher, Samuel Fiorini, Tony Huynh", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We show that performing just one round of the Sherali-Adams hierarchy gives an easy 7/3-approximation algorithm for the Feedback Vertex Set (FVST) problem in tournaments. This matches the best deterministic approximation algorithm for FVST due to Mnich, Williams, and V\u00e9gh, and is a significant simplification and runtime improvement of their approach.", "pdf_url": "https://arxiv.org/pdf/2008.08779", "subject": "Combinatorics (math.CO)"},
{"title": "A Generalized Framework for Domain Adaptation of PLDA in Speaker Recognition", "author": "Qiongqiong Wang, Koji Okabe, Kong Aik Lee, Takafumi Koshinaka", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper proposes a generalized framework for domain adaptation of Probabilistic Linear Discriminant Analysis (PLDA) in speaker recognition. It not only includes several existing supervised and unsupervised domain adaptation methods but also makes possible more flexible usage of available data in different domains. In particular, we introduce here the two new techniques described below. (1) Correlation-alignment-based interpolation and (2) covariance regularization. The proposed correlation-alignment-based interpolation method decreases minCprimary up to 30.5% as compared with that from an out-of-domain PLDA model before adaptation, and minCprimary is also 5.5% lower than with a conventional linear interpolation method with optimal interpolation weights. Further, the proposed regularization technique ensures robustness in interpolations w.r.t. varying interpolation weights, which in practice is essential.", "pdf_url": "https://arxiv.org/pdf/2008.08815", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Uncertainty Estimation in Medical Image Denoising with Bayesian Deep Image Prior", "author": "Max-Heinrich Laves, Malte T\u00f6lle, Tobias Ortmaier", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Uncertainty quantification in inverse medical imaging tasks with deep learning has received little attention. However, deep models trained on large data sets tend to hallucinate and create artifacts in the reconstructed output that are not anatomically present. We use a randomly initialized convolutional network as parameterization of the reconstructed image and perform gradient descent to match the observation, which is known as deep image prior. In this case, the reconstruction does not suffer from hallucinations as no prior training is performed. We extend this to a Bayesian approach with Monte Carlo dropout to quantify both aleatoric and epistemic uncertainty. The presented method is evaluated on the task of denoising different medical imaging modalities. The experimental results show that our approach yields well-calibrated uncertainty. That is, the predictive uncertainty correlates with the predictive error. This allows for reliable uncertainty estimates and can tackle the problem of hallucinations and artifacts in inverse medical imaging tasks.", "pdf_url": "https://arxiv.org/pdf/2008.08837", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Image quality assessment for closed-loop computer-assisted lung ultrasound", "author": "Zachary M C Baum, Ester Bonmati, Lorenzo Cristoni, Andrew Walden, Ferran Prados, Baris Kanber, Dean C Barratt, David J Hawkes, Geoffrey J M Parker, Claudia A M Gandini Wheeler-Kingshott, Yipeng Hu", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We describe a novel, two-stage computer assistance system for lung anomaly detection using ultrasound imaging in the intensive care setting to improve operator performance and patient stratification during coronavirus pandemics. The proposed system consists of two deep-learning-based models. A quality assessment module automates predictions of image quality, and a diagnosis assistance module determines the likelihood-of-anomaly in ultrasound images of sufficient quality. Our two-stage strategy uses a novelty detection algorithm to address the lack of control cases available for training a quality assessment classifier. The diagnosis assistance module can then be trained with data that are deemed of sufficient quality, guaranteed by the closed-loop feedback mechanism from the quality assessment module. Integrating the two modules yields accurate, fast, and practical acquisition guidance and diagnostic assistance for patients with suspected respiratory conditions at the point-of-care. Using more than 25,000 ultrasound images from 37 COVID-19-positive patients scanned at two hospitals, plus 12 control cases, this study demonstrates the feasibility of using the proposed machine learning approach. We report an accuracy of 86% when classifying between sufficient and insufficient quality images by the quality assessment module. For data of sufficient quality, the mean classification accuracy in detecting COVID-19-positive cases was 95% on five holdout test data sets, unseen during the training of any networks within the proposed system.", "pdf_url": "https://arxiv.org/pdf/2008.08840", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Fast recognition of some parametric graph families", "author": "Nina Klobas, Matja\u017e Krnc", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We identify all $[1, \\lambda, 8]$-cycle regular $I$-graphs, all $[1, \\lambda, 8]$-cycle regular double generalized Petersen graphs, and the unique $[1, \\lambda, 6]$-cycle regular folded hypercube. As a consequence we describe linear recognition algorithms for the first two graph families, and a quasilinear recognition algorithm for the folded hypercubes.", "pdf_url": "https://arxiv.org/pdf/2008.08856", "subject": "Combinatorics (math.CO)"},
{"title": "Simple Analysis of Johnson-Lindenstrauss Transform under Neuroscience Constraints", "author": "Maciej Skorski", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The paper re-analyzes a version of the celebrated Johnson-Lindenstrauss Lemma, in which matrices are subjected to constraints that naturally emerge from neuroscience applications: a) sparsity and b) sign-consistency. This particular variant was studied first by Allen-Zhu, Gelashvili, Micali, Shavit and more recently by Jagadeesan (RANDOM'19). The contribution of this work is a novel proof, which in contrast to previous works a) uses the modern probability toolkit, particularly basics of sub-gaussian and sub-gamma estimates b) is self-contained, with no dependencies on subtle third-party results c) offers explicit constants. At the heart of our proof is a novel variant of Hanson-Wright Lemma (on concentration of quadratic forms). Of independent interest are also auxiliary facts on sub-gaussian random variables.", "pdf_url": "https://arxiv.org/pdf/2008.08857", "subject": "Statistics Theory (math.ST)"},
{"title": "Using Multi-Resolution Feature Maps with Convolutional Neural Networks for Anti-Spoofing in ASV", "author": "Qiongqiong Wang, Kong Aik Lee, Takafumi Koshinaka", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper presents a simple but effective method that uses multi-resolution feature maps with convolutional neural networks (CNNs) for anti-spoofing in automatic speaker verification (ASV). The central idea is to alleviate the problem that the feature maps commonly used in anti-spoofing networks are insufficient for building discriminative representations of audio segments, as they are often extracted by a single-length sliding window. Resulting trade-offs between time and frequency resolutions restrict the information in single spectrograms. The proposed method improves both frequency resolution and time resolution by stacking multiple spectrograms that are extracted using different window lengths. These are fed into a convolutional neural network in the form of multiple channels, making it possible to extract more information from input signals while only marginally increasing computational costs. The efficiency of the proposed method has been conformed on the ASVspoof 2019 database. We show that the use of the proposed multiresolution inputs consistently outperforms that of score fusion across different CNN architectures. Moreover, computational cost remains small.", "pdf_url": "https://arxiv.org/pdf/2008.08865", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Deep learning-based transformation of the H&E stain into special stains improves kidney disease diagnosis", "author": "Kevin de Haan, Yijie Zhang, Tairan Liu, Anthony E. Sisk, Miguel F. P. Diaz, Jonathan E. Zuckerman, Yair Rivenson, W. Dean Wallace, Aydogan Ozcan", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Pathology is practiced by visual inspection of histochemically stained slides. Most commonly, the hematoxylin and eosin (H&E) stain is used in the diagnostic workflow and it is the gold standard for cancer diagnosis. However, in many cases, especially for non-neoplastic diseases, additional \"special stains\" are used to provide different levels of contrast and color to tissue components and allow pathologists to get a clearer diagnostic picture. In this study, we demonstrate the utility of supervised learning-based computational stain transformation from H&E to different special stains (Masson's Trichrome, periodic acid-Schiff and Jones silver stain) using tissue sections from kidney needle core biopsies. Based on evaluation by three renal pathologists, followed by adjudication by a fourth renal pathologist, we show that the generation of virtual special stains from existing H&E images improves the diagnosis in several non-neoplastic kidney diseases, sampled from 16 unique subjects. Adjudication of N=48 diagnoses from the three pathologists revealed that the virtually generated special stains yielded 22 improvements (45.8%), 23 concordances (47.9%) and 3 discordances (6.3%), when compared against the use of H&E stained tissue only. As the virtual transformation of H&E images into special stains can be achieved in less than 1 min per patient core specimen slide, this stain-to-stain transformation framework can improve the quality of the preliminary diagnosis when additional special stains are needed, along with significant savings in time and cost, reducing the burden on healthcare system and patients.", "pdf_url": "https://arxiv.org/pdf/2008.08871", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Resource-efficient adaptive Bayesian tracking of magnetic fields with a quantum sensor", "author": "K. Craigie, E. M. Gauger, Y. Altmann, C. Bonato", "pub_date": "Submitted on 20 Aug 2020", "abstract": "By addressing single electron spins through Ramsey experiments, nitrogen-vacancy centres can act as high-resolution sensors of magnetic field. In applications where the magnetic field may be changing rapidly, total sensing time is crucial and must be minimised. Bayesian estimation and adaptive experiment optimisation protocols work by computing the probability distribution of the magnetic field based on measurement outcomes and, by computing aquisition settings for the next measurement. These protocols can speed up the sensing process by reducing the number of measurements required. However, the computations feeding into the next iteration measurement settings must be performed quickly enough to allow real-time updates. This paper addresses the issue of computational speed by implementing an approximated Bayesian estimation technique, where probability distributions are approximated by a superposition of Gaussian functions. Given that only three parameters are required to fully describe a Gaussian, we find that the magnetic field probability distribution can typically be described by fewer than ten numbers, achieving a reduction in the number of operations by factor 20 compared to existing approaches, allowing for faster processing.", "pdf_url": "https://arxiv.org/pdf/2008.08891", "subject": "Quantum Physics (quant-ph)"},
{"title": "Speaker-Utterance Dual Attention for Speaker and Utterance Verification", "author": "Tianchi Liu, Rohan Kumar Das, Maulik Madhavi, Shengmei Shen, Haizhou Li", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this paper, we study a novel technique that exploits the interaction between speaker traits and linguistic content to improve both speaker verification and utterance verification performance. We implement an idea of speaker-utterance dual attention (SUDA) in a unified neural network. The dual attention refers to an attention mechanism for the two tasks of speaker and utterance verification. The proposed SUDA features an attention mask mechanism to learn the interaction between the speaker and utterance information streams. This helps to focus only on the required information for respective task by masking the irrelevant counterparts. The studies conducted on RSR2015 corpus confirm that the proposed SUDA outperforms the framework without attention mask as well as several competitive systems for both speaker and utterance verification.", "pdf_url": "https://arxiv.org/pdf/2008.08901", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "A Data-Efficient Deep Learning Based Smartphone Application For Detection Of Pulmonary Diseases Using Chest X-rays", "author": "Hrithwik Shalu, Harikrishnan P, Akash Das, Megdut Mandal, Harshavardhan M Sali, Juned Kadiwala", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper introduces a paradigm of smartphone application based disease diagnostics that may completely revolutionise the way healthcare services are being provided. Although primarily aimed to assist the problems in rendering the healthcare services during the coronavirus pandemic, the model can also be extended to identify the exact disease that the patient is caught with from a broad spectrum of pulmonary diseases. The app inputs Chest X-Ray images captured from the mobile camera which is then relayed to the AI architecture in a cloud platform, and diagnoses the disease with state of the art accuracy. Doctors with a smartphone can leverage the application to save the considerable time that standard COVID-19 tests take for preliminary diagnosis. The scarcity of training data and class imbalance issues were effectively tackled in our approach by the use of Data Augmentation Generative Adversarial Network (DAGAN) and model architecture based as a Convolutional Siamese Network with attention mechanism. The backend model was tested for robustness us-ing publicly available datasets under two different classification scenarios(Binary/Multiclass) with minimal and noisy data. The model achieved pinnacle testing accuracy of 99.30% and 98.40% on the two respective scenarios, making it completely reliable for its users. On top of that a semi-live training scenario was introduced, which helps improve the app performance over time as data accumulates. Overall, the problems of generalisability of complex models and data inefficiency is tackled through the model architecture. The app based setting with semi live training helps in ease of access to reliable healthcare in the society, as well as help ineffective research of rare diseases in a minimal data setting.", "pdf_url": "https://arxiv.org/pdf/2008.08912", "subject": "Image and Video Processing (eess.IV)"},
{"title": "LOCUS: A Novel Decomposition Method for Brain Network Connectivity Matrices using Low-rank Structure with Uniform Sparsity", "author": "Yikai Wang, Ying Guo", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Network-oriented research has been increasingly popular in many scientific areas. In neuroscience research, imaging-based network connectivity measures have become the key for understanding brain organizations, potentially serving as individual neural fingerprints. There are major challenges in analyzing connectivity matrices including the high dimensionality of brain networks, unknown latent sources underlying the observed connectivity, and the large number of brain connections leading to spurious findings. In this paper, we propose a novel blind source separation method with low-rank structure and uniform sparsity (LOCUS) as a fully data-driven decomposition method for network measures. Compared with the existing method that vectorizes connectivity matrices ignoring brain network topology, LOCUS achieves more efficient and accurate source separation for connectivity matrices using low-rank structure. We propose a novel angle-based uniform sparsity regularization that demonstrates better performance than the existing sparsity controls for low-rank tensor methods. We propose a highly efficient iterative Node-Rotation algorithm that exploits the block multi-convexity of the objective function to solve the non-convex optimization problem for learning LOCUS. We illustrate the advantage of LOCUS through extensive simulation studies. Application of LOCUS to Philadelphia Neurodevelopmental Cohort neuroimaging study reveals biologically insightful connectivity traits which are not found using the existing method.", "pdf_url": "https://arxiv.org/pdf/2008.08915", "subject": "Machine Learning (stat.ML)"},
{"title": "A Passive Circuit-Emulator for a Current-controlled Memristor", "author": "Leonardo Barboni", "pub_date": "Submitted on 9 Jul 2020", "abstract": "A memristor is an electrical element, which has been conjectured in 1971 to complete the lumped circuit theory. Currently, researchers use memristors emulators through diodes and other passive (or active) elements to study circuits with possible attractors, chaos, and ways of implementing nonlinear transformations for low-voltage novel computing paradigms. However, to date, such passive memristor emulators have been voltage-controlled. In this study, the first circuit realization of a current-controlled passive emulator is established. The formal theory and simulations validate the proposed circuit.", "pdf_url": "https://arxiv.org/pdf/2008.08925", "subject": "Applied Physics (physics.app-ph)"},
{"title": "Generating Music with a Self-Correcting Non-Chronological Autoregressive Model", "author": "Wayne Chi, Prachi Kumar, Suri Yaddanapudi, Rahul Suresh, Umut Isik", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We describe a novel approach for generating music using a self-correcting, non-chronological, autoregressive model. We represent music as a sequence of edit events, each of which denotes either the addition or removal of a note---even a note previously generated by the model. During inference, we generate one edit event at a time using direct ancestral sampling. Our approach allows the model to fix previous mistakes such as incorrectly sampled notes and prevent accumulation of errors which autoregressive models are prone to have. Another benefit is a finer, note-by-note control during human and AI collaborative composition. We show through quantitative metrics and human survey evaluation that our approach generates better results than orderless NADE and Gibbs sampling approaches.", "pdf_url": "https://arxiv.org/pdf/2008.08927", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "A Special Conic Associated with the Reuleaux Negative Pedal Curve", "author": "Liliana Gabriela Gheorghe, Dan Reznik", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The Negative Pedal Curve of the Reuleaux Triangle w.r. to a point $M$ on its boundary consists of two elliptic arcs and a point $P_0$. Interestingly, the conic passing through the four arc endpoints and by $P_0$ has a remarkable property: one of its foci is $M$. We provide a synthetic proof based on Poncelet's polar duality and inversive techniques. Additional intriguing properties of Reuleaux negative pedal are proved using straightforward techniques.", "pdf_url": "https://arxiv.org/pdf/2008.08950", "subject": "Dynamical Systems (math.DS)"},
{"title": "asya: Mindful verbal communication using deep learning", "author": "Evalds Urtans, Ariel Tabaks", "pub_date": "Submitted on 20 Aug 2020", "abstract": "asya is a mobile application that consists of deep learning models which analyze spectra of a human voice and do noise detection, speaker diarization, gender detection, tempo estimation, and classification of emotions using only voice. All models are language agnostic and capable of running in real-time. Our speaker diarization models have accuracy over 95% on the test data set. These models can be applied for a variety of areas like customer service improvement, sales effective conversations, psychology and couples therapy.", "pdf_url": "https://arxiv.org/pdf/2008.08965", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Coordinated appendages accumulate more energy to self-right on the ground", "author": "Qihan Xuan, Chen Li", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Animals and robots must right themselves after flipping over on the ground. The discoid cockroach pushes its wings against the ground in an attempt to dynamically self-right by a somersault. However, because this maneuver is strenuous, the animal often fails to overcome the potential energy barrier and makes continual attempts. In this process, the animal flails its legs, whose lateral perturbation eventually leads it to roll to the side to self-right. Our previous work developed a cockroach-inspired robot capable of leg-assisted, winged self-righting, and a robot simulation study revealed that the outcome of this strategy depends sensitively on wing-leg coordination (measured by the phase between their motions). Here, we further elucidate why this is the case by developing a template to model the complex hybrid dynamics resulting from discontinuous contact and actuation. We used the template to calculate the potential energy barrier that the body must overcome to self-right, mechanical energy contribution by wing pushing and leg flailing, and mechanical energy dissipation due to wing-ground collision. The template revealed that wing-leg coordination (phase) strongly affects self-righting outcome by changing mechanical energy budget. Well-coordinated appendage motions (good phase) accumulate more mechanical energy than poorly-coordinated motions (bad phase), thereby better overcoming the potential energy barrier to self-right more successfully. Finally, we demonstrated practical use of the template for predicting a new control strategy to further increase self-righting performance and informing robot design.", "pdf_url": "https://arxiv.org/pdf/2008.08981", "subject": "Biological Physics (physics.bio-ph)"},
{"title": "Randomness in appendage coordination facilitates strenuous ground self-righting", "author": "Qihan Xuan, Chen Li", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Randomness is common in biological and artificial systems, resulting either from stochasticity of the environment or noise in organisms or devices themselves. In locomotor control, randomness is typically considered a nuisance. For example, during dynamic walking, randomness in stochastic terrain leads to metastable dynamics, which must be mitigated to stabilize the system around limit cycles. Here, we studied whether randomness in motion is beneficial for strenuous locomotor tasks. Our study used robotic simulation modeling of strenuous, leg-assisted, winged ground self-righting observed in cockroaches, in which unusually large randomness in wing and leg motions is present. We developed a simplified simulation robot capable of generating similar self-righting behavior and varied the randomness level in wing-leg coordination. During each wing opening attempt, the more randomness added to the time delay between wing opening and leg swinging, the more likely it was for the naive robot (which did not know what coordination is best) to self-right within a finite time. Wing-leg coordination, measured by the phase between wing and leg oscillations, had a crucial impact on self-righting outcome. Without randomness, periodic wing and leg oscillations often limited the system to visit a few bad phases, leading to failure to escape from the metastable state. With randomness, the system explored phases thoroughly and had a better chance of encountering good phases to self-right. Our study complements previous work by demonstrating that randomness helps destabilize locomotor systems from being trapped in undesired metastable states, a situation common in strenuous locomotion.", "pdf_url": "https://arxiv.org/pdf/2008.08983", "subject": "Biological Physics (physics.bio-ph)"},
{"title": "A New Combinatorial Property of Geometric Unique Sink Orientations", "author": "Yuan Gao, Bernd G\u00e4rtner, Jourdain Lamperski", "pub_date": "Submitted on 20 Aug 2020", "abstract": "A unique sink orientation (USO) is an orientation of the hypercube graph with the property that every face has a unique sink. A number of well-studied problems reduce in strongly polynomial time to finding the global sink of a USO; most notably, linear programming (LP) and the P-matrix linear complementarity problem (P-LCP). The former is not known to have a strongly polynomial-time algorithm, while the latter is not known to even have a polynomial-time algorithm, motivating the problem to find the global sink of a USO. Although, every known class of geometric USOs, arising from a concrete problem such as LP, is exponentially small, relative to the class of all USOs. Accordingly, geometric USOs exhibit additional properties that set them apart from general USOs, and it may be advantageous, if not necessary, to leverage these properties to find the global sink of a USO faster. Only a few such properties are known. In this paper, we establish a new combinatorial property of the USOs that arise from symmetric P-LCP, which includes the USOs that arise from linear and simple convex quadratic programming.", "pdf_url": "https://arxiv.org/pdf/2008.08992", "subject": "Combinatorics (math.CO)"},
{"title": "Compression with wildcards: All exact, or all minimal hitting sets", "author": "Marcel Wild", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Our main objective is the COMPRESSED enumeration (based on wildcards) of all minimal hitting sets of general hypergraphs. To the author's best knowledge the only previous attempt towards compression, due to Toda [T], is based on BDD's and much different from our techniques. Preliminary numerical experiments show that traditional one-by-one enumeration schemes cannot compete against compressed enumeration when the degree of compression is high. Despite the fact that thorough numerical experiments are postponed to a later version of our article, several tools to enhance compression (inclusion-exclusion, a matroid theorem of Rado, or adding dual kinds of wildcards) are put in place and their pros and cons are evaluated. Nevertheless, classic one-by-one enumeration is not neglected. Corollary 2 states that under mild provisos all perfect matchings of a graph can be enumerated in polynomial total time. Likewise all minimal edge-covers of a graph (Corollary 6). Furthermore, enumerating all minimal hypergraph transversals is fixed-parameter tractable for novel types of parameters (Corollary 5 and 4.6.3). Exact hitting sets constitute only a 'side show' but we start with them by pedagogical reasons: Our wildcard method is more clear-cut for exact hitting sets than for minimal hitting sets.", "pdf_url": "https://arxiv.org/pdf/2008.08996", "subject": "Combinatorics (math.CO)"},
{"title": "Generative chemistry: drug discovery with deep learning generative models", "author": "Yuemin Bian, Xiang-Qun Xie", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The de novo design of molecular structures using deep learning generative models introduces an encouraging solution to drug discovery in the face of the continuously increased cost of new drug development. From the generation of original texts, images, and videos, to the scratching of novel molecular structures, the incredible creativity of deep learning generative models surprised us about the height machine intelligence can achieve. The purpose of this paper is to review the latest advances in generative chemistry which relies on generative modeling to expedite the drug discovery process. This review starts with a brief history of artificial intelligence in drug discovery to outline this emerging paradigm. Commonly used chemical databases, molecular representations, and tools in cheminformatics and machine learning are covered as the infrastructure for the generative chemistry. The detailed discussions on utilizing cutting-edge generative architectures, including recurrent neural network, variational autoencoder, adversarial autoencoder, and generative adversarial network for compound generation are focused. Challenges and future perspectives follow.", "pdf_url": "https://arxiv.org/pdf/2008.09000", "subject": "Biomolecules (q-bio.BM)"},
{"title": "From Intuitionism to Many-Valued Logics through Kripke Models", "author": "Saeed Salehi", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Intuitionistic Propositional Logic is proved to be an infinitely many valued logic by Kurt G\u00f6del (1932), and it is proved by Stanis\u0142aw Ja\u015bkowski (1936) to be a countably many valued logic. In this paper, we provide alternative proofs for these theorems by using models of Saul Kripke (1959). G\u00f6del's proof gave rise to an intermediate propositional logic (between intuitionistic and classical), that is known nowadays as G\u00f6del or the G\u00f6del-Dummet Logic, and is studied by fuzzy logicians as well. We also provide some results on the inter-definablility of propositional connectives in this logic.", "pdf_url": "https://arxiv.org/pdf/2008.09016", "subject": "Logic (math.LO)"},
{"title": "Substrate engineering of inductors on SOI for improvement of Q-factor and application in LNA", "author": "Arun Bhaskar, Justine Philippe, Vanessa Avramovic, Flavie Braud, Jean-Fran\u00e7ois Robillard, C\u00e9dric Durand, Daniel Gloria, Christophe Gaquiere, Emmanuel Dubois", "pub_date": "Submitted on 20 Aug 2020", "abstract": "High Q-factor inductors are critical in designing high performance RF/microwave circuits on SOI technology. Substrate losses is a key limiting factor when designing inductors with high Q-factors. In this context, we report a substrate engineering method that enables improvement of quality factors of already fabricated inductors on SOI. A novel femtosecond laser milling process is utilized for the fabrication of locally suspended membranes of inductors with handler silicon completely etched. Such flexible membranes suspended freely on the BOX show up to 92 % improvement in Q factor for single turn inductor. The improvement in Q-factor is reported on large sized inductors due to reduced parallel capacitance which allows enhanced operation of inductors at high frequencies. A compact model extraction methodology has been developed to model inductor membranes. These membranes have been utilized for the improvement of noise performance of LNA working in the 4.9,5.9 GHz range. A 0.1 dB improvement in noise figure has been reported by taking an existing design and suspending the input side inductors of the LNA circuit. The substrate engineering method reported in this work is not only applicable to inductors but also to active circuits, making it a powerful tool for enhancement of RF devices.", "pdf_url": "https://arxiv.org/pdf/2008.09030", "subject": "Applied Physics (physics.app-ph)"},
{"title": "Sparse phase retrieval via Phaseliftoff", "author": "Yu Xia, Zhiqiang Xu", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The aim of sparse phase retrieval is to recover a $k$-sparse signal $\\mathbf{x}_0\\in \\mathbb{C}^{d}$ from quadratic measurements $|\\langle \\mathbf{a}_i,\\mathbf{x}_0\\rangle|^2$ where $\\mathbf{a}_i\\in \\mathbb{C}^d, i=1,\\ldots,m$. Noting $|\\langle \\mathbf{a}_i,\\mathbf{x}_0\\rangle|^2={\\text{Tr}}(A_iX_0)$ with $A_i=\\mathbf{a}_i\\mathbf{a}_i^*\\in \\mathbb{C}^{d\\times d}, X_0=\\mathbf{x}_0\\mathbf{x}_0^*\\in \\mathbb{C}^{d\\times d}$, one can recast sparse phase retrieval as a problem of recovering a rank-one sparse matrix from linear measurements. Yin and Xin introduced PhaseLiftOff which presents a proxy of rank-one condition via the difference of trace and Frobenius norm. By adding sparsity penalty to PhaseLiftOff, in this paper, we present a novel model to recover sparse signals from quadratic measurements. Theoretical analysis shows that the solution to our model provides the stable recovery of $\\mathbf{x}_0$ under almost optimal sampling complexity $m=O(k\\log(d/k))$. The computation of our model is carried out by the difference of convex function algorithm (DCA). Numerical experiments demonstrate that our algorithm outperforms other state-of-the-art algorithms used for solving sparse phase retrieval.", "pdf_url": "https://arxiv.org/pdf/2008.09032", "subject": "Functional Analysis (math.FA)"},
{"title": "Direct Adversarial Training for GANs", "author": "Ziqiang Li", "pub_date": "Submitted on 19 Aug 2020", "abstract": "There is an interesting discovery that several neural networks are vulnerable to adversarial examples. That is, many machines learning models misclassify the samples with only a little change which will not be noticed by human eyes. Generative adversarial networks (GANs) are the most popular models for image generation by jointly optimizing discriminator and generator. With stability train, some regularization and normalization have been used to let the discriminator satisfy Lipschitz consistency. In this paper, we have analyzed that the generator may produce adversarial examples for discriminator during the training process, which may cause the unstable training of GANs. For this reason, we propose a direct adversarial training method for GANs. At the same time, we prove that this direct adversarial training can limit the lipschitz constant of the discriminator and accelerate the convergence of the generator. We have verified the advanced performs of the method on multiple baseline networks, such as DCGAN, WGAN, WGAN-GP, and WGAN-LP.", "pdf_url": "https://arxiv.org/pdf/2008.09041", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Modeling flexoelectricity in soft dielectrics at finite deformation", "author": "David Codony, Prakhar Gupta, Onofre Marco, Irene Arias", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper develops the equilibrium equations describing the flexoelectric effect in soft dielectrics under large deformations. Previous works have developed related theories using a flexoelectric coupling tensor of mixed material-spatial character. Here, we formulate the model in terms of a flexoelectric tensor completely defined in the material frame, with the same symmetries of the small-strain flexocoupling tensor and leading naturally to objective flexoelectric polarization fields. The energy potential and equilibrium equations are first expressed in terms of deformation and polarization, and then rewritten in terms of deformation and electric potential, yielding an unconstrained system of fourth order partial differential equations (PDE). We further develop a theory of geometrically nonlinear extensible flexoelectric rods under open and closed circuit conditions, with which we examine cantilever bending and buckling under mechanical and electrical actuation. Besides being a simple and explicit model pertinent to slender structures, this rod theory also allows us to test our general theory and its numerical implementation using B-Splines. This numerical implementation is robust as it handles the electromechanical instabilities in soft flexoelectric materials.", "pdf_url": "https://arxiv.org/pdf/2008.09045", "subject": "Computational Physics (physics.comp-ph)"},
{"title": "On transversality of bent hyperplane arrangements and the topological expressiveness of ReLU neural networks", "author": "J. Elisenda Grigsby, Kathryn Lindsey", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Let F:R^n -> R be a feedforward ReLU neural network. It is well-known that for any choice of parameters, F is continuous and piecewise (affine) linear. We lay some foundations for a systematic investigation of how the architecture of F impacts the geometry and topology of its possible decision regions for binary classification tasks. Following the classical progression for smooth functions in differential topology, we first define the notion of a generic, transversal ReLU neural network and show that almost all ReLU networks are generic and transversal. We then define a partially-oriented linear 1-complex in the domain of F and identify properties of this complex that yield an obstruction to the existence of bounded connected components of a decision region. We use this obstruction to prove that a decision region of a generic, transversal ReLU network F: R^n -> R with a single hidden layer of dimension (n + 1) can have no more than one bounded connected component.", "pdf_url": "https://arxiv.org/pdf/2008.09052", "subject": "Combinatorics (math.CO)"},
{"title": "Neural Networks and Quantum Field Theory", "author": "James Halverson, Anindita Maiti, Keegan Stoner", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We propose a theoretical understanding of neural networks in terms of Wilsonian effective field theory. The correspondence relies on the fact that many asymptotic neural networks are drawn from Gaussian processes, the analog of non-interacting field theories. Moving away from the asymptotic limit yields a non-Gaussian process and corresponds to turning on particle interactions, allowing for the computation of correlation functions of neural network outputs with Feynman diagrams. Minimal non-Gaussian process likelihoods are determined by the most relevant non-Gaussian terms, according to the flow in their coefficients induced by the Wilsonian renormalization group. This yields a direct connection between overparameterization and simplicity of neural network likelihoods. Whether the coefficients are constants or functions may be understood in terms of GP limit symmetries, as expected from 't Hooft's technical naturalness. General theoretical calculations are matched to neural network experiments in the simplest class of models allowing the correspondence. Our formalism is valid for any of the many architectures that becomes a GP in an asymptotic limit, a property preserved under certain types of training.", "pdf_url": "https://arxiv.org/pdf/2008.08601", "subject": "Machine Learning (cs.LG)"},
{"title": "A Survey on Text Simplification", "author": "Punardeep Sikka, Manmeet Singh, Allen Pink, Vijay Mago", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Text Simplification (TS) aims to reduce the linguistic complexity of content to make it easier to understand. Research in TS has been of keen interest, especially as approaches to TS have shifted from manual, hand-crafted rules to automated simplification. This survey seeks to provide a comprehensive overview of TS, including a brief description of earlier approaches used, discussion of various aspects of simplification (lexical, semantic and syntactic), and latest techniques being utilized in the field. We note that the research in the field has clearly shifted towards utilizing deep learning techniques to perform TS, with a specific focus on developing solutions to combat the lack of data available for simplification. We also include a discussion of datasets and evaluations metrics commonly used, along with discussion of related fields within Natural Language Processing (NLP), like semantic similarity.", "pdf_url": "https://arxiv.org/pdf/2008.08612", "subject": "Computation and Language (cs.CL)"},
{"title": "Modeling Complex Spatial Patterns with Temporal Features via Heterogenous Graph Embedding Networks", "author": "Yida Huang, Haoyan Xu, Ziheng Duan, Anni Ren, Jie Feng, Xiaoqian Wang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Multivariate time series (MTS) forecasting is an important problem in many fields. Accurate forecasting results can effectively help decision-making. Variables in MTS have rich relations among each other and the value of each variable in MTS depends both on its historical values and on other variables. These rich relations can be static and predictable or dynamic and latent. Existing methods do not incorporate these rich relational information into modeling or only model certain relation among MTS variables. To jointly model rich relations among variables and temporal dependencies within the time series, a novel end-to-end deep learning model, termed Multivariate Time Series Forecasting via Heterogenous Graph Neural Networks (MTHetGNN) is proposed in this paper. To characterize rich relations among variables, a relation embedding module is introduced in our model, where each variable is regarded as a graph node and each type of edge represents a specific relationship among variables or one specific dynamic update strategy to model the latent dependency among variables. In addition, convolutional neural network (CNN) filters with different perception scales are used for time series feature extraction, which is used to generate the feature of each node. Finally, heterogenous graph neural networks are adopted to handle the complex structural information generated by temporal embedding module and relation embedding module. Three benchmark datasets from the real world are used to evaluate the proposed MTHetGNN and the comprehensive experiments show that MTHetGNN achieves state-of-the-art results in MTS forecasting task.", "pdf_url": "https://arxiv.org/pdf/2008.08617", "subject": "Machine Learning (cs.LG)"},
{"title": "On Qualitative Shape Inferences: a journey from geometry to topology", "author": "Steven W Zucker", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Shape inference is classically ill-posed, because it involves a map from the (2D) image domain to the (3D) world. Standard approaches regularize this problem by either assuming a prior on lighting and rendering or restricting the domain, and develop differential equations or optimization solutions. While elegant, the solutions that emerge in these situations are remarkably fragile. We exploit the observation that people infer shape qualitatively; that there are quantitative differences between individuals. The consequence is a topological approach based on critical contours and the Morse-Smale complex. This paper provides a developmental review of that theory, emphasizing the motivation at different stages of the research.", "pdf_url": "https://arxiv.org/pdf/2008.08622", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Estimating the time-lapse between medical insurance reimbursement with non-parametric regression models", "author": "Mary Akinyemi, Chika Yinka-Banjo, Ogban-Asuquo Ugot, Akwarandu Ugo Nwachuku", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Non-parametric supervised learning algorithms represent a succinct class of supervised learning algorithms where the learning parameters are highly flexible and whose values are directly dependent on the size of the training data. In this paper, we comparatively study the properties of four nonparametric algorithms, K-Nearest Neighbours (KNNs), Support Vector Machines (SVMs), Decision trees and Random forests. The supervised learning task is a regression estimate of the time-lapse in medical insurance reimbursement. Our study is concerned precisely with how well each of the nonparametric regression models fits the training data. We quantify the goodness of fit using the R-squared metric. The results are presented with a focus on the effect of the size of the training data, the feature space dimension and hyperparameter optimization.", "pdf_url": "https://arxiv.org/pdf/2008.08624", "subject": "Machine Learning (cs.LG)"},
{"title": "RFNet: Riemannian Fusion Network for EEG-based Brain-Computer Interfaces", "author": "Guangyi Zhang, Ali Etemad", "pub_date": "Submitted on 19 Aug 2020", "abstract": "This paper presents the novel Riemannian Fusion Network (RFNet), a deep neural architecture for learning spatial and temporal information from Electroencephalogram (EEG) for a number of different EEG-based Brain Computer Interface (BCI) tasks and applications. The spatial information relies on Spatial Covariance Matrices (SCM) of multi-channel EEG, whose space form a Riemannian Manifold due to the Symmetric and Positive Definite structure. We exploit a Riemannian approach to map spatial information onto feature vectors in Euclidean space. The temporal information characterized by features based on differential entropy and logarithm power spectrum density is extracted from different windows through time. Our network then learns the temporal information by employing a deep long short-term memory network with a soft attention mechanism. The output of the attention mechanism is used as the temporal feature vector. To effectively fuse spatial and temporal information, we use an effective fusion strategy, which learns attention weights applied to embedding-specific features for decision making. We evaluate our proposed framework on four public datasets from three popular fields of BCI, notably emotion recognition, vigilance estimation, and motor imagery classification, containing various types of tasks such as binary classification, multi-class classification, and regression. RFNet approaches the state-of-the-art on one dataset (SEED) and outperforms other methods on the other three datasets (SEED-VIG, BCI-IV 2A, and BCI-IV 2B), setting new state-of-the-art values and showing the robustness of our framework in EEG representation learning.", "pdf_url": "https://arxiv.org/pdf/2008.08633", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Computational-Graph Partitioning Method for Training Memory-Constrained DNNs", "author": "Fareed Qararyah, Mohamed Wahib, Do\u011fa Dikbay\u0131r, Mehmet Esat Belviranli, Didem Unat", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We propose ParDNN, an automatic, generic, and non-intrusive partitioning strategy for large DNN models that do not fit into single device memory.ParDNN decides a placement of DNN's underlying computational graph operations across multiple devices so that the devices' memory constraints are met and the training time is minimized.ParDNN is completely independent of the deep learning aspects of a DNN and requires no modification neither at the model nor at the systems level implementation of operation kernels. It partitions DNNs having billions of parameters and hundreds of thousands of operations in seconds to a few minutes. Our experiments with TensorFlow on 16 GPUs demonstrate efficient training of 5 very large models while achieving super-linear scaling for both the batch size and training throughput. In comparison to related work (Mesh-TensorFlow and gradient Checkpointing), ParDNN either outperforms or qualitatively improves upon them.", "pdf_url": "https://arxiv.org/pdf/2008.08636", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Low Power Wide Area Networks: A Survey of Enabling Technologies, Applications and Interoperability Needs", "author": "Qahhar Muhammad Qadir, Tarik A. Rashid, Nawzad K. Al-Salihi, Birzo Ismael, Alexander A. Kist, Zhongwei Zhang", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Low power wide area (LPWA) technologies are strongly recommended as the underlying networks for Internet of things (IoT) applications. They offer attractive features, including wide-range coverage, long battery life and low data rates. This paper reviews the current trends in this technology, with an emphasis on the services it provides and the challenges it faces. The industrial paradigms for LPWA implementation are presented. Compared with other work in the field, this survey focuses on the need for integration among different LPWA technologies and recommends the appropriate LPWA solutions for a wide range of IoT application and service use-cases. Opportunities created by these technologies in the market are also analyzed. The latest research efforts to investigate and improve the operation of LPWA networks are also compared and classified to enable researchers to quickly get up to speed on the current status of this technology. Finally, challenges facing LPWA are identified and directions for future research are recommended.", "pdf_url": "https://arxiv.org/pdf/2008.08639", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Fast and reliable high accuracy computation of Gauss--Jacobi quadrature", "author": "A. Gil, J. Segura, N. M. Temme", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Iterative methods with certified convergence for the computation of Gauss--Jacobi quadratures are described. The methods do not require a priori estimations of the nodes to guarantee its fourth-order convergence. They are shown to be generally faster than previous methods and without practical restrictions on the range of the parameters. The evaluation of the nodes and weights of the quadrature is exclusively based on convergent processes which, together with the fourth order convergence of the fixed point method for computing the nodes, makes this an ideal approach for high accuracy computations, so much so that computations of quadrature rules with even millions of nodes and thousands of digits are possible in a typical laptop.", "pdf_url": "https://arxiv.org/pdf/2008.08641", "subject": "Numerical Analysis (math.NA)"},
{"title": "$\\ell_p$-Norm Multiple Kernel One-Class Fisher Null-Space", "author": "Shervin Rahimzadeh Arashloo", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The paper addresses the multiple kernel learning (MKL) problem for one-class classification (OCC). For this purpose, based on the Fisher null-space one-class classification method, we present a multiple kernel learning algorithm where a general $\\ell_p$-norm constraint ($p\\geq1$) on kernel weights is considered. The proposed approach is then extended to learn several related one-class MKL problems jointly by constraining them to share common kernel weights. We pose the one-class MKL task as a min-max saddle point Lagrangian optimisation problem and propose an efficient alternating optimisation method to solve it. An extensive assessment of the proposed method on ten data sets from different application domains in one-class classification confirms its merits against the baseline and several other one-class multiple kernel learning methods.", "pdf_url": "https://arxiv.org/pdf/2008.08642", "subject": "Machine Learning (cs.LG)"},
{"title": "A Robust Opinion Spam Detection Method Against Malicious Attackers in Social Media", "author": "Amir Jalaly Bidgolya, Zoleikha Rahmaniana", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Online reviews are potent sources for industry owners and buyers, however opportunistic people may try to destruct or promote their desired product by publishing fake comments named spam opinion. So far, many models have been developed to detect spam opinions, but none have addressed the issue of spam attack. It is a way a smart spammer can deceive the system in a manner in which he can continue generating spams without the fear of being detected and blocked by the system. In this paper, the spam attacks are discussed. Moreover, a robust graph-based spam detection method is proposed. The method respectively estimates honesty, trust and reliability values of reviews, reviewers, and products considering possible deception scenarios. The paper also presents the efficiency of the proposed method as compared to other graph-based methods through some case studies.", "pdf_url": "https://arxiv.org/pdf/2008.08650", "subject": "Social and Information Networks (cs.SI)"},
{"title": "The Organization of Software Teams in the Quest for Continuous Delivery: A Grounded Theory Approach", "author": "Leonardo Leite, Gustavo Pinto, Fabio Kon, Paulo Meirelles", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Context: Continuous delivery practices accelerate time to market and improve customer satisfaction. Although recent related work suggests that organizations employing continuous delivery should promote a collaborative culture among different IT teams, there is no substantial literature tackling how organizations should organize their teams to excel in continuous delivery. Objective: In this study, we investigate how organizations pursuing continuous delivery organize their development and operations teams. Method: We collected and analyzed data from interviews with 46 IT professionals, following Grounded Theory guidelines. Results: After a careful analysis, we identified four patterns of organizational structures: (1) siloed departments, (2) classical DevOps, (3) cross-functional teams, and (4) platform teams. The main contribution of this study is a taxonomy that organizes these structures along with their properties. This taxonomy is our theory for organizing software teams in the context of continuous delivery.", "pdf_url": "https://arxiv.org/pdf/2008.08652", "subject": "Software Engineering (cs.SE)"},
{"title": "The Power of Hashing with Mersenne Primes", "author": "Thomas Dybdahl Ahle, Jakob Tejs B\u00e6k Knudsen, Mikkel Thorup", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The classic way of computing a $k$-universal hash function is to use a random degree-$(k-1)$ polynomial over a prime field $\\mathbb Z_p$. For a fast computation of the polynomial, the prime $p$ is often chosen as a Mersenne prime $p=2^b-1$. In this paper, we show that there are other nice advantages to using Mersenne primes. Our view is that the output of the hash function is a $b$-bit integer that is uniformly distributed in $[2^b]$, except that $p$ (the all \\texttt1s value) is missing. Uniform bit strings have many nice properties, such as splitting into substrings which gives us two or more hash functions for the cost of one, while preserving strong theoretical qualities. We call this trick \"Two for one\" hashing, and we demonstrate it on 4-universal hashing in the classic Count Sketch algorithm for second moment estimation. We also provide a new fast branch-free code for division and modulus with Mersenne primes. Contrasting our analytic work, this code generalizes to Pseudo-Mersenne primes $p=2^b-c$ for small $c$, improving upon a classical algorithm of Crandall.", "pdf_url": "https://arxiv.org/pdf/2008.08654", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "ConfEx: A Framework for Automating Text-based Software Configuration Analysis in the Cloud", "author": "Ozan Tuncer, Anthony Byrne, Nilton Bila, Sastry Duri, Canturk Isci, Ayse K. Coskun", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Modern cloud services have complex architectures, often comprising many software components, and depend on hundreds of configurations parameters to function correctly, securely, and with high performance. Due to the prevalence of open-source software, developers can easily deploy services using third-party software without mastering the configurations of that software. As a result, configuration errors (i.e., misconfigurations) are among the leading causes of service disruptions and outages. While existing cloud automation tools ease the process of service deployment and management, support for detecting misconfigurations in the cloud has not been addressed thoroughly, likely due to the lack of frameworks suitable for consistent parsing of unstandardized configuration files. This paper introduces ConfEx, a framework that enables discovery and extraction of text-based software configurations in the cloud. ConfEx uses a novel vocabulary-based technique to identify configuration files in cloud system instances with unlabeled content. To extract the information in these files, ConfEx leverages existing configuration parsers and post-processes the extracted data for analysis. We show that ConfEx achieves over 99% precision and 100% recall in identifying configuration files on 7805 popular Docker Hub images. Using two applied examples, we demonstrate that ConfEx also enables detecting misconfigurations in the cloud via existing tools that are designed for configurations represented as key-value pairs, revealing 184 errors in public Docker Hub images.", "pdf_url": "https://arxiv.org/pdf/2008.08656", "subject": "Software Engineering (cs.SE)"},
{"title": "LMFAO: An Engine for Batches of Group-By Aggregates", "author": "Maximilian Schleich, Dan Olteanu", "pub_date": "Submitted on 19 Aug 2020", "abstract": "LMFAO is an in-memory optimization and execution engine for large batches of group-by aggregates over joins. Such database workloads capture the data-intensive computation of a variety of data science applications. We demonstrate LMFAO for three popular models: ridge linear regression with batch gradient descent, decision trees with CART, and clustering with Rk-means.", "pdf_url": "https://arxiv.org/pdf/2008.08657", "subject": "Databases (cs.DB)"},
{"title": "Segmenting Bank Customers via RFM Model and Unsupervised Machine Learning", "author": "Musadig Aliyev, Elvin Ahmadov, Habil Gadirli, Arzu Mammadova, Emin Alasgarov", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In recent years, one of the major challenges for financial institutions is the retention of their customers using new methodologies of reliable and profitable segmentation. In the field of banking, the approach of offering all of the services to all the existing customers at the same time does not always work. However, being aware of what to sell, when to sell and whom to sell makes a huge difference in the conversion rate of the customers responding to new services and buying new products. In this paper, we used RFM technique and various clustering algorithms applied to the real customer data of one of the largest private banks of Azerbaijan.", "pdf_url": "https://arxiv.org/pdf/2008.08662", "subject": "Machine Learning (cs.LG)"},
{"title": "Intelligent Replication Management for HDFS Using Reinforcement Learning", "author": "Hyunsung Lee", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Storage systems for cloud computing merge a large number of commodity computers into a single large storage pool. It provides high-performance storage over an unreliable, and dynamic network at a lower cost than purchasing and maintaining large mainframe. In this paper, we examine whether it is feasible to apply Reinforcement Learning(RL) to system domain problems. Our experiments show that the RL model is comparable, even outperform other heuristics for block management problem. However, our experiments are limited in terms of scalability and fidelity. Even though our formulation is not very practical,applying Reinforcement Learning to system domain could offer good alternatives to existing heuristics.", "pdf_url": "https://arxiv.org/pdf/2008.08665", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "A Computationally Intelligent Hierarchical Authentication and Key Establishment Framework for Internet of Things", "author": "Mohammad Sayad Haghighi, Orwa Nader, Alireza Jolfaei", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Our high expectations from Internet of Things (IoT) and how it will positively influence our lifestyles depend on a secure and trusted implementation of it, especially in the sensitive sectors such as health or financial. IoT platforms and solutions must provide Confidentiality, Integrity and Availability (CIA) in a secure and transparent way. Due to the extremely large scales of IoT, traditional centralized solutions for security provisioning cannot be employed in their original form. This article discusses the authentication problem in IoT, which is fundamental to providing CIA. We propose a hierarchical security architecture for this problem and focus on computationally lightweight authentication protocols which can intelligently distribute the computational load across multiple levels and effectively push the load towards upper layers.", "pdf_url": "https://arxiv.org/pdf/2008.08672", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Image Segmentation of Zona-Ablated Human Blastocysts", "author": "Md Yousuf Harun, M Arifur Rahman, Joshua Mellinger, Willy Chang, Thomas Huang, Brienne Walker, Kristen Hori, Aaron T. Ohta", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Automating human preimplantation embryo grading offers the potential for higher success rates with in vitro fertilization (IVF) by providing new quantitative and objective measures of embryo quality. Current IVF procedures typically use only qualitative manual grading, which is limited in the identification of genetically abnormal embryos. The automatic quantitative assessment of blastocyst expansion can potentially improve sustained pregnancy rates and reduce health risks from abnormal pregnancies through a more accurate identification of genetic abnormality. The expansion rate of a blastocyst is an important morphological feature to determine the quality of a developing embryo. In this work, a deep learning based human blastocyst image segmentation method is presented, with the goal of facilitating the challenging task of segmenting irregularly shaped blastocysts. The type of blastocysts evaluated here has undergone laser ablation of the zona pellucida, which is required prior to trophectoderm biopsy. This complicates the manual measurements of the expanded blastocyst's size, which shows a correlation with genetic abnormalities. The experimental results on the test set demonstrate segmentation greatly improves the accuracy of expansion measurements, resulting in up to 99.4% accuracy, 98.1% precision, 98.8% recall, a 98.4% Dice Coefficient, and a 96.9% Jaccard Index.", "pdf_url": "https://arxiv.org/pdf/2008.08673", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Asymptotics of Wide Convolutional Neural Networks", "author": "Anders Andreassen, Ethan Dyer", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Wide neural networks have proven to be a rich class of architectures for both theory and practice. Motivated by the observation that finite width convolutional networks appear to outperform infinite width networks, we study scaling laws for wide CNNs and networks with skip connections. Following the approach of (Dyer & Gur-Ari, 2019), we present a simple diagrammatic recipe to derive the asymptotic width dependence for many quantities of interest. These scaling relationships provide a solvable description for the training dynamics of wide convolutional networks. We test these relations across a broad range of architectures. In particular, we find that the difference in performance between finite and infinite width models vanishes at a definite rate with respect to model width. Nonetheless, this relation is consistent with finite width models generalizing either better or worse than their infinite width counterparts, and we provide examples where the relative performance depends on the optimization details.", "pdf_url": "https://arxiv.org/pdf/2008.08675", "subject": "Machine Learning (cs.LG)"},
{"title": "Neural Neighborhood Encoding for Classification", "author": "Kaushik Sinha, Parikshit Ram", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Inspired by the fruit-fly olfactory circuit, the Fly Bloom Filter [Dasgupta et al., 2018] is able to efficiently summarize the data with a single pass and has been used for novelty detection. We propose a new classifier (for binary and multi-class classification) that effectively encodes the different local neighborhoods for each class with a per-class Fly Bloom Filter. The inference on test data requires an efficient {\\tt FlyHash} [Dasgupta, et al., 2017] operation followed by a high-dimensional, but {\\em sparse}, dot product with the per-class Bloom Filters. The learning is trivially parallelizable. On the theoretical side, we establish conditions under which the prediction of our proposed classifier on any test example agrees with the prediction of the nearest neighbor classifier with high probability. We extensively evaluate our proposed scheme with over $50$ data sets of varied data dimensionality to demonstrate that the predictive performance of our proposed neuroscience inspired classifier is competitive the the nearest-neighbor classifiers and other single-pass classifiers.", "pdf_url": "https://arxiv.org/pdf/2008.08685", "subject": "Machine Learning (cs.LG)"},
{"title": "RealitySketch: Embedding Responsive Graphics and Visualizations in AR through Dynamic Sketching", "author": "Ryo Suzuki, Rubaiat Habib Kazi, Li-Yi Wei, Stephen DiVerdi, Wilmot Li, Daniel Leithinger", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We present RealitySketch, an augmented reality interface for sketching interactive graphics and visualizations. In recent years, an increasing number of AR sketching tools enable users to draw and embed sketches in the real world. However, with the current tools, sketched contents are inherently static, floating in mid air without responding to the real world. This paper introduces a new way to embed dynamic and responsive graphics in the real world. In RealitySketch, the user draws graphical elements on a mobile AR screen and binds them with physical objects in real-time and improvisational ways, so that the sketched elements dynamically move with the corresponding physical motion. The user can also quickly visualize and analyze real-world phenomena through responsive graph plots or interactive visualizations. This paper contributes to a set of interaction techniques that enable capturing, parameterizing, and visualizing real-world motion without pre-defined programs and configurations. Finally, we demonstrate our tool with several application scenarios, including physics education, sports training, and in-situ tangible interfaces.", "pdf_url": "https://arxiv.org/pdf/2008.08688", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters", "author": "Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, Philip S. Yu", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Graph Neural Networks (GNNs) have been widely applied to fraud detection problems in recent years, revealing the suspiciousness of nodes by aggregating their neighborhood information via different relations. However, few prior works have noticed the camouflage behavior of fraudsters, which could hamper the performance of GNN-based fraud detectors during the aggregation process. In this paper, we introduce two types of camouflages based on recent empirical studies, i.e., the feature camouflage and the relation camouflage. Existing GNNs have not addressed these two camouflages, which results in their poor performance in fraud detection problems. Alternatively, we propose a new model named CAmouflage-REsistant GNN (CARE-GNN), to enhance the GNN aggregation process with three unique modules against camouflages. Concretely, we first devise a label-aware similarity measure to find informative neighboring nodes. Then, we leverage reinforcement learning (RL) to find the optimal amounts of neighbors to be selected. Finally, the selected neighbors across different relations are aggregated together. Comprehensive experiments on two real-world fraud datasets demonstrate the effectiveness of the RL algorithm. The proposed CARE-GNN also outperforms state-of-the-art GNNs and GNN-based fraud detectors. We integrate all GNN-based fraud detectors as an opensource toolbox: . The CARE-GNN code and datasets are available at .", "pdf_url": "https://arxiv.org/pdf/2008.08692", "subject": "Social and Information Networks (cs.SI)"},
{"title": "RoomShift: Room-scale Dynamic Haptics for VR with Furniture-moving Swarm Robots", "author": "Ryo Suzuki, Hooman Hedayati, Clement Zheng, James Bohn, Daniel Szafir, Ellen Yi-Luen Do, Mark D. Gross, Daniel Leithinger", "pub_date": "Submitted on 19 Aug 2020", "abstract": "RoomShift is a room-scale dynamic haptic environment for virtual reality, using a small swarm of robots that can move furniture. RoomShift consists of nine shape-changing robots: Roombas with mechanical scissor lifts. These robots drive beneath a piece of furniture to lift, move and place it. By augmenting virtual scenes with physical objects, users can sit on, lean against, place and otherwise interact with furniture with their whole body; just as in the real world. When the virtual scene changes or users navigate within it, the swarm of robots dynamically reconfigures the physical environment to match the virtual content. We describe the hardware and software implementation, applications in virtual tours and architectural design and interaction techniques.", "pdf_url": "https://arxiv.org/pdf/2008.08695", "subject": "Robotics (cs.RO)"},
{"title": "Toward an Abstract Model of Programmable Data Plane Devices", "author": "Debobroto Das Robin, Dr. Javed I. Khan", "pub_date": "Submitted on 19 Aug 2020", "abstract": "SDN divides the networking landscape into 2 parts: control and data plane. SDN expanded it's foot mark starting with OpenFlow based highly flexible control plane and rigid data plane. Innovation and improvement in hardware design and development is bringing various new architectures for data plane. Data plane is becoming more programmable then ever before. A common abstract model of data plane is required to develop complex application over these heterogeneous data plane devices. It can also provide insight about performance optimization and bench-marking of programmable data plane devices. Moreover, to understand and utilize data plane's programmability, a detailed structural analysis and an identifiable matrix to compare different devices are required. In this work, an improved and structured abstract model of the programmable data plane devices is presented and features of its components are discussed in detail. Several commercially available programmable data plane devices are also compared based on those features.", "pdf_url": "https://arxiv.org/pdf/2008.08697", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Hidden Footprints: Learning Contextual Walkability from 3D Human Trails", "author": "Jin Sun, Hadar Averbuch-Elor, Qianqian Wang, Noah Snavely", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Predicting where people can walk in a scene is important for many tasks, including autonomous driving systems and human behavior analysis. Yet learning a computational model for this purpose is challenging due to semantic ambiguity and a lack of labeled data: current datasets only tell you where people are, not where they could be. We tackle this problem by leveraging information from existing datasets, without additional labeling. We first augment the set of valid, labeled walkable regions by propagating person observations between images, utilizing 3D information to create what we call hidden footprints. However, this augmented data is still sparse. We devise a training strategy designed for such sparse labels, combining a class-balanced classification loss with a contextual adversarial loss. Using this strategy, we demonstrate a model that learns to predict a walkability map from a single image. We evaluate our model on the Waymo and Cityscapes datasets, demonstrating superior performance compared to baselines and state-of-the-art models.", "pdf_url": "https://arxiv.org/pdf/2008.08701", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Synthesizing Optimal Collective Algorithms", "author": "Zixian Cai, Zhengyang Liu, Saeed Maleki, Madan Musuvathi, Todd Mytkowicz, Jacob Nelson, Olli Saarikivi", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Collective communication algorithms are an important component of distributed computation. Indeed, in the case of deep-learning, collective communication is the Amdahl's bottleneck of data-parallel training. This paper introduces SCCL (for Synthesized Collective Communication Library), a systematic approach to synthesize collective communication algorithms that are explicitly tailored to a particular hardware topology. SCCL synthesizes algorithms along the Pareto-frontier spanning from latency-optimal to bandwidth-optimal implementations of a collective. The paper demonstrates how to encode SCCL's synthesis as a quantifier-free SMT formula which can be discharged to a theorem prover. We further demonstrate how to scale our synthesis by exploiting symmetries in topologies and collectives. We synthesize and introduce novel latency and bandwidth optimal algorithms not seen in the literature on two popular hardware topologies. We also show how SCCL efficiently lowers algorithms to implementations on two hardware architectures (NVIDIA and AMD) and demonstrate competitive performance with hand optimized collective communication libraries.", "pdf_url": "https://arxiv.org/pdf/2008.08708", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Using Ensemble Classifiers to Detect Incipient Anomalies", "author": "Baihong Jin, Yingshui Tan, Albert Liu, Xiangyu Yue, Yuxin Chen, Alberto Sangiovanni Vincentelli", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Incipient anomalies present milder symptoms compared to severe ones, and are more difficult to detect and diagnose due to their close resemblance to normal operating conditions. The lack of incipient anomaly examples in the training data can pose severe risks to anomaly detection methods that are built upon Machine Learning (ML) techniques, because these anomalies can be easily mistaken as normal operating conditions. To address this challenge, we propose to utilize the uncertainty information available from ensemble learning to identify potential misclassified incipient anomalies. We show in this paper that ensemble learning methods can give improved performance on incipient anomalies and identify common pitfalls in these models through extensive experiments on two real-world datasets. Then, we discuss how to design more effective ensemble models for detecting incipient anomalies.", "pdf_url": "https://arxiv.org/pdf/2008.08710", "subject": "Machine Learning (cs.LG)"},
{"title": "Generalizing Fault Detection Against Domain Shifts Using Stratification-Aware Cross-Validation", "author": "Yingshui Tan, Baihong Jin, Qiushi Cui, Xiangyu Yue, Alberto Sangiovanni Vincentelli", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Incipient anomalies present milder symptoms compared to severe ones, and are more difficult to detect and diagnose due to their close resemblance to normal operating conditions. The lack of incipient anomaly examples in the training data can pose severe risks to anomaly detection methods that are built upon Machine Learning (ML) techniques, because these anomalies can be easily mistaken as normal operating conditions. To address this challenge, we propose to utilize the uncertainty information available from ensemble learning to identify potential misclassified incipient anomalies. We show in this paper that ensemble learning methods can give improved performance on incipient anomalies and identify common pitfalls in these models through extensive experiments on two real-world datasets. Then, we discuss how to design more effective ensemble models for detecting incipient anomalies.", "pdf_url": "https://arxiv.org/pdf/2008.08713", "subject": "Machine Learning (cs.LG)"},
{"title": "Text-based Localization of Moments in a Video Corpus", "author": "Sudipta Paul, Niluthpol Chowdhury Mithun, Amit K. Roy-Chowdhury", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Prior works on text-based video moment localization focus on temporally grounding the textual query in an untrimmed video. These works assume that the relevant video is already known and attempt to localize the moment on that relevant video only. Different from such works, we relax this assumption and address the task of localizing moments in a corpus of videos for a given sentence query. This task poses a unique challenge as the system is required to perform: (i) retrieval of the relevant video where only a segment of the video corresponds with the queried sentence, and (ii) temporal localization of moment in the relevant video based on sentence query. Towards overcoming this challenge, we propose Hierarchical Moment Alignment Network (HMAN) which learns an effective joint embedding space for moments and sentences. In addition to learning subtle differences between intra-video moments, HMAN focuses on distinguishing inter-video global semantic concepts based on sentence queries. Qualitative and quantitative results on three benchmark text-based video moment retrieval datasets - Charades-STA, DiDeMo, and ActivityNet Captions - demonstrate that our method achieves promising performance on the proposed task of temporal localization of moments in a corpus of videos.", "pdf_url": "https://arxiv.org/pdf/2008.08716", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Non-overlapping block smoothers for the Stokes equations", "author": "Lisa Claus, Matthias Bolten", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Overlapping block smoothers efficiently damp the error contributions from highly oscillatory components within multigrid methods for the Stokes equations but they are computationally expensive. This paper is concentrated on the development and analysis of new block smoothers for the Stokes equations that are discretized on staggered grids. These smoothers are non-overlapping and therefore desirable due to reduced computational costs. Traditional geometric multigrid methods are based on simple pointwise smoothers. However, the efficiency of multigrid methods for solving more difficult problems such as the Stokes equations lead to computationally more expensive smoothers, e.g., overlapping block smoothers. Non-overlapping smoothers are less expensive, but have been considered less efficient in the literature. In this paper, we develop new non-overlapping smoothers, the so-called triad-wise smoothers, and show their efficiency within multigrid methods to solve the Stokes equations. In addition, we compare overlapping and non-overlapping smoothers by measuring their computational costs and analyzing their behavior by the use of local Fourier analysis.", "pdf_url": "https://arxiv.org/pdf/2008.08719", "subject": "Numerical Analysis (math.NA)"},
{"title": "The Quantum Supremacy Tsirelson Inequality", "author": "William Kretschmer", "pub_date": "Submitted on 20 Aug 2020", "abstract": "A leading proposal for verifying near-term quantum supremacy experiments on noisy random quantum circuits is linear cross-entropy benchmarking. For a quantum circuit $C$ on $n$ qubits and a sample $z \\in \\{0,1\\}^n$, the benchmark involves computing $|\\langle z|C|0^n \\rangle|^2$, i.e. the probability of measuring $z$ from the output distribution of $C$ on the all zeros input. Under a strong conjecture about the classical hardness of estimating output probabilities of quantum circuits, no polynomial-time classical algorithm given $C$ can output a string $z$ such that $|\\langle z|C|0^n\\rangle|^2$ is substantially larger than $\\frac{1}{2^n}$ (Aaronson and Gunn, 2019). On the other hand, for a random quantum circuit $C$, sampling $z$ from the output distribution of $C$ achieves $|\\langle z|C|0^n\\rangle|^2 \\approx \\frac{2}{2^n}$ on average (Arute et al., 2019). In analogy with the Tsirelson inequality from quantum nonlocal correlations, we ask: can a polynomial-time quantum algorithm do substantially better than $\\frac{2}{2^n}$? We study this question in the query (or black box) model, where the quantum algorithm is given oracle access to $C$. We show that, for any $\\varepsilon \\ge \\frac{1}{\\mathrm{poly}(n)}$, outputting a sample $z$ such that $|\\langle z|C|0^n\\rangle|^2 \\ge \\frac{2 + \\varepsilon}{2^n}$ on average requires at least $\\Omega\\left(\\frac{2^{n/4}}{\\mathrm{poly}(n)}\\right)$ queries to $C$, but not more than $O\\left(2^{n/3}\\right)$ queries to $C$, if $C$ is either a Haar-random $n$-qubit unitary, or a canonical state preparation oracle for a Haar-random $n$-qubit state. We also show that when $C$ samples from the Fourier distribution of a random Boolean function, the naive algorithm that samples from $C$ is the optimal 1-query algorithm for maximizing $|\\langle z|C|0^n\\rangle|^2$ on average.", "pdf_url": "https://arxiv.org/pdf/2008.08721", "subject": "Computational Complexity (cs.CC)"},
{"title": "Assigning function to protein-protein interactions: a weakly supervised BioBERT based approach using PubMed abstracts", "author": "Aparna Elangovan, Melissa Davis, Karin Verspoor", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Motivation: Protein-protein interactions (PPI) are critical to the function of proteins in both normal and diseased cells, and many critical protein functions are mediated by interactions.Knowledge of the nature of these interactions is important for the construction of networks to analyse biological data. However, only a small percentage of PPIs captured in protein interaction databases have annotations of function available, e.g. only 4% of PPI are functionally annotated in the IntAct database. Here, we aim to label the function type of PPIs by extracting relationships described in PubMed abstracts. Method: We create a weakly supervised dataset from the IntAct PPI database containing interacting protein pairs with annotated function and associated abstracts from the PubMed database. We apply a state-of-the-art deep learning technique for biomedical natural language processing tasks, BioBERT, to build a model - dubbed PPI-BioBERT - for identifying the function of PPIs. In order to extract high quality PPI functions at large scale, we use an ensemble of PPI-BioBERT models to improve uncertainty estimation and apply an interaction type-specific threshold to counteract the effects of variations in the number of training samples per interaction type. Results: We scan 18 million PubMed abstracts to automatically identify 3253 new typed PPIs, including phosphorylation and acetylation interactions, with an overall precision of 46% (87% for acetylation) based on a human-reviewed sample. This work demonstrates that analysis of biomedical abstracts for PPI function extraction is a feasible approach to substantially increasing the number of interactions annotated with function captured in online databases.", "pdf_url": "https://arxiv.org/pdf/2008.08727", "subject": "Computation and Language (cs.CL)"},
{"title": "Model-free optimal control of discrete-time systems with additive and multiplicative noises", "author": "Jing Lai, Junlin Xiong, Zhan Shu", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper investigates the optimal control problem for a class of discrete-time stochastic systems subject to additive and multiplicative noises. A stochastic Lyapunov equation and a stochastic algebra Riccati equation are established for the existence of the optimal admissible control policy. A model-free reinforcement learning algorithm is proposed to learn the optimal admissible control policy using the data of the system states and inputs without requiring any knowledge of the system matrices. It is proven that the learning algorithm converges to the optimal admissible control policy. The implementation of the model-free algorithm is based on batch least squares and numerical average. The proposed algorithm is illustrated through a numerical example, which shows our algorithm outperforms other policy iteration algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.08734", "subject": "Systems and Control (eess.SY)"},
{"title": "Simultaneously-Collected Multimodal Lying Pose Dataset: Towards In-Bed Human Pose Monitoring under Adverse Vision Conditions", "author": "Shuangjun Liu, Xiaofei Huang, Nihang Fu, Cheng Li, Zhongnan Su, Sarah Ostadabbas", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Computer vision (CV) has achieved great success in interpreting semantic meanings from images, yet CV algorithms can be brittle for tasks with adverse vision conditions and the ones suffering from data/label pair limitation. One of this tasks is in-bed human pose estimation, which has significant values in many healthcare applications. In-bed pose monitoring in natural settings could involve complete darkness or full occlusion. Furthermore, the lack of publicly available in-bed pose datasets hinders the use of many successful pose estimation algorithms for this task. In this paper, we introduce our Simultaneously-collected multimodal Lying Pose (SLP) dataset, which includes in-bed pose images from 109 participants captured using multiple imaging modalities including RGB, long wave infrared, depth, and pressure map. We also present a physical hyper parameter tuning strategy for ground truth pose label generation under extreme conditions such as lights off and being fully covered by a sheet/blanket. SLP design is compatible with the mainstream human pose datasets, therefore, the state-of-the-art 2D pose estimation models can be trained effectively with SLP data with promising performance as high as 95% at PCKh@0.5 on a single modality. The pose estimation performance can be further improved by including additional modalities through collaboration.", "pdf_url": "https://arxiv.org/pdf/2008.08735", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Simple and Efficient Cardinality Estimation in Data Streams", "author": "Seth Pettie, Dingyu Wang, Longhui Yin", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We study sketching schemes for the cardinality estimation problem in data streams, and advocate for measuring the efficiency of such a scheme in terms of its MVP: Memory-Variance Product, i.e., the product of its space, in bits, and the relative variance of its estimates. Under this natural metric, the celebrated HyperLogLog sketch of Flajolet et al. (2007) has an MVP approaching $6(3\\ln 2-1)\\approx 6.48$ for estimating cardinalities up to $2^{64}$. Applying the Cohen/Ting (2014) martingale transformation results in a sketch Martingale HyperLogLog with MVP $ \\approx 4.16$, though it is not composable. Recently Pettie and Wang (2020) proved that it is possible to achieve MVP approaching $\\approx 1.98$ with a composable sketch called Fishmonger, though the time required to update this sketch is not constant. Our aim in this paper is to strike a nice balance between extreme simplicity (exemplified by (Martingale) (Hyper)LogLog) and extreme information-theoretic efficiency exemplified by Fishmonger). We develop a new class of \"curtain\" sketches that are a bit more complex than Martingale LogLog but with substantially better $\\MVP$s, e.g., Martingale Curtain has MVP $ \\approx 2.31$. We also prove that Martingale Fishmonger has an MVP of around $1.63$, and conjecture this to be an information-theoretic lower bound on the problem, independent of update time.", "pdf_url": "https://arxiv.org/pdf/2008.08739", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Energy-efficiency of Massive Random Access with Individual Codebook", "author": "Junyuan Gao, Yongpeng Wu, Wenjun Zhang", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The massive machine-type communication has been one of the most representative services for future wireless networks. It aims to support massive connectivity of user equipments (UEs) which sporadically transmit packets with small size. In this work, we assume the number of UEs grows linearly and unboundedly with blocklength and each UE has an individual codebook. Among all UEs, an unknown subset of UEs are active and transmit a fixed number of data bits to a base station over a shared-spectrum radio link. Under these settings, we derive the achievability and converse bounds on the minimum energy-per-bit for reliable random access over quasi-static fading channels with and without channel state information (CSI) at the receiver. These bounds provide energy-efficiency guidance for new schemes suited for massive random access. Simulation results indicate that the orthogonalization scheme TDMA is energy-inefficient for large values of UE density $\\mu$. Besides, the multi-user interference can be perfectly cancelled when $\\mu$ is below a critical threshold. In the case of no-CSI, the energy-per-bit for random access is only a bit more than that with the knowledge UE activity.", "pdf_url": "https://arxiv.org/pdf/2008.08740", "subject": "Information Theory (cs.IT)"},
{"title": "Massive Unsourced Random Access for Massive MIMO Correlated Channels", "author": "Xinyu Xie, Yongpeng Wu, Junyuan Gao, Wenjun Zhang", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper investigates the massive random access for a huge amount of user devices served by a base station (BS) equipped with a massive number of antennas. We consider a grant-free unsourced random access (U-RA) scheme where all users possess the same codebook and the BS aims at declaring a list of transmitted codewords and recovering the messages sent by active users. Most of the existing works concentrate on applying U-RA in the oversimplified independent and identically distributed (i.i.d.) channels. In this paper, we consider a fairly general joint-correlated MIMO channel model with line-of-sight components for the realistic outdoor wireless propagation environments. We conduct the activity detection for the emitted codewords by performing an improved coordinate descent approach with Bayesian learning automaton to solve a covariance-based maximum likelihood estimation problem. The proposed algorithm exhibits a faster convergence rate than traditional descent approaches. We further employ a coupled coding scheme to resolve the issue that the dimensions of the common codebook expand exponentially with user payload size in the practical massive machine-type communications scenario. Our simulations reveal that to achieve an error probability of 0.05 for reliable communications in correlated channels, one must pay a 0.9 to 1.3 dB penalty comparing to the minimum signal to noise ratio needed in i.i.d. channels on condition that a sufficient number of receiving antennas is equipped at the BS.", "pdf_url": "https://arxiv.org/pdf/2008.08742", "subject": "Information Theory (cs.IT)"},
{"title": "Understanding the Advisor-advisee Relationship via Scholarly Data Analysis", "author": "Jiaying Liu, Tao Tang, Xiangjie Kong, Amr Tolba, Zafer AL-Makhadmeh, Feng Xia", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Advisor-advisee relationship is important in academic networks due to its universality and necessity. Despite the increasing desire to analyze the career of newcomers, however, the outcomes of different collaboration patterns between advisors and advisees remain unknown. The purpose of this paper is to find out the correlation between advisors' academic characteristics and advisees' academic performance in Computer Science. Employing both quantitative and qualitative analysis, we find that with the increase of advisors' academic age, advisees' performance experiences an initial growth, follows a sustaining stage, and finally ends up with a declining trend. We also discover the phenomenon that accomplished advisors can bring up skilled advisees. We explore the conclusion from two aspects: (1) Advisees mentored by advisors with high academic level have better academic performance than the rest; (2) Advisors with high academic level can raise their advisees' h-index ranking. This work provides new insights on promoting our understanding of the relationship between advisors' academic characteristics and advisees' performance, as well as on advisor choosing.", "pdf_url": "https://arxiv.org/pdf/2008.08743", "subject": "Digital Libraries (cs.DL)"},
{"title": "A comparison of mixed multiscale finite element methods for multiphase transport in highly heterogeneous media", "author": "Yiran Wang, Eric Chung, Shubin Fu", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this paper, we systemically review and compare two mixed multiscale finite element methods (MMsFEM) for multiphase transport in highly heterogeneous media. In particular, we will consider the mixed multiscale finite element method using limited global information, simply denoted by MMsFEM, and the mixed generalized multiscale finite element method (MGMsFEM) with residual driven online multiscale basis functions. Both methods are under the framework of mixed multiscale finite element methods, where the pressure equation is solved in the coarse grid with carefully constructed multiscale basis functions for the velocity. The multiscale basis functions in both methods include local and global media information. In terms of MsFEM using limited global information, only one multiscale basis function is utilized in each local neighborhood while multiple basis are used in MGMsFEM. We will test and compare these two methods using the benchmark three-dimensional SPE10 model. A range of coarse grid sizes and different combinations of basis functions (offline and online) will be considered with CPU time reported for each case. In our numerical experiments, we observe good accuracy by the two above methods. Finally, we will discuss and compare the advantages and disadvantages of the two methods in terms of accuracy and computational costs.", "pdf_url": "https://arxiv.org/pdf/2008.08744", "subject": "Numerical Analysis (math.NA)"},
{"title": "DPMC: Weighted Model Counting by Dynamic Programming on Project-Join Trees", "author": "Jeffrey M. Dudek, Vu H. N. Phan, Moshe Y. Vardi", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We propose a unifying dynamic-programming framework to compute exact literal-weighted model counts of formulas in conjunctive normal form. At the center of our framework are project-join trees, which specify efficient project-join orders to apply additive projections (variable eliminations) and joins (clause multiplications). In this framework, model counting is performed in two phases. First, the planning phase constructs a project-join tree from a formula. Second, the execution phase computes the model count of the formula, employing dynamic programming as guided by the project-join tree. We empirically evaluate various methods for the planning phase and compare constraint-satisfaction heuristics with tree-decomposition tools. We also investigate the performance of different data structures for the execution phase and compare algebraic decision diagrams with tensors. We show that our dynamic-programming model-counting framework DPMC is competitive with the state-of-the-art exact weighted model counters cachet, c2d, d4, and miniC2D.", "pdf_url": "https://arxiv.org/pdf/2008.08748", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "Prototype-based interpretation of the functionality of neurons in winner-take-all neural networks", "author": "Ramin Zarei Sabzevar, Kamaledin Ghiasi-Shirazi, Ahad Harati", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Prototype-based learning (PbL) using a winner-take-all (WTA) network based on minimum Euclidean distance (ED-WTA) is an intuitive approach to multiclass classification. By constructing meaningful class centers, PbL provides higher interpretability and generalization than hyperplane-based learning (HbL) methods based on maximum Inner Product (IP-WTA) and can efficiently detect and reject samples that do not belong to any classes. In this paper, we first prove the equivalence of IP-WTA and ED-WTA from a representational point of view. Then, we show that naively using this equivalence leads to unintuitive ED-WTA networks in which the centers have high distances to data that they represent. We propose $\\pm$ED-WTA which models each neuron with two prototypes: one positive prototype representing samples that are modeled by this neuron and a negative prototype representing the samples that are erroneously won by that neuron during training. We propose a novel training algorithm for the $\\pm$ED-WTA network, which cleverly switches between updating the positive and negative prototypes and is essential to the emergence of interpretable prototypes. Unexpectedly, we observed that the negative prototype of each neuron is indistinguishably similar to the positive one. The rationale behind this observation is that the training data that are mistaken with a prototype are indeed similar to it. The main finding of this paper is this interpretation of the functionality of neurons as computing the difference between the distances to a positive and a negative prototype, which is in agreement with the BCM theory. In our experiments, we show that the proposed $\\pm$ED-WTA method constructs highly interpretable prototypes that can be successfully used for detecting outlier and adversarial examples.", "pdf_url": "https://arxiv.org/pdf/2008.08750", "subject": "Machine Learning (cs.LG)"},
{"title": "When Homomorphic Encryption Marries Secret Sharing: Secure Large-Scale Sparse Logistic Regression and Applications in Risk Control", "author": "Chaochao Chen, Jun Zhou, Li Wang, Xibin Wu, Wenjing Fang, Jin Tan, Lei Wang, Xiaoxi Ji, Alex Liu, Hao Wang, Cheng Hong", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Logistic Regression (LR) is the most widely used machine learning model in industry due to its efficiency, robustness, and interpretability. Meanwhile, with the problem of data isolation and the requirement of high model performance, building secure and efficient LR model for multi-parties becomes a hot topic for both academia and industry. Existing works mainly employ either Homomorphic Encryption (HE) or Secret Sharing (SS) to build secure LR. HE based methods can deal with high-dimensional sparse features, but they may suffer potential security risk. In contrast, SS based methods have provable security but they have efficiency issue under high-dimensional sparse features. In this paper, we first present CAESAR, which combines HE and SS to build seCure lArge-scalE SpArse logistic Regression model and thus has the advantages of both efficiency and security. We then present the distributed implementation of CAESAR for scalability requirement. We finally deploy CAESAR into a risk control task and conduct comprehensive experiments to study the efficiency of CAESAR.", "pdf_url": "https://arxiv.org/pdf/2008.08753", "subject": "Cryptography and Security (cs.CR)"},
{"title": "On $\\ell_p$-norm Robustness of Ensemble Stumps and Trees", "author": "Yihan Wang, Huan Zhang, Hongge Chen, Duane Boning, Cho-Jui Hsieh", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Recent papers have demonstrated that ensemble stumps and trees could be vulnerable to small input perturbations, so robustness verification and defense for those models have become an important research problem. However, due to the structure of decision trees, where each node makes decision purely based on one feature value, all the previous works only consider the $\\ell_\\infty$ norm perturbation. To study robustness with respect to a general $\\ell_p$ norm perturbation, one has to consider the correlation between perturbations on different features, which has not been handled by previous algorithms. In this paper, we study the problem of robustness verification and certified defense with respect to general $\\ell_p$ norm perturbations for ensemble decision stumps and trees. For robustness verification of ensemble stumps, we prove that complete verification is NP-complete for $p\\in(0, \\infty)$ while polynomial time algorithms exist for $p=0$ or $\\infty$. For $p\\in(0, \\infty)$ we develop an efficient dynamic programming based algorithm for sound verification of ensemble stumps. For ensemble trees, we generalize the previous multi-level robustness verification algorithm to $\\ell_p$ norm. We demonstrate the first certified defense method for training ensemble stumps and trees with respect to $\\ell_p$ norm perturbations, and verify its effectiveness empirically on real datasets.", "pdf_url": "https://arxiv.org/pdf/2008.08755", "subject": "Machine Learning (cs.LG)"},
{"title": "iCaps: An Interpretable Classifier via Disentangled Capsule Networks", "author": "Dahuin Jung, Jonghyun Lee, Jihun Yi, Sungroh Yoon", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We propose an interpretable Capsule Network, iCaps, for image classification. A capsule is a group of neurons nested inside each layer, and the one in the last layer is called a class capsule, which is a vector whose norm indicates a predicted probability for the class. Using the class capsule, existing Capsule Networks already provide some level of interpretability. However, there are two limitations which degrade its interpretability: 1) the class capsule also includes classification-irrelevant information, and 2) entities represented by the class capsule overlap. In this work, we address these two limitations using a novel class-supervised disentanglement algorithm and an additional regularizer, respectively. Through quantitative and qualitative evaluations on three datasets, we demonstrate that the resulting classifier, iCaps, provides a prediction along with clear rationales behind it with no performance degradation.", "pdf_url": "https://arxiv.org/pdf/2008.08756", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Semi-Blind and l1 Robust System Identification for Anemia Management", "author": "Affan Affan, Tamer Inanc", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Chronic diseases such as cancer, diabetes, heart diseases, chronic kidney disease (CKD) require a drug management system that ensures a stable and robust output of the patient's condition in response to drug dosage. In the case of CKD, the patients suffer from the deficiency of red blood cell count and external human recombinant erythropoietin (EPO) is required to maintain healthy levels of hemoglobin (Hb). Anemia is a common comorbidity in patients with CKD. For an efficient and robust anemia management system for CKD patients instead of traditional population-based approaches, individualized patient-specific approaches are needed. Hence, individualized system (patient) models for patient-specific drug-dose responses are required. In this research, system identification for CKD is performed for individual patients. For control-oriented system identification, two robust identification techniques are applied: (1) l1 robust identification considering zero initial conditions and (2) semi-blind robust system identification considering non-zero initial conditions. The EPO data of patients are used as the input and Hb data is used as the output of the system. For this study, individualized patient models are developed by using patient-specific data. The ARX one-step-ahead prediction technique is used for model validation at real patient data. The performance of these two techniques is compared by calculating minimum means square error (MMSE). By comparison, we show that the semi-blind robust identification technique gives better results as compared to l1 robust identification.", "pdf_url": "https://arxiv.org/pdf/2008.08758", "subject": "Quantitative Methods (q-bio.QM)"},
{"title": "Corrections to \"An Innovations Approach to Viterbi Decoding of Convolutional Codes\"", "author": "Masato Tajima", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We correct errors in Section III-B of the above-titled paper. The corrections are related to the joint distribution of the inputs to the main decoder which corresponds to a branch in the code trellis for the main decoder. Note that as far as the distribution of the input corresponding to a single code symbol is concerned, the results in Section III-B are correct. We have noticed that alpha in Proposition 12 (beta in Proposition 14) has another meaning, which has made it possible to derive the joint distribution of the inputs corresponding to the whole branch. Corrections are based on this important observation.", "pdf_url": "https://arxiv.org/pdf/2008.08760", "subject": "Information Theory (cs.IT)"},
{"title": "Deformable PV-RCNN: Improving 3D Object Detection with Learned Deformations", "author": "Prarthana Bhattacharyya, Krzysztof Czarnecki", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We present Deformable PV-RCNN, a high-performing point-cloud based 3D object detector. Currently, the proposal refinement methods used by the state-of-the-art two-stage detectors cannot adequately accommodate differing object scales, varying point-cloud density, part-deformation and clutter. We present a proposal refinement module inspired by 2D deformable convolution networks that can adaptively gather instance-specific features from locations where informative content exists. We also propose a simple context gating mechanism which allows the keypoints to select relevant context information for the refinement stage. We show state-of-the-art results on the KITTI dataset.", "pdf_url": "https://arxiv.org/pdf/2008.08766", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Lite Training Strategies for Portuguese-English and English-Portuguese Translation", "author": "Alexandre Lopes, Rodrigo Nogueira, Roberto Lotufo, Helio Pedrini", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Despite the widespread adoption of deep learning for machine translation, it is still expensive to develop high-quality translation models. In this work, we investigate the use of pre-trained models, such as T5 for Portuguese-English and English-Portuguese translation tasks using low-cost hardware. We explore the use of Portuguese and English pre-trained language models and propose an adaptation of the English tokenizer to represent Portuguese characters, such as diaeresis, acute and grave accents. We compare our models to the Google Translate API and MarianMT on a subset of the ParaCrawl dataset, as well as to the winning submission to the WMT19 Biomedical Translation Shared Task. We also describe our submission to the WMT20 Biomedical Translation Shared Task. Our results show that our models have a competitive performance to state-of-the-art models while being trained on modest hardware (a single 8GB gaming GPU for nine days). Our data, models and code are available at .", "pdf_url": "https://arxiv.org/pdf/2008.08769", "subject": "Computation and Language (cs.CL)"},
{"title": "Spatial--spectral FFPNet: Attention-Based Pyramid Network for Segmentation and Classification of Remote Sensing Images", "author": "Qingsong Xu, Xin Yuan, Chaojun Ouyang, Yue Zeng", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We consider the problem of segmentation and classification of high-resolution and hyperspectral remote sensing images. Unlike conventional natural (RGB) images, the inherent large scale and complex structures of remote sensing images pose major challenges such as spatial object distribution diversity and spectral information extraction when existing models are directly applied for image classification. In this study, we develop an attention-based pyramid network for segmentation and classification of remote sensing datasets. Attention mechanisms are used to develop the following modules: i) a novel and robust attention-based multi-scale fusion method effectively fuses useful spatial or spectral information at different and same scales; ii) a region pyramid attention mechanism using region-based attention addresses the target geometric size diversity in large-scale remote sensing images; and iii cross-scale attention} in our adaptive atrous spatial pyramid pooling network adapts to varied contents in a feature-embedded space. Different forms of feature fusion pyramid frameworks are established by combining these attention-based modules. First, a novel segmentation framework, called the heavy-weight spatial feature fusion pyramid network (FFPNet), is proposed to address the spatial problem of high-resolution remote sensing images. Second, an end-to-end spatial--spectral FFPNet is presented for classifying hyperspectral images. Experiments conducted on ISPRS Vaihingen and ISPRS Potsdam high-resolution datasets demonstrate the competitive segmentation accuracy achieved by the proposed heavy-weight spatial FFPNet. Furthermore, experiments on the Indian Pines and the University of Pavia hyperspectral datasets indicate that the proposed spatial--spectral FFPNet outperforms the current state-of-the-art methods in hyperspectral image classification.", "pdf_url": "https://arxiv.org/pdf/2008.08775", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Facial movement synergies and Action Unit detection from distal wearable Electromyography and Computer Vision", "author": "Monica Perusquia-Hernandez, Felix Dollack, Chun Kwang Tan, Shushi Namba, Saho Ayabe-Kanamura, Kenji Suzuki", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Distal facial Electromyography (EMG) can be used to detect smiles and frowns with reasonable accuracy. It capitalizes on volume conduction to detect relevant muscle activity, even when the electrodes are not placed directly on the source muscle. The main advantage of this method is to prevent occlusion and obstruction of the facial expression production, whilst allowing EMG measurements. However, measuring EMG distally entails that the exact source of the facial movement is unknown. We propose a novel method to estimate specific Facial Action Units (AUs) from distal facial EMG and Computer Vision (CV). This method is based on Independent Component Analysis (ICA), Non-Negative Matrix Factorization (NNMF), and sorting of the resulting components to determine which is the most likely to correspond to each CV-labeled action unit (AU). Performance on the detection of AU06 (Orbicularis Oculi) and AU12 (Zygomaticus Major) was estimated by calculating the agreement with Human Coders. The results of our proposed algorithm showed an accuracy of 81% and a Cohen's Kappa of 0.49 for AU6; and accuracy of 82% and a Cohen's Kappa of 0.53 for AU12. This demonstrates the potential of distal EMG to detect individual facial movements. Using this multimodal method, several AU synergies were identified. We quantified the co-occurrence and timing of AU6 and AU12 in posed and spontaneous smiles using the human-coded labels, and for comparison, using the continuous CV-labels. The co-occurrence analysis was also performed on the EMG-based labels to uncover the relationship between muscle synergies and the kinematics of visible facial movement.", "pdf_url": "https://arxiv.org/pdf/2008.08791", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Distributed Stochastic Subgradient Optimization Algorithms Over Random and Noisy Networks", "author": "Tao Li, Keli Fu, Xiaozheng Fu", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We study distributed stochastic optimization by networked nodes to cooperatively minimize a sum of convex cost functions. The network is modeled by a sequence of time-varying random digraphs with each node representing a local optimizer and each edge representing a communication link. We consider the distributed subgradient optimization algorithm with noisy measurements of local cost functions' subgradients, additive and multiplicative noises among information exchanging between each pair of nodes. By stochastic Lyapunov method, convex analysis, algebraic graph theory and martingale convergence theory, it is proved that if the local subgradient functions grow linearly and the sequence of digraphs is conditionally balanced and uniformly conditionally jointly connected, then proper algorithm step sizes can be designed so that all nodes' states converge to the global optimal solution almost surely.", "pdf_url": "https://arxiv.org/pdf/2008.08796", "subject": "Systems and Control (eess.SY)"},
{"title": "Existence of EFX for Two Additive Valuations", "author": "Ryoga Mahara", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Fair division of indivisible items is a well-studied topic in Economics and Computer Science. The objective is to allocate items to agents in a fair manner, where each agent has a valuation for each subset of items. Several concepts of fairness have been established, and envy-freeness is one of the most widely studied notions of fairness. Since envy-free allocations do not always exist when items are indivisible, several relaxations have been considered. Among them, possibly the most compelling one is envy-freeness up to any item (EFX), where no agent envies another agent after the removal of any single item from the other agent's bundle. However, despite significant efforts by many researchers for several years, it is only known that an EFX allocation always exists when there are at most three agents and their valuations are additive or when all agents have identical valuations. In this paper, we show that an EFX allocation always exists when every agent has one of the two additive valuations. We give a constructive proof, in which we iteratively obtain a Pareto dominating EFX allocation from an existing EFX allocation.", "pdf_url": "https://arxiv.org/pdf/2008.08798", "subject": "Computer Science and Game Theory (cs.GT)"},
{"title": "Adaptive finite element approximation for steady-state Poisson-Nernst-Planck equations", "author": "Tingting Hao, Manman Ma, Xuejun Xu", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this paper, we develop an adaptive finite element method for the nonlinear steady-state Poisson-Nernst-Planck equations, where the spatial adaptivity for geometrical singularities and boundary layer effects are mainly considered. As a key contribution, the steady-state Poisson-Nernst-Planck equations are studied systematically and rigorous analysis for a residual-based a posteriori error estimate of the nonlinear system is presented. With the help of Schauder fixed point theorem, we show the solution existence and uniqueness of the linearized system derived by taking $G-$derivatives of the nonlinear system, followed by the proof of the relationship between the error of solution and the a posteriori error estimator $\\eta$. Numerical experiments are given to validate the efficiency of the a posteriori error estimator and demonstrate the expected rate of convergence. In the further tests, adaptive mesh refinements for geometrical singularities and boundary layer effects are successfully observed.", "pdf_url": "https://arxiv.org/pdf/2008.08805", "subject": "Numerical Analysis (math.NA)"},
{"title": "Varying Annotations in the Steps of the Visual Analysis", "author": "Christoph Schmidt, Paul Rosenthal, Heidrun Schumann", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Annotations in Visual Analytics (VA) have become a common means to support the analysis by integrating additional information into the VA system. That additional information often depends on the current process step in the visual analysis. For example, the data preprocessing step has data structuring operations while the data exploration step focuses on user interaction and input. Describing suitable annotations to meet the goals of the different steps is challenging. To tackle this issue, we identify individual annotations for each step and outline their gathering and design properties for the visual analysis of heterogeneous clinical data. We integrate our annotation design into a visual analysis tool to show its applicability to data from the ophthalmic domain. In interviews and application sessions with experts we asses its usefulness for the analysis of patients with different medications.", "pdf_url": "https://arxiv.org/pdf/2008.08806", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Not one but many Tradeoffs: Privacy Vs. Utility in Differentially Private Machine Learning", "author": "Benjamin Zi Hao Zhao, Mohamed Ali Kaafar, Nicolas Kourtellis", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Data holders are increasingly seeking to protect their user's privacy, whilst still maximizing their ability to produce machine models with high quality predictions. In this work, we empirically evaluate various implementations of differential privacy (DP), and measure their ability to fend off real-world privacy attacks, in addition to measuring their core goal of providing accurate classifications. We establish an evaluation framework to ensure each of these implementations are fairly evaluated. Our selection of DP implementations add DP noise at different positions within the framework, either at the point of data collection/release, during updates while training of the model, or after training by perturbing learned model parameters. We evaluate each implementation across a range of privacy budgets, and datasets, each implementation providing the same mathematical privacy guarantees. By measuring the models' resistance to real world attacks of membership and attribute inference, and their classification accuracy. we determine which implementations provide the most desirable tradeoff between privacy and utility. We found that the number of classes of a given dataset is unlikely to influence where the privacy and utility tradeoff occurs. Additionally, in the scenario that high privacy constraints are required, perturbing input training data does not trade off as much utility, as compared to noise added later in the ML process.", "pdf_url": "https://arxiv.org/pdf/2008.08807", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Multi-Agent Reinforcement Learning with Graph Clustering", "author": "Tianze Zhou, Fubiao Zhang, Chenfei Wang", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this paper, we introduce the group concept into multi-agent reinforcement learning. In this method, agents are divided into several groups and each group completes a specific subtask so that agents can cooperate to complete the main task. Existing methods use the communication vector to exchange information between agents. This may encounter communication redundancy. To solve this problem, we propose a MARL method based on graph clustering. It allows agents to adaptively learn group features and replaces the communication operation. In our method, agent features are divide into two types, including in-group features and individual features. They represent the generality and differences between agents, respectively. Based on the graph attention network(GAT), we introduce the graph clustering method as a punishment to optimize agent group feature. Then these features are used to generate individual Q value. To overcome the consistent problem brought by GAT, we introduce the split loss to distinguish agent features. Our method is easy to convert into the CTDE framework via using Kullback-Leibler divergence method. Empirical results are evaluated on a challenging set of StarCraft II micromanagement tasks. The result shows that our method outperforms existing multi-agent reinforcement learning methods and the performance increases with the number of agents increasing.", "pdf_url": "https://arxiv.org/pdf/2008.08808", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "An Experimental Study of Deep Neural Network Models for Vietnamese Multiple-Choice Reading Comprehension", "author": "Son T. Luu, Kiet Van Nguyen, Anh Gia-Tuan Nguyen, Ngan Luu-Thuy Nguyen", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Machine reading comprehension (MRC) is a challenging task in natural language processing that makes computers understanding natural language texts and answer questions based on those texts. There are many techniques for solving this problems, and word representation is a very important technique that impact most to the accuracy of machine reading comprehension problem in the popular languages like English and Chinese. However, few studies on MRC have been conducted in low-resource languages such as Vietnamese. In this paper, we conduct several experiments on neural network-based model to understand the impact of word representation to the Vietnamese multiple-choice machine reading comprehension. Our experiments include using the Co-match model on six different Vietnamese word embeddings and the BERT model for multiple-choice reading comprehension. On the ViMMRC corpus, the accuracy of BERT model is 61.28% on test set.", "pdf_url": "https://arxiv.org/pdf/2008.08810", "subject": "Computation and Language (cs.CL)"},
{"title": "Faster Heuristics for Graph Burning", "author": "Rahul Kumar Gautam, Anjeneya Swami Kare, S. Durga Bhavani", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Graph burning is a process of information spreading through the network by an agent in discrete steps. The problem is to find an optimal sequence of nodes which have to be given information so that the network is covered in least number of steps. Graph burning problem is NP-Hard for which two approximation algorithms and a few heuristics have been proposed in the literature. In this work, we propose three heuristics, namely, Backbone Based Greedy Heuristic (BBGH), Improved Cutting Corners Heuristic (ICCH) and Component Based Recursive Heuristic (CBRH). These are mainly based on Eigenvector centrality measure. BBGH finds a backbone of the network and picks vertex to be burned greedily from the vertices of the backbone. ICCH is a shortest path based heuristic and picks vertex to burn greedily from best central nodes. The burning number problem on disconnected graphs is harder than on the connected graphs. For example, burning number problem is easy on a path where as it is NP-Hard on disjoint paths. In practice, large networks are generally disconnected and moreover even if the input graph is connected, during the burning process the graph among the unburned vertices may be disconnected. For disconnected graphs, ordering of the components is crucial. Our CBRH works well on disconnected graphs as it prioritizes the components. All the heuristics have been implemented and tested on several bench-mark networks including large networks of size more than $50$K nodes. The experimentation also includes comparison to the approximation algorithms. The advantages of our algorithms are that they are much simpler to implement and also several orders faster than the heuristics proposed in the literature.", "pdf_url": "https://arxiv.org/pdf/2008.08811", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Expressing Diverse Human Driving Behavior with ProbabilisticRewards and Online Inference", "author": "Liting Sun, Zheng Wu, Hengbo Ma, Masayoshi Tomizuka", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In human-robot interaction (HRI) systems, such as autonomous vehicles, understanding and representing human behavior are important. Human behavior is naturally rich and diverse. Cost/reward learning, as an efficient way to learn and represent human behavior, has been successfully applied in many domains. Most of traditional inverse reinforcement learning (IRL) algorithms, however, cannot adequately capture the diversity of human behavior since they assume that all behavior in a given dataset is generated by a single cost this paper, we propose a probabilistic IRL framework that directly learns a distribution of cost functions in continuous domain. Evaluations on both synthetic data and real human driving data are conducted. Both the quantitative and subjective results show that our proposed framework can better express diverse human driving behaviors, as well as extracting different driving styles that match what human participants interpret in our user study.", "pdf_url": "https://arxiv.org/pdf/2008.08812", "subject": "Robotics (cs.RO)"},
{"title": "Grasping Detection Network with Uncertainty Estimation for Confidence-Driven Semi-Supervised Domain Adaptation", "author": "Haiyue Zhu, Yiting Li, Fengjun Bai, Wenjie Chen, Xiaocong Li, Jun Ma, Chek Sing Teo, Pey Yuen Tao, Wei Lin", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Data-efficient domain adaptation with only a few labelled data is desired for many robotic applications, e.g., in grasping detection, the inference skill learned from a grasping dataset is not universal enough to directly apply on various other daily/industrial applications. This paper presents an approach enabling the easy domain adaptation through a novel grasping detection network with confidence-driven semi-supervised learning, where these two components deeply interact with each other. The proposed grasping detection network specially provides a prediction uncertainty estimation mechanism by leveraging on Feature Pyramid Network (FPN), and the mean-teacher semi-supervised learning utilizes such uncertainty information to emphasizing the consistency loss only for those unlabelled data with high confidence, which we referred it as the confidence-driven mean teacher. This approach largely prevents the student model to learn the incorrect/harmful information from the consistency loss, which speeds up the learning progress and improves the model accuracy. Our results show that the proposed network can achieve high success rate on the Cornell grasping dataset, and for domain adaptation with very limited data, the confidence-driven mean teacher outperforms the original mean teacher and direct training by more than 10% in evaluation loss especially for avoiding the overfitting and model diverging.", "pdf_url": "https://arxiv.org/pdf/2008.08817", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "VAIM: Visual Analytics for Influence Maximization", "author": "Alessio Arleo, Walter Didimo, Giuseppe Liotta, Silvia Miksch, Fabrizio Montecchiani", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In social networks, individuals' decisions are strongly influenced by recommendations from their friends and acquaintances. The influence maximization (IM) problem asks to select a seed set of users that maximizes the influence spread, i.e., the expected number of users influenced through a stochastic diffusion process triggered by the seeds. In this paper, we present VAIM, a visual analytics system that supports users in analyzing the information diffusion process determined by different IM algorithms. By using VAIM one can: (i) simulate the information spread for a given seed set on a large network, (ii) analyze and compare the effectiveness of different seed sets, and (iii) modify the seed sets to improve the corresponding influence spread.", "pdf_url": "https://arxiv.org/pdf/2008.08821", "subject": "Social and Information Networks (cs.SI)"},
{"title": "A Simple and Fast Algorithm for Computing the $N$-th Term of a Linearly Recurrent Sequence", "author": "Alin Bostan, Ryuhei Mori", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We present a simple and fast algorithm for computing the $N$-th term of a given linearly recurrent sequence. Our new algorithm uses $O(\\mathsf{M}(d) \\log N)$ arithmetic operations, where $d$ is the order of the recurrence, and $\\mathsf{M}(d)$ denotes the number of arithmetic operations for computing the product of two polynomials of degree $d$. The state-of-the-art algorithm, due to Charles Fiduccia (1985), has the same arithmetic complexity up to a constant factor. Our algorithm is simpler, faster and obtained by a totally different method. We also discuss several algorithmic applications, notably to polynomial modular exponentiation, powering of matrices and high-order lifting.", "pdf_url": "https://arxiv.org/pdf/2008.08822", "subject": "Symbolic Computation (cs.SC)"},
{"title": "DronePose: Photorealistic UAV-Assistant Dataset Synthesis for 3D Pose Estimation via a Smooth Silhouette Loss", "author": "Georgios Albanis, Nikolaos Zioulis, Anastasios Dimou, Dimitrios Zarpalas, Petrod Daras", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this work we consider UAVs as cooperative agents supporting human users in their operations. In this context, the 3D localisation of the UAV assistant is an important task that can facilitate the exchange of spatial information between the user and the UAV. To address this in a data-driven manner, we design a data synthesis pipeline to create a realistic multimodal dataset that includes both the exocentric user view, and the egocentric UAV view. We then exploit the joint availability of photorealistic and synthesized inputs to train a single-shot monocular pose estimation model. During training we leverage differentiable rendering to supplement a state-of-the-art direct regression objective with a novel smooth silhouette loss. Our results demonstrate its qualitative and quantitative performance gains over traditional silhouette objectives. Our data and code are available at", "pdf_url": "https://arxiv.org/pdf/2008.08823", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Efficient and Accurate Algorithms for Solving the Bethe-Salpeter Eigenvalue Problem for Crystalline Systems", "author": "Peter Benner, Carolin Penke", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Optical properties of materials related to light absorption and scattering are explained by the excitation of electrons. The Bethe-Salpeter equation is the state-of-the-art approach to describe these processes from first principles (ab initio), i.e. without the need for empirical data in the model. To harness the predictive power of the equation, it is mapped to an eigenvalue problem via an appropriate discretization scheme. The eigenpairs of the resulting large, dense, structured matrix can be used to compute dielectric properties of the considered crystalline or molecular system. The matrix always shows a $2\\times 2$ block structure. Additionally, certain definiteness properties typically hold. One form can be acquired for crystalline systems, another one is more general and can for example be used to study molecules. In this work, we present new theoretical results characterizing the structure of the two forms in the language of non-standard scalar products. These results enable us to develop a new perspective on the state-of-the-art solution approach for crystalline systems. This new viewpoint is used to develop two new methods for solving the eigenvalue problem. One requires less computational effort while providing the same degree of accuracy. The other one improves the expected accuracy, compared to methods currently in use, with a comparable performance. Both methods are well suited for high performance environments and only rely on basic numerical linear algebra building blocks.", "pdf_url": "https://arxiv.org/pdf/2008.08825", "subject": "Numerical Analysis (math.NA)"},
{"title": "Simultaneous Detection and Tracking with Motion Modelling for Multiple Object Tracking", "author": "ShiJie Sun, Naveed Akhtar, XiangYu Song, HuanSheng Song, Ajmal Mian, Mubarak Shah", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Deep learning-based Multiple Object Tracking (MOT) currently relies on off-the-shelf detectors for tracking-by-detection.This results in deep models that are detector biased and evaluations that are detector influenced. To resolve this issue, we introduce Deep Motion Modeling Network (DMM-Net) that can estimate multiple objects' motion parameters to perform joint detection and association in an end-to-end manner. DMM-Net models object features over multiple frames and simultaneously infers object classes, visibility, and their motion parameters. These outputs are readily used to update the tracklets for efficient MOT. DMM-Net achieves PR-MOTA score of 12.80 @ 120+ fps for the popular UA-DETRAC challenge, which is better performance and orders of magnitude faster. We also contribute a synthetic large-scale public dataset Omni-MOT for vehicle tracking that provides precise ground-truth annotations to eliminate the detector influence in MOT evaluation. This 14M+ frames dataset is extendable with our public script (Code at Dataset < >, Dataset Recorder < >, Omni-MOT Source < >). We demonstrate the suitability of Omni-MOT for deep learning with DMMNet and also make the source code of our network public.", "pdf_url": "https://arxiv.org/pdf/2008.08826", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Plane Spanning Trees in Edge-Colored Simple Drawings of $K_n$", "author": "Oswin Aichholzer, Michael Hoffmann, Johannes Obenaus, Rosna Paul, Daniel Perz, Nadja Seiferth, Birgit Vogtenhuber, Alexandra Weinberger", "pub_date": "Submitted on 20 Aug 2020", "abstract": "K\u00e1rolyi, Pach, and T\u00f3th proved that every 2-edge-colored straight-line drawing of the complete graph contains a monochromatic plane spanning tree. It is open if this statement generalizes to other classes of drawings, specifically, to simple drawings of the complete graph. These are drawings where edges are represented by Jordan arcs, any two of which intersect at most once. We present two partial results towards such a generalization. First, we show that the statement holds for cylindrical simple drawings. (In a cylindrical drawing, all vertices are placed on two concentric circles and no edge crosses either circle.) Second, we introduce a relaxation of the problem in which the graph is $k$-edge-colored, and the target structure must be hypochromatic, that is, avoid (at least) one color class. In this setting, we show that every $\\lceil (n+5)/6\\rceil$-edge-colored monotone simple drawing of $K_n$ contains a hypochromatic plane spanning tree. (In a monotone drawing, every edge is represented as an $x$-monotone curve.)", "pdf_url": "https://arxiv.org/pdf/2008.08827", "subject": "Computational Geometry (cs.CG)"},
{"title": "On the Use of Quasiorders in Formal Language Theory", "author": "Pedro Valero", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this thesis we use quasiorders on words to offer a new perspective on two well-studied problems from Formal Language Theory: deciding language inclusion and manipulating the finite automata representations of regular languages. First, we present a generic quasiorder-based framework that, when instantiated with different quasiorders, yields different algorithms (some of them new) for deciding language inclusion. We then instantiate this framework to devise an efficient algorithm for searching with regular expressions on grammar-compressed text. Finally, we define a framework of quasiorder-based automata constructions to offer a new perspective on residual automata.", "pdf_url": "https://arxiv.org/pdf/2008.08828", "subject": "Formal Languages and Automata Theory (cs.FL)"},
{"title": "Optimal Load Balancing in Bipartite Graphs", "author": "Wentao Weng, Xingyu Zhou, R. Srikant", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Applications in cloud platforms motivate the study of efficient load balancing under job-server constraints and server heterogeneity. In this paper, we study load balancing on a bipartite graph where left nodes correspond to job types and right nodes correspond to servers, with each edge indicating that a job type can be served by a server. Thus edges represent locality constraints, i.e., each job can only be served at servers which contained certain data and/or machine learning (ML) models. Servers in this system can have heterogeneous service rates. In this setting, we investigate the performance of two policies named Join-the-Fastest-of-the-Shortest-Queue (JFSQ) and Join-the-Fastest-of-the-Idle-Queue (JFIQ), which are simple variants of Join-the-Shortest-Queue and Join-the-Idle-Queue, where ties are broken in favor of the fastest servers. Under a \"well-connected\" graph condition, we show that JFSQ and JFIQ are asymptotically optimal in the mean response time when the number of servers goes to infinity. In addition to asymptotic optimality, we also obtain upper bounds on the mean response time for finite-size systems. We further show that the well-connectedness condition can be satisfied by a random bipartite graph construction with relatively sparse connectivity.", "pdf_url": "https://arxiv.org/pdf/2008.08830", "subject": "Performance (cs.PF)"},
{"title": "EGO-Planner: An ESDF-free Gradient-based Local Planner for Quadrotors", "author": "Xin Zhou, Zhepei Wang, Chao Xu, Fei Gao", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Gradient-based planners are widely used for quadrotor local planning, in which a Euclidean Signed Distance Field (ESDF) is crucial for evaluating gradient magnitude and direction. Nevertheless, computing such a field has much redundancy since the trajectory optimization procedure only covers a very limited subspace of the ESDF updating range. In this paper, an ESDF-free gradient-based planning framework is proposed, which significantly reduces computation time. The main improvement is that the collision term in penalty function is formulated by comparing the colliding trajectory with a collision-free guiding path. The resulting obstacle information will be stored only if the trajectory hits new obstacles, making the planner only extract necessary obstacle information. Then, we lengthen the time allocation if dynamical feasibility is violated. An anisotropic curve fitting algorithm is introduced to adjust higher order derivatives of the trajectory while maintaining the original shape. Benchmark comparisons and real-world experiments verify its robustness and high-performance. The source code is released as ros packages.", "pdf_url": "https://arxiv.org/pdf/2008.08835", "subject": "Robotics (cs.RO)"},
{"title": "Training Matters: Unlocking Potentials of Deeper Graph Convolutional Neural Networks", "author": "Sitao Luan, Mingde Zhao, Xiao-Wen Chang, Doina Precup", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The performance limit of Graph Convolutional Networks (GCNs) and the fact that we cannot stack more of them to increase the performance, which we usually do for other deep learning paradigms, are pervasively thought to be caused by the limitations of the GCN layers, including insufficient expressive power, etc. However, if so, for a fixed architecture, it would be unlikely to lower the training difficulty and to improve performance by changing only the training procedure, which we show in this paper not only possible but possible in several ways. This paper first identify the training difficulty of GCNs from the perspective of graph signal energy loss. More specifically, we find that the loss of energy in the backward pass during training nullifies the learning of the layers closer to the input. Then, we propose several methodologies to mitigate the training problem by slightly modifying the GCN operator, from the energy perspective. After empirical validation, we confirm that these changes of operator lead to significant decrease in the training difficulties and notable performance boost, without changing the composition of parameters. With these, we conclude that the root cause of the problem is more likely the training difficulty than the others.", "pdf_url": "https://arxiv.org/pdf/2008.08838", "subject": "Machine Learning (cs.LG)"},
{"title": "Yet Another Intermediate-Level Attack", "author": "Qizhang Li, Yiwen Guo, Hao Chen", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The transferability of adversarial examples across deep neural network (DNN) models is the crux of a spectrum of black-box attacks. In this paper, we propose a novel method to enhance the black-box transferability of baseline adversarial examples. By establishing a linear mapping of the intermediate-level discrepancies (between a set of adversarial inputs and their benign counterparts) for predicting the evoked adversarial loss, we aim to take full advantage of the optimization procedure of multi-step baseline attacks. We conducted extensive experiments to verify the effectiveness of our method on CIFAR-100 and ImageNet. Experimental results demonstrate that it outperforms previous state-of-the-arts considerably. Our code is at .", "pdf_url": "https://arxiv.org/pdf/2008.08847", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "The Curse of Shared Knowledge: Recursive Belief Reasoning in a Coordination Game with Imperfect Information", "author": "Thomas Bolander, Robin Engelhardt, Thomas S. Nicolet", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Common knowledge is a necessary condition for safe group coordination. When common knowledge can not be obtained, humans routinely use their ability to attribute beliefs and intentions in order to infer what is known. But such shared knowledge attributions are limited in depth and therefore prone to coordination failures, because any finite-order knowledge attribution allows for an even higher order attribution that may change what is known by whom. In three separate experiments we investigate to which degree human participants (N=802) are able to recognize the difference between common knowledge and nth-order shared knowledge. We use a new two-person coordination game with imperfect information that is able to cast the recursive game structure and higher-order uncertainties into a simple, everyday-like setting. Our results show that participants have a very hard time accepting the fact that common knowledge is not reducible to shared knowledge. Instead, participants try to coordinate even at the shallowest depths of shared knowledge and in spite of huge payoff penalties.", "pdf_url": "https://arxiv.org/pdf/2008.08849", "subject": "Multiagent Systems (cs.MA)"},
{"title": "Checkworthiness in Automatic Claim Detection Models: Definitions and Analysis of Datasets", "author": "Liesbeth Allein, Marie-Francine Moens", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Public, professional and academic interest in automated fact-checking has drastically increased over the past decade, with many aiming to automate one of the first steps in a fact-check procedure: the selection of so-called checkworthy claims. However, there is little agreement on the definition and characteristics of checkworthiness among fact-checkers, which is consequently reflected in the datasets used for training and testing checkworthy claim detection models. After elaborate analysis of checkworthy claim selection procedures in fact-check organisations and analysis of state-of-the-art claim detection datasets, checkworthiness is defined as the concept of having a spatiotemporal and context-dependent worth and need to have the correctness of the objectivity it conveys verified. This is irrespective of the claim's perceived veracity judgement by an individual based on prior knowledge and beliefs. Concerning the characteristics of current datasets, it is argued that the data is not only highly imbalanced and noisy, but also too limited in scope and language. Furthermore, we believe that the subjective concept of checkworthiness might not be a suitable filter for claim detection.", "pdf_url": "https://arxiv.org/pdf/2008.08854", "subject": "Computation and Language (cs.CL)"},
{"title": "Model-based Automated Testing of Mobile Applications: An Industrial Case Study", "author": "Stefan Karlsson, Adnan \u010cau\u0161evi\u0107, Daniel Sundmark, M\u00e5rten Larsson", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Automatic testing of mobile applications has been a well-researched area in recent years. However, testing in industry is still a very manual practice, as research results have not been fully transferred and adopted. Considering mobile applications, manual testing has the additional burden of adequate testing posed by a large number of available devices and different configurations, as well as the maintenance and setup of such devices. In this paper, we propose and evaluate the use of a model-based test generation approach, where generated tests are executed on a set of cloud-hosted real mobile devices. By using a model-based approach we generate dynamic, less brittle, and implementation simple test cases. The test execution on multiple real devices with different configurations increase the confidence in the implementation of the system under test. Our evaluation shows that the used approach produces a high coverage of the parts of the application related to user interactions. Nevertheless, the inclusion of external services in test generation is required in order to additionally increase the coverage of the complete application. Furthermore, we present the lessons learned while transferring and implementing this approach in an industrial context and applying it to the real product.", "pdf_url": "https://arxiv.org/pdf/2008.08859", "subject": "Software Engineering (cs.SE)"},
{"title": "Unsupervised Learning Facial Parameter Regressor for Action Unit Intensity Estimation via Differentiable Renderer", "author": "Xinhui Song, Tianyang Shi, Zunlei Feng, Mingli Song, Jackie Lin, Chuanjie Lin, Changjie Fan, Yi Yuan", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Facial action unit (AU) intensity is an index to describe all visually discernible facial movements. Most existing methods learn intensity estimator with limited AU data, while they lack generalization ability out of the dataset. In this paper, we present a framework to predict the facial parameters (including identity parameters and AU parameters) based on a bone-driven face model (BDFM) under different views. The proposed framework consists of a feature extractor, a generator, and a facial parameter regressor. The regressor can fit the physical meaning parameters of the BDFM from a single face image with the help of the generator, which maps the facial parameters to the game-face images as a differentiable renderer. Besides, identity loss, loopback loss, and adversarial loss can improve the regressive results. Quantitative evaluations are performed on two public databases BP4D and DISFA, which demonstrates that the proposed method can achieve comparable or better performance than the state-of-the-art methods. What's more, the qualitative results also demonstrate the validity of our method in the wild.", "pdf_url": "https://arxiv.org/pdf/2008.08862", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Reinforcement Learning based dynamic weighing of Ensemble Models for Time Series Forecasting", "author": "Satheesh K. Perepu, Bala Shyamala Balaji, Hemanth Kumar Tanneru, Sudhakar Kathari, Vivek Shankar Pinnamaraju", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Ensemble models are powerful model building tools that are developed with a focus to improve the accuracy of model predictions. They find applications in time series forecasting in varied scenarios including but not limited to process industries, health care, and economics where a single model might not provide optimal performance. It is known that if models selected for data modelling are distinct (linear/non-linear, static/dynamic) and independent (minimally correlated models), the accuracy of the predictions is improved. Various approaches suggested in the literature to weigh the ensemble models use a static set of weights. Due to this limitation, approaches using a static set of weights for weighing ensemble models cannot capture the dynamic changes or local features of the data effectively. To address this issue, a Reinforcement Learning (RL) approach to dynamically assign and update weights of each of the models at different time instants depending on the nature of data and the individual model predictions is proposed in this work. The RL method implemented online, essentially learns to update the weights and reduce the errors as the time progresses. Simulation studies on time series data showed that the dynamic weighted approach using RL learns the weight better than existing approaches. The accuracy of the proposed method is compared with an existing approach of online Neural Network tuning quantitatively through normalized mean square error(NMSE) values.", "pdf_url": "https://arxiv.org/pdf/2008.08878", "subject": "Machine Learning (cs.LG)"},
{"title": "A comparative study of similarity-based and GNN-based link prediction approaches", "author": "Md Kamrul Islam, Sabeur Aridhi, Malika Smail-Tabbone", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The task of inferring the missing links in a graph based on its current structure is referred to as link prediction. Link prediction methods that are based on pairwise node similarity are well-established approaches in the literature. They show good prediction performance in many real-world graphs though they are heuristics and lack of universal applicability. On the other hand, the success of neural networks for classification tasks in various domains leads researchers to study them in graphs. When a neural network can operate directly on the graph, then it is termed as the graph neural network (GNN). GNN is able to learn hidden features from graphs which can be used for link prediction task in graphs. Link predictions based on GNNs have gained much attention of researchers due to their convincing high performance in many real-world graphs. This appraisal paper studies some similarity and GNN-based link prediction approaches in the domain of homogeneous graphs that consists of a single type of (attributed) nodes and single type of pairwise links. We evaluate the studied approaches against several benchmark graphs with different properties from various domains.", "pdf_url": "https://arxiv.org/pdf/2008.08879", "subject": "Social and Information Networks (cs.SI)"},
{"title": "PhysCap: Physically Plausible Monocular 3D Motion Capture in Real Time", "author": "Soshi Shimada, Vladislav Golyanik, Weipeng Xu, Christian Theobalt", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Marker-less 3D human motion capture from a single colour camera has seen significant progress. However, it is a very challenging and severely ill-posed problem. In consequence, even the most accurate state-of-the-art approaches have significant limitations. Purely kinematic formulations on the basis of individual joints or skeletons, and the frequent frame-wise reconstruction in state-of-the-art methods greatly limit 3D accuracy and temporal stability compared to multi-view or marker-based motion capture. Further, captured 3D poses are often physically incorrect and biomechanically implausible, or exhibit implausible environment interactions (floor penetration, foot skating, unnatural body leaning and strong shifting in depth), which is problematic for any use case in computer graphics. We, therefore, present PhysCap, the first algorithm for physically plausible, real-time and marker-less human 3D motion capture with a single colour camera at 25 fps. Our algorithm first captures 3D human poses purely kinematically. To this end, a CNN infers 2D and 3D joint positions, and subsequently, an inverse kinematics step finds space-time coherent joint angles and global 3D pose. Next, these kinematic reconstructions are used as constraints in a real-time physics-based pose optimiser that accounts for environment constraints (e.g., collision handling and floor placement), gravity, and biophysical plausibility of human postures. Our approach employs a combination of ground reaction force and residual force for plausible root control, and uses a trained neural network to detect foot contact events in images. Our method captures physically plausible and temporally stable global 3D human motion, without physically implausible postures, floor penetrations or foot skating, from video in real time and in general scenes. The video is available at", "pdf_url": "https://arxiv.org/pdf/2008.08880", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Does MAML really want feature reuse only?", "author": "Jaehoon Oh, Hyungjun Yoo, ChangHwan Kim, Se-Young Yun", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Meta-learning, the effort to solve new tasks with only a few samples, has attracted great attention in recent years. Model Agnostic Meta-Learning (MAML) is one of the most representative gradient-based meta-learning algorithms. MAML learns new tasks with a few data samples with inner updates from a meta-initialization point and learns the meta-initialization parameters with outer updates. Recently, it has been hypothesized that feature reuse, which makes little change in efficient representations, is the dominant factor in the performance of meta-initialized model through MAML rather than rapid learning, which makes a big change in representations. In this work, we propose a novel meta-learning algorithm, coined as BOIL (Body Only update in Inner Loop), that updates only the body (extractor) of the model and freezes the head (classifier) of the model during inner loop updates. The BOIL algorithm thus heavily relies on rapid learning. Note that BOIL is the opposite direction to the hypothesis that feature reuse is more efficient than rapid learning. We validate the BOIL algorithm on various data sets and show significant performance improvement over MAML. The results imply that rapid learning in gradient-based meta-learning approaches is necessary.", "pdf_url": "https://arxiv.org/pdf/2008.08882", "subject": "Machine Learning (cs.LG)"},
{"title": "High-Performance Simultaneous Multiprocessing for Heterogeneous System-on-Chip", "author": "Kris Nikov, Mohammad Hosseinabady, Rafael Asenjo, Andr\u00e9s Rodr\u00edguezz, Angeles Navarro, Jose Nunez-Yanez", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper presents a methodology for simultaneous heterogeneous computing, named ENEAC, where a quad core ARM Cortex-A53 CPU works in tandem with a preprogrammed on-board FPGA accelerator. A heterogeneous scheduler distributes the tasks optimally among all the resources and all compute units run asynchronously, which allows for improved performance for irregular workloads. ENEAC achieves up to 17\\% performance improvement \\ignore{and 14\\% energy usage reduction,} when using all platform resources compared to just using the FPGA accelerators and up to 865\\% performance increase \\ignore{and up to 89\\% energy usage decrease} when using just the CPU. The workflow uses existing commercial tools and C/C++ as a single programming language for both accelerator design and CPU programming for improved productivity and ease of verification.", "pdf_url": "https://arxiv.org/pdf/2008.08883", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Line detection via a lightweight CNN with a Hough Layer", "author": "Lev Teplyakov, Kirill Kaymakov, Evgeny Shvets, Dmitry Nikolaev", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Line detection is an important computer vision task traditionally solved by Hough Transform. With the advance of deep learning, however, trainable approaches to line detection became popular. In this paper we propose a lightweight CNN for line detection with an embedded parameter-free Hough layer, which allows the network neurons to have global strip-like receptive fields. We argue that traditional convolutional networks have two inherent problems when applied to the task of line detection and show how insertion of a Hough layer into the network solves them. Additionally, we point out some major inconsistencies in the current datasets used for line detection.", "pdf_url": "https://arxiv.org/pdf/2008.08884", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "No-regret Algorithms for Multi-task Bayesian Optimization", "author": "Sayak Ray Chowdhury, Aditya Gopalan", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We consider multi-objective optimization (MOO) of an unknown vector-valued function in the non-parametric Bayesian optimization (BO) setting, with the aim being to learn points on the Pareto front of the objectives. Most existing BO algorithms do not model the fact that the multiple objectives, or equivalently, tasks can share similarities, and even the few that do lack rigorous, finite-time regret guarantees that capture explicitly inter-task structure. In this work, we address this problem by modelling inter-task dependencies using a multi-task kernel and develop two novel BO algorithms based on random scalarizations of the objectives. Our algorithms employ vector-valued kernel regression as a stepping stone and belong to the upper confidence bound class of algorithms. Under a smoothness assumption that the unknown vector-valued function is an element of the reproducing kernel Hilbert space associated with the multi-task kernel, we derive worst-case regret bounds for our algorithms that explicitly capture the similarities between tasks. We numerically benchmark our algorithms on both synthetic and real-life MOO problems, and show the advantages offered by learning with multi-task kernels.", "pdf_url": "https://arxiv.org/pdf/2008.08885", "subject": "Machine Learning (cs.LG)"},
{"title": "An In-Depth Analysis of the Slingshot Interconnect", "author": "Daniele De Sensi, Salvatore Di Girolamo, Kim H. McMahon, Duncan Roweth, Torsten Hoefler", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The interconnect is one of the most critical components in large scale computing systems, and its impact on the performance of applications is going to increase with the system size. In this paper, we will describe Slingshot, an interconnection network for large scale computing systems. Slingshot is based on high-radix switches, which allow building exascale and hyperscale datacenters networks with at most three switch-to-switch hops. Moreover, Slingshot provides efficient adaptive routing and congestion control algorithms, and highly tunable traffic classes. Slingshot uses an optimized Ethernet protocol, which allows it to be interoperable with standard Ethernet devices while providing high performance to HPC applications. We analyze the extent to which Slingshot provides these features, evaluating it on microbenchmarks and on several applications from the datacenter and AI worlds, as well as on HPC applications. We find that applications running on Slingshot are less affected by congestion compared to previous generation networks.", "pdf_url": "https://arxiv.org/pdf/2008.08886", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Autonomous Social Distancing in Urban Environments using a Quadruped Robot", "author": "Tingxiang Fan, Zhiming Chen, Xuan Zhao, Jing Liang, Cong Shen, Dinesh Manocha, Jia Pan, Wei Zhang", "pub_date": "Submitted on 20 Aug 2020", "abstract": "COVID-19 pandemic has become a global challenge faced by people all over the world. Social distancing has been proved to be an effective practice to reduce the spread of COVID-19. Against this backdrop, we propose that the surveillance robots can not only monitor but also promote social distancing. Robots can be flexibly deployed and they can take precautionary actions to remind people of practicing social distancing. In this paper, we introduce a fully autonomous surveillance robot based on a quadruped platform that can promote social distancing in complex urban environments. Specifically, to achieve autonomy, we mount multiple cameras and a 3D LiDAR on the legged robot. The robot then uses an onboard real-time social distancing detection system to track nearby pedestrian groups. Next, the robot uses a crowd-aware navigation algorithm to move freely in highly dynamic scenarios. The robot finally uses a crowd-aware routing algorithm to effectively promote social distancing by using human-friendly verbal cues to send suggestions to over-crowded pedestrians. We demonstrate and validate that our robot can be operated autonomously by conducting several experiments in various urban scenarios.", "pdf_url": "https://arxiv.org/pdf/2008.08889", "subject": "Robotics (cs.RO)"},
{"title": "Switching Model Predictive Control for Online Structural Reformations of a Foldable Quadrotor", "author": "Andreas Papadimitriou, George Nikolakopoulos", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The aim of this article is the formulation of a switching model predictive control framework for the case of a foldable quadrotor with the ability to retain the overall control quality during online structural reformations. The majority of the related scientific publications consider fixed morphology of the aerial vehicles. Recent advances in mechatronics have brought novel considerations for generalized aerial robotic designs with the ability to alter their morphology in order to adapt to their environment, thus enhancing their capabilities. Simulation results are provided to prove the efficacy of the selected control scheme.", "pdf_url": "https://arxiv.org/pdf/2008.08893", "subject": "Robotics (cs.RO)"},
{"title": "Frank-Wolfe algorithm for learning SVM-type multi-category classifiers", "author": "Kenya Tajima, Yoshihiro Hirohashi, Esmeraldo Ronnie Rey Zara, Tsuyoshi Kato", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Multi-category support vector machine (MC-SVM) is one of the most popular machine learning algorithms. There are lots of variants of MC-SVM, although different optimization algorithms were developed for different learning machines. In this study, we developed a new optimization algorithm that can be applied to many of MC-SVM variants. The algorithm is based on the Frank-Wolfe framework that requires two subproblems, direction finding and line search, in each iteration. The contribution of this study is the discovery that both subproblems have a closed form solution if the Frank-Wolfe framework is applied to the dual problem. Additionally, the closed form solutions on both for the direction finding and for the line search exist even for the Moreau envelopes of the loss functions. We use several large datasets to demonstrate that the proposed optimization algorithm converges rapidly and thereby improves the pattern recognition performance.", "pdf_url": "https://arxiv.org/pdf/2008.08894", "subject": "Machine Learning (cs.LG)"},
{"title": "Towards a Decomposable Metric for Explainable Evaluation of Text Generation from AMR", "author": "Juri Opitz, Anette Frank", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Systems that generate sentences from (abstract) meaning representations (AMRs) are typically evaluated using automatic surface matching metrics that compare the generated texts to the texts that were originally given to human annotators to construct AMR meaning representations. However, besides well-known issues from which such metrics suffer (Callison-Burch et al., 2006; Novikova et al., 2017), we show that an additional problem arises when applied for AMR-to-text evaluation because mapping from the more abstract domain of AMR to the more concrete domain of sentences allows for manifold sentence realizations. In this work we aim to alleviate these issues and propose $\\mathcal{M}\\mathcal{F}_\\beta$, an automatic metric that builds on two pillars. The first pillar is the principle of meaning preservation $\\mathcal{M}$: it measures to what extent the original AMR graph can be reconstructed from the generated sentence. We implement this principle by i) automatically constructing an AMR from the generated sentence using state-of-the-art AMR parsers and ii) apply fine-grained principled AMR metrics to measure the distance between the original and the reconstructed AMR. The second pillar builds on a principle of (grammatical) form $\\mathcal{F}$, which measures the linguistic quality of the generated sentences, which we implement using SOTA language models. We show - theoretically and experimentally - that fulfillment of both principles offers several benefits for evaluation of AMR-to-text systems, including the explainability of scores.", "pdf_url": "https://arxiv.org/pdf/2008.08896", "subject": "Computation and Language (cs.CL)"},
{"title": "Document Visual Question Answering Challenge 2020", "author": "Minesh Mathew, Ruben Tito, Dimosthenis Karatzas, R. Manmatha, C.V. Jawahar", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper presents results of Document Visual Question Answering Challenge organized as part of \"Text and Documents in the Deep Learning Era\" workshop, in CVPR 2020. The challenge introduces a new problem - Visual Question Answering on document images. The challenge comprised two tasks. The first task concerns with asking questions on a single document image. On the other hand, the second task is set as a retrieval task where the question is posed over a collection of images. For the task 1 a new dataset is introduced comprising 50,000 questions-answer(s) pairs defined over 12,767 document images. For task 2 another dataset has been created comprising 20 questions over 14,362 document images which share the same document template.", "pdf_url": "https://arxiv.org/pdf/2008.08899", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Coded Caching over Multicast Routing Networks", "author": "Mozhgan Bayat, Kai Wan, Giuseppe Caire", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The coded caching scheme originally proposed by Maddah-Ali and Niesen (MAN) transmits coded multicast messages from a server to users equipped with caches via a capacitated shared-link and was shown to be information theoretically optimal within a constant multiplicative factor. This work extends the MAN scheme to a class of two-hop wired-wireless networks including one server connected via fronthaul links to a layer of $H$ helper nodes (access points/base stations), which in turns communicate via a wireless access network to $K$ users, each equipped with its own cache. Two variants are considered, which differ in the modeling of the access segment. Both models should be regarded as abstractions at the network layer for physical scenarios such as local area networks and cellular networks, spatially distributed over a certain coverage area. The key focus of our approach consists of routing MAN-type multicast messages through the network and formulating the optimal routing scheme as an optimization problem that can be solved exactly or for which we give powerful heuristic algorithms. Our approach solves at once many of the open practical problems identified as stumbling blocks for the application of coded caching in practical scenarios, namely: asynchronous streaming sessions, finite file size, scalability of the scheme to large and spatially distributed networks, user mobility and random activity (users joining and leaving the system at arbitrary times), decentralized prefetching of the cache contents, end-to-end encryption of HTTPS requests, which renders the helper nodes oblivious of the user demands.", "pdf_url": "https://arxiv.org/pdf/2008.08900", "subject": "Information Theory (cs.IT)"},
{"title": "Topology Optimization and 3D-printing of Large Deformation Compliant Mechanisms for Straining Biological Tissues", "author": "P. Kumar, C. Schmidleithner, N. B. Larsen, O. Sigmund", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper presents a synthesis approach in a density-based topology optimization setting to design large deformation compliant mechanisms for inducing desired strains in biological tissues. The modelling is based on geometrical nonlinearity together with a suitably chosen hypereleastic material model, wherein the mechanical equilibrium equations are solved using the total Lagrangian finite element formulation. An objective based on least-square error with respect to target strains is formulated and minimized with the given set of constraints and the appropriate surroundings of the tissues. To circumvent numerical instabilities arising due to large deformation in low stiffness design regions during topology optimization, a strain-energy based interpolation scheme is employed. The approach uses an extended robust formulation i.e. the eroded, intermediate and dilated projections for the design description as well as variation in tissue stiffness. Efficacy of the synthesis approach is demonstrated by designing various compliant mechanisms for providing different target strains in biological tissue constructs. Optimized compliant mechanisms are 3D-printed and their performances are recorded in a simplified experiment and compared with simulation results obtained by a commercial software.", "pdf_url": "https://arxiv.org/pdf/2008.08902", "subject": "Computational Engineering, Finance, and Science (cs.CE)"},
{"title": "Generative Adversarial Networks for Spatio-temporal Data: A Survey", "author": "Nan Gao, Hao Xue, Wei Shao, Sichen Zhao, Kyle Kai Qin, Arian Prabowo, Mohammad Saiedur Rahaman, Flora D. Salim", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Generative Adversarial Networks (GANs) have shown remarkable success in the computer vision area for producing realistic-looking images. Recently, GAN-based techniques are shown to be promising for spatiotemporal-based applications such as trajectory prediction, events generation and time-series data imputation. While several reviews for GANs in computer vision been presented, nobody has considered addressing the practical applications and challenges relevant to spatio-temporal data. In this paper, we conduct a comprehensive review of the recent developments of GANs in spatio-temporal data. we summarise the popular GAN architectures in spatio-temporal data and common practices for evaluating the performance of spatio-temporal applications with GANs. In the end, we point out the future directions with the hope of benefiting researchers interested in this area.", "pdf_url": "https://arxiv.org/pdf/2008.08903", "subject": "Machine Learning (cs.LG)"},
{"title": "Cooperative Multi-Point Vehicular Positioning Using Millimeter-Wave Surface Reflection (Extended version)", "author": "Zezhong Zhang, Seung-Woo Ko, Rui Wang, Kaibin Huang", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Multi-point vehicular positioning is one essential operation for autonomous vehicles. However, the state-of-the-art positioning technologies, relying on reflected signals from a target (i.e., RADAR and LIDAR), cannot work without line-of-sight. Besides, it takes significant time for environment scanning and object recognition with potential detection inaccuracy, especially in complex urban situations. Some recent fatal accidents involving autonomous vehicles further expose such limitations. In this paper, we aim at overcoming these limitations by proposing a novel relative positioning approach, called Cooperative Multi-point Positioning (COMPOP). The COMPOP establishes cooperation between a target vehicle (TV) and a sensing vehicle (SV) if a LoS path exists, where a TV explicitly lets an SV to know the TV's existence by transmitting positioning waveforms. This cooperation makes it possible to remove the time-consuming scanning and target recognizing processes, facilitating real-time positioning. One prerequisite for the cooperation is a clock synchronization between a pair of TV and SV. To this end, we use a phase-differential-of-arrival based approach to remove the TV-SV clock difference from the received signal. With clock difference correction, the TV's position can be obtained via peak detection over a 3D power spectrum constructed by a Fourier transform (FT) based algorithm. The COMPOP also incorporates nearby vehicles, without knowing their locations, into the above cooperation for the case without a LoS path. The effectiveness of the COMPOP is verified by several simulations concerning practical channel parameters.", "pdf_url": "https://arxiv.org/pdf/2008.08906", "subject": "Information Theory (cs.IT)"},
{"title": "A Value of Information Framework for Latent Variable Models", "author": "Zijing Wang, Mihai-Alin Badiu, Justin P. Coon", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this paper, a general value of information (VoI) framework is formalised for latent variable models. In particular, the mutual information between the current status at the source node and the observed noisy measurements at the destination node is used to evaluate the information value, which gives the theoretical interpretation of the reduction in uncertainty in the current status given that we have measurements of the latent process. Moreover, the VoI expression for a hidden Markov model is obtained in this setting. Numerical results are provided to show the relationship between the VoI and the traditional age of information (AoI) metric, and the VoI of Markov and hidden Markov models are analysed for the particular case when the latent process is an Ornstein-Uhlenbeck process. While the contributions of this work are theoretical, the proposed VoI framework is general and useful in designing wireless systems that support timely, but noisy, status updates in the physical world.", "pdf_url": "https://arxiv.org/pdf/2008.08907", "subject": "Information Theory (cs.IT)"},
{"title": "Co-Saliency Detection with Co-Attention Fully Convolutional Network", "author": "Guangshuai Gao, Wenting Zhao, Qingjie Liu, Yunhong Wang", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Co-saliency detection aims to detect common salient objects from a group of relevant images. Some attempts have been made with the Fully Convolutional Network (FCN) framework and achieve satisfactory detection results. However, due to stacking convolution layers and pooling operation, the boundary details tend to be lost. In addition, existing models often utilize the extracted features without discrimination, leading to redundancy in representation since actually not all features are helpful to the final prediction and some even bring distraction. In this paper, we propose a co-attention module embedded FCN framework, called as Co-Attention FCN (CA-FCN). Specifically, the co-attention module is plugged into the high-level convolution layers of FCN, which can assign larger attention weights on the common salient objects and smaller ones on the background and uncommon distractors to boost final detection performance. Extensive experiments on three popular co-saliency benchmark datasets demonstrate the superiority of the proposed CA-FCN, which outperforms state-of-the-arts in most cases. Besides, the effectiveness of our new co-attention module is also validated with ablation studies.", "pdf_url": "https://arxiv.org/pdf/2008.08909", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "SentiQ: A Probabilistic Logic Approach to Enhance Sentiment Analysis Tool Quality", "author": "Wissam Maamar Kouadri, Salima Benbernou, Mourad Ouziri, Themis Palpanas, Iheb Ben Amor", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The opinion expressed in various Web sites and social-media is an essential contributor to the decision making process of several organizations. Existing sentiment analysis tools aim to extract the polarity (i.e., positive, negative, neutral) from these opinionated contents. Despite the advance of the research in the field, sentiment analysis tools give \\textit{inconsistent} polarities, which is harmful to business decisions. In this paper, we propose SentiQ, an unsupervised Markov logic Network-based approach that injects the semantic dimension in the tools through rules. It allows to detect and solve inconsistencies and then improves the overall accuracy of the tools. Preliminary experimental results demonstrate the usefulness of SentiQ.", "pdf_url": "https://arxiv.org/pdf/2008.08919", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "scikit-dyn2sel -- A Dynamic Selection Framework for Data Streams", "author": "Lucca Portes Cavalheiro, Jean Paul Barddal, Alceu de Souza Britto Jr, Laurent Heutte", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Mining data streams is a challenge per se. It must be ready to deal with an enormous amount of data and with problems not present in batch machine learning, such as concept drift. Therefore, applying a batch-designed technique, such as dynamic selection of classifiers (DCS) also presents a challenge. The dynamic characteristic of ensembles that deal with streams presents barriers to the application of traditional DCS techniques in such classifiers. scikit-dyn2sel is an open-source python library tailored for dynamic selection techniques in streaming data. scikit-dyn2sel's development follows code quality and testing standards, including PEP8 compliance and automated high test coverage using and . Source code, documentation, and examples are made available on GitHub at .", "pdf_url": "https://arxiv.org/pdf/2008.08920", "subject": "Machine Learning (cs.LG)"},
{"title": "Construction of control barrier function and $C^2$ reference trajectory for constrained attitude maneuvers", "author": "Xiao Tan, Dimos V. Dimarogonas", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Constrained attitude maneuvers have numerous applications in robotics and aerospace. In our previous work, a general framework to this problem was proposed with resolution completeness guarantee. However, a smooth reference trajectory and a low-level safety-critical controller were lacking. In this work, we propose a novel construction of a $C^2$ continuous reference trajectory based on B\u00e9zier curves on $ SO(3) $ that evolves within predetermined cells and eliminates previous stop-and-go behavior. Moreover, we propose a novel zeroing control barrier function on $ SO(3) $ that provides a safety certificate over a set of overlapping cells on $ SO(3) $ while avoiding nonsmooth analysis. The safety certificate is given as a linear constraint on the control input and implemented in real-time. A remedy is proposed to handle the states where the coefficient of the control input in the linear constraint vanishes. Numerical simulations are given to verify the advantages of the proposed method.", "pdf_url": "https://arxiv.org/pdf/2008.08921", "subject": "Systems and Control (eess.SY)"},
{"title": "Proceedings Eighth and Ninth International Workshop on Trends in Functional Programming in Education", "author": "Jurriaan Hage", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This volume contains five papers, accepted after post-reviewing, based on presentations submitted to TFPIE 2019 and TFPIE 2020 that took places in Vancouver, Canada and Krakow, Poland respectively. TFPIE stands for Trends in Functional Programming in Education, where authors present research and experiences in teaching concepts of functional programming at any level.", "pdf_url": "https://arxiv.org/html/2008.08923", "subject": "Programming Languages (cs.PL)"},
{"title": "Regularization And Normalization For Generative Adversarial Networks: A Review", "author": "Ziqiang Li, Rentuo Tao, Bin Li", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Generative adversarial networks(GANs) is a popular generative model. With the development of the deep network, its application is more and more widely. By now, people think that the training of GANs is a two-person zero-sum game(discriminator and generator). The lack of strong supervision information makes the training very difficult, such as non-convergence, mode collapses, gradient disappearance, and the sensitivity of hyperparameters. As we all know, regularization and normalization are commonly used for stability training. This paper reviews and summarizes the research in the regularization and normalization for GAN. All the methods are classified into six groups: Gradient penalty, Norm normalization and regularization, Jacobian regularization, Layer normalization, Consistency regularization, and Self-supervision.", "pdf_url": "https://arxiv.org/pdf/2008.08930", "subject": "Machine Learning (cs.LG)"},
{"title": "A Deep Prediction Network for Understanding Advertiser Intent and Satisfaction", "author": "Liyi Guo, Rui Lu, Haoqi Zhang, Junqi Jin, Zhenzhe Zheng, Fan Wu, Jin Li, Haiyang Xu, Han Li, Wenkai Lu, Jian Xu, Kun Gai", "pub_date": "Submitted on 20 Aug 2020", "abstract": "For e-commerce platforms such as Taobao and Amazon, advertisers play an important role in the entire digital ecosystem: their behaviors explicitly influence users' browsing and shopping experience; more importantly, advertiser's expenditure on advertising constitutes a primary source of platform revenue. Therefore, providing better services for advertisers is essential for the long-term prosperity for e-commerce platforms. To achieve this goal, the ad platform needs to have an in-depth understanding of advertisers in terms of both their marketing intents and satisfaction over the advertising performance, based on which further optimization could be carried out to service the advertisers in the correct direction. In this paper, we propose a novel Deep Satisfaction Prediction Network (DSPN), which models advertiser intent and satisfaction simultaneously. It employs a two-stage network structure where advertiser intent vector and satisfaction are jointly learned by considering the features of advertiser's action information and advertising performance indicators. Experiments on an Alibaba advertisement dataset and online evaluations show that our proposed DSPN outperforms state-of-the-art baselines and has stable performance in terms of AUC in the online environment. Further analyses show that DSPN not only predicts advertisers' satisfaction accurately but also learns an explainable advertiser intent, revealing the opportunities to optimize the advertising performance further.", "pdf_url": "https://arxiv.org/pdf/2008.08931", "subject": "Social and Information Networks (cs.SI)"},
{"title": "SuperSuit: Simple Microwrappers for Reinforcement Learning Environments", "author": "Justin K. Terry, Benjamin Black, Ananth Hari", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In reinforcement learning, wrappers are universally used to transform the information that passes between a model and an environment. Despite their ubiquity, no library exists with reasonable implementations of all popular preprocessing methods. This leads to unnecessary bugs, code inefficiencies, and wasted developer time. Accordingly we introduce SuperSuit, a Python library that includes all popular wrappers, and wrappers that can easily apply lambda functions to the observations/actions/reward. It's compatible with the standard Gym environment specification, as well as the PettingZoo specification for multi-agent environments. The library is available at can be installed via pip.", "pdf_url": "https://arxiv.org/pdf/2008.08932", "subject": "Machine Learning (cs.LG)"},
{"title": "DataProVe: A Data Protection Policy and System Architecture Verification Tool", "author": "Vinh Thong Ta", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this paper, we propose a tool, called DataProVe, for specifying high-level data protection policies and system architectures, as well as verifying the conformance between them in a fully automated way. The syntax of the policies and the architectures is based on semi-formal languages, and the automated verification engine relies on logic and resolution based proofs. The functionality and operation of the tool are presented using different examples.", "pdf_url": "https://arxiv.org/pdf/2008.08936", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Institutional Grammar 2.0 Codebook", "author": "Christopher K. Frantz, Saba N. Siddiki", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The Grammar of Institutions, or Institutional Grammar (IG), is an established approach to encode policy information in terms of institutional statements based on a set of pre-defined syntactic components. This codebook provides coding guidelines for a revised version of the IG, the Institutional Grammar 2.0 (IG 2.0). IG 2.0 is a specification that aims at facilitating the encoding of policy to meet varying analytical objectives. To this end, it revises the grammar with respect to comprehensiveness, flexibility, and specificity by offering multiple levels of expressiveness (IG Core, IG Extended, IG Logico), and further introduces encoding of constitutive institutional statements, in addition to the encoding of regulative statements. The codebook covers fundamental concepts of IG 2.0, before providing an overview of pre-coding steps relevant for document preparation. Following this, detailed coding guidelines are provided for both regulative and constitutive statements across all levels of expressiveness, along with the encoding instructions for hybrid and polymorphic institutional statements. The document further provides an overview of taxonomies used in the encoding process and referred to throughout the codebook. Note that this codebook specifically focuses on operational aspects of IG 2.0 in the context of policy coding. Links to additional resources such as the underlying scientific literature (that offers comprehensive treatment of the underlying theoretical concepts) as well as tool support are referred to in the concluding section of the codebook.", "pdf_url": "https://arxiv.org/pdf/2008.08937", "subject": "Multiagent Systems (cs.MA)"},
{"title": "Distributed Vehicle Grid Integration Over Communication and Physical Networks", "author": "Dimitra Apostolopoulou, Rahmat Poudineh, Anupama Sen", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This paper proposes a distributed framework for vehicle grid integration (VGI) taking into account the communication and physical networks. To this end, we model the electric vehicle (EV) behaviour that includes time of departure, time of arrival, state of charge, required energy, and its objectives, e.g., avoid battery degradation. Next, we formulate the centralised day ahead distribution market (DADM) which explicitly represents the physical system, supports unbalanced three phase networks with delta and wye connections, and incorporates the charging needs of EVs. The solution of the centralised market requires knowledge of EV information in terms of desired energy, departure and arrival times that EV owners are reluctant in providing. Moreover, the computational effort required to solve the DADM in cases of numerous EVs is very intensive. As such, we propose a distributed solution of the DADM clearing mechanism over a time-varying communication network. We illustrate the proposed VGI framework through the 13-bus, 33- bus, and 141-bus distribution feeders.", "pdf_url": "https://arxiv.org/pdf/2008.08939", "subject": "Systems and Control (eess.SY)"},
{"title": "Localizing Anomalies from Weakly-Labeled Videos", "author": "Hui Lv, Chuanwei Zhou, Chunyan Xu, Zhen Cui, Jian Yang", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Video anomaly detection under video-level labels is currently a challenging task. Previous works have made progresses on discriminating whether a video sequencecontains anomalies. However, most of them fail to accurately localize the anomalous events within videos in the temporal domain. In this paper, we propose a Weakly Supervised Anomaly Localization (WSAL) method focusing on temporally localizing anomalous segments within anomalous videos. Inspired by the appearance difference in anomalous videos, the evolution of adjacent temporal segments is evaluated for the localization of anomalous segments. To this end, a high-order context encoding model is proposed to not only extract semantic representations but also measure the dynamic variations so that the temporal context could be effectively utilized. In addition, in order to fully utilize the spatial context information, the immediate semantics are directly derived from the segment representations. The dynamic variations as well as the immediate semantics, are efficiently aggregated to obtain the final anomaly scores. An enhancement strategy is further proposed to deal with noise interference and the absence of localization guidance in anomaly detection. Moreover, to facilitate the diversity requirement for anomaly detection benchmarks, we also collect a new traffic anomaly (TAD) dataset which specifies in the traffic conditions, differing greatly from the current popular anomaly detection evaluation benchmarks.Extensive experiments are conducted to verify the effectiveness of different components, and our proposed method achieves new state-of-the-art performance on the UCF-Crime and TAD datasets.", "pdf_url": "https://arxiv.org/pdf/2008.08944", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Cellular Networks With Finite Precision CSIT: GDoF Optimality of Multi-Cell TIN and Extremal Gains of Multi-Cell Cooperation", "author": "Hamdi Joudeh, Giuseppe Caire", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We study the generalized degrees-of-freedom (GDoF) of cellular networks under finite precision channel state information at the transmitters (CSIT). We consider downlink settings modeled by the interfering broadcast channel (IBC) under no multi-cell cooperation, and the overloaded multiple-input-single-output broadcast channel (MISO-BC) under full multi-cell cooperation. We focus on three regimes of interest: the mc-TIN regime, where a scheme based on treating inter-cell interference as noise (mc-TIN) was shown to be GDoF optimal for the IBC; the mc-CTIN regime, where the GDoF region achievable by mc-TIN is convex without the need for time-sharing; and the mc-SLS regime which extends a previously identified regime, where a simple layered superposition (SLS) scheme is optimal for the 3-transmitter-3-user MISO-BC, to overloaded cellular-type networks with more users than transmitters. We first show that the optimality of mc-TIN for the IBC extends to the entire mc-CTIN regime when CSIT is limited to finite precision. The converse proof of this result relies on a new application of aligned images bounds. We then extend the IBC converse proof to the counterpart overloaded MISO-BC, obtained by enabling full transmitter cooperation. This, in turn, is utilized to show that a multi-cell variant of the SLS scheme is optimal in the mc-SLS regime under full multi-cell cooperation, albeit only for 2-cell networks. The overwhelming combinatorial complexity of the GDoF region stands in the way of extending this result to larger networks. Alternatively, we appeal to extremal network analysis, recently introduced by Chan et al., and study the GDoF gain of multi-cell cooperation over mc-TIN in the three regimes of interest. We show that this extremal GDoF gain is bounded by small constants in the mc-TIN and mc-CTIN regimes, yet scales logarithmically with the number of cells in the mc-SLS regime.", "pdf_url": "https://arxiv.org/pdf/2008.08945", "subject": "Information Theory (cs.IT)"},
{"title": "Cross-Modality Multi-Atlas Segmentation Using Deep Neural Networks", "author": "Wangbin Ding, Lei Li, Xiahai Zhuang, Liqin Huang", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Both image registration and label fusion in the multi-atlas segmentation (MAS) rely on the intensity similarity between target and atlas images. However, such similarity can be problematic when target and atlas images are acquired using different imaging protocols. High-level structure information can provide reliable similarity measurement for cross-modality images when cooperating with deep neural networks (DNNs). This work presents a new MAS framework for cross-modality images, where both image registration and label fusion are achieved by DNNs. For image registration, we propose a consistent registration network, which can jointly estimate forward and backward dense displacement fields (DDFs). Additionally, an invertible constraint is employed in the network to reduce the correspondence ambiguity of the estimated DDFs. For label fusion, we adapt a few-shot learning network to measure the similarity of atlas and target patches. Moreover, the network can be seamlessly integrated into the patch-based label fusion. The proposed framework is evaluated on the MM-WHS dataset of MICCAI 2017. Results show that the framework is effective in both cross-modality registration and segmentation.", "pdf_url": "https://arxiv.org/pdf/2008.08946", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "An Overview of Generalized Frequency Division Multiplexing (GFDM)", "author": "Ching-Lun Tai, Tzu-Han Wang, Yu-Hua Huang", "pub_date": "Submitted on 20 Aug 2020", "abstract": "As a candidate waveform for next-generation wireless communications, generalized frequency division multiplexing (GFDM) features several decent properties which make it promising. In this paper, we systematically overview the research about GFDM. We start with GFDM transceivers with their main components, which consist of prototype filter design, low-complexity transceiver implementation, and symbol detection algorithms. Then, we investigate a couple of non-ideal issues of GFDM, including synchronization issues, channel estimation, and in-phase/quadrature (I/Q) imbalance compensation. Lastly, we study the applications of GFDM-based cognitive radio and full-duplex radio which boast of a high spectral efficiency.", "pdf_url": "https://arxiv.org/pdf/2008.08947", "subject": "Information Theory (cs.IT)"},
{"title": "Static Neural Compiler Optimization via Deep Reinforcement Learning", "author": "Rahim Mammadli, Ali Jannesari, Felix Wolf", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The phase-ordering problem of modern compilers has received a lot of attention from the research community over the years, yet remains largely unsolved. Various optimization sequences exposed to the user are manually designed by compiler developers. In designing such a sequence developers have to choose the set of optimization passes, their parameters and ordering within a sequence. Resulting sequences usually fall short of achieving optimal runtime for a given source code and may sometimes even degrade the performance when compared to unoptimized version. In this paper, we employ a deep reinforcement learning approach to the phase-ordering problem. Provided with sub-sequences constituting LLVM's O3 sequence, our agent learns to outperform the O3 sequence on the set of source codes used for training and achieves competitive performance on the validation set, gaining up to 1.32x speedup on previously-unseen programs. Notably, our approach differs from autotuning methods by not depending on one or more test runs of the program for making successful optimization decisions. It has no dependence on any dynamic feature, but only on the statically-attainable intermediate representation of the source code. We believe that the models trained using our approach can be integrated into modern compilers as neural optimization agents, at first to complement, and eventually replace the hand-crafted optimization sequences.", "pdf_url": "https://arxiv.org/pdf/2008.08951", "subject": "Machine Learning (cs.LG)"},
{"title": "Linear hash-functions and their applications to error detection and correction", "author": "Boris Ryabko", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We describe and explore so-called linear hash functions and show how they can be used to build error detection and correction codes. The method can be applied for different types of errors (for example, burst errors). When the method is applied to a model where number of distorted letters is limited, the obtained estimate of its performance is slightly better than the known Varshamov-Gilbert bound. We also describe random code whose performance is close to the same boundary, but its construction is much simpler. In some cases the obtained methods are simpler and more flexible than the known ones. In particular, the complexity of the obtained error detection code and the well-known CRC code is close, but the proposed code, unlike CRC, can detect with certainty errors whose number does not exceed a predetermined limit.", "pdf_url": "https://arxiv.org/pdf/2008.08955", "subject": "Information Theory (cs.IT)"},
{"title": "Investigating the Effect of Intraclass Variability in Temporal Ensembling", "author": "Siddharth Vohra, Manikandan Ravikiran", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Temporal Ensembling is a semi-supervised approach that allows training deep neural network models with a small number of labeled images. In this paper, we present our preliminary study on the effect of intraclass variability on temporal ensembling, with a focus on seed size and seed type, respectively. Through our experiments we find that (a) there is a significant drop in accuracy with datasets that offer high intraclass variability, (b) more seed images offer consistently higher accuracy across the datasets, and (c) seed type indeed has an impact on the overall efficiency, where it produces a spectrum of accuracy lower and higher. Besides, based on all of our experiments, we also find that KMNIST is a strong baseline for temporal ensembling.", "pdf_url": "https://arxiv.org/pdf/2008.08956", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Patient ADE Risk Prediction through Hierarchical Time-Aware Neural Network Using Claim Codes", "author": "Jinhe Shi, Xiangyu Gao, Chenyu Ha, Yage Wang, Guodong Gao, Yi Chen", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Adverse drug events (ADEs) are a serious health problem that can be life-threatening. While a lot of studies have been performed on detect correlation between a drug and an AE, limited studies have been conducted on personalized ADE risk prediction. Among treatment alternatives, avoiding the drug that has high likelihood of causing severe AE can help physicians to provide safer treatment to patients. Existing work on personalized ADE risk prediction uses the information obtained in the current medical visit. However, on the other hand, medical history reveals each patient's unique characteristics and comprehensive medical information. The goal of this study is to assess personalized ADE risks that a target drug may induce on a target patient, based on patient medical history recorded in claims codes, which provide information about diagnosis, drugs taken, related medical supplies besides billing information. We developed a HTNNR model (Hierarchical Time-aware Neural Network for ADE Risk) that capture characteristics of claim codes and their relationship. The empirical evaluation show that the proposed HTNNR model substantially outperforms the comparison methods, especially for rare drugs.", "pdf_url": "https://arxiv.org/pdf/2008.08957", "subject": "Machine Learning (cs.LG)"},
{"title": "Drawing Tree-Based Phylogenetic Networks with Minimum Number of Crossings", "author": "Jonathan Klawitter, Peter Stumpf", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In phylogenetics, tree-based networks are used to model and visualize the evolutionary history of species where reticulate events such as horizontal gene transfer have occurred. Formally, a tree-based network $N$ consists of a phylogenetic tree $T$ (a rooted, binary, leaf-labeled tree) and so-called reticulation edges that span between edges of $T$. The network $N$ is typically visualized by drawing $T$ downward and planar and reticulation edges with one of several different styles. One aesthetic criteria is to minimize the number of crossings between tree edges and reticulation edges. This optimization problem has not yet been researched. We show that, if reticulation edges are drawn x-monotone, the problem is NP-complete, but fixed-parameter tractable in the number of reticulation edges. If, on the other hand, reticulation edges are drawn like \"ears\", the crossing minimization problem can be solved in quadratic time.", "pdf_url": "https://arxiv.org/pdf/2008.08960", "subject": "Discrete Mathematics (cs.DM)"},
{"title": "A Direct Product Theorem for One-Way Quantum Communication", "author": "Rahul Jain, Srijita Kundu", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We prove a direct product theorem for the one-way entanglement-assisted quantum communication complexity of a general relation $f\\subseteq\\mathcal{X}\\times\\mathcal{Y}\\times\\mathcal{Z}$. For any $\\varepsilon, \\zeta > 0$ and any $k\\geq1$, we show that \\[ \\mathrm{Q}^1_{1-(1-\\varepsilon)^{\\Omega(\\zeta^6k/\\log|\\mathcal{Z}|)}}(f^k) = \\Omega\\left(k\\left(\\zeta^5\\cdot\\mathrm{Q}^1_{\\varepsilon + 12\\zeta}(f) - \\log\\log(1/\\zeta)\\right)\\right),\\] where $\\mathrm{Q}^1_{\\varepsilon}(f)$ represents the one-way entanglement-assisted quantum communication complexity of $f$ with worst-case error $\\varepsilon$ and $f^k$ denotes $k$ parallel instances of $f$. As far as we are aware, this is the first direct product theorem for quantum communication. Our techniques are inspired by the parallel repetition theorems for the entangled value of two-player non-local games, under product distributions due to Jain, Pereszl\u00e9nyi and Yao, and under anchored distributions due to Bavarian, Vidick and Yuen, as well as message-compression for quantum protocols due to Jain, Radhakrishnan and Sen. Our techniques also work for entangled non-local games which have input distributions anchored on any one side. In particular, we show that for any game $G = (q, \\mathcal{X}\\times\\mathcal{Y}, \\mathcal{A}\\times\\mathcal{B}, \\mathsf{V})$ where $q$ is a distribution on $\\mathcal{X}\\times\\mathcal{Y}$ anchored on any one side with anchoring probability $\\zeta$, then \\[ \\omega^*(G^k) = \\left(1 - (1-\\omega^*(G))^5\\right)^{\\Omega\\left(\\frac{\\zeta^2 k}{\\log(|\\mathcal{A}|\\cdot|\\mathcal{B}|)}\\right)}\\] where $\\omega^*(G)$ represents the entangled value of the game $G$. This is a generalization of the result of Bavarian, Vidick and Yuen, who proved a parallel repetition theorem for games anchored on both sides, and potentially a simplification of their proof.", "pdf_url": "https://arxiv.org/pdf/2008.08963", "subject": "Computational Complexity (cs.CC)"},
{"title": "Component-by-component digit-by-digit construction of good polynomial lattice rules in weighted Walsh spaces", "author": "Adrian Ebert, Peter Kritzer, Onyekachi Osisiogu, Tetiana Stepaniuk", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We consider the efficient construction of polynomial lattice rules, which are special cases of so-called quasi-Monte Carlo (QMC) rules. These are of particular interest for the approximate computation of multivariate integrals where the dimension $d$ may be in the hundreds or thousands. We study a construction method that assembles the generating vector, which is in this case a vector of polynomials over a finite field, of the polynomial lattice rule in a digit-by-digit (or, equivalently, coefficient-by-coefficient) fashion. As we will show, the integration error of the corresponding QMC rules achieves excellent convergence order, and, under suitable conditions, we can vanquish the curse of dimensionality by considering function spaces equipped with coordinate weights. The construction algorithm is based on a quality measure that is independent of the underlying smoothness of the function space and can be implemented in a fast manner (without the use of fast Fourier transformations). Furthermore, we illustrate our findings with extensive numerical results.", "pdf_url": "https://arxiv.org/pdf/2008.08966", "subject": "Numerical Analysis (math.NA)"},
{"title": "A Simple Proof of Optimal Approximations", "author": "M\u00f3nika Csik\u00f3s, Nabil H. Mustafa", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The fundamental result of Li, Long, and Srinivasan on approximations of set systems has become a key tool across several communities such as learning theory, algorithms, combinatorics and data analysis (described as `the pinnacle of a long sequence of papers'). The goal of this paper is to give a simpler, self-contained, modular proof of this result for finite set systems. The only ingredient we assume is the standard Chernoff's concentration bound. This makes the proof accessible to a wider audience, readers not familiar with techniques from statistical learning theory, and makes it possible to be covered in a single self-contained lecture in an algorithms course.", "pdf_url": "https://arxiv.org/pdf/2008.08970", "subject": "Machine Learning (cs.LG)"},
{"title": "Transactive Community Microgrids to Share Energy Storage Resources in Portugal", "author": "Pedro Moura, Uday Sriram, Javad Mohammadi", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The contribution of renewable energy sources to Portugal's energy generation portfolio is significant and on the path to achieving 100\\% renewable generation by 2050. Most of the new renewable generation capacity will be procured from distributed photovoltaic (PV) generation installed at buildings. The inherent intermittence of PV output combined with a mismatch with demand profile are challenging the operation and resiliency of the electrical grid. Addressing these issues requires leveraging spatio-temporal flexibility of controllable energy resources such as batteries and Electric Vehicles (EV). This need is recognized by regulators in Portugal and the recent renewable generation self-consumption legislation enables generation-surplus trading in communities. Implementing intra-community trading and utilizing the potentials of renewable generation requires oversight and coordination at the community level in the context of transactive energy systems. This paper focuses on addressing energy sharing through a transactive energy market in community microgrids. The proposed framework considers public and commercial buildings with on-site battery storage and numerous EV charging stations as the main source of flexibility. The formulation is tested using real data from a community of buildings on a Portuguese University campus. The results showcase the achieved increase in renewable self-consumption at building and community levels, as well as the reduction in electricity costs.", "pdf_url": "https://arxiv.org/pdf/2008.08971", "subject": "Systems and Control (eess.SY)"},
{"title": "Online inverse reinforcement learning with limited data", "author": "Ryan Self, S M Nahid Mahmud, Katrine Hareland, Rushikesh Kamalapurkar", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This paper addresses the problem of online inverse reinforcement learning for systems with limited data and uncertain dynamics. In the developed approach, the state and control trajectories are recorded online by observing an agent perform a task, and reward function estimation is performed in real-time using a novel inverse reinforcement learning approach. Parameter estimation is performed concurrently to help compensate for uncertainties in the agent's dynamics. Data insufficiency is resolved by developing a data-driven update law to estimate the optimal feedback controller. The estimated controller can then be queried to artificially create additional data to drive reward function estimation.", "pdf_url": "https://arxiv.org/pdf/2008.08972", "subject": "Systems and Control (eess.SY)"},
{"title": "ISSAFE: Improving Semantic Segmentation in Accidents by Fusing Event-based Data", "author": "Jiaming Zhang, Kailun Yang, Rainer Stiefelhagen", "pub_date": "Submitted on 20 Aug 2020", "abstract": "To bring autonomous vehicles closer to real-world applications, a major task is to ensure the safety of all traffic participants. In addition to the high accuracy under controlled conditions, the assistance system is still supposed to obtain robust perception against extreme situations, especially in accident scenarios, which involve object collisions, deformations, overturns, etc. However, models trained on common datasets may suffer from a large performance degradation when applied in these challenging scenes. To tackle this issue, we present a rarely addressed task regarding semantic segmentation in accident scenarios, along with an associated large-scale dataset DADA-seg. Our dataset contains 313 sequences with 40 frames each, of which the time windows are located before and during a traffic accident. For benchmarking the segmentation performance, every 11th frame is manually annotated with reference to Cityscapes. Furthermore, we propose a novel event-based multi-modal segmentation architecture ISSAFE. Our experiments indicate that event-based data can provide complementary information to stabilize semantic segmentation under adverse conditions by preserving fine-grain motion of fast-moving foreground (crash objects) in accidents. Compared with state-of-the-art models, our approach achieves 30.0% mIoU with 9.9% performance gain on the proposed evaluation set.", "pdf_url": "https://arxiv.org/pdf/2008.08974", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Co-Design to Enable User-Friendly Tools to Assess the Impact of Future Mobility Solutions", "author": "Gioele Zardini, Nicolas Lanzetti, Andrea Censi, Emilio Frazzoli, Marco Pavone", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The design of future mobility solutions (autonomous vehicles, micromobility solutions, etc.) and the design of the mobility systems they enable are closely coupled. Indeed, knowledge about the intended service of novel mobility solutions would impact their design and deployment process, whilst insights about their technological development could significantly affect transportation management policies. This requires tools to study such a coupling and co-design future mobility systems in terms of different objectives. This paper presents a framework to address such co-design problems. In particular, we leverage the recently developed mathematical theory of co-design to frame and solve the problem of designing and deploying an intermodal mobility system, whereby autonomous vehicles service travel demands jointly with micromobility solutions such as shared bikes and e-scooters, and public transit, in terms of fleets sizing, vehicle characteristics, and public transit service frequency. Our framework is modular and compositional, allowing one to describe the design problem as the interconnection of its individual components and to tackle it from a system-level perspective. Moreover, it only requires very general monotonicity assumptions and it naturally handles multiple objectives, delivering the rational solutions on the Pareto front and thus enabling policy makers to select a policy. To showcase our methodology, we present a real-world case study for Washington D.C., USA. Our work suggests that it is possible to create user-friendly optimization tools to systematically assess the costs and benefits of interventions, and that such analytical techniques might inform policy-making in the future.", "pdf_url": "https://arxiv.org/pdf/2008.08975", "subject": "Systems and Control (eess.SY)"},
{"title": "Improving Text to Image Generation using Mode-seeking Function", "author": "Naitik Bhise, Zhenfei Zhang, Tien D. Bui", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Generative Adversarial Networks (GANs) have long been used to understand the semantic relationship between the text and image. However, there are problems with mode collapsing in the image generation that causes some preferred output modes. Our aim is to improve the training of the network by using a specialized mode-seeking loss function to avoid this issue. In the text to image synthesis, our loss function differentiates two points in latent space for the generation of distinct images. We validate our model on the Caltech Birds (CUB) dataset and the Microsoft COCO dataset by changing the intensity of the loss function during the training. Experimental results demonstrate that our model works very well compared to some state-of-the-art approaches.", "pdf_url": "https://arxiv.org/pdf/2008.08976", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Generating Adjacency Matrix for Video-Query based Video Moment Retrieval", "author": "Yuan Zhou, Mingfei Wang, Ruolin Wang, Shuwei Huo", "pub_date": "Submitted on 19 Aug 2020", "abstract": "In this paper, we continue our work on Video-Query based Video Moment retrieval task. Based on using graph convolution to extract intra-video and inter-video frame features, we improve the method by using similarity-metric based graph convolution, whose weighted adjacency matrix is achieved by calculating similarity metric between features of any two different timesteps in the graph. Experiments on ActivityNet v1.2 and Thumos14 dataset shows the effectiveness of this improvement, and it outperforms the state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2008.08977", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Cache-aided Interference Management using Hypercube Combinatorial Cache Design with Reduced Subpacketizations and Order Optimal Sum-Degrees of Freedom", "author": "Xiang Zhang, Nicholas Woolsey, Mingyue Ji", "pub_date": "Submitted on 19 Aug 2020", "abstract": "We consider a cache-aided interference network which consists of a library of $N$ files, $K_T$ transmitters and $K_R$ receivers (users), each equipped with a local cache of size $M_T$ and $M_R$ files respectively, and connected via a discrete-time additive white Gaussian noise (AWGN) channel. Each receiver requests an arbitrary file from the library. The objective is to design a cache placement without knowing the receivers' requests and a communication scheme such that the sum Degrees of Freedom (sum-DoF) of the delivery is maximized. This network model with one-shot transmission was firstly investigated by Naderializadeh {\\em et al.}, who proposed a scheme that achieves a one-shot sum-DoF of $\\min\\{\\frac{M_TK_T+K_RM_R}{N}, K_R\\}$, which is optimal within a constant of $2$. One of the biggest limitations of this scheme is the requirement of high subpacketization level. This paper attempts to design new algorithms to reduce the file subpacketization in such a network without hurting the sum-DoF. In particular, we propose a new approach for both prefetching and linearly coded delivery based on a combinatorial design called {\\em hypercube}. The proposed approach reduces the subpacketization exponentially in terms of $K_R M/N$ and achieves the identical one-shot sum DoF when $\\frac{M_TK_T+K_RM_R}{N} \\leq K_R$.", "pdf_url": "https://arxiv.org/pdf/2008.08978", "subject": "Information Theory (cs.IT)"},
{"title": "Fair and consistent prize allocation in competitions", "author": "Bas J. Dietzenbacher, Aleksei Y. Kondratev", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Given the final ranking of a competition, how should the total prize endowment be allocated among the competitors? We study consistent prize allocation rules satisfying elementary solidarity and fairness principles. In particular, we axiomatically characterize two families of rules satisfying anonymity, order preservation, and endowment monotonicity, which all fall between the Equal Division rule and the Winner-Takes-All rule. Specific characterizations of rules and subfamilies are directly obtained.", "pdf_url": "https://arxiv.org/pdf/2008.08985", "subject": "Computer Science and Game Theory (cs.GT)"},
{"title": "Towards Inferring Queries from Simple and Partial Provenance Examples", "author": "Amir Gilad, Yuval Moskovitch", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The field of query-by-example aims at inferring queries from output examples given by non-expert users, by finding the underlying logic that binds the examples. However, for a very small set of examples, it is difficult to correctly infer such logic. To bridge this gap, previous work suggested attaching explanations to each output example, modeled as provenance, allowing users to explain the reason behind their choice of example. In this paper, we explore the problem of inferring queries from a few output examples and intuitive explanations. We propose a two step framework: (1) convert the explanations into (partial) provenance and (2) infer a query that generates the output examples using a novel algorithm that employs a graph based approach. This framework is suitable for non-experts as it does not require the specification of the provenance in its entirety or an understanding of its structure. We show promising initial experimental results of our approach.", "pdf_url": "https://arxiv.org/pdf/2008.08989", "subject": "Databases (cs.DB)"},
{"title": "Constructing a Knowledge Graph from Unstructured Documents without External Alignment", "author": "Seunghak Yu, Tianxing He, James Glass", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Knowledge graphs (KGs) are relevant to many NLP tasks, but building a reliable domain-specific KG is time-consuming and expensive. A number of methods for constructing KGs with minimized human intervention have been proposed, but still require a process to align into the human-annotated knowledge base. To overcome this issue, we propose a novel method to automatically construct a KG from unstructured documents that does not require external alignment and explore its use to extract desired information. To summarize our approach, we first extract knowledge tuples in their surface form from unstructured documents, encode them using a pre-trained language model, and link the surface-entities via the encoding to form the graph structure. We perform experiments with benchmark datasets such as WikiMovies and MetaQA. The experimental results show that our method can successfully create and search a KG with 18K documents and achieve 69.7% hits@10 (close to an oracle model) on a query retrieval task.", "pdf_url": "https://arxiv.org/pdf/2008.08995", "subject": "Computation and Language (cs.CL)"},
{"title": "Object Properties Inferring from and Transfer for Human Interaction Motions", "author": "Qian Zheng, Weikai Wu, Hanting Pan, Niloy Mitra, Daniel Cohen-Or, Hui Huang", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Humans regularly interact with their surrounding objects. Such interactions often result in strongly correlated motion between humans and the interacting objects. We thus ask: \"Is it possible to infer object properties from skeletal motion alone, even without seeing the interacting object itself?\" In this paper, we present a fine-grained action recognition method that learns to infer such latent object properties from human interaction motion alone. This inference allows us to disentangle the motion from the object property and transfer object properties to a given motion. We collected a large number of videos and 3D skeletal motions of the performing actors using an inertial motion capture device. We analyze similar actions and learn subtle differences among them to reveal latent properties of the interacting objects. In particular, we learn to identify the interacting object, by estimating its weight, or its fragility or delicacy. Our results clearly demonstrate that the interaction motions and interacting objects are highly correlated and indeed relative object latent properties can be inferred from the 3D skeleton sequences alone, leading to new synthesis possibilities for human interaction motions. Dataset will be available at .", "pdf_url": "https://arxiv.org/pdf/2008.08999", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "On Turn-Regular Orthogonal Representations", "author": "Michael A. Bekos, Carla Binucci, Giuseppe Di Battista, Walter Didimo, Martin Gronemann, Karsten Klein, Maurizio Patrignani, Ignaz Rutter", "pub_date": "Submitted on 20 Aug 2020", "abstract": "An interesting class of orthogonal representations consists of the so-called turn-regular ones, i.e., those that do not contain any pair of reflex corners that \"point to each other\" inside a face. For such a representation H it is possible to compute in linear time a minimum-area drawing, i.e., a drawing of minimum area over all possible assignments of vertex and bend coordinates of H. In contrast, finding a minimum-area drawing of H is NP-hard if H is non-turn-regular. This scenario naturally motivates the study of which graphs admit turn-regular orthogonal representations. In this paper we identify notable classes of biconnected planar graphs that always admit such representations, which can be computed in linear time. We also describe a linear-time testing algorithm for trees and provide a polynomial-time algorithm that tests whether a biconnected plane graph with \"small\" faces has a turn-regular orthogonal representation without bends.", "pdf_url": "https://arxiv.org/pdf/2008.09002", "subject": "Computational Geometry (cs.CG)"},
{"title": "Solving problems on generalized convex graphs via mim-width", "author": "Nick Brettell, Andrea Munaro, Dani\u00ebl Paulusma", "pub_date": "Submitted on 20 Aug 2020", "abstract": "A bipartite graph $G=(A,B,E)$ is ${\\cal H}$-convex, for some family of graphs ${\\cal H}$, if there exists a graph $H\\in {\\cal H}$ with $V(H)=A$ such that the set of neighbours in $A$ of each $b\\in B$ induces a connected subgraph of $H$. A variety of well-known $\\mathsf{NP}$-complete problems, including \\textsc{Dominating Set}, \\textsc{Feedback Vertex Set}, \\textsc{Induced Matching} and \\textsc{List $k$-Colouring}, become polynomial-time solvable for ${\\mathcal H}$-convex graphs when ${\\mathcal H}$ is the set of paths. In this case, the class of ${\\mathcal H}$-convex graphs is known as the class of convex graphs. The underlying reason is that the class of convex graphs has bounded mim-width. We extend the latter result to families of ${\\mathcal H}$-convex graphs where (i) ${\\mathcal H}$ is the set of cycles, or (ii) ${\\mathcal H}$ is the set of trees with bounded maximum degree and a bounded number of vertices of degree at least $3$. As a consequence, we can re-prove and strengthen a large number of results on generalized convex graphs known in the literature. To complement result (ii), we show that the mim-width of ${\\mathcal H}$-convex graphs is unbounded if ${\\mathcal H}$ is the set of trees with arbitrarily large maximum degree or arbitrarily large number of vertices of degree at least $3$. In this way we are able to determine complexity dichotomies for the aforementioned graph problems.", "pdf_url": "https://arxiv.org/pdf/2008.09004", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "On Fine-Grained Exact Computation in Regular Graphs", "author": "Saeed Akhoondian Amiri", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We show that there is no subexponential time algorithm for computing the exact solution of the maximum independent set problem in $d$-regular graphs, for any constant $d>2$, unless ETH fails. We also discuss the extensions of our construction to other problems and other classes of graphs, including $5$-regular planar graphs.", "pdf_url": "https://arxiv.org/pdf/2008.09008", "subject": "Computational Complexity (cs.CC)"},
{"title": "$\u03b2$-Variational Classifiers Under Attack", "author": "Marco Maggipinto, Matteo Terzi, Gian Antonio Susto", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Deep Neural networks have gained lots of attention in recent years thanks to the breakthroughs obtained in the field of Computer Vision. However, despite their popularity, it has been shown that they provide limited robustness in their predictions. In particular, it is possible to synthesise small adversarial perturbations that imperceptibly modify a correctly classified input data, making the network confidently misclassify it. This has led to a plethora of different methods to try to improve robustness or detect the presence of these perturbations. In this paper, we perform an analysis of $\\beta$-Variational Classifiers, a particular class of methods that not only solve a specific classification task, but also provide a generative component that is able to generate new samples from the input distribution. More in details, we study their robustness and detection capabilities, together with some novel insights on the generative part of the model.", "pdf_url": "https://arxiv.org/pdf/2008.09010", "subject": "Machine Learning (cs.LG)"},
{"title": "PRINCIPIA: a Decentralized Peer-Review Ecosystem", "author": "Andrea Mambrini, Andrea Baronchelli, Michele Starnini, Daniele Marinazzo, Manlio De Domenico", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Peer review is a cornerstone of modern scientific endeavor. However, there is growing consensus that several limitations of the current peer review system, from lack of incentives to reviewers to lack of transparency, risks to undermine its benefits. Here, we introduce the PRINCIPIA (http://www.principia.network/) framework for peer-review of scientific outputs (e.g., papers, grant proposals or patents). The framework allows key players of the scientific ecosystem -- including existing publishing groups -- to create and manage peer-reviewed journals, by building a free market for reviews and publications. PRINCIPIA's referees are transparently rewarded according to their efforts and the quality of their reviews. PRINCIPIA also naturally allows to recognize the prestige of users and journals, with an intrinsic reputation system that does not depend on third-parties. PRINCIPIA re-balances the power between researchers and publishers, stimulates valuable assessments from referees, favors a fair competition between journals, and reduces the costs to access research output and to publish.", "pdf_url": "https://arxiv.org/pdf/2008.09011", "subject": "Digital Libraries (cs.DL)"},
{"title": "Erasure decoding of convolutional codes using first order representations", "author": "Julia Lieb, Joachim Rosenthal", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In this paper, we employ the linear systems representation of a convolutional code to develop a decoding algorithm for convolutional codes over the erasure channel. We study the decoding problem using the state space description and this provides in a natural way additional information. With respect to previously known decoding algorithms, our new algorithm has the advantage that it is able to reduce the decoding delay as well as the computational effort in the erasure recovery process. We describe which properties a convolutional code should have in order to obtain a good decoding performance and illustrate it with an example.", "pdf_url": "https://arxiv.org/pdf/2008.09013", "subject": "Information Theory (cs.IT)"},
{"title": "A stabilized finite element method for delamination analysis of composites using cohesive elements", "author": "Gourab Ghosh, Ravindra Duddu, Chandrasekhar Annavarapu", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We demonstrate the ability of a stabilized finite element method, inspired by the weighted Nitsche approach, to alleviate spurious traction oscillations at interlaminar interfaces in multi-ply multi-directional composite laminates. In contrast with the standard (penalty-like) method, the stabilized method allows the use of arbitrarily large values of cohesive stiffness and obviates the need for engineering approaches to estimate minimum cohesive stiffness necessary for accurate delamination analysis. This is achieved by defining a weighted interface traction in the stabilized method, which allows a gradual transition from penalty-like method for soft elastic contact to Nitsche-like method for rigid contact. We conducted several simulation studies involving constant strain patch tests and benchmark delamination tests under mode-I, mode-II and mixed-mode loadings. Our results show clear evidence of traction oscillations with the standard method with structured and perturbed finite element meshes, and that the stabilized method alleviates these oscillations, thus illustrating its robustness.", "pdf_url": "https://arxiv.org/pdf/2008.09015", "subject": "Computational Engineering, Finance, and Science (cs.CE)"},
{"title": "A summary of the prevalence of Genetic Algorithms in Bioinformatics from 2015 onwards", "author": "Mekaal Swerhun, Jasmine Foley, Brandon Massop, Vijay Mago", "pub_date": "Submitted on 20 Aug 2020", "abstract": "In recent years, machine learning has seen an increasing presencein a large variety of fields, especially in health care and bioinformatics.More specifically, the field where machine learning algorithms have found most applications is Genetic Algorithms.The objective of this paper is to conduct a survey of articles published from 2015 onwards that deal with Genetic Algorithms(GA) and how they are used in achieve the objective, a scoping review was conducted that utilized Google Scholar alongside Publish or Perish and the Scimago Journal & CountryRank to search for respectable sources. Upon analyzing 31 articles from the field of bioinformatics, it became apparent that genetic algorithms rarely form a full application, instead they rely on other vital algorithms such as support vector machines.Indeed, support vector machines were the most prevalent algorithms used alongside genetic algorithms; however, while the usage of such algorithms contributes to the heavy focus on accuracy by GA programs, it often sidelines computation times in the process. In fact, most applications employing GAs for classification and feature selectionare nearing or at 100% success rate, and the focus of future GA development should be directed elsewhere. Population-based searches, like GA, are often combined with other machine learning algorithms. In this scoping review, genetic algorithms combined with Support Vector Machines were found to perform best. The performance metric that was evaluated most often was accuracy. Measuring the accuracy avoids measuring the main weakness of GAs, which is computational time. The future of genetic algorithms could be open-ended evolutionary algorithms, which attempt to increase complexity and find diverse solutions, rather than optimize a fitness function and converge to a single best solution from the initial population of solutions.", "pdf_url": "https://arxiv.org/pdf/2008.09017", "subject": "Neural and Evolutionary Computing (cs.NE)"},
{"title": "Balanced Order Batching with Task-Oriented Graph Clustering", "author": "Lu Duan, Haoyuan Hu, Zili Wu, Guozheng Li, Xinhang Zhang, Yu Gong, Yinghui Xu", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Balanced order batching problem (BOBP) arises from the process of warehouse picking in Cainiao, the largest logistics platform in China. Batching orders together in the picking process to form a single picking route, reduces travel distance. The reason for its importance is that order picking is a labor intensive process and, by using good batching methods, substantial savings can be obtained. The BOBP is a NP-hard combinational optimization problem and designing a good problem-specific heuristic under the quasi-real-time system response requirement is non-trivial. In this paper, rather than designing heuristics, we propose an end-to-end learning and optimization framework named Balanced Task-orientated Graph Clustering Network (BTOGCN) to solve the BOBP by reducing it to balanced graph clustering optimization problem. In BTOGCN, a task-oriented estimator network is introduced to guide the type-aware heterogeneous graph clustering networks to find a better clustering result related to the BOBP objective. Through comprehensive experiments on single-graph and multi-graphs, we show: 1) our balanced task-oriented graph clustering network can directly utilize the guidance of target signal and outperforms the two-stage deep embedding and deep clustering method; 2) our method obtains an average 4.57m and 0.13m picking distance (\"m\" is the abbreviation of the meter (the SI base unit of length)) reduction than the expert-designed algorithm on single and multi-graph set and has a good generalization ability to apply in practical scenario.", "pdf_url": "https://arxiv.org/pdf/2008.09018", "subject": "Machine Learning (cs.LG)"},
{"title": "Long-Lived LoRa: Prolonging the Lifetime of a LoRa Network", "author": "Sezana Fahmida, Venkata P Modekurthy, Mahbubur Rahman, Abusayeed Saifullah, Marco Brocanelli", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Prolonging the network lifetime is a major consideration in many Internet of Things applications. In this paper, we study maximizing the network lifetime of an energy-harvesting LoRa network. Such a network is characterized by heterogeneous recharging capabilities across the nodes that is not taken into account in existing work. We propose a link-layer protocol to achieve a long-lived LoRa network which dynamically enables the nodes with depleting batteries to exploit the superfluous energy of the neighboring nodes with affluent batteries by letting a depleting node offload its packets to an affluent node. By exploiting the LoRa's capability of adjusting multiple transmission parameters, we enable low-cost offloading by depleting nodes instead of high-cost direct forwarding. Such offloading requires synchronization of wake-up times as well as transmission parameters between the two nodes which also need to be selected dynamically. The proposed protocol addresses these challenges and prolongs the lifetime of a LoRa network through three novel techniques. (1) We propose a lightweight medium access control protocol for peer-to-peer communication to enable packet offloading which circumvents the synchronization overhead between the two nodes. (2) We propose an intuitive heuristic method for effective parameter selections for different modes (conventional vs. offloading). (3) We analyze the energy overhead of offloading and, based on it, the protocol dynamically selects affluent and depleting nodes while ensuring that an affluent node is not overwhelmed by the depleting ones. Simulations in NS-3 as well as real experiments show that our protocol can increase the network lifetime up to $4$ times while maintaining the same throughput compared to traditional LoRa network.", "pdf_url": "https://arxiv.org/pdf/2008.09019", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Training Sensitivity in Graph Isomorphism Network", "author": "Md. Khaledur Rahman", "pub_date": "Submitted on 19 Aug 2020", "abstract": "Graph neural network (GNN) is a popular tool to learn the lower-dimensional representation of a graph. It facilitates the applicability of machine learning tasks on graphs by incorporating domain-specific features. There are various options for underlying procedures (such as optimization functions, activation functions, etc.) that can be considered in the implementation of GNN. However, most of the existing tools are confined to one approach without any analysis. Thus, this emerging field lacks a robust implementation ignoring the highly irregular structure of the real-world graphs. In this paper, we attempt to fill this gap by studying various alternative functions for a respective module using a diverse set of benchmark datasets. Our empirical results suggest that the generally used underlying techniques do not always perform well to capture the overall structure from a set of graphs.", "pdf_url": "https://arxiv.org/pdf/2008.09020", "subject": "Machine Learning (cs.LG)"},
{"title": "Detecting Aedes Aegypti Mosquitoes through Audio Classification with Convolutional Neural Networks", "author": "Marcelo Schreiber Fernandes, Weverton Cordeiro, Mariana Recamonde-Mendoza", "pub_date": "Submitted on 19 Aug 2020", "abstract": "The incidence of mosquito-borne diseases is significant in under-developed regions, mostly due to the lack of resources to implement aggressive control measurements against mosquito proliferation. A potential strategy to raise community awareness regarding mosquito proliferation is building a live map of mosquito incidences using smartphone apps and crowdsourcing. In this paper, we explore the possibility of identifying Aedes aegypti mosquitoes using machine learning techniques and audio analysis captured from commercially available smartphones. In summary, we downsampled Aedes aegypti wingbeat recordings and used them to train a convolutional neural network (CNN) through supervised learning. As a feature, we used the recording spectrogram to represent the mosquito wingbeat frequency over time visually. We trained and compared three classifiers: a binary, a multiclass, and an ensemble of binary classifiers. In our evaluation, the binary and ensemble models achieved accuracy of 97.65% ($\\pm$ 0.55) and 94.56% ($\\pm$ 0.77), respectively, whereas the multiclass had an accuracy of 78.12% ($\\pm$ 2.09). The best sensitivity was observed in the ensemble approach (96.82% $\\pm$ 1.62), followed by the multiclass for the particular case of Aedes aegypti (90.23% $\\pm$ 3.83) and the binary (88.49% $\\pm$ 6.68). The binary classifier and the multiclass classifier presented the best balance between precision and recall, with F1-measure close to 90%. Although the ensemble classifier achieved the lowest precision, thus impairing its F1-measure (79.95% $\\pm$ 2.13), it was the most powerful classifier to detect Aedes aegypti in our dataset.", "pdf_url": "https://arxiv.org/pdf/2008.09024", "subject": "Sound (cs.SD)"},
{"title": "How Have We Reacted To The COVID-19 Pandemic? Analyzing Changing Indian Emotions Through The Lens of Twitter", "author": "Rajdeep Mukherjee, Sriyash Poddar, Atharva Naik, Soham Dasgupta", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Since its outbreak, the ongoing COVID-19 pandemic has caused unprecedented losses to human lives and economies around the world. As of 18th July 2020, the World Health Organization (WHO) has reported more than 13 million confirmed cases including close to 600,000 deaths across 216 countries and territories. Despite several government measures, India has gradually moved up the ranks to become the third worst-hit nation by the pandemic after the US and Brazil, thus causing widespread anxiety and fear among her citizens. As majority of the world's population continues to remain confined to their homes, more and more people have started relying on social media platforms such as Twitter for expressing their feelings and attitudes towards various aspects of the pandemic. With rising concerns of mental well-being, it becomes imperative to analyze the dynamics of public affect in order to anticipate any potential threats and take precautionary measures. Since affective states of human mind are more nuanced than meager binary sentiments, here we propose a deep learning-based system to identify people's emotions from their tweets. We achieve competitive results on two benchmark datasets for multi-label emotion classification. We then use our system to analyze the evolution of emotional responses among Indians as the pandemic continues to spread its wings. We also study the development of salient factors contributing towards the changes in attitudes over time. Finally, we discuss directions to further improve our work and hope that our analysis can aid in better public health monitoring.", "pdf_url": "https://arxiv.org/pdf/2008.09035", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries", "author": "Benjamin Heinzerling, Kentaro Inui", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Pretrained language models have been suggested as a possible alternative or complement to structured knowledge bases. However, this emerging LM-as-KB paradigm has so far only been considered in a very limited setting, which only allows handling 21k entities whose single-token name is found in common LM vocabularies. Furthermore, the main benefit of this paradigm, namely querying the KB using a variety of natural language paraphrases, is underexplored so far. Here, we formulate two basic requirements for treating LMs as KBs: (i) the ability to store a large number facts involving a large number of entities and (ii) the ability to query stored facts. We explore three entity representations that allow LMs to represent millions of entities and present a detailed case study on paraphrased querying of world knowledge in LMs, thereby providing a proof-of-concept that language models can indeed serve as knowledge bases.", "pdf_url": "https://arxiv.org/pdf/2008.09036", "subject": "Computation and Language (cs.CL)"},
{"title": "Accuracy and Performance Comparison of Video Action Recognition Approaches", "author": "Matthew Hutchinson, Siddharth Samsi, William Arcand, David Bestor, Bill Bergeron, Chansup Byun, Micheal Houle, Matthew Hubbell, Micheal Jones, Jeremy Kepner, Andrew Kirby, Peter Michaleas, Lauren Milechin, Julie Mullen, Andrew Prout, Antonio Rosa, Albert Reuther, Charles Yee, Vijay Gadepally", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Over the past few years, there has been significant interest in video action recognition systems and models. However, direct comparison of accuracy and computational performance results remain clouded by differing training environments, hardware specifications, hyperparameters, pipelines, and inference methods. This article provides a direct comparison between fourteen off-the-shelf and state-of-the-art models by ensuring consistency in these training characteristics in order to provide readers with a meaningful comparison across different types of video action recognition algorithms. Accuracy of the models is evaluated using standard Top-1 and Top-5 accuracy metrics in addition to a proposed new accuracy metric. Additionally, we compare computational performance of distributed training from two to sixty-four GPUs on a state-of-the-art HPC system.", "pdf_url": "https://arxiv.org/pdf/2008.09037", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Considerations, Good Practices, Risks and Pitfalls in Developing AI Solutions Against COVID-19", "author": "Alexandra Luccioni, Joseph Bullock, Katherine Hoffmann Pham, Cynthia Sin Nga Lam, Miguel Luengo-Oroz", "pub_date": "Submitted on 13 Aug 2020", "abstract": "The COVID-19 pandemic has been a major challenge to humanity, with 12.7 million confirmed cases as of July 13th, 2020 [1]. In previous work, we described how Artificial Intelligence can be used to tackle the pandemic with applications at the molecular, clinical, and societal scales [2]. In the present follow-up article, we review these three research directions, and assess the level of maturity and feasibility of the approaches used, as well as their potential for operationalization. We also summarize some commonly encountered risks and practical pitfalls, as well as guidelines and best practices for formulating and deploying AI applications at different scales.", "pdf_url": "https://arxiv.org/pdf/2008.09043", "subject": "Computers and Society (cs.CY)"},
{"title": "Pose2Mesh: Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose", "author": "Hongsuk Choi, Gyeongsik Moon, Kyoung Mu Lee", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Most of the recent deep learning-based 3D human pose and mesh estimation methods regress the pose and shape parameters of human mesh models, such as SMPL and MANO, from an input image. The first weakness of these methods is an appearance domain gap problem, due to different image appearance between train data from controlled environments, such as a laboratory, and test data from in-the-wild environments. The second weakness is that the estimation of the pose parameters is quite challenging owing to the representation issues of 3D rotations. To overcome the above weaknesses, we propose Pose2Mesh, a novel graph convolutional neural network (GraphCNN)-based system that estimates the 3D coordinates of human mesh vertices directly from the 2D human pose. The 2D human pose as input provides essential human body articulation information, while having a relatively homogeneous geometric property between the two domains. Also, the proposed system avoids the representation issues, while fully exploiting the mesh topology using a GraphCNN in a coarse-to-fine manner. We show that our Pose2Mesh outperforms the previous 3D human pose and mesh estimation methods on various benchmark datasets. The codes are publicly available .", "pdf_url": "https://arxiv.org/pdf/2008.09047", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Survey of Coded Distributed Computing", "author": "Jer Shyuan Ng, Wei Yang Bryan Lim, Nguyen Cong Luong, Zehui Xiong, Alia Asheralieva, Dusit Niyato, Cyril Leung, Chunyan Miao", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Distributed computing has become a common approach for large-scale computation of tasks due to benefits such as high reliability, scalability, computation speed, and costeffectiveness. However, distributed computing faces critical issues related to communication load and straggler effects. In particular, computing nodes need to exchange intermediate results with each other in order to calculate the final result, and this significantly increases communication overheads. Furthermore, a distributed computing network may include straggling nodes that run intermittently slower. This results in a longer overall time needed to execute the computation tasks, thereby limiting the performance of distributed computing. To address these issues, coded distributed computing (CDC), i.e., a combination of coding theoretic techniques and distributed computing, has been recently proposed as a promising solution. Coding theoretic techniques have proved effective in WiFi and cellular systems to deal with channel noise. Therefore, CDC may significantly reduce communication load, alleviate the effects of stragglers, provide fault-tolerance, privacy and security. In this survey, we first introduce the fundamentals of CDC, followed by basic CDC schemes. Then, we review and analyze a number of CDC approaches proposed to reduce the communication costs, mitigate the straggler effects, and guarantee privacy and security. Furthermore, we present and discuss applications of CDC in modern computer networks. Finally, we highlight important challenges and promising research directions related to CDC", "pdf_url": "https://arxiv.org/pdf/2008.09048", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Discovering Useful Sentence Representations from Large Pretrained Language Models", "author": "Nishant Subramani, Nivedita Suresh", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Despite the extensive success of pretrained language models as encoders for building NLP systems, they haven't seen prominence as decoders for sequence generation tasks. We explore the question of whether these models can be adapted to be used as universal decoders. To be considered \"universal,\" a decoder must have an implicit representation for any target sentence $s$, such that it can recover that sentence exactly when conditioned on its representation. For large transformer-based language models trained on vast amounts of English text, we investigate whether such representations can be easily discovered using standard optimization methods. We present and compare three representation injection techniques for transformer-based models and three accompanying methods which map sentences to and from this representation space. Experiments show that not only do representations exist for sentences from a variety of genres. More importantly, without needing complex optimization algorithms, our methods recover these sentences almost perfectly without fine-tuning the underlying language model at all.", "pdf_url": "https://arxiv.org/pdf/2008.09049", "subject": "Computation and Language (cs.CL)"},
{"title": "Analysis of Multivariate Scoring Functions for Automatic Unbiased Learning to Rank", "author": "Tao Yang, Shikai Fang, Shibo Li, Yulan Wang, Qingyao Ai", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Leveraging biased click data for optimizing learning to rank systems has been a popular approach in information retrieval. Because click data is often noisy and biased, a variety of methods have been proposed to construct unbiased learning to rank (ULTR) algorithms for the learning of unbiased ranking models. Among them, automatic unbiased learning to rank (AutoULTR) algorithms that jointly learn user bias models (i.e., propensity models) with unbiased rankers have received a lot of attention due to their superior performance and low deployment cost in practice. Despite their differences in theories and algorithm design, existing studies on ULTR usually use uni-variate ranking functions to score each document or result independently. On the other hand, recent advances in context-aware learning-to-rank models have shown that multivariate scoring functions, which read multiple documents together and predict their ranking scores jointly, are more powerful than uni-variate ranking functions in ranking tasks with human-annotated relevance labels. Whether such superior performance would hold in ULTR with noisy data, however, is mostly unknown. In this paper, we investigate existing multivariate scoring functions and AutoULTR algorithms in theory and prove that permutation invariance is a crucial factor that determines whether a context-aware learning-to-rank model could be applied to existing AutoULTR framework. Our experiments with synthetic clicks on two large-scale benchmark datasets show that AutoULTR models with permutation-invariant multivariate scoring functions significantly outperform those with uni-variate scoring functions and permutation-variant multivariate scoring functions.", "pdf_url": "https://arxiv.org/pdf/2008.09061", "subject": "Information Retrieval (cs.IR)"},
{"title": "Monocular Expressive Body Regression through Body-Driven Attention", "author": "Vasileios Choutas, Georgios Pavlakos, Timo Bolkart, Dimitrios Tzionas, Michael J. Black", "pub_date": "Submitted on 20 Aug 2020", "abstract": "To understand how people look, interact, or perform tasks, we need to quickly and accurately capture their 3D body, face, and hands together from an RGB image. Most existing methods focus only on parts of the body. A few recent approaches reconstruct full expressive 3D humans from images using 3D body models that include the face and hands. These methods are optimization-based and thus slow, prone to local optima, and require 2D keypoints as input. We address these limitations by introducing ExPose (EXpressive POse and Shape rEgression), which directly regresses the body, face, and hands, in SMPL-X format, from an RGB image. This is a hard problem due to the high dimensionality of the body and the lack of expressive training data. Additionally, hands and faces are much smaller than the body, occupying very few image pixels. This makes hand and face estimation hard when body images are downscaled for neural networks. We make three main contributions. First, we account for the lack of training data by curating a dataset of SMPL-X fits on in-the-wild images. Second, we observe that body estimation localizes the face and hands reasonably well. We introduce body-driven attention for face and hand regions in the original image to extract higher-resolution crops that are fed to dedicated refinement modules. Third, these modules exploit part-specific knowledge from existing face- and hand-only datasets. ExPose estimates expressive 3D humans more accurately than existing optimization methods at a small fraction of the computational cost. Our data, model and code are available for research at .", "pdf_url": "https://arxiv.org/pdf/2008.09062", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A review on the mobile applications developed for COVID-19: An exploratory analysis", "author": "Muhammad Nazrul Islam, Iyolita Islam, Kazi MD. Munim, A.K.M. Najmul Islam", "pub_date": "Submitted on 20 Aug 2020", "abstract": "The objective of this research is to explore the existing mobile applications developed for the COVID-19 pandemic. To obtain this research objective, firstly the related applications were selected through the systematic search technique in the popular application stores. Secondly, data related to the app objectives, functionalities provided by the app, user ratings, and user reviews were extracted. Thirdly, the extracted data were analyzed through the affinity diagram, noticing-collecting-thinking, and descriptive analysis. As outcomes, the review provides a state-of-the-art view of mobile apps developed for COVID-19 by revealing nine functionalities or features. It revealed ten factors related to information systems design characteristics that can guide future app design. The review outcome highlights the need for new development and further refinement of the existing applications considering not only the revealed objectives and their associated functionalities, but also revealed design characteristics such as reliability, performance, usefulness, supportive, security, privacy, flexibility, responsiveness, ease of use, and cultural sensitivity.", "pdf_url": "https://arxiv.org/pdf/2008.09063", "subject": "Software Engineering (cs.SE)"},
{"title": "Adventures in Mathematical Reasoning", "author": "Toby Walsh", "pub_date": "Submitted on 20 Aug 2020", "abstract": "\"Mathematics is not a careful march down a well-cleared highway, but a journey into a strange wilderness, where the explorers often get lost. Rigour should be a signal to the historian that the maps have been made, and the real explorers have gone elsewhere.\" W.S. Anglin, the Mathematical Intelligencer, 4 (4), 1982.", "pdf_url": "https://arxiv.org/pdf/2008.09067", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Implementation of model predictive control for tracking in embedded systems using a sparse extended ADMM algorithm", "author": "Pablo Krupa, Ignacio Alvarado, Daniel Limon, Teodoro Alamo", "pub_date": "Submitted on 20 Aug 2020", "abstract": "This article presents an implementation of a sparse, low-memory footprint optimization algorithm for the implementation of the model predictive control for tracking formulation in embedded systems. The algorithm is based on an extension of the alternating direction method of multipliers to problems with three separable functions in the objective function. One of the main advantages of the proposed algorithm is that its memory requirements grow linearly with the prediction horizon of the controller. Its sparse implementation is attained by identification of the particular structure of the optimization problem, and not by employing the common sparse algebra techniques, leading to a very computationally efficient implementation. We describe the controller formulation and provide a detailed description of the proposed algorithm, including its pseudocode. We also provide a simple (and sparse) warmstarting procedure that can significantly reduce the number of iterations. Finally, we show some preliminary numerical results of the performance of the algorithm.", "pdf_url": "https://arxiv.org/pdf/2008.09071", "subject": "Systems and Control (eess.SY)"},
{"title": "Utilizing Explainable AI for Quantization and Pruning of Deep Neural Networks", "author": "Muhammad Sabih, Frank Hannig, Juergen Teich", "pub_date": "Submitted on 20 Aug 2020", "abstract": "For many applications, utilizing DNNs (Deep Neural Networks) requires their implementation on a target architecture in an optimized manner concerning energy consumption, memory requirement, throughput, etc. DNN compression is used to reduce the memory footprint and complexity of a DNN before its deployment on hardware. Recent efforts to understand and explain AI (Artificial Intelligence) methods have led to a new research area, termed as explainable AI. Explainable AI methods allow us to understand better the inner working of DNNs, such as the importance of different neurons and features. The concepts from explainable AI provide an opportunity to improve DNN compression methods such as quantization and pruning in several ways that have not been sufficiently explored so far. In this paper, we utilize explainable AI methods: mainly DeepLIFT method. We use these methods for (1) pruning of DNNs; this includes structured and unstructured pruning of \\ac{CNN} filters pruning as well as pruning weights of fully connected layers, (2) non-uniform quantization of DNN weights using clustering algorithm; this is also referred to as Weight Sharing, and (3) integer-based mixed-precision quantization; this is where each layer of a DNN may use a different number of integer bits. We use typical image classification datasets with common deep learning image classification models for evaluation. In all these three cases, we demonstrate significant improvements as well as new insights and opportunities from the use of explainable AI in DNN compression.", "pdf_url": "https://arxiv.org/pdf/2008.09072", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Controlling Dialogue Generation with Semantic Exemplars", "author": "Prakhar Gupta, Jeffrey P. Bigham, Yulia Tsvetkov, Amy Pavel", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Dialogue systems pretrained with large language models generate locally coherent responses, but lack the fine-grained control over responses necessary to achieve specific goals. A promising method to control response generation is exemplar-based generation, in which models edit exemplar responses that are retrieved from training data, or hand-written to strategically address discourse-level goals, to fit new dialogue contexts. But, current exemplar-based approaches often excessively copy words from the exemplar responses, leading to incoherent replies. We present an Exemplar-based Dialogue Generation model, EDGE, that uses the semantic frames present in exemplar responses to guide generation. We show that controlling dialogue generation based on the semantic frames of exemplars, rather than words in the exemplar itself, improves the coherence of generated responses, while preserving semantic meaning and conversation goals present in exemplar responses.", "pdf_url": "https://arxiv.org/pdf/2008.09075", "subject": "Computation and Language (cs.CL)"},
{"title": "Do Syntax Trees Help Pre-trained Transformers Extract Information?", "author": "Devendra Singh Sachan, Yuhao Zhang, Peng Qi, William Hamilton", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Much recent work suggests that incorporating syntax information from dependency trees can improve task-specific transformer models. However, the effect of incorporating dependency tree information into pre-trained transformer models (e.g., BERT) remains unclear, especially given recent studies highlighting how these models implicitly encode syntax. In this work, we systematically study the utility of incorporating dependency trees into pre-trained transformers on three representative information extraction tasks: semantic role labeling (SRL), named entity recognition, and relation extraction. We propose and investigate two distinct strategies for incorporating dependency structure: a late fusion approach, which applies a graph neural network on the output of a transformer, and a joint fusion approach, which infuses syntax structure into the transformer attention layers. These strategies are representative of prior work, but we introduce essential design decisions that are necessary for strong performance. Our empirical analysis demonstrates that these syntax-infused transformers obtain state-of-the-art results on SRL and relation extraction tasks. However, our analysis also reveals a critical shortcoming of these models: we find that their performance gains are highly contingent on the availability of human-annotated dependency parses, which raises important questions regarding the viability of syntax-augmented transformers in real-world applications.", "pdf_url": "https://arxiv.org/pdf/2008.09084", "subject": "Computation and Language (cs.CL)"},
{"title": "DeepGMR: Learning Latent Gaussian Mixture Models for Registration", "author": "Wentao Yuan, Ben Eckart, Kihwan Kim, Varun Jampani, Dieter Fox, Jan Kautz", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Point cloud registration is a fundamental problem in 3D computer vision, graphics and robotics. For the last few decades, existing registration algorithms have struggled in situations with large transformations, noise, and time constraints. In this paper, we introduce Deep Gaussian Mixture Registration (DeepGMR), the first learning-based registration method that explicitly leverages a probabilistic registration paradigm by formulating registration as the minimization of KL-divergence between two probability distributions modeled as mixtures of Gaussians. We design a neural network that extracts pose-invariant correspondences between raw point clouds and Gaussian Mixture Model (GMM) parameters and two differentiable compute blocks that recover the optimal transformation from matched GMM parameters. This construction allows the network learn an SE(3)-invariant feature space, producing a global registration method that is real-time, generalizable, and robust to noise. Across synthetic and real-world data, our proposed method shows favorable performance when compared with state-of-the-art geometry-based and learning-based registration methods.", "pdf_url": "https://arxiv.org/pdf/2008.09088", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "TRU-NET: A Deep Learning Approach to High Resolution Prediction of Rainfall", "author": "Rilwan Adewoyin, Peter Dueben, Peter Watson, Yulan He, Ritabrata Dutta", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Climate models (CM) are used to evaluate the impact of climate change on the risk of floods and strong precipitation events. However, these numerical simulators have difficulties representing precipitation events accurately, mainly due to limited spatial resolution when simulating multi-scale dynamics in the atmosphere. To improve the prediction of high resolution precipitation we apply a Deep Learning (DL) approach using an input of CM simulations of the model fields (weather variables) that are more predictable than local precipitation. To this end, we present TRU-NET (Temporal Recurrent U-Net), an encoder-decoder model featuring a novel 2D cross attention mechanism between contiguous convolutional-recurrent layers to effectively model multi-scale spatio-temporal weather processes. We use a conditional-continuous loss function to capture the zero-skewed %extreme event patterns of rainfall. Experiments show that our model consistently attains lower RMSE and MAE scores than a DL model prevalent in short term precipitation prediction and improves upon the rainfall predictions of a state-of-the-art dynamical weather model. Moreover, by evaluating the performance of our model under various, training and testing, data formulation strategies, we show that there is enough data for our deep learning approach to output robust, high-quality results across seasons and varying regions.", "pdf_url": "https://arxiv.org/pdf/2008.09090", "subject": "Computational Engineering, Finance, and Science (cs.CE)"},
{"title": "Meta-Sim2: Unsupervised Learning of Scene Structure for Synthetic Data Generation", "author": "Jeevan Devaranjan, Amlan Kar, Sanja Fidler", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Procedural models are being widely used to synthesize scenes for graphics, gaming, and to create (labeled) synthetic datasets for ML. In order to produce realistic and diverse scenes, a number of parameters governing the procedural models have to be carefully tuned by experts. These parameters control both the structure of scenes being generated (e.g. how many cars in the scene), as well as parameters which place objects in valid configurations. Meta-Sim aimed at automatically tuning parameters given a target collection of real images in an unsupervised way. In Meta-Sim2, we aim to learn the scene structure in addition to parameters, which is a challenging problem due to its discrete nature. Meta-Sim2 proceeds by learning to sequentially sample rule expansions from a given probabilistic scene grammar. Due to the discrete nature of the problem, we use Reinforcement Learning to train our model, and design a feature space divergence between our synthesized and target images that is key to successful training. Experiments on a real driving dataset show that, without any supervision, we can successfully learn to generate data that captures discrete structural statistics of objects, such as their frequency, in real images. We also show that this leads to downstream improvement in the performance of an object detector trained on our generated dataset as opposed to other baseline simulation methods. Project page: .", "pdf_url": "https://arxiv.org/pdf/2008.09092", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "PARADE: Passage Representation Aggregation for Document Reranking", "author": "Canjia Li, Andrew Yates, Sean MacAvaney, Ben He, Yingfei Sun", "pub_date": "Submitted on 20 Aug 2020", "abstract": "We present PARADE, an end-to-end Transformer-based model that considers document-level context for document reranking. PARADE leverages passage-level relevance representations to predict a document relevance score, overcoming the limitations of previous approaches that perform inference on passages independently. Experiments on two ad-hoc retrieval benchmarks demonstrate PARADE's effectiveness over such methods. We conduct extensive analyses on PARADE's efficiency, highlighting several strategies for improving it. When combined with knowledge distillation, a PARADE model with 72\\% fewer parameters achieves effectiveness competitive with previous approaches using BERT-Base. Our code is available at \\url{ }.", "pdf_url": "https://arxiv.org/pdf/2008.09093", "subject": "Information Retrieval (cs.IR)"},
{"title": "Scruples: A Corpus of Community Ethical Judgments on 32,000 Real-Life Anecdotes", "author": "Nicholas Lourie, Ronan Le Bras, Yejin Choi", "pub_date": "Submitted on 20 Aug 2020", "abstract": "As AI systems become an increasing part of people's everyday lives, it becomes ever more important that they understand people's ethical norms. Motivated by descriptive ethics, a field of study that focuses on people's descriptive judgments rather than theoretical prescriptions on morality, we investigate a novel, data-driven approach to machine ethics. We introduce Scruples, the first large-scale dataset with 625,000 ethical judgments over 32,000 real-life anecdotes. Each anecdote recounts a complex ethical situation, often posing moral dilemmas, paired with a distribution of judgments contributed by the community members. Our dataset presents a major challenge to state-of-the-art neural language models, leaving significant room for improvement. However, when presented with simplified moral situations, the results are considerably more promising, suggesting that neural models can effectively learn simpler ethical building blocks. A key take-away of our empirical analysis is that norms are not always clean-cut; many situations are naturally divisive. We present a new method to estimate the best possible performance on such tasks with inherently diverse label distributions, and explore likelihood functions that separate intrinsic from model uncertainty.", "pdf_url": "https://arxiv.org/pdf/2008.09094", "subject": "Computation and Language (cs.CL)"},
{"title": "The Role of Domain Expertise in User Trust and the Impact of First Impressions with Intelligent Systems", "author": "Mahsan Nourani, Joanie T. King, Eric D. Ragan", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Domain-specific intelligent systems are meant to help system users in their decision-making process. Many systems aim to simultaneously support different users with varying levels of domain expertise, but prior domain knowledge can affect user trust and confidence in detecting system errors. While it is also known that user trust can be influenced by first impressions with intelligent systems, our research explores the relationship between ordering bias and domain expertise when encountering errors in intelligent systems. In this paper, we present a controlled user study to explore the role of domain knowledge in establishing trust and susceptibility to the influence of first impressions on user trust. Participants reviewed an explainable image classifier with a constant accuracy and two different orders of observing system errors (observing errors in the beginning of usage vs. in the end). Our findings indicate that encountering errors early-on can cause negative first impressions for domain experts, negatively impacting their trust over the course of interactions. However, encountering correct outputs early helps more knowledgable users to dynamically adjust their trust based on their observations of system performance. In contrast, novice users suffer from over-reliance due to their lack of proper knowledge to detect errors.", "pdf_url": "https://arxiv.org/pdf/2008.09100", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "A Plug-and-play Scheme to Adapt Image Saliency Deep Model for Video Data", "author": "Yunxiao Li, Shuai Li, Chenglizhao Chen, Aimin Hao, Hong Qin", "pub_date": "Submitted on 2 Aug 2020", "abstract": "With the rapid development of deep learning techniques, image saliency deep models trained solely by spatial information have occasionally achieved detection performance for video data comparable to that of the models trained by both spatial and temporal information. However, due to the lesser consideration of temporal information, the image saliency deep models may become fragile in the video sequences dominated by temporal information. Thus, the most recent video saliency detection approaches have adopted the network architecture starting with a spatial deep model that is followed by an elaborately designed temporal deep model. However, such methods easily encounter the performance bottleneck arising from the single stream learning methodology, so the overall detection performance is largely determined by the spatial deep model. In sharp contrast to the current mainstream methods, this paper proposes a novel plug-and-play scheme to weakly retrain a pretrained image saliency deep model for video data by using the newly sensed and coded temporal information. Thus, the retrained image saliency deep model will be able to maintain temporal saliency awareness, achieving much improved detection performance. Moreover, our method is simple yet effective for adapting any off-the-shelf pre-trained image saliency deep model to obtain high-quality video saliency detection. Additionally, both the data and source code of our method are publicly available.", "pdf_url": "https://arxiv.org/pdf/2008.09103", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A review of deep learning in medical imaging: Image traits, technology trends, case studies with progress highlights, and future promises", "author": "S. Kevin Zhou, Hayit Greenspan, Christos Davatzikos, James S. Duncan, Bram van Ginneken, Anant Madabhushi, Jerry L. Prince, Daniel Rueckert, Ronald M. Summers", "pub_date": "Submitted on 2 Aug 2020", "abstract": "Since its renaissance, deep learning has been widely used in various medical imaging tasks and has achieved remarkable success in many medical imaging applications, thereby propelling us into the so-called artificial intelligence (AI) era. It is known that the success of AI is mostly attributed to the availability of big data with annotations for a single task and the advances in high performance computing. However, medical imaging presents unique challenges that confront deep learning approaches. In this survey paper, we first highlight both clinical needs and technical challenges in medical imaging and describe how emerging trends in deep learning are addressing these issues. We cover the topics of network architecture, sparse and noisy labels, federating learning, interpretability, uncertainty quantification, etc. Then, we present several case studies that are commonly found in clinical practice, including digital pathology and chest, brain, cardiovascular, and abdominal imaging. Rather than presenting an exhaustive literature survey, we instead describe some prominent research highlights related to these case study applications. We conclude with a discussion and presentation of promising future directions.", "pdf_url": "https://arxiv.org/pdf/2008.09104", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Location-aware Graph Convolutional Networks for Video Question Answering", "author": "Deng Huang, Peihao Chen, Runhao Zeng, Qing Du, Mingkui Tan, Chuang Gan", "pub_date": "Submitted on 7 Aug 2020", "abstract": "We addressed the challenging task of video question answering, which requires machines to answer questions about videos in a natural language form. Previous state-of-the-art methods attempt to apply spatio-temporal attention mechanism on video frame features without explicitly modeling the location and relations among object interaction occurred in videos. However, the relations between object interaction and their location information are very critical for both action recognition and question reasoning. In this work, we propose to represent the contents in the video as a location-aware graph by incorporating the location information of an object into the graph construction. Here, each node is associated with an object represented by its appearance and location features. Based on the constructed graph, we propose to use graph convolution to infer both the category and temporal locations of an action. As the graph is built on objects, our method is able to focus on the foreground action contents for better video question answering. Lastly, we leverage an attention mechanism to combine the output of graph convolution and encoded question features for final answer reasoning. Extensive experiments demonstrate the effectiveness of the proposed methods. Specifically, our method significantly outperforms state-of-the-art methods on TGIF-QA, Youtube2Text-QA, and MSVD-QA datasets. Code and pre-trained models are publicly available at:", "pdf_url": "https://arxiv.org/pdf/2008.09105", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Generative View Synthesis: From Single-view Semantics to Novel-view Images", "author": "Tewodros Habtegebrial, Varun Jampani, Orazio Gallo, Didier Stricker", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Content creation, central to applications such as virtual reality, can be a tedious and time-consuming. Recent image synthesis methods simplify this task by offering tools to generate new views from as little as a single input image, or by converting a semantic map into a photorealistic image. We propose to push the envelope further, and introduce \\emph{Generative View Synthesis} (GVS), which can synthesize multiple photorealistic views of a scene given a single semantic map. We show that the sequential application of existing techniques, e.g., semantics-to-image translation followed by monocular view synthesis, fail at capturing the scene's structure. In contrast, we solve the semantics-to-image translation in concert with the estimation of the 3D layout of the scene, thus producing geometrically consistent novel views that preserve semantic structures. We first lift the input 2D semantic map onto a 3D layered representation of the scene in feature space, thereby preserving the semantic labels of 3D geometric structures. We then project the layered features onto the target views to generate the final novel-view images. We verify the strengths of our method and compare it with several advanced baselines on three different datasets. Our approach also allows for style manipulation and image editing operations, such as the addition or removal of objects, with simple manipulations of the input style images and semantic maps respectively. Visit the project page at .", "pdf_url": "https://arxiv.org/pdf/2008.09106", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Weakly-supervised 3D Shape Completion in the Wild", "author": "Jiayuan Gu, Wei-Chiu Ma, Sivabalan Manivasagam, Wenyuan Zeng, Zihao Wang, Yuwen Xiong, Hao Su, Raquel Urtasun", "pub_date": "Submitted on 20 Aug 2020", "abstract": "3D shape completion for real data is important but challenging, since partial point clouds acquired by real-world sensors are usually sparse, noisy and unaligned. Different from previous methods, we address the problem of learning 3D complete shape from unaligned and real-world partial point clouds. To this end, we propose a weakly-supervised method to estimate both 3D canonical shape and 6-DoF pose for alignment, given multiple partial observations associated with the same instance. The network jointly optimizes canonical shapes and poses with multi-view geometry constraints during training, and can infer the complete shape given a single partial point cloud. Moreover, learned pose estimation can facilitate partial point cloud registration. Experiments on both synthetic and real data show that it is feasible and promising to learn 3D shape completion through large-scale data without shape and pose supervision.", "pdf_url": "https://arxiv.org/pdf/2008.09110", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Inducing Language-Agnostic Multilingual Representations", "author": "Wei Zhao, Steffen Eger, Johannes Bjerva, Isabelle Augenstein", "pub_date": "Submitted on 20 Aug 2020", "abstract": "Multilingual representations have the potential to make cross-lingual systems available to the vast majority of languages in the world. However, they currently require large pretraining corpora, or assume access to typologically similar languages. In this work, we address these obstacles by removing language identity signals from multilingual embeddings. We examine three approaches for this: 1) re-aligning the vector spaces of target languages (all together) to a pivot source language; 2) removing languages-specific means and variances, which yields better discriminativeness of embeddings as a by-product; and 3) normalizing input texts by removing morphological contractions and sentence reordering, thus yielding language-agnostic representations. We evaluate on the tasks of XNLI and reference-free MT evaluation of varying difficulty across 19 selected languages. Our experiments demonstrate the language-agnostic behavior of our multilingual representations, which manifest the potential of zero-shot cross-lingual transfer to distant and low-resource languages, and decrease the performance gap by 8.9 points (M-BERT) and 18.2 points (XLM-R) on average across all tasks and languages. We make our codes and models available.", "pdf_url": "https://arxiv.org/pdf/2008.09112", "subject": "Computation and Language (cs.CL)"},
{"title": "Four short stories on surprising algorithmic uses of treewidth", "author": "D\u00e1niel Marx", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This article briefly describes four algorithmic problems where the notion of treewidth is very useful. Even though the problems themselves have nothing to do with treewidth, it turns out that combining known results on treewidth allows us to easily describe very clean and high-level algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.07968", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "A Sensitivity-based Approach for Optimal Siting of Distributed Energy Resources", "author": "Mukesh Gautam, Narayan Bhusal, Mohammed Benidris, Chanan Singh, Joydeep Mitra", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This paper presents a sensitivity-based approach for the placement of distributed energy resources (DERs) in power systems. The approach is based on the fact that most planning studies utilize some form of optimization, and solutions to these optimization problems provide insights into the sensitivity of many system variables to operating conditions and constraints. However, most of the existing sensitivity-based planning criteria do not capture ranges of effectiveness of these solutions (i.e., ranges of the effectiveness of Lagrange multipliers). The proposed method detects the ranges of the effectiveness of Lagrange multipliers and uses them to determine optimal solution alternatives. Profiles for existing generation and loads, and transmission constraints are taken into consideration. The proposed method is used to determine the impacts of DERs at different locations, in the presence of a stochastic element (load variability). This method consists of sequentially calculating Lagrange multipliers of the dual solution of the optimization problem for various load buses for all load scenarios. Optimal sizes and sites of resources are jointly determined in a sequential manner based on the validity of active constraints. The effectiveness of the proposed method is demonstrated through several case studies on various test systems including the IEEE reliability test system (IEEE RTS), the IEEE 14, and 30 bus systems. In comparison with conventional sensitivity-based approaches (i.e., without considering ranges of validity of Lagrange multipliers), the proposed approach provides more accurate results for active constraints.", "pdf_url": "https://arxiv.org/pdf/2008.07896", "subject": "Systems and Control (eess.SY)"},
{"title": "Retargetable AR: Context-aware Augmented Reality in Indoor Scenes based on 3D Scene Graph", "author": "Tomu Tahara, Takashi Seno, Gaku Narita, Tomoya Ishikawa", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this paper, we present Retargetable AR, a novel AR framework that yields an AR experience that is aware of scene contexts set in various real environments, achieving natural interaction between the virtual and real worlds. To this end, we characterize scene contexts with relationships among objects in 3D space, not with coordinates transformations. A context assumed by an AR content and a context formed by a real environment where users experience AR are represented as abstract graph representations, i.e. scene graphs. From RGB-D streams, our framework generates a volumetric map in which geometric and semantic information of a scene are integrated. Moreover, using the semantic map, we abstract scene objects as oriented bounding boxes and estimate their orientations. With such a scene representation, our framework constructs, in an online fashion, a 3D scene graph characterizing the context of a real environment for AR. The correspondence between the constructed graph and an AR scene graph denoting the context of AR content provides a semantically registered content arrangement, which facilitates natural interaction between the virtual and real worlds. We performed extensive evaluations on our prototype system through quantitative evaluation of the performance of the oriented bounding box estimation, subjective evaluation of the AR content arrangement based on constructed 3D scene graphs, and an online AR demonstration. The results of these evaluations showed the effectiveness of our framework, demonstrating that it can provide a context-aware AR experience in a variety of real scenes.", "pdf_url": "https://arxiv.org/pdf/2008.07817", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Parallel Extraction of Long-term Trends and Short-term Fluctuation Framework for Multivariate Time Series Forecasting", "author": "Haoyan Xu, Ziheng Duan, Yida Huang, Jie Feng, Anni Ren, Pengyu Song, Xiaoqian Wang", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Multivariate time series forecasting is widely used in various fields. Reasonable prediction results can assist people in planning and decision-making, generate benefits and avoid risks. Normally, there are two characteristics of time series, that is, long-term trend and short-term fluctuation. For example, stock prices will have a long-term upward trend with the market, but there may be a small decline in the short term. These two characteristics are often relatively independent of each other. However, the existing prediction methods often do not distinguish between them, which reduces the accuracy of the prediction model. In this paper, a MTS forecasting framework that can capture the long-term trends and short-term fluctuations of time series in parallel is proposed. This method uses the original time series and its first difference to characterize long-term trends and short-term fluctuations. Three prediction sub-networks are constructed to predict long-term trends, short-term fluctuations and the final value to be predicted. In the overall optimization goal, the idea of multi-task learning is used for reference, which is to make the prediction results of long-term trends and short-term fluctuations as close to the real values as possible while requiring to approximate the values to be predicted. In this way, the proposed method uses more supervision information and can more accurately capture the changing trend of the time series, thereby improving the forecasting performance.", "pdf_url": "https://arxiv.org/pdf/2008.07730", "subject": "Machine Learning (cs.LG)"},
{"title": "Residual Learning from Demonstration", "author": "Todor Davchev, Kevin Sebastian Luck, Michael Burke, Franziska Meier, Stefan Schaal, Subramanian Ramamoorthy", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Contacts and friction are inherent to nearly all robotic manipulation tasks. Through the motor skill of insertion, we study how robots can learn to cope when these attributes play a salient role. In this work we propose residual learning from demonstration (rLfD), a framework that combines dynamic movement primitives (DMP) that rely on behavioural cloning with a reinforcement learning (RL) based residual correction policy. The proposed solution is applied directly in task space and operates on the full pose of the robot. We show that rLfD outperforms alternatives and improves the generalisation abilities of DMPs. We evaluate this approach by training an agent to successfully perform both simulated and real world insertions of pegs, gears and plugs into respective sockets.", "pdf_url": "https://arxiv.org/pdf/2008.07682", "subject": "Robotics (cs.RO)"},
{"title": "Stock Index Prediction with Multi-task Learning and Word Polarity Over Time", "author": "Yue Zhou, Kerstin Voigt", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Sentiment-based stock prediction systems aim to explore sentiment or event signals from online corpora and attempt to relate the signals to stock price variations. Both the feature-based and neural-networks-based approaches have delivered promising results. However, the frequently minor fluctuations of the stock prices restrict learning the sentiment of text from price patterns, and learning market sentiment from text can be biased if the text is irrelevant to the underlying market. In addition, when using discrete word features, the polarity of a certain term can change over time according to different events. To address these issues, we propose a two-stage system that consists of a sentiment extractor to extract the opinion on the market trend and a summarizer that predicts the direction of the index movement of following week given the opinions of the news over the current week. We adopt BERT with multitask learning which additionally predicts the worthiness of the news and propose a metric called Polarity-Over-Time to extract the word polarity among different event periods. A Weekly-Monday prediction framework and a new dataset, the 10-year Reuters financial news dataset, are also proposed.", "pdf_url": "https://arxiv.org/pdf/2008.07605", "subject": "Computation and Language (cs.CL)"},
{"title": "Deep Learning Based on Generative Adversarial and Convolutional Neural Networks for Financial Time Series Predictions", "author": "Wilfredo Tovar", "pub_date": "Submitted on 8 Aug 2020", "abstract": "In the big data era, deep learning and intelligent data mining technique solutions have been applied by researchers in various areas. Forecast and analysis of stock market data have represented an essential role in today's economy, and a significant challenge to the specialist since the market's tendencies are immensely complex, chaotic and are developed within a highly dynamic environment. There are numerous researches from multiple areas intending to take on that challenge, and Machine Learning approaches have been the focus of many of them. There are multiple models of Machine Learning algorithms been able to obtain competent outcomes doing that class of foresight. This paper proposes the implementation of a generative adversarial network (GAN), which is composed by a bi-directional Long short-term memory (LSTM) and convolutional neural network(CNN) referred as Bi-LSTM-CNN to generate synthetic data that agree with existing real financial data so the features of stocks with positive or negative trends can be retained to predict future trends of a stock. The novelty of this proposed solution that distinct from previous solutions is that this paper introduced the concept of a hybrid system (Bi-LSTM-CNN) rather than a sole LSTM model. It was collected data from multiple stock markets such as TSX, SHCOMP, KOSPI 200 and the S&P 500, proposing an adaptative-hybrid system for trends prediction on stock market prices, and carried a comprehensive evaluation on several commonly utilized machine learning prototypes, and it is concluded that the proposed solution approach outperforms preceding models. Additionally, during the research stage from preceding works, gaps were found between investors and researchers who dedicated to the technical domain.", "pdf_url": "https://arxiv.org/pdf/2008.08041", "subject": "Signal Processing (eess.SP)"},
{"title": "Deep Learning Based Source Separation Applied To Choir Ensembles", "author": "Darius Petermann, Pritish Chandna, Helena Cuesta, Jordi Bonada, Emilia Gomez", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Choral singing is a widely practiced form of ensemble singing wherein a group of people sing simultaneously in polyphonic harmony. The most commonly practiced setting for choir ensembles consists of four parts; Soprano, Alto, Tenor and Bass (SATB), each with its own range of fundamental frequencies (F$0$s). The task of source separation for this choral setting entails separating the SATB mixture into the constituent parts. Source separation for musical mixtures is well studied and many deep learning based methodologies have been proposed for the same. However, most of the research has been focused on a typical case which consists in separating vocal, percussion and bass sources from a mixture, each of which has a distinct spectral structure. In contrast, the simultaneous and harmonic nature of ensemble singing leads to high structural similarity and overlap between the spectral components of the sources in a choral mixture, making source separation for choirs a harder task than the typical case. This, along with the lack of an appropriate consolidated dataset has led to a dearth of research in the field so far. In this paper we first assess how well some of the recently developed methodologies for musical source separation perform for the case of SATB choirs. We then propose a novel domain-specific adaptation for conditioning the recently proposed U-Net architecture for musical source separation using the fundamental frequency contour of each of the singing groups and demonstrate that our proposed approach surpasses results from domain-agnostic architectures.", "pdf_url": "https://arxiv.org/pdf/2008.07645", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Metaheuristic optimization of power and energy systems: underlying principles and main issues of the 'rush to heuristics'", "author": "Gianfranco Chicco, Andrea Mazza", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In the power and energy systems area, a progressive increase of literature contributions containing applications of metaheuristic algorithms is occurring. In many cases, these applications are merely aimed at proposing the testing of an existing metaheuristic algorithm on a specific problem, claiming that the proposed method is better than other methods based on weak comparisons. This 'rush to heuristics' does not happen in the evolutionary computation domain, where the rules for setting up rigorous comparisons are stricter, but are typical of the domains of application of the metaheuristics. This paper considers the applications to power and energy systems, and aims at providing a comprehensive view of the main issues concerning the use of metaheuristics for global optimization problems. A set of underlying principles that characterize the metaheuristic algorithms is presented. The customization of metaheuristic algorithms to fit the constraints of specific problems is discussed. Some weaknesses and pitfalls found in literature contributions are identified, and specific guidelines are provided on how to prepare sound contributions on the application of metaheuristic algorithms to specific problems.", "pdf_url": "https://arxiv.org/pdf/2008.07491", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Improving Emergency Response during Hurricane Season using Computer Vision", "author": "Marc Bosch, Christian Conroy, Benjamin Ortiz, Philip Bogden", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We have developed a framework for crisis response and management that incorporates the latest technologies in computer vision (CV), inland flood prediction, damage assessment and data visualization. The framework uses data collected before, during, and after the crisis to enable rapid and informed decision making during all phases of disaster response. Our computer-vision model analyzes spaceborne and airborne imagery to detect relevant features during and after a natural disaster and creates metadata that is transformed into actionable information through web-accessible mapping tools. In particular, we have designed an ensemble of models to identify features including water, roads, buildings, and vegetation from the imagery. We have investigated techniques to bootstrap and reduce dependency on large data annotation efforts by adding use of open source labels including OpenStreetMaps and adding complementary data sources including Height Above Nearest Drainage (HAND) as a side channel to the network's input to encourage it to learn other features orthogonal to visual characteristics. Modeling efforts include modification of connected U-Nets for (1) semantic segmentation, (2) flood line detection, and (3) for damage assessment. In particular for the case of damage assessment, we added a second encoder to U-Net so that it could learn pre-event and post-event image features simultaneously. Through this method, the network is able to learn the difference between the pre- and post-disaster images, and therefore more effectively classify the level of damage. We have validated our approaches using publicly available data from the National Oceanic and Atmospheric Administration (NOAA)'s Remote Sensing Division, which displays the city and street-level details as mosaic tile images as well as data released as part of the Xview2 challenge.", "pdf_url": "https://arxiv.org/pdf/2008.07418", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Estimating action plans for smart poultry houses", "author": "Darlan Felipe Klotz, Richardson Ribeiro, Fabr\u00edcio Enembreck, Gustavo Denardin, Marco Barbosa, Dalcimar Casanova, Marcelo Teixeira", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In poultry farming, the systematic choice, update, and implementation of periodic (t) action plans define the feed conversion rate (FCR[t]), which is an acceptable measure for successful production. Appropriate action plans provide tailored resources for broilers, allowing them to grow within the so-called thermal comfort zone, without wast or lack of resources. Although the implementation of an action plan is automatic, its configuration depends on the knowledge of the specialist, tending to be inefficient and error-prone, besides to result in different FCR[t] for each poultry house. In this article, we claim that the specialist's perception can be reproduced, to some extent, by computational intelligence. By combining deep learning and genetic algorithm techniques, we show how action plans can adapt their performance over the time, based on previous well succeeded plans. We also implement a distributed network infrastructure that allows to replicate our method over distributed poultry houses, for their smart, interconnected, and adaptive control. A supervision system is provided as interface to users. Experiments conducted over real data show that our method improves 5% on the performance of the most productive specialist, staying very close to the optimal FCR[t].", "pdf_url": "https://arxiv.org/pdf/2008.07356", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Lanfrica: A Participatory Approach to Documenting Machine Translation Research on African Languages", "author": "Chris C. Emezue, Bonaventure F.P. Dossou", "pub_date": "Submitted on 3 Aug 2020", "abstract": "Over the years, there have been campaigns to include the African languages in the growing research on machine translation (MT) in particular, and natural language processing (NLP) in general. Africa has the highest language diversity, with 1500-2000 documented languages and many more undocumented or extinct languages(Lewis, 2009; Bendor-Samuel, 2017). This makes it hard to keep track of the MT research, models and dataset that have been developed for some of them. As the internet and social media make up the daily lives of more than half of the world(Lin, 2020), as well as over 40% of Africans(Campbell, 2019), online platforms can be useful in creating accessibility to researches, benchmarks and datasets in these African languages, thereby improving reproducibility and sharing of existing research and their results. In this paper, we introduce Lanfrica, a novel, on-going framework that employs a participatory approach to documenting researches, projects, benchmarks and dataset on African languages.", "pdf_url": "https://arxiv.org/pdf/2008.07302", "subject": "Computers and Society (cs.CY)"},
{"title": "Self-Supervised Learning for Monocular Depth Estimation from Aerial Imagery", "author": "Max Hermann, Boitumelo Ruf, Martin Weinmann, Stefan Hinz", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Supervised learning based methods for monocular depth estimation usually require large amounts of extensively annotated training data. In the case of aerial imagery, this ground truth is particularly difficult to acquire. Therefore, in this paper, we present a method for self-supervised learning for monocular depth estimation from aerial imagery that does not require annotated training data. For this, we only use an image sequence from a single moving camera and learn to simultaneously estimate depth and pose information. By sharing the weights between pose and depth estimation, we achieve a relatively small model, which favors real-time application. We evaluate our approach on three diverse datasets and compare the results to conventional methods that estimate depth maps based on multi-view geometry. We achieve an accuracy {\\delta}1.25 of up to 93.5 %. In addition, we have paid particular attention to the generalization of a trained model to unknown data and the self-improving capabilities of our approach. We conclude that, even though the results of monocular depth estimation are inferior to those achieved by conventional methods, they are well suited to provide a good initialization for methods that rely on image matching or to provide estimates in regions where image matching fails, e.g. occluded or texture-less regions.", "pdf_url": "https://arxiv.org/pdf/2008.07246", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "CARGO : Context Augmented Critical Region Offload for Network-bound datacenter Workloads", "author": "Siddharth Rai, Trevor E. Carlson", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Network bound applications, like a database server executing OLTP queries or a caching server storing objects for a dynamic web applications, are essential services that consumers and businesses use daily. These services run on a large datacenters and are required to meet predefined Service Level Objectives (SLO), or latency targets, with high probability. Thus, efficient datacenter applications should optimize their execution in terms of power and performance. However, to support large scale data storage, these workloads make heavy use of pointer connected data structures (e.g., hash table, large fan-out tree, trie) and exhibit poor instruction and memory level parallelism. Our experiments show that due to long memory access latency, these workloads occupy processor resources (e.g., ROB entries, RS buffers, LS queue entries etc.) for a prolonged period of time that delay the processing of subsequent requests. Delayed execution not only increases request processing latency, but also severely effects an application throughput and power-efficiency. To overcome this limitation, we present CARGO, a novel mechanism to overlap queuing latency and request processing by executing select instructions on an application critical path at the network interface card (NIC) while requests wait for processor resources to become available. Our mechanism dynamically identifies the critical instructions and includes the register state needed to compute the long latency memory accesses. This context-augmented critical region is often executed at the NIC well before execution begins at the core, effectively prefetching the data ahead of time. Across a variety of interactive datacenter applications, our proposal improves latency, throughput, and power efficiency by 2.7X, 2.7X, and 1.5X, respectively, while incurring a modest amount storage overhead.", "pdf_url": "https://arxiv.org/pdf/2008.07171", "subject": "Hardware Architecture (cs.AR)"},
{"title": "OCEAN: Online Task Inference for Compositional Tasks with Context Adaptation", "author": "Hongyu Ren, Yuke Zhu, Jure Leskovec, Anima Anandkumar, Animesh Garg", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Real-world tasks often exhibit a compositional structure that contains a sequence of simpler sub-tasks. For instance, opening a door requires reaching, grasping, rotating, and pulling the door knob. Such compositional tasks require an agent to reason about the sub-task at hand while orchestrating global behavior accordingly. This can be cast as an online task inference problem, where the current task identity, represented by a context variable, is estimated from the agent's past experiences with probabilistic inference. Previous approaches have employed simple latent distributions, e.g., Gaussian, to model a single context for the entire task. However, this formulation lacks the expressiveness to capture the composition and transition of the sub-tasks. We propose a variational inference framework OCEAN to perform online task inference for compositional tasks. OCEAN models global and local context variables in a joint latent space, where the global variables represent a mixture of sub-tasks required for the task, while the local variables capture the transitions between the sub-tasks. Our framework supports flexible latent distributions based on prior knowledge of the task structure and can be trained in an unsupervised manner. Experimental results show that OCEAN provides more effective task inference with sequential context adaptation and thus leads to a performance boost on complex, multi-stage tasks.", "pdf_url": "https://arxiv.org/pdf/2008.07087", "subject": "Machine Learning (cs.LG)"},
{"title": "Time-Supervised Primary Object Segmentation", "author": "Yanchao Yang, Brian Lai, Stefano Soatto", "pub_date": "Submitted on 16 Aug 2020", "abstract": "We describe an unsupervised method to detect and segment portions of live scenes that, at some point in time, are seen moving as a coherent whole, which we refer to as primary objects. Our method first segments motions by minimizing the mutual information between partitions of the image domain, which bootstraps a static object detection model that takes a single image as input. The two models are mutually reinforced within a feedback loop, enabling extrapolation to previously unseen classes of objects. Our method requires video for training, but can be used on either static images or videos at inference time. As the volume of our training sets grows, more and more objects are seen moving, thus turning our method into unsupervised (or time-supervised) training to segment primary objects. The resulting system outperforms the state-of-the-art in both video object segmentation and salient object detection benchmarks, even when compared to methods that use explicit manual annotation.", "pdf_url": "https://arxiv.org/pdf/2008.07012", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Object-Aware Multi-Branch Relation Networks for Spatio-Temporal Video Grounding", "author": "Zhu Zhang, Zhou Zhao, Zhijie Lin, Baoxing Huai, Nicholas Jing Yuan", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Spatio-temporal video grounding aims to retrieve the spatio-temporal tube of a queried object according to the given sentence. Currently, most existing grounding methods are restricted to well-aligned segment-sentence pairs. In this paper, we explore spatio-temporal video grounding on unaligned data and multi-form sentences. This challenging task requires to capture critical object relations to identify the queried target. However, existing approaches cannot distinguish notable objects and remain in ineffective relation modeling between unnecessary objects. Thus, we propose a novel object-aware multi-branch relation network for object-aware relation discovery. Concretely, we first devise multiple branches to develop object-aware region modeling, where each branch focuses on a crucial object mentioned in the sentence. We then propose multi-branch relation reasoning to capture critical object relationships between the main branch and auxiliary branches. Moreover, we apply a diversity loss to make each branch only pay attention to its corresponding object and boost multi-branch learning. The extensive experiments show the effectiveness of our proposed method.", "pdf_url": "https://arxiv.org/pdf/2008.06941", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Dependability Evaluation of Middleware Technology for Large-scale Distributed Caching", "author": "Domenico Cotroneo, Roberto Natella, Stefano Rosiello", "pub_date": "Submitted on 16 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "Distributed caching systems (e.g., Memcached) are widely used by service providers to satisfy accesses by millions of concurrent clients. Given their large-scale, modern distributed systems rely on a middleware layer to manage caching nodes, to make applications easier to develop, and to apply load balancing and replication strategies. In this work, we performed a dependability evaluation of three popular middleware platforms, namely Twemproxy by Twitter, Mcrouter by Facebook, and Dynomite by Netflix, to assess availability and performance under faults, including failures of Memcached nodes and congestion due to unbalanced workloads and network link bandwidth bottlenecks. We point out the different availability and performance trade-offs achieved by the three platforms, and scenarios in which few faulty components cause cascading failures of the whole distributed system.", "pdf_url": "https://arxiv.org/pdf/2008.06943", "subject": "Software Engineering (cs.SE)"},
{"title": "Spectrum-Based Log Diagnosis", "author": "Carl Martin Rosenberg, Leon Moonen", "pub_date": "Submitted on 16 Aug 2020", "abstract": "We present and evaluate Spectrum-Based Log Diagnosis (SBLD), a method to help developers quickly diagnose problems found in complex integration and deployment runs. Inspired by Spectrum-Based Fault Localization, SBLD leverages the differences in event occurrences between logs for failing and passing runs, to highlight events that are stronger associated with failing runs. Using data provided by our industrial partner, we empirically investigate the following questions: (i) How well does SBLD reduce the effort needed to identify all failure-relevant events in the log for a failing run? (ii) How is the performance of SBLD affected by available data? (iii) How does SBLD compare to searching for simple textual patterns that often occur in failure-relevant events? We answer (i) and (ii) using summary statistics and heatmap visualizations, and for (iii) we compare three configurations of SBLD (with resp. minimum, median and maximum data) against a textual search using Wilcoxon signed-rank tests and the Vargha-Delaney measure of stochastic superiority. Our evaluation shows that (i) SBLD achieves a significant effort reduction for the dataset used, (ii) SBLD benefits from additional logs for passing runs in general, and it benefits from additional logs for failing runs when there is a proportional amount of logs for passing runs in the data. Finally, (iii) SBLD and textual search are roughly equally effective at effort-reduction, while textual search has a slightly better recall. We investigate the cause, and discuss how it is due to the characteristics of a specific part of our data. We conclude that SBLD shows promise as a method for diagnosing failing runs, that its performance is positively affected by additional data, but that it does not outperform textual search on the dataset considered. Future work includes investigating SBLD's generalizability on additional datasets.", "pdf_url": "https://arxiv.org/pdf/2008.06948", "subject": "Software Engineering (cs.SE)"},
{"title": "A Functional Perspective on Learning Symmetric Functions with Neural Networks", "author": "Aaron Zweig, Joan Bruna", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Symmetric functions, which take as input an unordered, fixed-size set, are known to be universally representable by neural networks that enforce permutation invariance. However, these architectures only give guarantees for fixed input sizes, yet in many practical scenarios, such as particle physics, a relevant notion of generalization should include varying the input size. In this paper, we embed symmetric functions (of any size) as functions over probability measures, and study the ability of neural networks defined over this space of measures to represent and learn in that space. By focusing on shallow architectures, we establish approximation and generalization bounds under different choices of regularization (such as RKHS and variation norms), that capture a hierarchy of functional spaces with increasing amount of non-linear learning. The resulting models can be learnt efficiently and enjoy generalization guarantees that extend across input sizes, as we verify empirically.", "pdf_url": "https://arxiv.org/pdf/2008.06952", "subject": "Machine Learning (cs.LG)"},
{"title": "Semi-Analytical Solution for a Multi-Objective TEAM Benchmark Problem", "author": "Pavel Karban, David P\u00e1nek, Tam\u00e1s Orosz, Ivo Dole\u017eel", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Benchmarking is essential for testing new numerical analysis codes. Their solution is crucial both for testing the partial differential equation solvers and both for the optimization methods. Especially, nature-inspired optimization algorithm-based solvers, where is an important study is to use benchmark functions to test how the new algorithm may perform, in comparison with other algorithms or fine-tune the optimizer parameters. This paper proposes a novel semi-analytical solution of the multi-objective T.E.A.M benchmark problem. The goal of the benchmark problem is to optimize the layout of a coil and provide a uniform magnetic field in the given region. The proposed methodology was realized in the open-source robust design optimization framework \u0100rtap, and the precision of the solution is compared with the result of a fully hp-adaptive numerical solver: Agros-suite. The coil layout optimization was performed by derivative-free non-linear methods and the NSGA-II algorithm.", "pdf_url": "https://arxiv.org/pdf/2008.06954", "subject": "Numerical Analysis (math.NA)"},
{"title": "Improving Services Offered by Internet Providers by Analyzing Online Reviews using Text Analytics", "author": "Suchithra Rajendran, John Fennewald", "pub_date": "Submitted on 16 Aug 2020", "abstract": "With the proliferation of digital infrastructure, there is a plethora of demand for internet services, which makes the wireless communications industry highly competitive. Thus internet service providers (ISPs) must ensure that their efforts are targeted towards attracting and retaining customers to ensure continued growth. As Web 2.0 has gained traction and more tools have become available, customers in recent times are equipped to make well-informed decisions, specifically due to the colossal information available in online reviews. ISPs can use this information to better understand the views of the customers about their products and services. The goal of this paper is to identify the current strengths, weaknesses, opportunities, and threats (SWOT) of each ISP by exploring consumer reviews using text analytics. The proposed approach consists of four different stages: bigram and trigram analyses, topic identification, SWOT analysis and Root Cause Analysis (RCA). For each ISP, we first categorize online reviews into positive and negative based on customer ratings and then leverage text analytic tools to determine the most frequently used and co-occurring words in each categorization of reviews. Subsequently, looking at the positive and negative topics in each ISP, we conduct the SWOT analysis as well as the RCA to help companies identify the internal and external factors impacting customer satisfaction. We use a case study to illustrate the proposed approach. The proposed managerial insights that are derived from the results can act as a decision support tool for ISPs to offer better products and services for their customers.", "pdf_url": "https://arxiv.org/pdf/2008.06957", "subject": "Computers and Society (cs.CY)"},
{"title": "Image Stylization for Robust Features", "author": "Iaroslav Melekhov, Gabriel J. Brostow, Juho Kannala, Daniyar Turmukhambetov", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Local features that are robust to both viewpoint and appearance changes are crucial for many computer vision tasks. In this work we investigate if photorealistic image stylization improves robustness of local features to not only day-night, but also weather and season variations. We show that image stylization in addition to color augmentation is a powerful method of learning robust features. We evaluate learned features on visual localization benchmarks, outperforming state of the art baseline models despite training without ground-truth 3D correspondences using synthetic homographies only. We use trained feature networks to compete in Long-Term Visual Localization and Map-based Localization for Autonomous Driving challenges achieving competitive scores.", "pdf_url": "https://arxiv.org/pdf/2008.06959", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Do Not Disturb Me: Person Re-identification Under the Interference of Other Pedestrians", "author": "Shizhen Zhao, Changxin Gao, Jun Zhang, Hao Cheng, Chuchu Han, Xinyang Jiang, Xiaowei Guo, Wei-Shi Zheng, Nong Sang, Xing Sun", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In the conventional person Re-ID setting, it is widely assumed that cropped person images are for each individual. However, in a crowded scene, off-shelf-detectors may generate bounding boxes involving multiple people, where the large proportion of background pedestrians or human occlusion exists. The representation extracted from such cropped images, which contain both the target and the interference pedestrians, might include distractive information. This will lead to wrong retrieval results. To address this problem, this paper presents a novel deep network termed Pedestrian-Interference Suppression Network (PISNet). PISNet leverages a Query-Guided Attention Block (QGAB) to enhance the feature of the target in the gallery, under the guidance of the query. Furthermore, the involving Guidance Reversed Attention Module and the Multi-Person Separation Loss promote QGAB to suppress the interference of other pedestrians. Our method is evaluated on two new pedestrian-interference datasets and the results show that the proposed method performs favorably against existing Re-ID methods.", "pdf_url": "https://arxiv.org/pdf/2008.06963", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Mesorasi: Architecture Support for Point Cloud Analytics via Delayed-Aggregation", "author": "Yu Feng, Boyuan Tian, Tiancheng Xu, Paul Whatmough, Yuhao Zhu", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Point cloud analytics is poised to become a key workload on battery-powered embedded and mobile platforms in a wide range of emerging application domains, such as autonomous driving, robotics, and augmented reality, where efficiency is paramount. This paper proposes Mesorasi, an algorithm-architecture co-designed system that simultaneously improves the performance and energy efficiency of point cloud analytics while retaining its accuracy. Our extensive characterizations of state-of-the-art point cloud algorithms show that, while structurally reminiscent of convolutional neural networks (CNNs), point cloud algorithms exhibit inherent compute and memory inefficiencies due to the unique characteristics of point cloud data. We propose delayed-aggregation, a new algorithmic primitive for building efficient point cloud algorithms. Delayed-aggregation hides the performance bottlenecks and reduces the compute and memory redundancies by exploiting the approximately distributive property of key operations in point cloud algorithms. Delayed-aggregation let point cloud algorithms achieve 1.6x speedup and 51.1% energy reduction on a mobile GPU while retaining the accuracy (-0.9% loss to 1.2% gains). To maximize the algorithmic benefits, we propose minor extensions to contemporary CNN accelerators, which can be integrated into a mobile Systems-on-a-Chip (SoC) without modifying other SoC components. With additional hardware support, Mesorasi achieves up to 3.6x speedup.", "pdf_url": "https://arxiv.org/pdf/2008.06967", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "An adaptive synchronization approach for weights of deep reinforcement learning", "author": "S. Amirreza Badran, Mansoor Rezghi", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Deep Q-Networks (DQN) is one of the most well-known methods of deep reinforcement learning, which uses deep learning to approximate the action-value function. Solving numerous Deep reinforcement learning challenges such as moving targets problem and the correlation between samples are the main advantages of this model. Although there have been various extensions of DQN in recent years, they all use a similar method to DQN to overcome the problem of moving targets. Despite the advantages mentioned, synchronizing the network weight in a fixed step size, independent of the agent's behavior, may in some cases cause the loss of some properly learned networks. These lost networks may lead to states with more rewards, hence better samples stored in the replay memory for future training. In this paper, we address this problem from the DQN family and provide an adaptive approach for the synchronization of the neural weights used in DQN. In this method, the synchronization of weights is done based on the recent behavior of the agent, which is measured by a criterion at the end of the intervals. To test this method, we adjusted the DQN and rainbow methods with the proposed adaptive synchronization method. We compared these adjusted methods with their standard form on well-known games, which results confirm the quality of our synchronization methods.", "pdf_url": "https://arxiv.org/pdf/2008.06973", "subject": "Machine Learning (cs.LG)"},
{"title": "OpenFraming: We brought the ML; you bring the data. Interact with your data and discover its frames", "author": "Alyssa Smith, David Assefa Tofu, Mona Jalal, Edward Edberg Halim, Yimeng Sun, Vidya Akavoor, Margrit Betke, Prakash Ishwar, Lei Guo, Derry Wijaya", "pub_date": "Submitted on 16 Aug 2020", "abstract": "When journalists cover a news story, they can cover the story from multiple angles or perspectives. A news article written about COVID-19 for example, might focus on personal preventative actions such as mask-wearing, while another might focus on COVID-19's impact on the economy. These perspectives are called \"frames,\" which when used may influence public perception and opinion of the issue. We introduce a Web-based system for analyzing and classifying frames in text documents. Our goal is to make effective tools for automatic frame discovery and labeling based on topic modeling and deep learning widely accessible to researchers from a diverse array of disciplines. To this end, we provide both state-of-the-art pre-trained frame classification models on various issues as well as a user-friendly pipeline for training novel classification models on user-provided corpora. Researchers can submit their documents and obtain frames of the documents. The degree of user involvement is flexible: they can run models that have been pre-trained on select issues; submit labeled documents and train a new model for frame classification; or submit unlabeled documents and obtain potential frames of the documents. The code making up our system is also open-sourced and well-documented, making the system transparent and expandable. The system is available on-line at and via our GitHub page .", "pdf_url": "https://arxiv.org/pdf/2008.06974", "subject": "Computation and Language (cs.CL)"},
{"title": "Applications of Robots for COVID-19 Response", "author": "Robin R. Murphy, Vignesh Babu Manjunath Gandudi, Justin Adams", "pub_date": "Submitted on 16 Aug 2020", "abstract": "This paper reviews 262 reports appearing between March 27 and July 4, 2020, in the press, social media, and scientific literature describing 203 instances of actual use of 104 different models of ground and aerial robots for the COVID19 response. The reports are organized by stakeholders and work domain into a novel taxonomy of six application categories, reflecting major differences in work envelope, adoption strategy, and human-robot interaction constraints. Each application category is further divided into a total of 30 subcategories based on differences in mission. The largest number of reported instances were for public safety (74 out of 203) and clinical care (46), though robots for quality of life (27), continuity of work and education (22), laboratory and supply chain automation (21), and non-clinical care (13) were notable. Ground robots were used more frequently (119) than aerial systems (84), but unlike ground robots, aerial applications appeared to take advantage of existing general purpose platforms that were used for multiple applications and missions. Of the 104 models of robots, 82 were determined to be commercially available or already existed as a prototype, 11 were modifications to existing robots, 11 were built from scratch. Teleoperation dominated the control style (105 instances), with the majority of those applications intentionally providing remote presence and thus not amenable to full autonomy in the future. Automation accounted for 74 instances and taskable agency forms of autonomy, 24. The data suggests areas for further research in autonomy, human-robot interaction, and adaptability.", "pdf_url": "https://arxiv.org/pdf/2008.06976", "subject": "Robotics (cs.RO)"},
{"title": "Prediction of Homicides in Urban Centers: A Machine Learning Approach", "author": "Jos\u00e9 Ribeiro, Lair Meneses, Denis Costa, Wando Miranda, Ronnie Alves", "pub_date": "Submitted on 16 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Relevant research has been standing out in the computing community aiming to develop computational models capable of predicting occurrence of crimes, analyzing contexts of crimes, extracting profiles of individuals linked to crimes, and analyzing crimes according to time. This, due to the social impact and also the complex origin of the data, thus showing itself as an interesting computational challenge. This research presents a computational model for the prediction of homicide crimes, based on tabular data of crimes registered in the city of Bel\u00e9m - Par\u00e1, Brazil. Statistical tests were performed with 8 different classification methods, both Random Forest, Logistic Regression, and Neural Network presented best results, AUC ~ 0.8. Results considered as a baseline for the proposed problem.", "pdf_url": "https://arxiv.org/pdf/2008.06979", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Bowtie Networks: Generative Modeling for Joint Few-Shot Recognition and Novel-View Synthesis", "author": "Zhipeng Bao, Yu-Xiong Wang, Martial Hebert", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Generative modeling has recently shown great promise in computer vision, but its success is often limited to separate tasks. In this paper, motivated by multi-task learning of shareable feature representations, we consider a novel problem of learning a shared generative model across various tasks. We instantiate it on the illustrative dual-task of joint few-shot recognition and novel-view synthesis: given only one or few images of a novel object from arbitrary views with only category annotation, we aim to simultaneously learn an object classifier and generate images of the object from new viewpoints. To this end, we propose bowtie networks that jointly learn 3D geometric and semantic representations with feedback in the loop. Experimental evaluation on challenging fine-grained recognition datasets demonstrates that our synthesized images are realistic from multiple viewpoints and significantly improve recognition performance as ways of data augmentation, especially in the low-data regime. We further show that our approach is flexible and can be easily extended to incorporate other tasks, such as style guided synthesis.", "pdf_url": "https://arxiv.org/pdf/2008.06981", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Self-supervised GAN for Unsupervised Few-shot Object Recognition", "author": "Khoi Nguyen, Sinisa Todorovic", "pub_date": "Submitted on 16 Aug 2020", "abstract": "This paper addresses unsupervised few-shot object recognition, where all training images are unlabeled, and test images are divided into queries and a few labeled support images per object class of interest. The training and test images do not share object classes. We extend the vanilla GAN with two loss functions, both aimed at self-supervised learning. The first is a reconstruction loss that enforces the discriminator to reconstruct the probabilistically sampled latent code which has been used for generating the ``fake'' image. The second is a triplet loss that enforces the discriminator to output image encodings that are closer for more similar images. Evaluation, comparisons, and detailed ablation studies are done in the context of few-shot classification. Our approach significantly outperforms the state of the art on the Mini-Imagenet and Tiered-Imagenet datasets.", "pdf_url": "https://arxiv.org/pdf/2008.06982", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "False Detection (Positives and Negatives) in Object Detection", "author": "Subrata Goswami", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Object detection is a very important function of visual perception systems. Since the early days of classical object detection based on HOG to modern deep learning based detectors, object detection has improved in accuracy. Two stage detectors usually have higher accuracy than single stage ones. Both types of detectors use some form of quantization of the search space of rectangular regions of image. There are far more of the quantized elements than true objects. The way these bounding boxes are filtered out possibly results in the false positive and false negatives. This empirical experimental study explores ways of reducing false positives and negatives with labelled data.. In the process also discovered insufficient labelling in Openimage 2019 Object Detection dataset.", "pdf_url": "https://arxiv.org/pdf/2008.06986", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Is Face Recognition Sexist? No, Gendered Hairstyles and Biology Are", "author": "V\u00edtor Albiero, Kevin W. Bowyer", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Recent news articles have accused face recognition of being \"biased\", \"sexist\" or \"racist\". There is consensus in the research literature that face recognition accuracy is lower for females, who often have both a higher false match rate and a higher false non-match rate. However, there is little published research aimed at identifying the cause of lower accuracy for females. For instance, the 2019 Face Recognition Vendor Test that documents lower female accuracy across a broad range of algorithms and datasets also lists \"Analyze cause and effect\" under the heading \"What we did not do\". We present the first experimental analysis to identify major causes of lower face recognition accuracy for females on datasets where previous research has observed this result. Controlling for equal amount of visible face in the test images reverses the apparent higher false non-match rate for females. Also, principal component analysis indicates that images of two different females are inherently more similar than of two different males, potentially accounting for a difference in false match rates.", "pdf_url": "https://arxiv.org/pdf/2008.06989", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "In-situ Workflow Auto-tuning via Combining Performance Models of Component Applications", "author": "Tong Shu, Yanfei Guo, Justin Wozniak, Xiaoning Ding, Ian Foster, Tahsin Kurc", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In-situ parallel workflows couple multiple component applications, such as simulation and analysis, via streaming data transfer. in order to avoid data exchange via shared file systems. Such workflows are challenging to configure for optimal performance due to the large space of possible configurations. Expert experience is rarely sufficient to identify optimal configurations, and existing empirical auto-tuning approaches are inefficient due to the high cost of obtaining training data for machine learning models. It is also infeasible to optimize individual components independently, due to component interactions. We propose here a new auto-tuning method, Component-based Ensemble Active Learning (CEAL), that combines machine learning techniques with knowledge of in-situ workflow structure to enable automated workflow configuration with a limited number of performance measurements.", "pdf_url": "https://arxiv.org/pdf/2008.06991", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Optimum M-PAM Transmission for Massive MIMO Systems with Channel Uncertainty", "author": "Ayed M. Alrashdi, Abla Kammoun, Ali H. Muqaibel, Tareq Y. Al-Naffouri", "pub_date": "Submitted on 16 Aug 2020", "abstract": "This paper considers the problem of symbol detection in massive multiple-input multiple-output (MIMO) wireless communication systems. We consider hard-thresholding preceeded by two variants of the regularized least squares (RLS) decoder; namely the unconstrained RLS and the RLS with box constraint. For all schemes, we focus on the evaluation of the mean squared error (MSE) and the symbol error probability (SEP) for M-ary pulse amplitude modulation (M-PAM) symbols transmitted over a massive MIMO system when the channel is estimated using linear minimum mean squared error (LMMSE) estimator. Under such circumstances, the channel estimation error is Gaussian which allows for the use of the convex Gaussian min-max theorem (CGMT) to derive asymptotic approximations for the MSE and SER when the system dimensions and the coherence duration grow large with the same pace. The obtained expressions are then leveraged to derive the optimal power distribution between pilot and data under a total transmit energy constraint. In addition, we derive an asymptotic approximation of the goodput for all schemes which is then used to jointly optimize the number of training symbols and their associated power. Numerical results are presented to support the accuracy of the theoretical results.", "pdf_url": "https://arxiv.org/pdf/2008.06993", "subject": "Information Theory (cs.IT)"},
{"title": "Efficient Knowledge Graph Validation via Cross-Graph Representation Learning", "author": "Yaqing Wang, Fenglong Ma, Jing Gao", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Recent advances in information extraction have motivated the automatic construction of huge Knowledge Graphs (KGs) by mining from large-scale text corpus. However, noisy facts are unavoidably introduced into KGs that could be caused by automatic extraction. To validate the correctness of facts (i.e., triplets) inside a KG, one possible approach is to map the triplets into vector representations by capturing the semantic meanings of facts. Although many representation learning approaches have been developed for knowledge graphs, these methods are not effective for validation. They usually assume that facts are correct, and thus may overfit noisy facts and fail to detect such facts. Towards effective KG validation, we propose to leverage an external human-curated KG as auxiliary information source to help detect the errors in a target KG. The external KG is built upon human-curated knowledge repositories and tends to have high precision. On the other hand, although the target KG built by information extraction from texts has low precision, it can cover new or domain-specific facts that are not in any human-curated repositories. To tackle this challenging task, we propose a cross-graph representation learning framework, i.e., CrossVal, which can leverage an external KG to validate the facts in the target KG efficiently. This is achieved by embedding triplets based on their semantic meanings, drawing cross-KG negative samples and estimating a confidence score for each triplet based on its degree of correctness. We evaluate the proposed framework on datasets across different domains. Experimental results show that the proposed framework achieves the best performance compared with the state-of-the-art methods on large-scale KGs.", "pdf_url": "https://arxiv.org/pdf/2008.06995", "subject": "Computation and Language (cs.CL)"},
{"title": "Learning Disentangled Expression Representations from Facial Images", "author": "Marah Halawa, Manuel W\u00f6llhaf, Eduardo Vellasques, Urko S\u00e1nchez Sanz, Olaf Hellwich", "pub_date": "Submitted on 16 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "Face images are subject to many different factors of variation, especially in unconstrained in-the-wild scenarios. For most tasks involving such images, e.g. expression recognition from video streams, having enough labeled data is prohibitively expensive. One common strategy to tackle such a problem is to learn disentangled representations for the different factors of variation of the observed data using adversarial learning. In this paper, we use a formulation of the adversarial loss to learn disentangled representations for face images. The used model facilitates learning on single-task datasets and improves the state-of-the-art in expression recognition with an accuracy of60.53%on the AffectNetdataset, without using any additional data.", "pdf_url": "https://arxiv.org/pdf/2008.07001", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Towards Faithful and Meaningful Interpretable Representations", "author": "Kacper Sokol, Peter Flach", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Interpretable representations are the backbone of many black-box explainers. They translate the low-level data representation necessary for good predictive performance into high-level human-intelligible concepts used to convey the explanation. Notably, the explanation type and its cognitive complexity are directly controlled by the interpretable representation, allowing to target a particular audience and use case. However, many explainers that rely on interpretable representations overlook their merit and fall back on default solutions, which may introduce implicit assumptions, thereby degrading the explanatory power of such techniques. To address this problem, we study properties of interpretable representations that encode presence and absence of human-comprehensible concepts. We show how they are operationalised for tabular, image and text data, discussing their strengths and weaknesses. Finally, we analyse their explanatory properties in the context of tabular data, where a linear model is used to quantify the importance of interpretable concepts.", "pdf_url": "https://arxiv.org/pdf/2008.07007", "subject": "Machine Learning (cs.LG)"},
{"title": "InstanceMotSeg: Real-time Instance Motion Segmentation for Autonomous Driving", "author": "Eslam Mohamed, Mahmoud Ewaisha, Mennatullah Siam, Hazem Rashed, Senthil Yogamani, Ahmad El-Sallab", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Moving object segmentation is a crucial task for autonomous vehicles as it can be used to segment objects in a class agnostic manner based on its motion cues. It will enable the detection of objects unseen during training (e.g., moose or a construction truck) generically based on their motion. Although pixel-wise motion segmentation has been studied in the literature, it is not dealt with at instance level, which would help separate connected segments of moving objects leading to better trajectory planning. In this paper, we proposed a motion-based instance segmentation task and created a new annotated dataset based on KITTI, which will be released publicly. We make use of the YOLACT model to solve the instance motion segmentation network by feeding inflow and image as input and instance motion masks as output. We extend it to a multi-task model that learns semantic and motion instance segmentation in a computationally efficient manner. Our model is based on sharing a prototype generation network between the two tasks and learning separate prototype coefficients per task. To obtain real-time performance, we study different efficient encoders and obtain 39 fps on a Titan Xp GPU using MobileNetV2 with an improvement of 10% mAP relative to the baseline. A video demonstration of our work is available in .", "pdf_url": "https://arxiv.org/pdf/2008.07008", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Computer-Generated Music for Tabletop Role-Playing Games", "author": "Lucas N. Ferreira, Levi H. S. Lelis, Jim Whitehead", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In this paper we present Bardo Composer, a system to generate background music for tabletop role-playing games. Bardo Composer uses a speech recognition system to translate player speech into text, which is classified according to a model of emotion. Bardo Composer then uses Stochastic Bi-Objective Beam Search, a variant of Stochastic Beam Search that we introduce in this paper, with a neural model to generate musical pieces conveying the desired emotion. We performed a user study with 116 participants to evaluate whether people are able to correctly identify the emotion conveyed in the pieces generated by the system. In our study we used pieces generated for Call of the Wild, a Dungeons and Dragons campaign available on YouTube. Our results show that human subjects could correctly identify the emotion of the generated music pieces as accurately as they were able to identify the emotion of pieces written by humans.", "pdf_url": "https://arxiv.org/pdf/2008.07009", "subject": "Sound (cs.SD)"},
{"title": "A Novel Traffic Rate Measurement Algorithm for QoE-Aware Video Admission Control", "author": "Qahhar Muhammad Qadir, Alexander A.Kist, Zhongwei Zhang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "With the inevitable dominance of video traffic on the Internet, providing perceptually good video quality is becoming a challenging task. This is partly due to the bursty nature of video traffic, changing network conditions and limitations of network transport protocols. This growth of video traffic has made Quality of Experience (QoE) of the end user the focus of the research community. In contrast, Internet service providers are concerned about maximizing revenue by accepting as many sessions as possible, as long as customers remain satisfied. However, there is still no entirely satisfactory admission algorithm for flows with variable rate. The trade-off between the number of sessions and perceived QoE can be optimized by exploiting the bursty nature of video traffic. This paper proposes a novel algorithm to determine the upper limit of the aggregate video rate that can exceed the available bandwidth without degrading the QoE of accepted video sessions. A parameter $\\beta$ that defines the exceedable limit is defined. The proposed algorithm results in accepting more sessions without compromising the QoE of on-going video sessions. Thus it contributes to the optimization of the QoE-Session trade-off in support of the expected growth of video traffic on the Internet.", "pdf_url": "https://arxiv.org/pdf/2008.07011", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Adversarial Concurrent Training: Optimizing Robustness and Accuracy Trade-off of Deep Neural Networks", "author": "Elahe Arani, Fahad Sarfraz, Bahram Zonooz", "pub_date": "Submitted on 16 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "Adversarial training has been proven to be an effective technique for improving the adversarial robustness of models. However, there seems to be an inherent trade-off between optimizing the model for accuracy and robustness. To this end, we propose Adversarial Concurrent Training (ACT), which employs adversarial training in a collaborative learning framework whereby we train a robust model in conjunction with a natural model in a minimax game. ACT encourages the two models to align their feature space by using the task-specific decision boundaries and explore the input space more broadly. Furthermore, the natural model acts as a regularizer, enforcing priors on features that the robust model should learn. Our analyses on the behavior of the models show that ACT leads to a robust model with lower model complexity, higher information compression in the learned representations, and high posterior entropy solutions indicative of convergence to a flatter minima. We demonstrate the effectiveness of the proposed approach across different datasets and network architectures. On ImageNet, ACT achieves 68.20% standard accuracy and 44.29% robustness accuracy under a 100-iteration untargeted attack, improving upon the standard adversarial training method's 65.70% standard accuracy and 42.36% robustness.", "pdf_url": "https://arxiv.org/pdf/2008.07015", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "AutoPose: Searching Multi-Scale Branch Aggregation for Pose Estimation", "author": "Xinyu Gong, Wuyang Chen, Yifan Jiang, Ye Yuan, Xianming Liu, Qian Zhang, Yuan Li, Zhangyang Wang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "We present AutoPose, a novel neural architecture search(NAS) framework that is capable of automatically discovering multiple parallel branches of cross-scale connections towards accurate and high-resolution 2D human pose estimation. Recently, high-performance hand-crafted convolutional networks for pose estimation show growing demands on multi-scale fusion and high-resolution representations. However, current NAS works exhibit limited flexibility on scale searching, they dominantly adopt simplified search spaces of single-branch architectures. Such simplification limits the fusion of information at different scales and fails to maintain high-resolution representations. The presentedAutoPose framework is able to search for multi-branch scales and network depth, in addition to the cell-level microstructure. Motivated by the search space, a novel bi-level optimization method is presented, where the network-level architecture is searched via reinforcement learning, and the cell-level search is conducted by the gradient-based method. Within 2.5 GPU days, AutoPose is able to find very competitive architectures on the MS COCO dataset, that are also transferable to the MPII dataset. Our code is available at .", "pdf_url": "https://arxiv.org/pdf/2008.07018", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Enforcing Safety at Runtime for Systems with Disturbances", "author": "Matthew Abate, Samuel Coogan", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Safety for control systems is often posed as an invariance constraint; the system is said to be safe if state trajectories avoid some unsafe region of the statespace for all time. An assured controller is one that enforces safety online by filtering a desired control input at runtime, and control barrier functions (CBFs) provide an assured controller that renders a safe subset of the state-space forward invariant. Recent extensions propose CBF-based assured controllers that allow the system to leave a known safe set so long as a given backup control strategy eventually returns to the safe set, however, these methods have yet to be extended to consider systems subjected to unknown disturbance inputs. In this work, we present a problem formulation for CBF-based runtime assurance for systems with disturbances, and controllers which solve this problem must, in some way, incorporate the online computation of reachable sets. In general, computing reachable sets in the presence of disturbances is computationally costly and cannot be directly incorporated in a CBF framework. To that end, we present a particular solution to the problem, whereby reachable sets are approximated via the mixed-monotonicity property. Efficient algorithms exist for overapproximating reachable sets for mixed-monotone systems with hyperrectangles, and we show that such approximations are suitable for incorporating into a CBF-based runtime assurance framework.", "pdf_url": "https://arxiv.org/pdf/2008.07019", "subject": "Systems and Control (eess.SY)"},
{"title": "Selection on $X_1 + X_1 + \\cdots X_m$ via Cartesian product tree", "author": "Patrick Kreitzberg, Kyle Lucke, Jake Pennington, Oliver Serang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Selection on the Cartesian product is a classic problem in computer science. Recently, an optimal algorithm for selection on $X+Y$, based on soft heaps, was introduced. By combining this approach with layer-ordered heaps (LOHs), an algorithm using a balanced binary tree of $X+Y$ selections was proposed to perform $k$-selection on $X_1+X_2+\\cdots+X_m$ in $o(n\\cdot m + k\\cdot m)$, where $X_i$ have length $n$. Here, that $o(n\\cdot m + k\\cdot m)$ algorithm is combined with a novel, optimal LOH-based algorithm for selection on $X+Y$ (without a soft heap). Performance of algorithms for selection on $X_1+X_2+\\cdots+X_m$ are compared empirically, demonstrating the benefit of the algorithm proposed here.", "pdf_url": "https://arxiv.org/pdf/2008.07023", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "LfEdNet: A Task-based Day-ahead Load Forecasting Model for Stochastic Economic Dispatch", "author": "Jiayu Han, Lei Yan, Zuyi Li", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Load forecasting is one of the most important and studied topics in modern power systems. Most of the existing researches on day-ahead load forecasting try to build a good model to improve the forecasting accuracy. The forecasted load is then used as the input to generation scheduling with the ultimate goal of minimizing the cost of generation schedules. However, existing day-ahead load forecasting models do not consider this ultimate goal at the training/forecasting stage. This paper proposes a task-based day-ahead load forecasting model labeled as LfEdNet that combines two individual layers in one model, including a load forecasting layer based on deep neural network (Lf layer) and a day-ahead stochastic economic dispatch (SED) layer (Ed layer). The training of LfEdNet aims to minimize the cost of the day-ahead SED in the Ed layer by updating the parameters of the Lf layer. Sequential quadratic programming (SQP) is used to solve the day-ahead SED in the Ed layer. The test results demonstrate that the forecasted results produced by LfEdNet can lead to lower cost of day-ahead SED while maintaining a relatively high forecasting accuracy.", "pdf_url": "https://arxiv.org/pdf/2008.07025", "subject": "Systems and Control (eess.SY)"},
{"title": "Adding Recurrence to Pretrained Transformers for Improved Efficiency and Context Size", "author": "Davis Yoshida, Allyson Ettinger, Kevin Gimpel", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Fine-tuning a pretrained transformer for a downstream task has become a standard method in NLP in the last few years. While the results from these models are impressive, applying them can be extremely computationally expensive, as is pretraining new models with the latest architectures. We present a novel method for applying pretrained transformer language models which lowers their memory requirement both at training and inference time. An additional benefit is that our method removes the fixed context size constraint that most transformer models have, allowing for more flexible use. When applied to the GPT-2 language model, we find that our method attains better perplexity than an unmodified GPT-2 model on the PG-19 and WikiText-103 corpora, for a given amount of computation or memory.", "pdf_url": "https://arxiv.org/pdf/2008.07027", "subject": "Computation and Language (cs.CL)"},
{"title": "Uncertainty aware Search Framework for Multi-Objective Bayesian Optimization with Constraints", "author": "Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa", "pub_date": "Submitted on 16 Aug 2020", "abstract": "We consider the problem of constrained multi-objective (MO) blackbox optimization using expensive function evaluations, where the goal is to approximate the true Pareto set of solutions satisfying a set of constraints while minimizing the number of function evaluations. We propose a novel framework named Uncertainty-aware Search framework for Multi-Objective Optimization with Constraints (USeMOC) to efficiently select the sequence of inputs for evaluation to solve this problem. The selection method of USeMOC consists of solving a cheap constrained MO optimization problem via surrogate models of the true functions to identify the most promising candidates and picking the best candidate based on a measure of uncertainty. We applied this framework to optimize the design of a multi-output switched-capacitor voltage regulator via expensive simulations. Our experimental results show that USeMOC is able to achieve more than 90 % reduction in the number of simulations needed to uncover optimized circuits.", "pdf_url": "https://arxiv.org/pdf/2008.07029", "subject": "Machine Learning (cs.LG)"},
{"title": "Beyond Point Estimate: Inferring Ensemble Prediction Variation from Neuron Activation Strength in Recommender Systems", "author": "Zhe Chen, Yuyan Wang, Dong Lin, Derek Zhiyuan Cheng, Lichan Hong, Ed H. Chi, Claire Cui", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Despite deep neural network (DNN)'s impressive prediction performance in various domains, it is well known now that a set of DNN models trained with the same model specification and the same data can produce very different prediction results. Ensemble method is one state-of-the-art benchmark for prediction uncertainty estimation. However, ensembles are expensive to train and serve for web-scale traffic. In this paper, we seek to advance the understanding of prediction variation estimated by the ensemble method. Through empirical experiments on two widely used benchmark datasets MovieLens and Criteo in recommender systems, we observe that prediction variations come from various randomness sources, including training data shuffling, and parameter random initialization. By introducing more randomness into model training, we notice that ensemble's mean predictions tend to be more accurate while the prediction variations tend to be higher. Moreover, we propose to infer prediction variation from neuron activation strength and demonstrate the strong prediction power from activation strength features. Our experiment results show that the average R squared on MovieLens is as high as 0.56 and on Criteo is 0.81. Our method performs especially well when detecting the lowest and highest variation buckets, with 0.92 AUC and 0.89 AUC respectively. Our approach provides a simple way for prediction variation estimation, which opens up new opportunities for future work in many interesting areas (e.g.,model-based reinforcement learning) without relying on serving expensive ensemble models.", "pdf_url": "https://arxiv.org/pdf/2008.07032", "subject": "Machine Learning (cs.LG)"},
{"title": "Good Classical and Quantum Codes from Multi-Twisted Codes", "author": "Nuh Aydin, Thomas Guidotti, Peihan Liu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Multi-twisted (MT) codes were introduced as a generalization of quasi-twisted (QT) codes. QT codes have been known to contain many good codes. In this work, we show that codes with good parameters and desirable properties can be obtained from MT codes. These include best known and optimal classical codes with additional properties such as reversibility and self-duality, and new and best known non-binary quantum codes obtained from special cases MT codes. Often times best known quantum codes in the literature are obtained indirectly by considering extension rings. Our constructions have the advantage that we obtain these codes by more direct and simpler methods. Additionally, we found theoretical results about binomials over finite fields that are useful in our search.", "pdf_url": "https://arxiv.org/pdf/2008.07037", "subject": "Information Theory (cs.IT)"},
{"title": "Securing OFDM-Based NOMA SWIPT Systems", "author": "Ahmed Badawy, Ahmed El Shafie", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper, we present a physical-layer security scheme that exploits artificial noise (AN) to secure the downlink legitimate communications and transfer energy to nodes operating under non-cooperative non-orthogonal multiple-access (NOMA) scenario. The nodes employ a joint time-switching and power-switching scheme to maximize the harvested energy. We provide necessary analysis and derivations for the optimization parameters and find the optimized transmission parameters that maximize the minimum secrecy rate among users while meeting constraints on minimum transferred energy and outage probabilities at the nodes through an exhaustive grid-based search. Our analysis and simulations prove the feasibility of securing the communication among NOMA nodes, while transferring energy and meeting outage probability constraints.", "pdf_url": "https://arxiv.org/pdf/2008.07039", "subject": "Information Theory (cs.IT)"},
{"title": "Oriented Object Detection in Aerial Images with Box Boundary-Aware Vectors", "author": "Jingru Yi, Pengxiang Wu, Bo Liu, Qiaoying Huang, Hui Qu, Dimitris Metaxas", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Oriented object detection in aerial images is a challenging task as the objects in aerial images are displayed in arbitrary directions and are usually densely packed. Current oriented object detection methods mainly rely on two-stage anchor-based detectors. However, the anchor-based detectors typically suffer from a severe imbalance issue between the positive and negative anchor boxes. To address this issue, in this work we extend the horizontal keypoint-based object detector to the oriented object detection task. In particular, we first detect the center keypoints of the objects, based on which we then regress the box boundary-aware vectors (BBAVectors) to capture the oriented bounding boxes. The box boundary-aware vectors are distributed in the four quadrants of a Cartesian coordinate system for all arbitrarily oriented objects. To relieve the difficulty of learning the vectors in the corner cases, we further classify the oriented bounding boxes into horizontal and rotational bounding boxes. In the experiment, we show that learning the box boundary-aware vectors is superior to directly predicting the width, height, and angle of an oriented bounding box, as adopted in the baseline method. Besides, the proposed method competes favorably with state-of-the-art methods. Code is available at .", "pdf_url": "https://arxiv.org/pdf/2008.07043", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Population-Scale Study of Human Needs During the COVID-19 Pandemic: Analysis and Implications", "author": "Jina Suh, Eric Horvitz, Ryen W. White, Tim Althoff", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Most work to date on mitigating the COVID-19 pandemic is focused urgently on biomedicine and epidemiology. However, pandemic-related policy decisions cannot be made on health information alone but need to take into account the broader impacts on people and their needs. Quantifying human needs across the population is challenging as it requires high geo-temporal granularity, high coverage across the population, and appropriate adjustment for seasonal and other external effects. Here, we propose a computational framework, based on Maslow's hierarchy of needs, that can characterize a holistic view of relative changes in needs following the pandemic through a difference-in-differences approach that corrects for seasonality and query volume variations. We apply this framework to characterize changes in human needs across physiological, socioeconomic, and psychological realms in the US, based on more than 35 billion search interactions spanning over 36,000 ZIP codes over a period of 14 months. Our analyses reveal that the expression of basic human needs has increased exponentially while higher-level aspirations declined during the pandemic in comparison to the pre-pandemic period. In exploring the timing and variations in statewide policies, we find that the duration of shelter-in-place mandates significantly influenced social and emotional needs. We demonstrate that potential barriers to addressing critical needs such as support for unemployment and domestic violence can be identified through web search interactions. Our approach and results suggest that population-scale monitoring of shifts in human needs can inform policies and recovery efforts for current and anticipated needs.", "pdf_url": "https://arxiv.org/pdf/2008.07045", "subject": "Computers and Society (cs.CY)"},
{"title": "A Deep Dive on the Impact of COVID-19 in Software Development", "author": "Paulo Anselmo da Mota Silveira Neto, Umme Ayda Mannan, Eduardo Santana de Almeida, Nachiappan Nagappan, David Lo, Pavneet Singh Kochhar, Cuiyun Gao, Iftekhar Ahmed", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Context: COVID-19 pandemic has impacted different business sectors around the world. Objective. This study investigates the impact of COVID-19 on software projects and software development professionals. Method: We conducted a mining software repository study based on 100 GitHub projects developed in Java using ten different metrics. Next, we surveyed 279 software development professionals for better understanding the impact of COVID-19 on daily activities and wellbeing. Results: We identified 12 observations related to productivity, code quality, and wellbeing. Conclusions: Our findings highlight that the impact of COVID-19 is not binary (reduce productivity vs. increase productivity) but rather a spectrum. For many of our observations, substantial proportions of respondents have differing opinions from each other. We believe that more research is needed to uncover specific conditions that cause certain outcomes to be more prevalent.", "pdf_url": "https://arxiv.org/pdf/2008.07048", "subject": "Software Engineering (cs.SE)"},
{"title": "Video Region Annotation with Sparse Bounding Boxes", "author": "Yuzheng Xu, Yang Wu, Nur Sabrina binti Zuraimi, Shohei Nobuhara, Ko Nishino", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Video analysis has been moving towards more detailed interpretation (e.g. segmentation) with encouraging progresses. These tasks, however, increasingly rely on densely annotated training data both in space and time. Since such annotation is labour-intensive, few densely annotated video data with detailed region boundaries exist. This work aims to resolve this dilemma by learning to automatically generate region boundaries for all frames of a video from sparsely annotated bounding boxes of target regions. We achieve this with a Volumetric Graph Convolutional Network (VGCN), which learns to iteratively find keypoints on the region boundaries using the spatio-temporal volume of surrounding appearance and motion. The global optimization of VGCN makes it significantly stronger and generalize better than existing solutions. Experimental results using two latest datasets (one real and one synthetic), including ablation studies, demonstrate the effectiveness and superiority of our method.", "pdf_url": "https://arxiv.org/pdf/2008.07049", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Embedded exponential-type low-regularity integrators for KdV equation under rough data", "author": "Yifei Wu, Xiaofei Zhao", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper, we introduce a novel class of embedded exponential-type low-regularity integrators (ELRIs) for solving the KdV equation and establish their optimal convergence results under rough initial data. The schemes are explicit and efficient to implement. By rigorous error analysis, we first show that the ELRI scheme provides the first order accuracy in $H^\\gamma$ for initial data in $H^{\\gamma+1}$ for $\\gamma>\\frac32$. Moreover, by adding two more correction terms to the first order scheme, we show a second order ELRI that provides the second order accuracy in $H^\\gamma$ for initial data in $H^{\\gamma+3}$. The proposed ELRIs further reduce the regularity requirement of existing methods so far. The theoretical results are confirmed by numerical experiments, and comparisons with existing methods illustrate the efficiency of the new methods.", "pdf_url": "https://arxiv.org/pdf/2008.07053", "subject": "Numerical Analysis (math.NA)"},
{"title": "Online Multitask Learning with Long-Term Memory", "author": "Mark Herbster, Stephen Pasteris, Lisa Tse", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We introduce a novel online multitask setting. In this setting each task is partitioned into a sequence of segments that is unknown to the learner. Associated with each segment is a hypothesis from some hypothesis class. We give algorithms that are designed to exploit the scenario where there are many such segments but significantly fewer associated hypotheses. We prove regret bounds that hold for any segmentation of the tasks and any association of hypotheses to the segments. In the single-task setting this is equivalent to switching with long-term memory in the sense of [Bousquet and Warmuth; 2003]. We provide an algorithm that predicts on each trial in time linear in the number of hypotheses when the hypothesis class is finite. We also consider infinite hypothesis classes from reproducing kernel Hilbert spaces for which we give an algorithm whose per trial time complexity is cubic in the number of cumulative trials. In the single-task special case this is the first example of an efficient regret-bounded switching algorithm with long-term memory for a non-parametric hypothesis class.", "pdf_url": "https://arxiv.org/pdf/2008.07055", "subject": "Machine Learning (cs.LG)"},
{"title": "Progressively Guided Alternate Refinement Network for RGB-D Salient Object Detection", "author": "Shuhan Chen, Yun Fu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper, we aim to develop an efficient and compact deep network for RGB-D salient object detection, where the depth image provides complementary information to boost performance in complex scenarios. Starting from a coarse initial prediction by a multi-scale residual block, we propose a progressively guided alternate refinement network to refine it. Instead of using ImageNet pre-trained backbone network, we first construct a lightweight depth stream by learning from scratch, which can extract complementary features more efficiently with less redundancy. Then, different from the existing fusion based methods, RGB and depth features are fed into proposed guided residual (GR) blocks alternately to reduce their mutual degradation. By assigning progressive guidance in the stacked GR blocks within each side-output, the false detection and missing parts can be well remedied. Extensive experiments on seven benchmark datasets demonstrate that our model outperforms existing state-of-the-art approaches by a large margin, and also shows superiority in efficiency (71 FPS) and model size (64.9 MB).", "pdf_url": "https://arxiv.org/pdf/2008.07064", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Putting the Semantics into Semantic Versioning", "author": "Patrick Lam, Jens Dietrich, David J. Pearce", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The long-standing aspiration for software reuse has made astonishing strides in the past few years. Many modern software development ecosystems now come with rich sets of publicly-available components contributed by the community. Downstream developers can leverage these upstream components, boosting their productivity. However, components evolve at their own pace. This imposes obligations on and yields benefits for downstream developers, especially since changes can be breaking, requiring additional downstream work to adapt to. Upgrading too late leaves downstream vulnerable to security issues and missing out on useful improvements; upgrading too early results in excess work. Semantic versioning has been proposed as an elegant mechanism to communicate levels of compatibility, enabling downstream developers to automate dependency upgrades. While it is questionable whether a version number can adequately characterize version compatibility in general, we argue that developers would greatly benefit from tools such as semantic version calculators to help them upgrade safely. The time is now for the research community to develop such tools: large component ecosystems exist and are accessible, component interactions have become observable through automated builds, and recent advances in program analysis make the development of relevant tools feasible. In particular, contracts (both traditional and lightweight) are a promising input to semantic versioning calculators, which can suggest whether an upgrade is likely to be safe.", "pdf_url": "https://arxiv.org/pdf/2008.07069", "subject": "Software Engineering (cs.SE)"},
{"title": "Artificial Neural Networks and Fault Injection Attacks", "author": "Shahin Tajik, Fatemeh Ganji", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This chapter is on the security assessment of artificial intelligence (AI) and neural network (NN) accelerators in the face of fault injection attacks. More specifically, it discusses the assets on these platforms and compares them with ones known and well-studied in the field of cryptographic systems. This is a crucial step that must be taken in order to define the threat models precisely. With respect to that, fault attacks mounted on NNs and AI accelerators are explored.", "pdf_url": "https://arxiv.org/pdf/2008.07072", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Alpha Net: Adaptation with Composition in Classifier Space", "author": "Nadine Chang, Jayanth Koushik, Michael J. Tarr, Martial Hebert, Yu-Xiong Wang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Deep learning classification models typically train poorly on classes with small numbers of examples. Motivated by the human ability to solve this task, models have been developed that transfer knowledge from classes with many examples to learn classes with few examples. Critically, the majority of these models transfer knowledge within model feature space. In this work, we demonstrate that transferring knowledge within classified space is more effective and efficient. Specifically, by linearly combining strong nearest neighbor classifiers along with a weak classifier, we are able to compose a stronger classifier. Uniquely, our model can be implemented on top of any existing classification model that includes a classifier layer. We showcase the success of our approach in the task of long-tailed recognition, whereby the classes with few examples, otherwise known as the \"tail\" classes, suffer the most in performance and are the most challenging classes to learn. Using classifier-level knowledge transfer, we are able to drastically improve - by a margin as high as 12.6% - the state-of-the-art performance on the \"tail\" categories.", "pdf_url": "https://arxiv.org/pdf/2008.07073", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Certificate and Signature Free Anonymity for V2V Communications", "author": "Vipin Singh Sehrawat, Yogendra Shah, Vinod Kumar Choyi, Alec Brusilovsky, Samir Ferdi", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Anonymity is a desirable feature for vehicle-to-vehicle (V2V) communications, but it conflicts with other requirements such as non-repudiation and revocation. Existing, pseudonym-based V2V communications schemes rely on certificate generation and signature verification. These schemes require cumbersome key management, frequent updating of certificate chains and other costly procedures such as cryptographic pairings. In this paper, we present novel V2V communications schemes, that provide authentication, authorization, anonymity, non-repudiation, replay protection, pseudonym revocation, and forward secrecy without relying on traditional certificate generation and signature verification. Security and privacy of our schemes rely on hard problems in number theory. Furthermore, our schemes guarantee security and privacy in the presence of subsets of colluding malicious parties, provided that the cardinality of such sets is below a fixed threshold.", "pdf_url": "https://arxiv.org/pdf/2008.07076", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Playing Catan with Cross-dimensional Neural Network", "author": "Quentin Gendre, Tomoyuki Kaneko", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Catan is a strategic board game having interesting properties, including multi-player, imperfect information, stochastic, complex state space structure (hexagonal board where each vertex, edge and face has its own features, cards for each player, etc), and a large action space (including negotiation). Therefore, it is challenging to build AI agents by Reinforcement Learning (RL for short), without domain knowledge nor heuristics. In this paper, we introduce cross-dimensional neural networks to handle a mixture of information sources and a wide variety of outputs, and empirically demonstrate that the network dramatically improves RL in Catan. We also show that, for the first time, a RL agent can outperform jsettler, the best heuristic agent available.", "pdf_url": "https://arxiv.org/pdf/2008.07079", "subject": "Machine Learning (cs.LG)"},
{"title": "MIDAS: Multi-agent Interaction-aware Decision-making with Adaptive Strategies for Urban Autonomous Navigation", "author": "Xiaoyi Chen, Pratik Chaudhari", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Autonomous navigation in crowded, complex urban environments requires interacting with other agents on the road. A common solution to this problem is to use a prediction model to guess the likely future actions of other agents. While this is reasonable, it leads to overly conservative plans because it does not explicitly model the mutual influence of the actions of interacting agents. This paper builds a reinforcement learning-based method named MIDAS where an ego-agent learns to affect the control actions of other cars in urban driving scenarios. MIDAS uses an attention-mechanism to handle an arbitrary number of other agents and includes a ''driver-type'' parameter to learn a single policy that works across different planning objectives. We build a simulation environment that enables diverse interaction experiments with a large number of agents and methods for quantitatively studying the safety, efficiency, and interaction among vehicles. MIDAS is validated using extensive experiments and we show that it (i) can work across different road geometries, (ii) results in an adaptive ego policy that can be tuned easily to satisfy performance criteria such as aggressive or cautious driving, (iii) is robust to changes in the driving policies of external agents, and (iv) is more efficient and safer than existing approaches to interaction-aware decision-making.", "pdf_url": "https://arxiv.org/pdf/2008.07081", "subject": "Machine Learning (cs.LG)"},
{"title": "Edge Network-Assisted Real-Time Object Detection Framework for Autonomous Driving", "author": "Seung Wook Kim, Keunsoo Ko, Haneul Ko, Victor C. M. Leung", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Autonomous vehicles (AVs) can achieve the desired results within a short duration by offloading tasks even requiring high computational power (e.g., object detection (OD)) to edge clouds. However, although edge clouds are exploited, real-time OD cannot always be guaranteed due to dynamic channel quality. To mitigate this problem, we propose an edge network-assisted real-time OD framework~(EODF). In an EODF, AVs extract the region of interests~(RoIs) of the captured image when the channel quality is not sufficiently good for supporting real-time OD. Then, AVs compress the image data on the basis of the RoIs and transmit the compressed one to the edge cloud. In so doing, real-time OD can be achieved owing to the reduced transmission latency. To verify the feasibility of our framework, we evaluate the probability that the results of OD are not received within the inter-frame duration (i.e., outage probability) and their accuracy. From the evaluation, we demonstrate that the proposed EODF provides the results to AVs in real-time and achieves satisfactory accuracy.", "pdf_url": "https://arxiv.org/pdf/2008.07083", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Spherical coordinates transformation pre-processing in Deep Convolution Neural Networks for brain tumor segmentation in MRI", "author": "Carlo Russo, Sidong Liu, Antonio Di Ieva", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Magnetic Resonance Imaging (MRI) is used in everyday clinical practice to assess brain tumors. Several automatic or semi-automatic segmentation algorithms have been introduced to segment brain tumors and achieve an expert-like accuracy. Deep Convolutional Neural Networks (DCNN) have recently shown very promising results, however, DCNN models are still far from achieving clinically meaningful results mainly because of the lack of generalization of the models. DCNN models need large annotated datasets to achieve good performance. Models are often optimized on the domain dataset on which they have been trained, and then fail the task when the same model is applied to different datasets from different institutions. One of the reasons is due to the lack of data standardization to adjust for different models and MR machines. In this work, a 3D Spherical coordinates transform during the pre-processing phase has been hypothesized to improve DCNN models' accuracy and to allow more generalizable results even when the model is trained on small and heterogeneous datasets and translated into different domains. Indeed, the spherical coordinate system avoids several standardization issues since it works independently of resolution and imaging settings. Both Cartesian and spherical volumes were evaluated in two DCNN models with the same network structure using the BraTS 2019 dataset. The model trained on spherical transform pre-processed inputs resulted in superior performance over the Cartesian-input trained model on predicting gliomas' segmentation on tumor core and enhancing tumor classes (increase of 0.011 and 0.014 respectively on the validation dataset), achieving a further improvement in accuracy by merging the two models together. Furthermore, the spherical transform is not resolution-dependent and achieve same results on different input resolution.", "pdf_url": "https://arxiv.org/pdf/2008.07090", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Understanding Brain Dynamics for Color Perception using Wearable EEG headband", "author": "Mahima Chaudhary, Sumona Mukhopadhyay, Marin Litoiu, Lauren E Sergio, Meaghan S Adams", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The perception of color is an important cognitive feature of the human brain. The variety of colors that impinge upon the human eye can trigger changes in brain activity which can be captured using electroencephalography (EEG). In this work, we have designed a multiclass classification model to detect the primary colors from the features of raw EEG signals. In contrast to previous research, our method employs spectral power features, statistical features as well as correlation features from the signal band power obtained from continuous Morlet wavelet transform instead of raw EEG, for the classification task. We have applied dimensionality reduction techniques such as Forward Feature Selection and Stacked Autoencoders to reduce the dimension of data eventually increasing the model's efficiency. Our proposed methodology using Forward Selection and Random Forest Classifier gave the best overall accuracy of 80.6\\% for intra-subject classification. Our approach shows promise in developing techniques for cognitive tasks using color cues such as controlling Internet of Thing (IoT) devices by looking at primary colors for individuals with restricted motor abilities.", "pdf_url": "https://arxiv.org/pdf/2008.07092", "subject": "Machine Learning (cs.LG)"},
{"title": "Decomposition-Based Multi-Objective Evolutionary Algorithm Design under Two Algorithm Frameworks", "author": "Lie Meng Pang, Hisao Ishibuchi, Ke Shang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The development of efficient and effective evolutionary multi-objective optimization (EMO) algorithms has been an active research topic in the evolutionary computation community. Over the years, many EMO algorithms have been proposed. The existing EMO algorithms are mainly developed based on the final population framework. In the final population framework, the final population of an EMO algorithm is presented to the decision maker. Thus, it is required that the final population produced by an EMO algorithm is a good solution set. Recently, the use of solution selection framework was suggested for the design of EMO algorithms. This framework has an unbounded external archive to store all the examined solutions. A pre-specified number of solutions are selected from the archive as the final solutions presented to the decision maker. When the solution selection framework is used, EMO algorithms can be designed in a more flexible manner since the final population is not necessarily to be a good solution set. In this paper, we examine the design of MOEA/D under these two frameworks. We use an offline genetic algorithm-based hyper-heuristic method to find the optimal configuration of MOEA/D in each framework. The DTLZ and WFG test suites and their minus versions are used in our experiments. The experimental results suggest the possibility that a more flexible, robust and high-performance MOEA/D algorithm can be obtained when the solution selection framework is used.", "pdf_url": "https://arxiv.org/pdf/2008.07094", "subject": "Neural and Evolutionary Computing (cs.NE)"},
{"title": "The Best of Both Worlds: Hybrid Data-Driven and Model-Based Vehicular Network Simulation", "author": "Benjamin Sliwa, Manuel Patchou, Christian Wietfeld", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The analysis of the end-to-end behavior of novel mobile communication methods in concrete evaluation scenarios frequently results in a methodological dilemma: Real world measurement campaigns are highly time-consuming and lack of a controllable environment, the derivation of analytical models is often not possible due to the immense system complexity, system-level network simulations imply simplifications that result in significant derivations to the real world observations. In this paper, we present a hybrid simulation approach which brings together model-based mobility simulation, multi-dimensional Radio Environmental Maps (REMs) for efficient maintenance of radio propagation data, and Data-driven Network Simulation (DDNS) for fast and accurate analysis of the end-to-end behavior of mobile networks. For the validation, we analyze an opportunistic vehicular data transfer use-case and compare the proposed method to real world measurements and a corresponding simulation setup in Network Simulator 3 (ns-3). In comparison to the latter, the proposed method is not only able to better mimic the real world behavior, it also achieves a 300 times higher computational efficiency.", "pdf_url": "https://arxiv.org/pdf/2008.07096", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Shifu2: A Network Representation Learning Based Model for Advisor-advisee Relationship Mining", "author": "Jiaying Liu, Feng Xia, Lei Wang, Bo Xu, Xiangjie Kong, Hanghang Tong, Irwin King", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The advisor-advisee relationship represents direct knowledge heritage, and such relationship may not be readily available from academic libraries and search engines. This work aims to discover advisor-advisee relationships hidden behind scientific collaboration networks. For this purpose, we propose a novel model based on Network Representation Learning (NRL), namely Shifu2, which takes the collaboration network as input and the identified advisor-advisee relationship as output. In contrast to existing NRL models, Shifu2 considers not only the network structure but also the semantic information of nodes and edges. Shifu2 encodes nodes and edges into low-dimensional vectors respectively, both of which are then utilized to identify advisor-advisee relationships. Experimental results illustrate improved stability and effectiveness of the proposed model over state-of-the-art methods. In addition, we generate a large-scale academic genealogy dataset by taking advantage of Shifu2.", "pdf_url": "https://arxiv.org/pdf/2008.07097", "subject": "Machine Learning (cs.LG)"},
{"title": "An Efficient Transition Algorithm For Seamless Drone Multicasting", "author": "Wanqing Tu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Many drone-related applications (e.g., drone-aided video capture, drone traffic and safety management) require group communications between drones to efficiently disseminate data or reliably deliver critical information, making use of the line-of-sight coverage of drones to realise services that ground devices may not be capable of. This paper studies highperformance yet resource-efficient mobile drone multicasting via trajectory adjustment. We first analyse the trajectory adjustment condition to determine whether a straight-line trajectory is fully covered by the multicast or not, by conducting simple computation tasks and with controlled overhead traffic. We then propose the trajectory adjustment scheme to provide a new trajectory with controlled travel distances. The ETTA algorithm is finally presented to apply the trajectory adjustment condition and scheme to a drone transiting between forwarders whose coverage do not overlap. The algorithm relies on multicasting forwarders, instead of additional transition forwarders, to fully cover the adjusted trajectory, helping to control interference and network traffic load. Our NS2 simulation results demonstrate that ETTA, as compared to other mobile multicasts, can achieve guaranteed performance for drone receivers in a multicast with heavier traffic loads.", "pdf_url": "https://arxiv.org/pdf/2008.07105", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "WSRNet: Joint Spotting and Recognition of Handwritten Words", "author": "George Retsinas, Giorgos Sfikas, Petros Maragos", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this work, we present a unified model that can handle both Keyword Spotting and Word Recognition with the same network architecture. The proposed network is comprised of a non-recurrent CTC branch and a Seq2Seq branch that is further augmented with an Autoencoding module. The related joint loss leads to a boost in recognition performance, while the Seq2Seq branch is used to create efficient word representations. We show how to further process these representations with binarization and a retraining scheme to provide compact and highly efficient descriptors, suitable for keyword spotting. Numerical results validate the usefulness of the proposed architecture, as our method outperforms the previous state-of-the-art in keyword spotting, and provides results in the ballpark of the leading methods for word recognition.", "pdf_url": "https://arxiv.org/pdf/2008.07109", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Generative Design by Reinforcement Learning: Maximizing Diversity of Topology Optimized Designs", "author": "Seowoo Jang, Namwoo Kang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Generative design is a design exploration process in which a large number of structurally optimal designs are generated in parallel by diversifying parameters of the topology optimization while fulfilling certain constraints. Recently, data-driven generative design has gained much attention due to its integration with artificial intelligence (AI) technologies. When generating new designs through a generative approach, one of the important evaluation factors is diversity. In general, the problem definition of topology optimization is diversified by varying the force and boundary conditions, and the diversity of the generated designs is influenced by such parameter combinations. This study proposes a reinforcement learning (RL) based generative design process with reward functions maximizing the diversity of the designs. We formulate the generative design as a sequential problem of finding optimal parameter level values according to a given initial design. Proximal Policy Optimization (PPO) was applied as the learning framework, which is demonstrated in the case study of an automotive wheel design problem. This study also proposes the use of a deep neural network to instantly generate new designs without the topology optimization process, thus reducing the large computational burdens required by reinforcement learning. We show that RL-based generative design produces a large number of diverse designs within a short inference time by exploiting GPU in a fully automated manner. It is different from the previous approach using CPU which takes much more processing time and involving human intervention.", "pdf_url": "https://arxiv.org/pdf/2008.07119", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Learning Interpretable Representation for Controllable Polyphonic Music Generation", "author": "Ziyu Wang, Dingsu Wang, Yixiao Zhang, Gus Xia", "pub_date": "Submitted on 17 Aug 2020", "abstract": "While deep generative models have become the leading methods for algorithmic composition, it remains a challenging problem to control the generation process because the latent variables of most deep-learning models lack good interpretability. Inspired by the content-style disentanglement idea, we design a novel architecture, under the VAE framework, that effectively learns two interpretable latent factors of polyphonic music: chord and texture. The current model focuses on learning 8-beat long piano composition segments. We show that such chord-texture disentanglement provides a controllable generation pathway leading to a wide spectrum of applications, including compositional style transfer, texture variation, and accompaniment arrangement. Both objective and subjective evaluations show that our method achieves a successful disentanglement and high quality controlled music generation.", "pdf_url": "https://arxiv.org/pdf/2008.07122", "subject": "Sound (cs.SD)"},
{"title": "Adversarial EXEmples: A Survey and Experimental Evaluation of Practical Attacks on Machine Learning for Windows Malware Detection", "author": "Luca Demetrio, Scott E. Coull, Battista Biggio, Giovanni Lagorio, Alessandro Armando, Fabio Roli", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Recent work has shown that adversarial Windows malware samples - also referred to as adversarial EXEmples in this paper - can bypass machine learning-based detection relying on static code analysis by perturbing relatively few input bytes. To preserve malicious functionality, previous attacks either add bytes to existing non-functional areas of the file, potentially limiting their effectiveness, or require running computationally-demanding validation steps to discard malware variants that do not correctly execute in sandbox environments. In this work, we overcome these limitations by developing a unifying framework that not only encompasses and generalizes previous attacks against machine-learning models, but also includes two novel attacks based on practical, functionality-preserving manipulations to the Windows Portable Executable (PE) file format, based on injecting the adversarial payload by respectively extending the DOS header and shifting the content of the first section. Our experimental results show that these attacks outperform existing ones in both white-box and black-box attack scenarios by achieving a better trade-off in terms of evasion rate and size of the injected payload, as well as enabling evasion of models that were shown to be robust to previous attacks. To facilitate reproducibility and future work, we open source our framework and all the corresponding attack implementations. We conclude by discussing the limitations of current machine learning-based malware detectors, along with potential mitigation strategies based on embedding domain knowledge coming from subject-matter experts naturally into the learning process.", "pdf_url": "https://arxiv.org/pdf/2008.07125", "subject": "Cryptography and Security (cs.CR)"},
{"title": "DORY: Automatic End-to-End Deployment of Real-World DNNs on Low-Cost IoT MCUs", "author": "Alessio Burrello, Angelo Garofalo, Nazareno Bruschi, Giuseppe Tagliavini, Davide Rossi, Francesco Conti", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The deployment of Deep Neural Networks (DNNs) on end-nodes at the extreme edge of the Internet-of-Things is a critical enabler to support pervasive Deep Learning-enhanced applications. Low-Cost MCU-based end-nodes have limited on-chip memory and often replace caches with scratchpads, to reduce area overheads and increase energy efficiency -- requiring explicit DMA-based memory transfers between different levels of the memory hierarchy. Mapping modern DNNs on these systems requires aggressive topology-dependent tiling and double-buffering. In this work, we propose DORY (Deployment Oriented to memoRY) - an automatic tool to deploy DNNs on low cost MCUs with typically less than 1MB of on-chip SRAM memory. DORY abstracts tiling as a Constraint Programming (CP) problem: it maximizes L1 memory utilization under the topological constraints imposed by each DNN layer. Then, it generates ANSI C code to orchestrate off- and on-chip transfers and computation phases. Furthermore, to maximize speed, DORY augments the CP formulation with heuristics promoting performance-effective tile sizes. As a case study for DORY, we target GreenWaves Technologies GAP8, one of the most advanced parallel ultra-low power MCU-class devices on the market. On this device, DORY achieves up to 2.5x better MAC/cycle than the GreenWaves proprietary software solution and 18.1x better than the state-of-the-art result on an STM32-F746 MCU on single layers. Using our tool, GAP-8 can perform end-to-end inference of a 1.0-MobileNet-128 network consuming just 63 pJ/MAC on average @ 4.3 fps - 15.4x better than an STM32-F746. We release all our developments - the DORY framework, the optimized backend kernels, and the related heuristics - as open-source software.", "pdf_url": "https://arxiv.org/pdf/2008.07127", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Reversing the cycle: self-supervised deep stereo through enhanced monocular distillation", "author": "Filippo Aleotti, Fabio Tosi, Li Zhang, Matteo Poggi, Stefano Mattoccia", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In many fields, self-supervised learning solutions are rapidly evolving and filling the gap with supervised approaches. This fact occurs for depth estimation based on either monocular or stereo, with the latter often providing a valid source of self-supervision for the former. In contrast, to soften typical stereo artefacts, we propose a novel self-supervised paradigm reversing the link between the two. Purposely, in order to train deep stereo networks, we distill knowledge through a monocular completion network. This architecture exploits single-image clues and few sparse points, sourced by traditional stereo algorithms, to estimate dense yet accurate disparity maps by means of a consensus mechanism over multiple estimations. We thoroughly evaluate with popular stereo datasets the impact of different supervisory signals showing how stereo networks trained with our paradigm outperform existing self-supervised frameworks. Finally, our proposal achieves notable generalization capabilities dealing with domain shift issues. Code available at", "pdf_url": "https://arxiv.org/pdf/2008.07130", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Fast and Robust Face-to-Parameter Translation for Game Character Auto-Creation", "author": "Tianyang Shi, Zhengxia Zou, Yi Yuan, Changjie Fan", "pub_date": "Submitted on 17 Aug 2020", "abstract": "With the rapid development of Role-Playing Games (RPGs), players are now allowed to edit the facial appearance of their in-game characters with their preferences rather than using default templates. This paper proposes a game character auto-creation framework that generates in-game characters according to a player's input face photo. Different from the previous methods that are designed based on neural style transfer or monocular 3D face reconstruction, we re-formulate the character auto-creation process in a different point of view: by predicting a large set of physically meaningful facial parameters under a self-supervised learning paradigm. Instead of updating facial parameters iteratively at the input end of the renderer as suggested by previous methods, which are time-consuming, we introduce a facial parameter translator so that the creation can be done efficiently through a single forward propagation from the face embeddings to parameters, with a considerable 1000x computational speedup. Despite its high efficiency, the interactivity is preserved in our method where users are allowed to optionally fine-tune the facial parameters on our creation according to their needs. Our approach also shows better robustness than previous methods, especially for those photos with head-pose variance. Comparison results and ablation analysis on seven public face verification datasets suggest the effectiveness of our method.", "pdf_url": "https://arxiv.org/pdf/2008.07132", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Logical Semantics, Dialogical Argumentation, and Textual Entailment", "author": "Davide Catta, Richard Moot, Christian Retor\u00e9", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this chapter, we introduce a new dialogical system for first order classical logic which is close to natural language argumentation, and we prove its completeness with respect to usual classical validity. We combine our dialogical system with the Grail syntactic and semantic parser developed by the second author in order to address automated textual entailment, that is, we use it for deciding whether or not a sentence is a consequence of a short text. This work-which connects natural language semantics and argumentation with dialogical logic-can be viewed as a step towards an inferentialist view of natural language semantics.", "pdf_url": "https://arxiv.org/pdf/2008.07138", "subject": "Computation and Language (cs.CL)"},
{"title": "How to Train Your Robust Human Pose Estimator: Pay Attention to the Constraint Cue", "author": "Junjie Huang, Zheng Zhu, Guan Huang, Dalong Du", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Both appearance cue and constraint cue are important in human pose estimation. However, the widely used response map supervision has the tendency to overfit the appearance cue and overlook the constraint cue. In this paper, we propose occlusion augmentation with customized training schedules to tackle this dilemma. Specifically, we implicitly force the neural network focus on the constraint cue by dropping appearance information within keypoint-aware strategy. Besides, a two-steps schedule is designed to deal with the information shortage in early training process, which effectively exploits the potential of the proposed occlusion augmentation. In experiments, as a model-agnostic approach, occlusion augmentation consistently promotes most SOTAs with different input sizes, frameworks, backbones, training and test sets. For HRNet within W32-256x192 and W48plus-384x288 configurations, occlusion augmentation obtains gains by 0.6 AP (75.6 to 76.2) and 0.7 AP (76.8 to 77.5) on COCO test-dev set, respectively. HRNet-W48plus-384x288 equipped with extra training data and occlusion augmentation achieves 78.7 AP. Furthermore, the proposed occlusion augmentation makes a remarkable improvement on more challenging CrowdPose dataset. The source code will be publicly available for further research in .", "pdf_url": "https://arxiv.org/pdf/2008.07139", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "AIPerf: Automated machine learning as an AI-HPC benchmark", "author": "Zhixiang Ren, Yongheng Liu, Tianhui Shi, Lei Xie, Yue Zhou, Jidong Zhai, Youhui Zhang, Yunquan Zhang, Wenguang Chen", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "The plethora of complex artificial intelligence (AI) algorithms and available high performance computing (HPC) power stimulates the convergence of AI and HPC. The expeditious development of AI components, in both hardware and software domain, increases the system heterogeneity, which prompts the challenge on fair and comprehensive benchmarking. Existing HPC and AI benchmarks fail to cover the variety of heterogeneous systems while providing a simple quantitative measurement to reflect the overall performance of large clusters for AI tasks. To address the challenges, we specify the requirements of an AI-HPC considering the future scenarios and propose an end-to-end benchmark suite utilizing automated machine learning (AutoML) as a representative AI application. The extremely high computational cost and high scalability make AutoML a desired workload candidate for AI-HPC benchmark. We implement the algorithms in a highly efficient and parallel way to ensure automatic adaption on various systems regarding AI accelerator's memory and quantity. The benchmark is particularly customizable on back-end training framework and hyperparameters so as to achieve optimal performance on diverse systems. The major metric to quantify the machine performance is floating-point operations per second (FLOPS), which is measured in a systematic and analytical approach. We also provide a regulated score as a complementary result to reflect hardware and software co-performance. We verify the benchmark's linear scalability on different scales of nodes up to 16 equipped with 128 GPUs and evaluate the stability as well as reproducibility at discrete timestamps. The source code, specifications, and detailed procedures are publicly accessible on GitHub: .", "pdf_url": "https://arxiv.org/pdf/2008.07141", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "POP909: A Pop-song Dataset for Music Arrangement Generation", "author": "Ziyu Wang, Ke Chen, Junyan Jiang, Yiyi Zhang, Maoran Xu, Shuqi Dai, Xianbin Gu, Gus Xia", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Music arrangement generation is a subtask of automatic music generation, which involves reconstructing and re-conceptualizing a piece with new compositional techniques. Such a generation process inevitably requires reference from the original melody, chord progression, or other structural information. Despite some promising models for arrangement, they lack more refined data to achieve better evaluations and more practical results. In this paper, we propose POP909, a dataset which contains multiple versions of the piano arrangements of 909 popular songs created by professional musicians. The main body of the dataset contains the vocal melody, the lead instrument melody, and the piano accompaniment for each song in MIDI format, which are aligned to the original audio files. Furthermore, we provide the annotations of tempo, beat, key, and chords, where the tempo curves are hand-labeled and others are done by MIR algorithms. Finally, we conduct several baseline experiments with this dataset using standard deep music generation algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.07142", "subject": "Sound (cs.SD)"},
{"title": "A Large-scale Open Dataset for Bandit Algorithms", "author": "Yuta Saito, Shunsuke Aihara, Megumi Matsutani, Yusuke Narita", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We build and publicize the Open Bandit Dataset and Pipeline to facilitate scalable and reproducible research on bandit algorithms. They are especially suitable for off-policy evaluation (OPE), which attempts to predict the performance of hypothetical algorithms using data generated by a different algorithm. We construct the dataset based on experiments and implementations on a large-scale fashion e-commerce platform, ZOZOTOWN. The data contain the ground-truth about the performance of several bandit policies and enable the fair comparisons of different OPE estimators. We also provide a pipeline to make its implementation easy and consistent. As a proof of concept, we use the dataset and pipeline to implement and evaluate OPE estimators. First, we find that a well-established estimator fails, suggesting that it is critical to choose an appropriate estimator. We then select a well-performing estimator and use it to improve the platform's fashion item recommendation. Our analysis succeeds in finding a counterfactual policy that significantly outperforms the historical ones. Our open data and pipeline will allow researchers and practitioners to easily evaluate and compare their bandit algorithms and OPE estimators with others in a large, real-world setting.", "pdf_url": "https://arxiv.org/pdf/2008.07146", "subject": "Machine Learning (cs.LG)"},
{"title": "Multi-organ Segmentation via Co-training Weight-averaged Models from Few-organ Datasets", "author": "Rui Huang, Yuanjie Zheng, Zhiqiang Hu, Shaoting Zhang, Hongsheng Li", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Multi-organ segmentation has extensive applications in many clinical applications. To segment multiple organs of interest, it is generally quite difficult to collect full annotations of all the organs on the same images, as some medical centers might only annotate a portion of the organs due to their own clinical practice. In most scenarios, one might obtain annotations of a single or a few organs from one training set, and obtain annotations of the the other organs from another set of training images. Existing approaches mostly train and deploy a single model for each subset of organs, which are memory intensive and also time inefficient. In this paper, we propose to co-train weight-averaged models for learning a unified multi-organ segmentation network from few-organ datasets. We collaboratively train two networks and let the coupled networks teach each other on un-annotated organs. To alleviate the noisy teaching supervisions between the networks, the weighted-averaged models are adopted to produce more reliable soft labels. In addition, a novel region mask is utilized to selectively apply the consistent constraint on the un-annotated organ regions that require collaborative teaching, which further boosts the performance. Extensive experiments on three public available single-organ datasets LiTS, KiTS, Pancreas and manually-constructed single-organ datasets from MOBA show that our method can better utilize the few-organ datasets and achieves superior performance with less inference computational cost.", "pdf_url": "https://arxiv.org/pdf/2008.07149", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Sublinear bounds for nullity of flows and approximating Tutte's flow conjectures", "author": "Vahan Mkrtchyan", "pub_date": "Submitted on 17 Aug 2020", "abstract": "A function $f:N\\rightarrow N$ is sublinear, if \\[\\lim_{x\\rightarrow +\\infty}\\frac{f(x)}{x}=0.\\] If $A$ is an Abelian group, $G$ is a graph and $\\phi$ is an $A$-flow in $G$, then let $N(\\phi)$ be the nullity of $\\phi$, that is, the set of edges $e$ of $G$ with $\\phi(e)=0$. In this paper we show that (a) Tutte's 5-flow conjecture is equivalent to the statement that there is a sublinear function $f$, such that all $3$-edge-connected cubic graphs admit a $\\mathbb{Z}_5$-flow $\\phi$ (not necessarily no-where zero), such that $|N(\\phi)|\\leq f(|E(G)|)$; (b) Tutte's 4-flow conjecture is equivalent to the statement that there is a sublinear function $f$, such that all bridgeless graphs without a Petersen minor admit a $\\mathbb{Z}_4$-flow $\\phi$ (not necessarily no-where zero), such that $|N(\\phi)|\\leq f(|E(G)|)$; (c) Tutte's 3-flow conjecture is equivalent to the statement that there is a sublinear function $f$, such that all $4$-edge-connected graphs admit a $\\mathbb{Z}_3$-flow $\\phi$ (not necessarily no-where zero), such that $|N(\\phi)|\\leq f(|E(G)|)$.", "pdf_url": "https://arxiv.org/pdf/2008.07152", "subject": "Discrete Mathematics (cs.DM)"},
{"title": "Neutral Face Game Character Auto-Creation via PokerFace-GAN", "author": "Tianyang Shi, Zhengxia Zou, Xinhui Song, Zheng Song, Changjian Gu, Changjie Fan, Yi Yuan", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Game character customization is one of the core features of many recent Role-Playing Games (RPGs), where players can edit the appearance of their in-game characters with their preferences. This paper studies the problem of automatically creating in-game characters with a single photo. In recent literature on this topic, neural networks are introduced to make game engine differentiable and the self-supervised learning is used to predict facial customization parameters. However, in previous methods, the expression parameters and facial identity parameters are highly coupled with each other, making it difficult to model the intrinsic facial features of the character. Besides, the neural network based renderer used in previous methods is also difficult to be extended to multi-view rendering cases. In this paper, considering the above problems, we propose a novel method named \"PokerFace-GAN\" for neutral face game character auto-creation. We first build a differentiable character renderer which is more flexible than the previous methods in multi-view rendering cases. We then take advantage of the adversarial training to effectively disentangle the expression parameters from the identity parameters and thus generate player-preferred neutral face (expression-less) characters. Since all components of our method are differentiable, our method can be easily trained under a multi-task self-supervised learning paradigm. Experiment results show that our method can generate vivid neutral face game characters that are highly similar to the input photos. The effectiveness of our method is verified by comparison results and ablation studies.", "pdf_url": "https://arxiv.org/pdf/2008.07154", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Where to Map? Iterative Rover-Copter Path Planning for Mars Exploration", "author": "Takahiro Sasaki, Kyohei Otsu, Rohan Thakker, Sofie Haesaert, Ali-akbar Agha-mohammadi", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In addition to conventional ground rovers, the Mars 2020 mission will send a helicopter to Mars. The copter's high-resolution data helps the rover to identify small hazards such as steps and pointy rocks, as well as providing rich textual information useful to predict perception performance. In this paper, we consider a three-agent system composed of a Mars rover, copter, and orbiter. The objective is to provide good localization to the rover by selecting an optimal path that minimizes the localization uncertainty accumulation during the rover's traverse. To achieve this goal, we quantify the localizability as a goodness measure associated with the map, and conduct a joint-space search over rover's path and copter's perceptual actions given prior information from the orbiter. We jointly address where to map by the copter and where to drive by the rover using the proposed iterative copter-rover path planner. We conducted numerical simulations using the map of Mars 2020 landing site to demonstrate the effectiveness of the proposed planner.", "pdf_url": "https://arxiv.org/pdf/2008.07157", "subject": "Robotics (cs.RO)"},
{"title": "Probabilistic Skyline Query Processing over Uncertain Data Streams in Edge Computing Environments", "author": "Chuan-Chi Lai, Chuan-Ming Liu, Yan-Lin Chen, Li-Chun Wang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "With the advancement of technology, the data generated in our lives is getting faster and faster, and the amount of data that various applications need to process becomes extremely huge. Therefore, we need to put more effort into analyzing data and extracting valuable information. Cloud computing used to be a good technology to solve a large number of data analysis problems. However, in the era of the popularity of the Internet of Things (IoT), transmitting sensing data back to the cloud for centralized data analysis will consume a lot of wireless communication and network transmission costs. To solve the above problems, edge computing has become a promising solution. In this paper, we propose a new algorithm for processing probabilistic skyline queries over uncertain data streams in an edge computing environment. We use the concept of a second skyline set to filter data that is unlikely to be the result of the skyline. Besides, the edge server only sends the information needed to update the global analysis results on the cloud server, which will greatly reduce the amount of data transmitted over the network. The results show that our proposed method not only reduces the response time by more than 50% compared with the brute force method on two-dimensional data but also maintains the leading processing speed on high-dimensional data.", "pdf_url": "https://arxiv.org/pdf/2008.07159", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Cross-stakeholder service orchestration for B5G through capability provisioning", "author": "Vilho Raisanen, Mohammed Elbamby, Dmitry Petrov", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Cross-stakeholder service orchestration is a generalization of 5G network slices which has potential to increase business agility in Beyond 5G (B5G). An architectural framework is proposed which enables domain operators to expose their functionalities towards E2E services as capabilities. Capability orchestration is proposed as a mechanism for exposure. The use of intent-based management for communicating domain owner's business goals to capability orchestration is analyzed. The combination of business goal input and capability orchestration provides a basis for agile monetization of domain resources for domain owners, and a building block for rich end-to-end B5G services.", "pdf_url": "https://arxiv.org/pdf/2008.07162", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "DeepGIN: Deep Generative Inpainting Network for Extreme Image Inpainting", "author": "Chu-Tak Li, Wan-Chi Siu, Zhi-Song Liu, Li-Wen Wang, Daniel Pak-Kong Lun", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The degree of difficulty in image inpainting depends on the types and sizes of the missing parts. Existing image inpainting approaches usually encounter difficulties in completing the missing parts in the wild with pleasing visual and contextual results as they are trained for either dealing with one specific type of missing patterns (mask) or unilaterally assuming the shapes and/or sizes of the masked areas. We propose a deep generative inpainting network, named DeepGIN, to handle various types of masked images. We design a Spatial Pyramid Dilation (SPD) ResNet block to enable the use of distant features for reconstruction. We also employ Multi-Scale Self-Attention (MSSA) mechanism and Back Projection (BP) technique to enhance our inpainting results. Our DeepGIN outperforms the state-of-the-art approaches generally, including two publicly available datasets (FFHQ and Oxford Buildings), both quantitatively and qualitatively. We also demonstrate that our model is capable of completing masked images in the wild.", "pdf_url": "https://arxiv.org/pdf/2008.07173", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "SDM-RDFizer: An RML Interpreter for the Efficient Creation of RDF Knowledge Graphs", "author": "Enrique Iglesias, Samaneh Jozashoori, David Chaves-Fraga, Diego Collarana, Maria-Esther Vidal", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In recent years, the amount of data has increased exponentially, and knowledge graphs have gained attention as data structures to integrate data and knowledge harvested from myriad data sources. However, data complexity issues like large volume, high-duplicate rate, and heterogeneity usually characterize these data sources, being required data management tools able to address the impact negatively of these issues on the knowledge graph creation process. In this paper, we propose the SDM-RDFizer, an interpreter of the RDF Mapping Language (RML), to transform raw data in various formats into an RDF knowledge graph. SDM-RDFizer implements novel algorithms to execute the logical operators between mappings in RML, allowing thus to scale up to complex scenarios where data is not only broad but has a high-duplication rate. We empirically evaluate the SDM-RDFizer performance against diverse testbeds with diverse configurations of data volume, duplicates, and heterogeneity. The observed results indicate that SDM-RDFizer is two orders of magnitude faster than state of the art, thus, meaning that SDM-RDFizer an interoperable and scalable solution for knowledge graph creation. SDM-RDFizer is publicly available as a resource through a Github repository and a DOI.", "pdf_url": "https://arxiv.org/pdf/2008.07176", "subject": "Databases (cs.DB)"},
{"title": "Disentangled Item Representation for Recommender Systems", "author": "Zeyu Cui, Feng Yu, Shu Wu, Qiang Liu, Liang Wang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Item representations in recommendation systems are expected to reveal the properties of items. Collaborative recommender methods usually represent an item as one single latent vector. Nowadays the e-commercial platforms provide various kinds of attribute information for items (e.g., category, price and style of clothing). Utilizing these attribute information for better item representations is popular in recent years. Some studies use the given attribute information as side information, which is concatenated with the item latent vector to augment representations. However, the mixed item representations fail to fully exploit the rich attribute information or provide explanation in recommender systems. To this end, we propose a fine-grained Disentangled Item Representation (DIR) for recommender systems in this paper, where the items are represented as several separated attribute vectors instead of a single latent vector. In this way, the items are represented at the attribute level, which can provide fine-grained information of items in recommendation. We introduce a learning strategy, LearnDIR, which can allocate the corresponding attribute vectors to items. We show how DIR can be applied to two typical models, Matrix Factorization (MF) and Recurrent Neural Network (RNN). Experimental results on two real-world datasets show that the models developed under the framework of DIR are effective and efficient. Even using fewer parameters, the proposed model can outperform the state-of-the-art methods, especially in the cold-start situation. In addition, we make visualizations to show that our proposition can provide explanation for users in real-world applications.", "pdf_url": "https://arxiv.org/pdf/2008.07178", "subject": "Information Retrieval (cs.IR)"},
{"title": "Shuffled Model of Federated Learning: Privacy, Communication and Accuracy Trade-offs", "author": "Antonious M. Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, Ananda Theertha Suresh", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We consider a distributed empirical risk minimization (ERM) optimization problem with communication efficiency and privacy requirements, motivated by the federated learning (FL) framework. Unique challenges to the traditional ERM problem in the context of FL include (i) need to provide privacy guarantees on clients' data, (ii) compress the communication between clients and the server, since clients might have low-bandwidth links, (iii) work with a dynamic client population at each round of communication between the server and the clients, as a small fraction of clients are sampled at each round. To address these challenges we develop (optimal) communication-efficient schemes for private mean estimation for several $\\ell_p$ spaces, enabling efficient gradient aggregation for each iteration of the optimization solution of the ERM. We also provide lower and upper bounds for mean estimation with privacy and communication constraints for arbitrary $\\ell_p$ spaces. To get the overall communication, privacy, and optimization performance operation point, we combine this with privacy amplification opportunities inherent to this setup. Our solution takes advantage of the inherent privacy amplification provided by client sampling and data sampling at each client (through Stochastic Gradient Descent) as well as the recently developed privacy framework using anonymization, which effectively presents to the server responses that are randomly shuffled with respect to the clients. Putting these together, we demonstrate that one can get the same privacy, optimization-performance operating point developed in recent methods that use full-precision communication, but at a much lower communication cost, i.e., effectively getting communication efficiency for \"free\".", "pdf_url": "https://arxiv.org/pdf/2008.07180", "subject": "Machine Learning (cs.LG)"},
{"title": "White blood cell classification", "author": "Na Dong, Meng-die Zhai, Jian-fang Chang, Chun-ho Wu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This paper proposes a novel automatic classification framework for the recognition of five types of white blood cells. Segmenting complete white blood cells from blood smears images and extracting advantageous features from them remain challenging tasks in the classification of white blood cells. Therefore, we present an adaptive threshold segmentation method to deal with blood smears images with non-uniform color and uneven illumination, which is designed based on color space information and threshold segmentation. Subsequently, after successfully separating the white blood cell from the blood smear image, a large number of nonlinear features including geometrical, color and texture features are extracted. Nevertheless, redundant features can affect the classification speed and efficiency, and in view of that, a feature selection algorithm based on classification and regression trees (CART) is designed. Through in-depth analysis of the nonlinear relationship between features, the irrelevant and redundant features are successfully removed from the initial nonlinear features. Afterwards, the selected prominent features are fed into particle swarm optimization support vector machine (PSO-SVM) classifier to recognize the types of the white blood cells. Finally, to evaluate the performance of the proposed white blood cell classification methodology, we build a white blood cell data set containing 500 blood smear images for experiments. By comparing with the ground truth obtained manually, the proposed segmentation method achieves an average of 95.98% and 97.57% dice similarity for segmented nucleus and cell regions respectively. Furthermore, the proposed methodology achieves 99.76% classification accuracy, which well demonstrates its effectiveness.", "pdf_url": "https://arxiv.org/pdf/2008.07181", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "CROW: Code Diversification for WebAssembly", "author": "Javier Cabrera Arteaga, Orestis Floros Malivitsis, Oscar Luis Vera P\u00e9rez, Benoit Baudry, Martin Monperrus", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The adoption of WebAssembly has rapidly increased in the last few years as it provides a fast and safe model for program execution. However, WebAssembly is not exempt from vulnerabilities that could be exploited by side channels attacks. This class of vulnerabilities that can be addressed by code diversification. In this paper, we present the first fully automated workflow for the diversification of WebAssembly binaries. We present CROW, an open-source tool implementing this workflow. We evaluate CROW's capabilities on 303 C programs and study its use on a real-life security-sensitive program: libsodium, a cryptographic library. Overall, CROW is able to generate diverse variants for 239 out of 303 (79%) small programs. On libsodium, the execution trace changes up to 83.4%.", "pdf_url": "https://arxiv.org/pdf/2008.07185", "subject": "Software Engineering (cs.SE)"},
{"title": "On the convergence of adaptive stochastic collocation for elliptic partial differential equations with affine diffusion", "author": "Martin Eigel, Oliver Ernst, Bj\u00f6rn Sprungk, Lorenzo Tamellini", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Convergence of an adaptive collocation method for the stationary parametric diffusion equation with finite-dimensional affine coefficient is shown. The adaptive algorithm relies on a recently introduced residual-based reliable a-posteriori error estimator. For the convergence proof, a strategy recently used for a stochastic Galerkin method with an hierarchical error estimator is transferred to the collocation setting.", "pdf_url": "https://arxiv.org/pdf/2008.07186", "subject": "Numerical Analysis (math.NA)"},
{"title": "A near-optimal direct-sum theorem for communication complexity", "author": "Rahul Jain", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We show a near optimal direct-sum theorem for the two-party randomized communication complexity. Let $f\\subseteq X \\times Y\\times Z$ be a relation, $\\varepsilon> 0$ and $k$ be an integer. We show, $$\\mathrm{R}^{\\mathrm{pub}}_\\varepsilon(f^k) \\cdot \\log(\\mathrm{R}^{\\mathrm{pub}}_\\varepsilon(f^k)) \\ge \\Omega(k \\cdot \\mathrm{R}^{\\mathrm{pub}}_\\varepsilon(f)) \\enspace,$$ where $f^k= f \\times \\ldots \\times f$ ($k$-times) and $\\mathrm{R}^{\\mathrm{pub}}_\\varepsilon(\\cdot)$ represents the public-coin randomized communication complexity with worst-case error $\\varepsilon$. Given a protocol $\\mathcal{P}$ for $f^k$ with communication cost $c \\cdot k$ and worst-case error $\\varepsilon$, we exhibit a protocol $\\mathcal{Q}$ for $f$ with external-information-cost $O(c)$ and worst-error $\\varepsilon$. We then use a message compression protocol due to Barak, Braverman, Chen and Rao [2013] for simulating $\\mathcal{Q}$ with communication $O(c \\cdot \\log(c\\cdot k))$ to arrive at our result. To show this reduction we show some new chain-rules for capacity, the maximum information that can be transmitted by a communication channel. We use the powerful concept of Nash-Equilibrium in game-theory, and its existence in suitably defined games, to arrive at the chain-rules for capacity. These chain-rules are of independent interest.", "pdf_url": "https://arxiv.org/pdf/2008.07188", "subject": "Information Theory (cs.IT)"},
{"title": "Comparison of Syntactic Parsers on Biomedical Texts", "author": "Maria Biryukov", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Syntactic parsing is an important step in the automated text analysis which aims at information extraction. Quality of the syntactic parsing determines to a large extent the recall and precision of the text mining results. In this paper we evaluate the performance of several popular syntactic parsers in application to the biomedical text mining.", "pdf_url": "https://arxiv.org/pdf/2008.07189", "subject": "Computation and Language (cs.CL)"},
{"title": "How to Put Users in Control of their Data via Federated Pair-Wise Recommendation", "author": "Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Antonio Ferrara, Fedelucio Narducci", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Recommendation services are extensively adopted in several user-centered applications as a tool to alleviate the information overload problem and help users in orienteering in a vast space of possible choices. In such scenarios, privacy is a crucial concern since users may not be willing to share their sensitive preferences (e.g., visited locations, read books, bought items) with a central server. Unfortunately, data harvesting and collection is at the basis of modern, state-of-the-art approaches to recommendation. Decreased users' willingness to share personal information along with data minimization/protection policies (such as the European GDPR), can result in the \"data scarcity\" dilemma affecting data-intensive applications such as recommender systems (RS). We argue that scarcity of adequate data due to privacy concerns can severely impair the quality of learned models and, in the long term, result in a turnover and disloyal customers with direct consequences for lives, society, and businesses. To address these issues, we present FPL, an architecture in which users collaborate in training a central factorization model while controlling the amount of sensitive data leaving their devices. The proposed approach implements pair-wise learning to rank optimization by following the Federated Learning principles conceived originally to mitigate the privacy risks of traditional machine learning. We have conducted an extensive experimental evaluation on three Foursquare datasets and have verified the effectiveness of the proposed architecture concerning accuracy and beyond-accuracy objectives. We have analyzed the impact of communication cost with the central server on the system's performance, by varying the amount of local computation and training parallelism. Finally, we have carefully examined the impact of disclosed users' information on the quality of the final model and ...", "pdf_url": "https://arxiv.org/pdf/2008.07192", "subject": "Machine Learning (cs.LG)"},
{"title": "LIC-Fusion 2.0: LiDAR-Inertial-Camera Odometry with Sliding-Window Plane-Feature Tracking", "author": "Xingxing Zuo, Yulin Yang, Patrick Geneva, Jiajun Lv, Yong Liu, Guoquan Huang, Marc Pollefeys", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Multi-sensor fusion of multi-modal measurements from commodity inertial, visual and LiDAR sensors to provide robust and accurate 6DOF pose estimation holds great potential in robotics and beyond. In this paper, building upon our prior work (i.e., LIC-Fusion), we develop a sliding-window filter based LiDAR-Inertial-Camera odometry with online spatiotemporal calibration (i.e., LIC-Fusion 2.0), which introduces a novel sliding-window plane-feature tracking for efficiently processing 3D LiDAR point clouds. In particular, after motion compensation for LiDAR points by leveraging IMU data, low-curvature planar points are extracted and tracked across the sliding window. A novel outlier rejection criterion is proposed in the plane-feature tracking for high-quality data association. Only the tracked planar points belonging to the same plane will be used for plane initialization, which makes the plane extraction efficient and robust. Moreover, we perform the observability analysis for the LiDAR-IMU subsystem and report the degenerate cases for spatiotemporal calibration using plane features. While the estimation consistency and identified degenerate motions are validated in Monte-Carlo simulations, different real-world experiments are also conducted to show that the proposed LIC-Fusion 2.0 outperforms its predecessor and other state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2008.07196", "subject": "Robotics (cs.RO)"},
{"title": "Category-Level 3D Non-Rigid Registration from Single-View RGB Images", "author": "Diego Rodriguez, Florian Huber, Sven Behnke", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper, we propose a novel approach to solve the 3D non-rigid registration problem from RGB images using Convolutional Neural Networks (CNNs). Our objective is to find a deformation field (typically used for transferring knowledge between instances, e.g., grasping skills) that warps a given 3D canonical model into a novel instance observed by a single-view RGB image. This is done by training a CNN that infers a deformation field for the visible parts of the canonical model and by employing a learned shape (latent) space for inferring the deformations of the occluded parts. As result of the registration, the observed model is reconstructed. Because our method does not need depth information, it can register objects that are typically hard to perceive with RGB-D sensors, e.g. with transparent or shiny surfaces. Even without depth data, our approach outperforms the Coherent Point Drift (CPD) registration method for the evaluated object categories.", "pdf_url": "https://arxiv.org/pdf/2008.07203", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "PAR: Personal Activity Radius Camera View for Contextual Sensing", "author": "Jessica Maria Echterhoff, Edward J. Wang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Contextual sensing using wearable cameras has seen a variety of different camera angles proposed to capture a wide gamut of different visual scenes. In this paper, we propose a new camera view that aims to capture the same visual information as many of the camera positions and orientations combined from a single camera view point. The camera, mounted on the corner of a glasses frame is pointing downwards towards the floor, a field-of-view we named Personal Activity Radius (PAR). The PAR field-of-view captures the visual information around a wearer's personal bubble, including items they interact with, their body motion, their surrounding environment, etc. In our evaluation, we tested the PAR view's interpretability by human labelers in two different activity tracking scenarios: food related behaviors and exercise tracking. Human labelers achieved an overall high level of precision in identifying body motions in exercise tracking of 91% precision and eating/drinking motions at 96% precision. Item interaction identification reached a precision of 86% precision for labeling grocery categories. We show a high level on the device setup and contextual views we were able to capture with the device. We see that the camera wide angle captures different activities such as driving, shopping, gym exercises, walking and eating and can observe the specific interaction item of the user as well as the immediate contextual surrounding.", "pdf_url": "https://arxiv.org/pdf/2008.07204", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Moment-to-moment Engagement Prediction through the Eyes of the Observer: PUBG Streaming on Twitch", "author": "David Melhart, Daniele Gravina, Georgios N. Yannakakis", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Is it possible to predict moment-to-moment gameplay engagement based solely on game telemetry? Can we reveal engaging moments of gameplay by observing the way the viewers of the game behave? To address these questions in this paper, we reframe the way gameplay engagement is defined and we view it, instead, through the eyes of a game's live audience. We build prediction models for viewers' engagement based on data collected from the popular battle royale game PlayerUnknown's Battlegrounds as obtained from the Twitch streaming service. In particular, we collect viewers' chat logs and in-game telemetry data from several hundred matches of five popular streamers (containing over 100,000 game events) and machine learn the mapping between gameplay and viewer chat frequency during play, using small neural network architectures. Our key findings showcase that engagement models trained solely on 40 gameplay features can reach accuracies of up to 80% on average and 84% at best. Our models are scalable and generalisable as they perform equally well within- and across-streamers, as well as across streamer play styles.", "pdf_url": "https://arxiv.org/pdf/2008.07207", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Optimal minimal Linear codes from posets", "author": "Jong Yoon Hyun, Hyun Kwang Kim, Yansheng Wu, Qin Yue", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Recently, some infinite families of minimal and optimal binary linear codes were constructed from simplicial complexes by Hyun {\\em et al.} We extend this construction method to arbitrary posets. Especially, anti-chains are corresponded to simplicial complexes. In this paper, we present two constructions of binary linear codes from hierarchical posets of two levels. In particular, we determine the weight distributions of binary linear codes associated with hierarchical posets with two levels. Based on these results, we also obtain some optimal and minimal binary linear codes not satisfying the condition of Ashikhmin-Barg.", "pdf_url": "https://arxiv.org/pdf/2008.07212", "subject": "Information Theory (cs.IT)"},
{"title": "Algorithm for SIS and MultiSIS problems", "author": "Igor Semaev", "pub_date": "Submitted on 17 Aug 2020", "abstract": "SIS problem has numerous applications in cryptography. Known algorithms for solving that problem are exponential in complexity. A new algorithm is suggested in this note, its complexity is sub-exponential for a range of parameters.", "pdf_url": "https://arxiv.org/pdf/2008.07216", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Structure preserving discretization of time-reparametrized Hamiltonian systems with application to nonholonomic mechanics", "author": "Luis C. Garc\u00eda-Naranjo, Mats Vermeeren", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We propose a discretization of vector fields that are Hamiltonian up to multiplication by a positive function on the phase space that may be interpreted as a time reparametrization. We prove that our method is structure preserving in the sense that the discrete flow is interpolated to arbitrary order by the flow of a continuous system possessing the same structure. In particular, our discretization preserves a smooth measure on the phase space to arbitrary order. We present applications to a remarkable class of nonholonomic mechanical systems that allow Hamiltonization. To our best knowledge, these results provide the first occurrence in the literature of a measure preserving discretization of measure preserving nonholonomic systems.", "pdf_url": "https://arxiv.org/pdf/2008.07222", "subject": "Numerical Analysis (math.NA)"},
{"title": "Privacy-Preserving Distributed Learning Framework for 6G Telecom Ecosystems", "author": "Pooyan Safari, Behnam Shariati, Johannes Karl Fischer", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We present a privacy-preserving distributed learning framework for telecom ecosystems in the 6G-era that enables the vision of shared ownership and governance of ML models, while protecting the privacy of the data owners. We demonstrate its benefits by applying it to the use-case of Quality of Transmission (QoT) estimation in multi-domain multi-vendor optical networks, where no data of individual domains is shared with the network management system (NMS).", "pdf_url": "https://arxiv.org/pdf/2008.07225", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Exploring Longitudinal Effects of Session-based Recommendations", "author": "Andres Ferraro, Dietmar Jannach, Xavier Serra", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Session-based recommendation is a problem setting where the task of a recommender system is to make suitable item suggestions based only on a few observed user interactions in an ongoing session. The lack of long-term preference information about individual users in such settings usually results in a limited level of personalization, where a small set of popular items may be recommended to many users. This repeated exposure of such a subset of the items through the recommendations may in turn lead to a reinforcement effect over time, and to a system which is not able to help users discover new content anymore to the desirable extent. In this work, we investigate such potential longitudinal effects of session-based recommendations in a simulation-based approach. Specifically, we analyze to what extent algorithms of different types may lead to concentration effects over time. Our experiments in the music domain reveal that all investigated algorithms---both neural and heuristic ones---may lead to lower item coverage and to a higher concentration on a subset of the items. Additional simulation experiments however also indicate that relatively simple re-ranking strategies, e.g., by avoiding too many repeated recommendations in the music domain, may help to deal with this problem.", "pdf_url": "https://arxiv.org/pdf/2008.07226", "subject": "Information Retrieval (cs.IR)"},
{"title": "What Makes a Data-GIF Understandable?", "author": "Xinhuan Shu, Aoyu Wu, Junxiu Tang, Benjamin Bach, Yingcai Wu, Huamin Qu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "GIFs are enjoying increasing popularity on social media as a format for data-driven storytelling with visualization; simple visual messages are embedded in short animations that usually last less than 15 seconds and are played in automatic repetition. In this paper, we ask the question, \"What makes a data-GIF understandable?\" While other storytelling formats such as data videos, infographics, or data comics are relatively well studied, we have little knowledge about the design factors and principles for \"data-GIFs\". To close this gap, we provide results from semi-structured interviews and an online study with a total of 118 participants investigating the impact of design decisions on the understandability of data-GIFs. The study and our consequent analysis are informed by a systematic review and structured design space of 108 data-GIFs that we found online. Our results show the impact of design dimensions from our design space such as animation encoding, context preservation, or repetition on viewers' understanding of the GIF's core message. The paper concludes with a list of suggestions for creating more effective Data-GIFs.", "pdf_url": "https://arxiv.org/pdf/2008.07227", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Multi-label Learning with Missing Values using Combined Facial Action Unit Datasets", "author": "Jaspar Pahl, Ines Rieger, Dominik Seuss", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Facial action units allow an objective, standardized description of facial micro movements which can be used to describe emotions in human faces. Annotating data for action units is an expensive and time-consuming task, which leads to a scarce data situation. By combining multiple datasets from different studies, the amount of training data for a machine learning algorithm can be increased in order to create robust models for automated, multi-label action unit detection. However, every study annotates different action units, leading to a tremendous amount of missing labels in a combined database. In this work, we examine this challenge and present our approach to create a combined database and an algorithm capable of learning under the presence of missing labels without inferring their values. Our approach shows competitive performance compared to recent competitions in action unit detection.", "pdf_url": "https://arxiv.org/pdf/2008.07234", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Survey of Deep Learning for Data Caching in Edge Network", "author": "Yantong Wang, Vasilis Friderikos", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The concept of edge caching provision in emerging 5G and beyond mobile networks is a promising method to deal both with the traffic congestion problem in the core network as well as reducing latency to access popular content. In that respect end user demand for popular content can be satisfied by proactively caching it at the network edge, i.e, at close proximity to the users. In addition to model based caching schemes learning-based edge caching optimizations has recently attracted significant attention and the aim hereafter is to capture these recent advances for both model based and data driven techniques in the area of proactive caching. This paper summarizes the utilization of deep learning for data caching in edge network. We first outline the typical research topics in content caching and formulate a taxonomy based on network hierarchical structure. Then, a number of key types of deep learning algorithms are presented, ranging from supervised learning to unsupervised learning as well as reinforcement learning. Furthermore, a comparison of state-of-the-art literature is provided from the aspects of caching topics and deep learning methods. Finally, we discuss research challenges and future directions of applying deep learning for caching", "pdf_url": "https://arxiv.org/pdf/2008.07235", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "On codes decoding a constant fraction of errors on the BSC", "author": "Alex Samorodnitsky, Ori Sberlo", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Using techniques and results from Kudekar et al. we strengthen the bounds on the weight distribution of linear codes achieving capacity on the BEC, which were shown by the first author. In particular, we show that for any doubly transitive binary linear code $C \\subseteq \\{0,1\\}^n$ of rate $0 < R < 1$ with weight distribution $\\left(a_0,...,a_n\\right)$ holds $a_i \\le 2^{o(n)} \\cdot (1-R)^{-2 \\ln 2 \\cdot \\min\\{i, n-i\\}}$. For doubly transitive codes with minimal distance at least $\\Omega\\left(n^c\\right)$, $0 < c \\le 1$, the error factor of $2^{o(n)}$ in this bound can be removed at the cost of replacing $1-R$ with a smaller constant $a = a(R,c) < 1- R$. Moreover, in the special case of Reed-Muller codes, due to the additional symmetries of these codes, this error factor can be removed at essentially no cost. This implies that for any doubly transitive code $C$ of rate $R$ with minimal distance at least $\\Omega\\left(n^c\\right)$, there exists a positive constant $p = p(R,c)$ such that $C$ decodes errors on $\\mathrm{BSC}(p)$ with high probability if $p < p(R,c)$. For doubly transitive codes of a sufficiently low rate (smaller than some absolute constant) the requirement on the minimal distance can be omitted, and hence this critical probability $p(R)$ depends only on $R$. Furthermore, $p(R) \\rightarrow \\frac12$ as $R \\rightarrow 0$. In particular, a Reed-Muller code $C$ of rate $R$ decodes errors on $\\mathrm{BSC}(p)$ with high probability if \\[ R ~<~ 1 - \\big(4p(1-p)\\big)^{\\frac{1}{4 \\ln 2}}, \\] answering a question of Abbe, Hazla, and Nachum.", "pdf_url": "https://arxiv.org/pdf/2008.07236", "subject": "Information Theory (cs.IT)"},
{"title": "Model-Reference Reinforcement Learning for Collision-Free Tracking Control of Autonomous Surface Vehicles", "author": "Qingrui Zhang, Wei Pan, Vasso Reppa", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This paper presents a novel model-reference reinforcement learning algorithm for the intelligent tracking control of uncertain autonomous surface vehicles with collision avoidance. The proposed control algorithm combines a conventional control method with reinforcement learning to enhance control accuracy and intelligence. In the proposed control design, a nominal system is considered for the design of a baseline tracking controller using a conventional control approach. The nominal system also defines the desired behaviour of uncertain autonomous surface vehicles in an obstacle-free environment. Thanks to reinforcement learning, the overall tracking controller is capable of compensating for model uncertainties and achieving collision avoidance at the same time in environments with obstacles. In comparison to traditional deep reinforcement learning methods, our proposed learning-based control can provide stability guarantees and better sample efficiency. We demonstrate the performance of the new algorithm using an example of autonomous surface vehicles.", "pdf_url": "https://arxiv.org/pdf/2008.07240", "subject": "Systems and Control (eess.SY)"},
{"title": "Exploring the weather impact on bike sharing usage through a clustering analysis", "author": "Jessica Quach, Reza Malekian", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Bike sharing systems (BSS) have been a popular traveling service for years and are used worldwide. It is attractive for cities and users who wants to promote healthier lifestyles; to reduce air pollution and greenhouse gas emission as well as improve traffic. One major challenge to docked bike sharing system is redistributing bikes and balancing dock stations. Some studies propose models that can help forecasting bike usage; strategies for rebalancing bike distribution; establish patterns or how to identify patterns. Other studies propose to extend the approach by including weather data. This study aims to extend upon these proposals and opportunities to explore how and in what magnitude weather impacts bike usage. Bike usage data and weather data are gathered for the city of Washington D.C. and are analyzed using k-means clustering algorithm. K-means managed to identify three clusters that correspond to bike usage depending on weather conditions. The results show that the weather impact on bike usage was noticeable between clusters. It showed that temperature followed by precipitation weighted the most, out of five weather variables.", "pdf_url": "https://arxiv.org/pdf/2008.07249", "subject": "Machine Learning (cs.LG)"},
{"title": "W[1]-Hardness of the k-Center Problem Parameterized by the Skeleton Dimension", "author": "Johannes Blum", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In the $k$-Center problem, we are given a graph $G=(V,E)$ with positive edge weights and an integer $k$ and the goal is to select $k$ center vertices $C \\subseteq V$ such that the maximum distance from any vertex to the closest center vertex is minimized. On general graphs, the problem is NP-hard and cannot be approximated within a factor less than $2$. Typical applications of the $k$-Center problem can be found in logistics or urban planning and hence, it is natural to study the problem on transportation networks. Such networks are often characterized as graphs that are (almost) planar or have low doubling dimension, highway dimension or skeleton dimension. It was shown by Feldmann and Marx that $k$-Center is W[1]-hard on planar graphs of constant doubling dimension when parameterized by the number of centers $k$, the highway dimension $hd$ and the pathwidth $pw$. We extend their result and show that even if we additionally parameterize by the skeleton dimension $\\kappa$, the $k$-Center problem remains W[1]-hard. Moreover, we prove that under the Exponential Time Hypothesis there is no exact algorithm for $k$-Center that has runtime $f(k,hd,pw,\\kappa) \\cdot \\vert V \\vert^{o(pw + \\kappa + \\sqrt{k+hd})}$ for any computable function $f$.", "pdf_url": "https://arxiv.org/pdf/2008.07252", "subject": "Computational Complexity (cs.CC)"},
{"title": "An Improved Dilated Convolutional Network for Herd Counting in Crowded Scenes", "author": "Soufien Hamrouni, Hakim Ghazzai, Hamid Menouar, Yahya Massoud", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Crowd management technologies that leverage computer vision are widespread in contemporary times. There exists many security-related applications of these methods, including, but not limited to: following the flow of an array of people and monitoring large gatherings. In this paper, we propose an accurate monitoring system composed of two concatenated convolutional deep learning architectures. The first part called Front-end, is responsible for converting bi-dimensional signals and delivering high-level features. The second part, called the Back-end, is a dilated Convolutional Neural Network (CNN) used to replace pooling layers. It is responsible for enlarging the receptive field of the whole network and converting the descriptors provided by the first network to a saliency map that will be utilized to estimate the number of people in highly congested images. We also propose to utilize a genetic algorithm in order to find an optimized dilation rate configuration in the back-end. The proposed model is shown to converge 30\\% faster than state-of-the-art approaches. It is also shown that it achieves 20\\% lower Mean Absolute Error (MAE) when applied to the Shanghai data~set.", "pdf_url": "https://arxiv.org/pdf/2008.07254", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Research on Survivability Strategies of Virtual Network", "author": "Subhadeep Sahoo", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Virtualization facilitates heterogeneous cloud applications to share the same physical infrastructure with admirable flexibility, while resource efficiency and survivability are critical concerns for virtual network embedding (VNE). As more and more internet applications migrate to the cloud, the resource efficiency and the survivability of VNs, such as single link failure or large-scale disaster survivability, have become crucial issues. Separating the VNE problem into node and link mapping sub-problems without coordination might cause a high embedding cost. This dissertation presents two independent approaches to solve the aforementioned challenges. First, we study two-stage coordinated survivable VNE (SVNE) problem and propose an adaptive path splitting based SVNE (APSS) scheme. We first develop a concise anchor node strategy to restrict the solution space of the candidate substrate nodes, which coordinates node mapping with link mapping to limit the distance spans of the virtual links. Then, we employ an adaptive path splitting policy to provide full protection against single-link failures with partial backup resource, and design an agile frequency slot windows choosing mechanism to mitigate the spectrum fragmentation for link resource efficiency. Simulation results demonstrate that the proposed APSS scheme can achieve satisfactory performance in terms of spectrum utilization and blocking ratio. Second, we propose a synchronous evacuation strategy for VNs with dual virtual machines (VMs) inside a disaster risk zone (DRZ), which suffer higher risks than the VNs with single. The evacuation strategy exploits post-copy technique to sustain the online service alive and enhances synchronous VM migrations to shorten the dual-VM evacuation time. Numerical results show that the proposed strategy can outperform the best-effort scheme in terms of average and total evacuation times of dual-VMs.", "pdf_url": "https://arxiv.org/pdf/2008.07255", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "An Isolated Data Island Benchmark Suite for Federated Learning", "author": "Yuan Liang, Yange Guo, Yanxia Gong, Chunjie Luo, Jianfeng Zhan, Yunyou Huang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Federated learning (FL) is a new machine learning paradigm, the goal of which is to build a machine learning model based on data sets distributed on multiple devices--so called Isolated Data Island--while keeping their data secure and private. Most existing work manually splits commonly-used public datasets into partitions to simulate real-world Isolated Data Island while failing to capture the intrinsic characteristics of real-world domain data, like medicine, finance or AIoT. To bridge this huge gap, this paper presents and characterizes an Isolated Data Island benchmark suite, named FLBench, for benchmarking federated learning algorithms. FLBench contains three domains: medical, financial and AIoT. By configuring various domains, FLBench is qualified for evaluating the important research aspects of federated learning, and hence become a promising platform for developing novel federated learning algorithms. Finally, FLBench is fully open-sourced and in fast-evolution. We package it as an automated deployment tool. The benchmark suite will be publicly available from .", "pdf_url": "https://arxiv.org/pdf/2008.07257", "subject": "Machine Learning (cs.LG)"},
{"title": "BUT-FIT at SemEval-2020 Task 4: Multilingual commonsense", "author": "Josef Jon, Martin Faj\u010d\u00edk, Martin Do\u010dekal, Pavel Smr\u017e", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This paper describes work of the BUT-FIT's team at SemEval 2020 Task 4 - Commonsense Validation and Explanation. We participated in all three subtasks. In subtasks A and B, our submissions are based on pretrained language representation models (namely ALBERT) and data augmentation. We experimented with solving the task for another language, Czech, by means of multilingual models and machine translated dataset, or translated model inputs. We show that with a strong machine translation system, our system can be used in another language with a small accuracy loss. In subtask C, our submission, which is based on pretrained sequence-to-sequence model (BART), ranked 1st in BLEU score ranking, however, we show that the correlation between BLEU and human evaluation, in which our submission ended up 4th, is low. We analyse the metrics used in the evaluation and we propose an additional score based on model from subtask B, which correlates well with our manual ranking, as well as reranking method based on the same principle. We performed an error and dataset analysis for all subtasks and we present our findings.", "pdf_url": "https://arxiv.org/pdf/2008.07259", "subject": "Computation and Language (cs.CL)"},
{"title": "Temporal Conformance Checking at Runtime based on Time-infused Process Models", "author": "Florian Stertz, Juergen Mangler, Stefanie Rinderle-Ma", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Conformance checking quantifies the deviations between a set of traces in a given process log and a set of possible traces defined by a process model. Current approaches mostly focus on added or missing events. Lately, multi-perspective mining has provided means to check for conformance with time and resource constraints encoded as data elements. This paper presents an approach for quantifying temporal deviations in conformance checking based on infusing the input process model with a temporal profile. The temporal profile is calculated based on an associated process log considering task durations and the temporal distance between events. Moreover, a simple semantic annotation on tasks in the process model signifies their importance with respect to time. During runtime, deviations between an event stream and the process model with the temporal profile are quantified through a cost function for temporal deviations. The evaluation of the approach shows that the results for two real-world data sets from the financial and a manufacturing domain hold the promise to improve runtime process monitoring and control capabilities.", "pdf_url": "https://arxiv.org/pdf/2008.07262", "subject": "Software Engineering (cs.SE)"},
{"title": "A Survey of Active Learning for Text Classification using Deep Neural Networks", "author": "Christopher Schr\u00f6der, Andreas Niekler", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Natural language processing (NLP) and neural networks (NNs) have both undergone significant changes in recent years. For active learning (AL) purposes, NNs are, however, less commonly used -- despite their current popularity. By using the superior text classification performance of NNs for AL, we can either increase a model's performance using the same amount of data or reduce the data and therefore the required annotation efforts while keeping the same performance. We review AL for text classification using deep neural networks (DNNs) and elaborate on two main causes which used to hinder the adoption: (a) the inability of NNs to provide reliable uncertainty estimates, on which the most commonly used query strategies rely, and (b) the challenge of training DNNs on small data. To investigate the former, we construct a taxonomy of query strategies, which distinguishes between data-based, model-based, and prediction-based instance selection, and investigate the prevalence of these classes in recent research. Moreover, we review recent NN-based advances in NLP like word embeddings or language models in the context of (D)NNs, survey the current state-of-the-art at the intersection of AL, text classification, and DNNs and relate recent advances in NLP to AL. Finally, we analyze recent work in AL for text classification, connect the respective query strategies to the taxonomy, and outline commonalities and shortcomings. As a result, we highlight gaps in current research and present open research questions.", "pdf_url": "https://arxiv.org/pdf/2008.07267", "subject": "Computation and Language (cs.CL)"},
{"title": "Building a Framework for Indigenous Astronomy Collaboration: Native Skywatchers, Indigenous Scientific Knowledge Systems, and The Bell Museum", "author": "Annette S. Lee, Sally Brummel, Kaitlin Ehret, Sarah Komperud, Thaddeus LaCoursiere", "pub_date": "Submitted on 12 Aug 2020", "abstract": "Hundreds of years ago, colonization happened. Today we are still living out the ripple effects of this history. How does this relate to science, informal science education, and institutions that promote science communication? What obligations or considerations should a science museum have before integrating Indigenous knowledge into their existing programming? Presented in this document is the process of building a framework intended to provide a roadmap for developing Indigenous astronomy programming which can be a model for other institutions that may be interested in collaborating with Indigenous communities.", "pdf_url": "https://arxiv.org/pdf/2008.07270", "subject": "Computers and Society (cs.CY)"},
{"title": "Why a computer program is a functional whole", "author": "C. Maria Keet", "pub_date": "Submitted on 21 Jul 2020", "abstract": "Sharing, downloading, and reusing software is common-place, some of which is carried out legally with open source software. When it is not legal, it is unclear just how many copyright infringements and trade secret violations have taken place: does an infringement count for the artefact as a whole or perhaps for each file of the program? To answer this question, it must first be established whether a program should be considered as an integral whole, a collection, or a mere set of distinct files, and why. We argue that a program is a functional whole, availing of, and combining, arguments from mereology, granularity, modularity, unity, and function to substantiate the claim. The argumentation and answer contributes to the ontology of software artefacts, may assist industry in litigation cases, and demonstrates that the notion of unifying relation is operationalisable. Indirectly, it provides support for continued modular design of artefacts following established engineering practices.", "pdf_url": "https://arxiv.org/pdf/2008.07273", "subject": "Computers and Society (cs.CY)"},
{"title": "mHealth Strategy to Fight Tuberculosis in Bangladesh", "author": "Md Monzur Morshed", "pub_date": "Submitted on 15 Jul 2020", "abstract": "Bangladesh is one of the high TB burden countries in the world and TB is still a major public health problem in the country. To eradicate TB in Bangladesh and to ensure proper monitoring and better health care service, digital interventions may play a pivotal role. Over the years Bangladesh Government has been actively working to hold a control over TB with the help of donors, local and international NGOs. For sustainability there has been a need to develop mHealth strategy for Bangladesh to align with the Digital Bangladesh Vision 2021.", "pdf_url": "https://arxiv.org/pdf/2008.07274", "subject": "Computers and Society (cs.CY)"},
{"title": "Facial Recognition: A cross-national Survey on Public Acceptance, Privacy, and Discrimination", "author": "L\u00e9a Steinacker, Miriam Meckel, Genia Kostka, Damian Borth", "pub_date": "Submitted on 15 Jul 2020", "abstract": "With rapid advances in machine learning (ML), more of this technology is being deployed into the real world interacting with us and our environment. One of the most widely applied application of ML is facial recognition as it is running on millions of devices. While being useful for some people, others perceive it as a threat when used by public authorities. This discrepancy and the lack of policy increases the uncertainty in the ML community about the future direction of facial recognition research and development. In this paper we present results from a cross-national survey about public acceptance, privacy, and discrimination of the use of facial recognition technology (FRT) in the public. This study provides insights about the opinion towards FRT from China, Germany, the United Kingdom (UK), and the United States (US), which can serve as input for policy makers and legal regulators.", "pdf_url": "https://arxiv.org/pdf/2008.07275", "subject": "Computers and Society (cs.CY)"},
{"title": "A Standardized Radiograph-Agnostic Framework and Platform For Evaluating AI Radiological Systems", "author": "Darlington Ahiale Akogo", "pub_date": "Submitted on 3 Aug 2020", "abstract": "Radiology has been essential to accurately diagnosing diseases and assessing responses to treatment. The challenge however lies in the shortage of radiologists globally. As a response to this, a number of Artificial Intelligence solutions are being developed. The challenge Artificial Intelligence radiological solutions however face is the lack of a benchmarking and evaluation standard, and the difficulties of collecting diverse data to truly assess the ability of such systems to generalise and properly handle edge cases. We are proposing a radiograph-agnostic platform and framework that would allow any Artificial Intelligence radiological solution to be assessed on its ability to generalise across diverse geographical location, gender and age groups.", "pdf_url": "https://arxiv.org/pdf/2008.07276", "subject": "Computers and Society (cs.CY)"},
{"title": "Adaptive Multi-level Hyper-gradient Descent", "author": "Renlong Jie, Junbin Gao, Andrey Vasnev, Minh-Ngoc Tran", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Adaptive learning rates can lead to faster convergence and better final performance for deep learning models. There are several widely known human-designed adaptive optimizers such as Adam and RMSProp, gradient based adaptive methods such as hyper-descent and L4, and meta learning approaches including learning to learn. However, the issue of balancing adaptiveness and over-parameterization is still a topic to be addressed. In this study, we investigate different levels of learning rate adaptation based on the framework of hyper-gradient descent, and further propose a method that adaptively learns the model parameters for combining different levels of adaptations. Meanwhile, we show the relationship between adding regularization on over-parameterized learning rates and building combinations of different levels of adaptive learning rates. The experiments on several network architectures including feed-forward networks, LeNet-5 and ResNet-34 show that the proposed multi-level adaptive approach can outperform baseline adaptive methods in a variety circumstances with statistical significance.", "pdf_url": "https://arxiv.org/pdf/2008.07277", "subject": "Machine Learning (cs.LG)"},
{"title": "Machine Learning in Population and Public Health", "author": "Vishwali Mhasawade, Yuan Zhao, Rumi Chunara", "pub_date": "Submitted on 21 Jul 2020", "abstract": "Research in population and public health focuses on the mechanisms between different cultural, social, and environmental factors and their effect on the health, of not just individuals, but communities as a whole. We present here a very brief introduction into research in these fields, as well as connections to existing machine learning work to help activate the machine learning community on such topics and highlight specific opportunities where machine learning, public and population health may synergize to better achieve health equity.", "pdf_url": "https://arxiv.org/pdf/2008.07278", "subject": "Computers and Society (cs.CY)"},
{"title": "Assessing Viewer's Mental Health by Detecting Depression in YouTube Videos", "author": "Shanya Sharma, Manan Dey", "pub_date": "Submitted on 29 Jul 2020", "abstract": "Depression is one of the most prevalent mental health issues around the world, proving to be one of the leading causes of suicide and placing large economic burdens on families and society. In this paper, we develop and test the efficacy of machine learning techniques applied to the content of YouTube videos captured through their transcripts and determine if the videos are depressive or have a depressing trigger. Our model can detect depressive videos with an accuracy of 83%. We also introduce a real-life evaluation technique to validate our classification based on the comments posted on a video by calculating the CES-D scores of the comments. This work conforms greatly with the UN Sustainable Goal of ensuring Good Health and Well Being with major conformity with section UN SDG 3.4.", "pdf_url": "https://arxiv.org/pdf/2008.07280", "subject": "Computers and Society (cs.CY)"},
{"title": "Imitation learning based on entropy-regularized forward and inverse reinforcement learning", "author": "Eiji Uchibe, Kenji Doya", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This paper proposes Entropy-Regularized Imitation Learning (ERIL), which is a combination of forward and inverse reinforcement learning under the framework of the entropy-regularized Markov decision process. ERIL minimizes the reverse Kullback-Leibler (KL) divergence between two probability distributions induced by a learner and an expert. Inverse reinforcement learning (RL) in ERIL evaluates the log-ratio between two distributions using the density ratio trick, which is widely used in generative adversarial networks. More specifically, the log-ratio is estimated by building two binary discriminators. The first discriminator is a state-only function, and it tries to distinguish the state generated by the forward RL step from the expert's state. The second discriminator is a function of current state, action, and transitioned state, and it distinguishes the generated experiences from the ones provided by the expert. Since the second discriminator has the same hyperparameters of the forward RL step, it can be used to control the discriminator's ability. The forward RL minimizes the reverse KL estimated by the inverse RL. We show that minimizing the reverse KL divergence is equivalent to finding an optimal policy under entropy regularization. Consequently, a new policy is derived from an algorithm that resembles Dynamic Policy Programming and Soft Actor-Critic. Our experimental results on MuJoCo-simulated environments show that ERIL is more sample-efficient than such previous methods. We further apply the method to human behaviors in performing a pole-balancing task and show that the estimated reward functions show how every subject achieves the goal.", "pdf_url": "https://arxiv.org/pdf/2008.07284", "subject": "Machine Learning (cs.LG)"},
{"title": "Modelo de Evaluaci\u00f3n T\u00e9cnico-Econ\u00f3mica de Tecnolog\u00edas de Acceso / Model for Techno-Economic Assessment of Access Technologies. Doctoral Dissertation for PhD, Telecommunications Engineering (EECS)", "author": "Carlos Bendicho", "pub_date": "Submitted on 27 Jul 2020", "abstract": "This doctoral dissertation shows State of the Art of techno-economic modeling for access network technologies, presents the characteristics a universal techno-economic model should have, and shows a classification and analysis of techno-economic models in the literature based on such characteristics. As a result of his research in this direction, the author defines and develops a Universal Techno-Economic Model called UTEM and the corresponding methodology to industrialize techno-economic assessment in multiple domains considering all market players perspectives, also suitable for technological consulting and currently available for all industry stakeholders under specific licence of use. -- Esta tesis doctoral presenta el Estado del Arte de la modelizaci\u00f3n t\u00e9cnico-econ\u00f3mica para tecnolog\u00edas de redes de acceso, define las caracter\u00edsticas que debe tener un modelo t\u00e9cnico-econ\u00f3mico universal y muestra una clasificaci\u00f3n y an\u00e1lisis de modelos t\u00e9cnico-econ\u00f3micos en la literatura basada en tales caracter\u00edsticas. Como resultado de su investigaci\u00f3n en este sentido, el autor define y desarrolla un modelo t\u00e9cnico-econ\u00f3mico universal llamado UTEM y la metodolog\u00eda correspondiente para industrializar la evaluaci\u00f3n t\u00e9cnico-econ\u00f3mica en m\u00faltiples dominios considerando todas las perspectivas de los diferentes actores del mercado, adecuado tambi\u00e9n para consultor\u00eda tecnol\u00f3gica y disponible actualmente para todos los grupos de inter\u00e9s de la industria bajo una licencia de uso espec\u00edfica.", "pdf_url": "https://arxiv.org/pdf/2008.07286", "subject": "Computers and Society (cs.CY)"},
{"title": "Commercial Cloud Computing for Connected Vehicle Applications in Transportation Cyber-Physical Systems", "author": "Hsien-Wen Deng, Mizanur Rahman, Mashrur Chowdhury, M Sabbir Salek, Mitch Shue", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This study focuses on the feasibility of commercial cloud services for connected vehicle (CV) applications in a Transportation Cyber-Physical Systems (TCPS) environment. TCPS implies that CVs, in addition to being connected with each other, communicates with the transportation and computing infrastructure to fulfill application requirements. The motivation of this study is to accelerate commercial cloud-based CV application development by presenting the lessons learned by implementing a CV mobility application using Amazon Web Services (AWS). The feasibility of the cloud-based CV application is assessed at three levels: (i) the development of a cloud-based TCPS architecture, (ii) the deployment of a cloud-based CV application using AWS, and (iii) the evaluation of the cloud-based CV application. We implemented this CV mobility application using a serverless cloud architecture and found that such a cloud-based TCPS environment could meet the permissible delay limits of CV mobility applications. Commercial cloud services, as an integral part of TCPS, could reduce costs associated with establishing and maintaining vast computing infrastructure for supporting CV applications. As the CV penetration levels on the surface transportation systems increase significantly over the next several years, scaling the backend infrastructure to support such applications is a critical issue. This study shows how commercial cloud services could automatically scale the backend infrastructure to meet the rapidly changing demands of real-world CV applications. Through real-world experiments, we demonstrate how commercial cloud services along with serverless cloud architecture could advance the transportation digital infrastructure for supporting connected mobility applications in a TCPS environment.", "pdf_url": "https://arxiv.org/pdf/2008.07290", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Evaluating for Diversity in Question Generation over Text", "author": "Michael Sejr Schlichtkrull, Weiwei Cheng", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Generating diverse and relevant questions over text is a task with widespread applications. We argue that commonly-used evaluation metrics such as BLEU and METEOR are not suitable for this task due to the inherent diversity of reference questions, and propose a scheme for extending conventional metrics to reflect diversity. We furthermore propose a variational encoder-decoder model for this task. We show through automatic and human evaluation that our variational model improves diversity without loss of quality, and demonstrate how our evaluation scheme reflects this improvement.", "pdf_url": "https://arxiv.org/pdf/2008.07291", "subject": "Computation and Language (cs.CL)"},
{"title": "A classical-logic view of a paraconsistent logic", "author": "C. A. Middelburg", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This paper is concerned with the first-order paraconsistent logic LPQ$^{\\supset,\\mathsf{F}}$. A sequent-style natural deduction proof system for this logic is given and, for this proof system, both a model-theoretic justification and a logical justification by means of an embedding into first-order classical logic is presented. For no logic that is essentially the same as LPQ$^{\\supset,\\mathsf{F}}$, a natural deduction proof system is currently available in the literature. The presented embedding provides both a classical-logic explanation of this logic and a logical justification of its proof system.", "pdf_url": "https://arxiv.org/pdf/2008.07292", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "AP-Loss for Accurate One-Stage Object Detection", "author": "Kean Chen, Weiyao Lin, Jianguo Li, John See, Ji Wang, Junni Zou", "pub_date": "Submitted on 17 Aug 2020", "abstract": "One-stage object detectors are trained by optimizing classification-loss and localization-loss simultaneously, with the former suffering much from extreme foreground-background class imbalance issue due to the large number of anchors. This paper alleviates this issue by proposing a novel framework to replace the classification task in one-stage detectors with a ranking task, and adopting the Average-Precision loss (AP-loss) for the ranking problem. Due to its non-differentiability and non-convexity, the AP-loss cannot be optimized directly. For this purpose, we develop a novel optimization algorithm, which seamlessly combines the error-driven update scheme in perceptron learning and backpropagation algorithm in deep networks. We provide in-depth analyses on the good convergence property and computational complexity of the proposed algorithm, both theoretically and empirically. Experimental results demonstrate notable improvement in addressing the imbalance issue in object detection over existing AP-based optimization algorithms. An improved state-of-the-art performance is achieved in one-stage detectors based on AP-loss over detectors using classification-losses on various standard benchmarks. The proposed framework is also highly versatile in accommodating different network architectures. Code is available at .", "pdf_url": "https://arxiv.org/pdf/2008.07294", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "WAFFLE: Watermarking in Federated Learning", "author": "Buse Gul Atli, Yuxi Xia, Samuel Marchal, N. Asokan", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Creators of machine learning models can use watermarking as a technique to demonstrate their ownership if their models are stolen. Several recent proposals watermark deep neural network (DNN) models using backdooring: training them with additional mislabeled data. Backdooring requires full access to the training data and control of the training process. This is feasible when a single party trains the model in a centralized manner, but not in a federated learning setting where the training process and training data are distributed among several parties. In this paper, we introduce WAFFLE, the first approach to watermark DNN models in federated learning. It introduces a re-training step after each aggregation of local models into the global model. We show that WAFFLE efficiently embeds a resilient watermark into models with a negligible test accuracy degradation (-0.17%), and does not require access to the training data. We introduce a novel technique to generate the backdoor used as a watermark. It outperforms prior techniques, imposing no communication, and low computational(+2.8%) overhead.", "pdf_url": "https://arxiv.org/pdf/2008.07298", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Visual Analytics for Temporal Hypergraph Model Exploration", "author": "Maximilian T. Fischer, Devanshu Arya, Dirk Streeb, Daniel Seebacher, Daniel A. Keim, Marcel Worring", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Many processes, from gene interaction in biology to computer networks to social media, can be modeled more precisely as temporal hypergraphs than by regular graphs. This is because hypergraphs generalize graphs by extending edges to connect any number of vertices, allowing complex relationships to be described more accurately and predict their behavior over time. However, the interactive exploration and seamless refinement of such hypergraph-based prediction models still pose a major challenge. We contribute Hyper-Matrix, a novel visual analytics technique that addresses this challenge through a tight coupling between machine-learning and interactive visualizations. In particular, the technique incorporates a geometric deep learning model as a blueprint for problem-specific models while integrating visualizations for graph-based and category-based data with a novel combination of interactions for an effective user-driven exploration of hypergraph models. To eliminate demanding context switches and ensure scalability, our matrix-based visualization provides drill-down capabilities across multiple levels of semantic zoom, from an overview of model predictions down to the content. We facilitate a focused analysis of relevant connections and groups based on interactive user-steering for filtering and search tasks, a dynamically modifiable partition hierarchy, various matrix reordering techniques, and interactive model feedback. We evaluate our technique in a case study and through formative evaluation with law enforcement experts using real-world internet forum communication data. The results show that our approach surpasses existing solutions in terms of scalability and applicability, enables the incorporation of domain knowledge, and allows for fast search-space traversal. With the technique, we pave the way for the visual analytics of temporal hypergraphs in a wide variety of domains.", "pdf_url": "https://arxiv.org/pdf/2008.07299", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Multiagent trajectory models via game theory and implicit layer-based learning", "author": "Philipp Geiger, Christoph-Niklas Straehle", "pub_date": "Submitted on 17 Aug 2020", "abstract": "For prediction of interacting agents' trajectories, we propose an end-to-end trainable architecture that hybridizes neural nets with game-theoretic principles, has interpretable intermediate representations, and transfers to robust downstream decisions. It combines a differentiable implicit layer, that maps preferences to local Nash equilibria, with a learned equilibrium refinement concept and preference revelation, upon initial trajectories as input. This is accompanied by a new class of continuous potential games, theoretical results for explicit gradients and soundness, and several measures to ensure tractability. In experiments, we evaluate our approach on two real-world data sets, where we predict highway driver merging trajectories, and a simple decision-making transfer task.", "pdf_url": "https://arxiv.org/pdf/2008.07303", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Bias and Discrimination in AI: a cross-disciplinary perspective", "author": "Xavier Ferrer, Tom van Nuenen, Jose M. Such, Mark Cot\u00e9, Natalia Criado", "pub_date": "Submitted on 11 Aug 2020", "abstract": "With the widespread and pervasive use of Artificial Intelligence (AI) for automated decision-making systems, AI bias is becoming more apparent and problematic. One of its negative consequences is discrimination: the unfair, or unequal treatment of individuals based on certain characteristics. However, the relationship between bias and discrimination is not always clear. In this paper, we survey relevant literature about bias and discrimination in AI from an interdisciplinary perspective that embeds technical, legal, social and ethical dimensions. We show that finding solutions to bias and discrimination in AI requires robust cross-disciplinary collaborations.", "pdf_url": "https://arxiv.org/pdf/2008.07309", "subject": "Computers and Society (cs.CY)"},
{"title": "Bijective Mapping Analysis to Extend the Theory of Functional Connections to Non-rectangular 2-dimensional Domains", "author": "Daniele Mortari, David Anas", "pub_date": "Submitted on 28 Jul 2020", "abstract": "This work presents an initial analysis of using bijective mappings to extend the Theory of Functional Connections to non-rectangular two-dimensional domains. Specifically, this manuscript proposes three different mappings techniques: a) complex mapping, b) projection mapping, and c) polynomial mapping. In that respect, an accurate least-squares approximated inverse mapping is also developed for those mappings having no closed-form inverse. The advantages and disadvantages of using these mappings are highlighted and a few examples are provided. Additionally, the paper shows how to replace boundary constraints expressed in terms of a piecewise sequence of functions with a single function, that is compatible and required by the Theory of Functional Connections already developed by rectangular domains.", "pdf_url": "https://arxiv.org/pdf/2008.07310", "subject": "Numerical Analysis (math.NA)"},
{"title": "Data-Driven Distributed Mitigation Strategies and Analysis of Mutating Epidemic Processes", "author": "Philip E Pare, Sebin Gracy, Henrik Sandberg, Karl Henrik Johansson", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper we study a discrete-time SIS (susceptible-infected-susceptible) model, where the infection and healing parameters and the underlying network may change over time. We provide conditions for the model to be well-defined and study its stability. For systems with homogeneous infection rates over symmetric graphs,we provide a sufficient condition for global exponential stability (GES) of the healthy state, that is, where the virus is eradicated. For systems with heterogeneous virus spread over directed graphs, provided that the variation is not too fast, a sufficient condition for GES of the healthy state is established.", "pdf_url": "https://arxiv.org/pdf/2008.07317", "subject": "Systems and Control (eess.SY)"},
{"title": "Towards Dynamic Urban Bike Usage Prediction for Station Network Reconfiguration", "author": "Xi Yang, Suining He", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Bike sharing has become one of the major choices of transportation for residents in metropolitan cities worldwide. A station-based bike sharing system is usually operated in the way that a user picks up a bike from one station, and drops it off at another. Bike stations are, however, not static, as the bike stations are often reconfigured to accommodate changing demands or city urbanization over time. One of the key operations is to evaluate candidate locations and install new stations to expand the bike sharing station network. Conventional practices have been studied to predict existing station usage, while evaluating new stations is highly challenging due to the lack of the historical bike usage. To fill this gap, in this work we propose a novel and efficient bike station-level prediction algorithm called AtCoR, which can predict the bike usage at both existing and new stations (candidate locations during reconfiguration). In order to address the lack of historical data issues, virtual historical usage of new stations is generated according to their correlations with the surrounding existing stations, for AtCoR model initialization. We have designed novel station-centered heatmaps which characterize for each target station centered at the heatmap the trend that riders travel between it and the station's neighboring regions, enabling the model to capture the learnable features of the bike station network. The captured features are further applied to the prediction of bike usage for new stations. Our extensive experiment study on more than 23 million trips from three major bike sharing systems in US, including New York City, Chicago and Los Angeles, shows that AtCoR outperforms baselines and state-of-art models in prediction of both existing and future stations.", "pdf_url": "https://arxiv.org/pdf/2008.07318", "subject": "Machine Learning (cs.LG)"},
{"title": "Expected Utilitarianism", "author": "Heather M. Roff", "pub_date": "Submitted on 19 Jul 2020", "abstract": "We want artificial intelligence (AI) to be beneficial. This is the grounding assumption of most of the attitudes towards AI research. We want AI to be \"good\" for humanity. We want it to help, not hinder, humans. Yet what exactly this entails in theory and in practice is not immediately apparent. Theoretically, this declarative statement subtly implies a commitment to a consequentialist ethics. Practically, some of the more promising machine learning techniques to create a robust AI, and perhaps even an artificial general intelligence (AGI) also commit one to a form of utilitarianism. In both dimensions, the logic of the beneficial AI movement may not in fact create \"beneficial AI\" in either narrow applications or in the form of AGI if the ethical assumptions are not made explicit and clear. Additionally, as it is likely that reinforcement learning (RL) will be an important technique for machine learning in this area, it is also important to interrogate how RL smuggles in a particular type of consequentialist reasoning into the AI: particularly, a brute form of hedonistic act utilitarianism. Since the mathematical logic commits one to a maximization function, the result is that an AI will inevitably be seeking more and more rewards. We have two conclusions that arise from this. First, is that if one believes that a beneficial AI is an ethical AI, then one is committed to a framework that posits 'benefit' is tantamount to the greatest good for the greatest number. Second, if the AI relies on RL, then the way it reasons about itself, the environment, and other agents, will be through an act utilitarian morality. This proposition may, or may not, in fact be actually beneficial for humanity.", "pdf_url": "https://arxiv.org/pdf/2008.07321", "subject": "Computers and Society (cs.CY)"},
{"title": "New CAP Reduction Mechanisms for IEEE 802.15.4 DSME to Support Fluctuating Traffic in IoT Systems", "author": "Florian Meyer, Ivonne Mantilla-Gonz\u00e1lez, Volker Turau", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "In 2015, the IEEE 802.15.4 standard was expanded by the Deterministic and Synchronous Multi-Channel Extension (DSME) to increase reliability, scalability and energy-efficiency in industrial applications. The extension offers a TDMA/FDMA-based channel access, where time is divided into two alternating phases, a contention access period (CAP) and a contention free period (CFP). During the CAP, transmission slots can be allocated offering an exclusive access to the shared medium during the CFP. The fraction $\\tau$ of CFP's time slots in a dataframe is a critical value, because it directly influences agility and throughput. A high throughput demands that the CFP is much longer than the CAP, i.e., a high value of the fraction $\\tau$, because application data is only sent during the CFP. High agility is given if the expected waiting time to send a CAP message is short and that the length of the CAPs are sufficiently long to accommodate necessary (de)allocations of GTSs, i.e., a low value of the fraction $\\tau$. Once DSME is configured according to the needs of an application, the fraction $\\tau$ can only assume one of two values and cannot be changed at run-time. In this paper, we propose two extensions of DSME that allow to adopt $\\tau$ to the current traffic pattern. We show theoretically and through simulations that the proposed extensions provide a high degree of responsiveness to traffic fluctuations while keeping the throughput high.", "pdf_url": "https://arxiv.org/pdf/2008.07323", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Intelligence Primer", "author": "Karl Fezer, Andrew Sloss", "pub_date": "Submitted on 13 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "This primer explores the exciting subject of intelligence. Intelligence is a fundamental component of all living things, as well as Artificial Intelligence(AI). Artificial Intelligence has the potential to affect all of our lives and a new era for modern humans. This paper is an attempt to explore the ideas associated with intelligence, and by doing so understand the implications, constraints, and potentially the capabilities of future Artificial Intelligence. As an exploration, we journey into different parts of intelligence that appear essential. We hope that people find this useful in determining where Artificial Intelligence may be headed. Also, during the exploration, we hope to create new thought-provoking questions. Intelligence is not a single weighable quantity but a subject that spans Biology, Physics, Philosophy, Cognitive Science, Neuroscience, Psychology, and Computer Science. Historian Yuval Noah Harari pointed out that engineers and scientists in the future will have to broaden their understandings to include disciplines such as Psychology, Philosophy, and Ethics. Fiction writers have long portrayed engineers and scientists as deficient in these areas. Today, modern society, the emergence of Artificial Intelligence, and legal requirements all act as forcing functions to push these broader subjects into the foreground. We start with an introduction to intelligence and move quickly onto more profound thoughts and ideas. We call this a Life, the Universe and Everything primer, after the famous science fiction book by Douglas Adams. Forty-two may very well be the right answer, but what are the questions?", "pdf_url": "https://arxiv.org/pdf/2008.07324", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Comparing manual contact tracing and digital contact advice", "author": "Ramesh Raskar, Ranu Dhillon, Suraj Kapa, Deepti Pahwa, Renaud Falgas, Lagnojita Sinha, Aarathi Prasad, Abhishek Singh, Andrea Nuzzo, Rohan Iyer, Vivek Sharma", "pub_date": "Submitted on 11 Aug 2020", "abstract": "Manual contact tracing is a top-down solution that starts with contact tracers at the public health level, who identify the contacts of infected individuals, interview them to get additional context about the exposure, and also monitor their symptoms and support them until the incubation period is passed. On the other hand, digital contact tracing is a bottom-up solution that starts with citizens who on obtaining a notification about possible exposure to an infected individual may choose to ignore the notification, get tested to determine if they were actually exposed or self-isolate and monitor their symptoms over the next two weeks. Most experts recommend a combination of manual contact tracing and digital contact advice but they are not based on a scientific basis. For example, a possible hybrid solution could involve a smartphone based alert that requests the possible contact of an infected individual to call the Public Health (PH) number for next steps, or in some cases, suggest ways to self-assess in order to reduce the burden on PH so only most critical cases require a phone conversation. In this paper, we aim to compare the manual and digital approaches to contact tracing and provide suggestions for potential hybrid solutions.", "pdf_url": "https://arxiv.org/pdf/2008.07325", "subject": "Computers and Society (cs.CY)"},
{"title": "Progressing Towards Responsible AI", "author": "Teresa Scantamburlo, Atia Cort\u00e9s, Marie Schacht", "pub_date": "Submitted on 11 Aug 2020", "abstract": "The field of Artificial Intelligence (AI) and, in particular, the Machine Learning area, counts on a wide range of performance metrics and benchmark data sets to assess the problem-solving effectiveness of its solutions. However, the appearance of research centres, projects or institutions addressing AI solutions from a multidisciplinary and multi-stakeholder perspective suggests a new approach to assessment comprising ethical guidelines, reports or tools and frameworks to help both academia and business to move towards a responsible conceptualisation of AI. They all highlight the relevance of three key aspects: (i) enhancing cooperation among the different stakeholders involved in the design, deployment and use of AI; (ii) promoting multidisciplinary dialogue, including different domains of expertise in this process; and (iii) fostering public engagement to maximise a trusted relation with new technologies and practitioners. In this paper, we introduce the Observatory on Society and Artificial Intelligence (OSAI), an initiative grew out of the project AI4EU aimed at stimulating reflection on a broad spectrum of issues of AI (ethical, legal, social, economic and cultural). In particular, we describe our work in progress around OSAI and suggest how this and similar initiatives can promote a wider appraisal of progress in AI. This will give us the opportunity to present our vision and our modus operandi to enhance the implementation of these three fundamental dimensions.", "pdf_url": "https://arxiv.org/pdf/2008.07326", "subject": "Computers and Society (cs.CY)"},
{"title": "An Ontological AI-and-Law Framework for the Autonomous Levels of AI Legal Reasoning", "author": "Lance Eliot", "pub_date": "Submitted on 4 Aug 2020", "abstract": "A framework is proposed that seeks to identify and establish a set of robust autonomous levels articulating the realm of Artificial Intelligence and Legal Reasoning (AILR). Doing so provides a sound and parsimonious basis for being able to assess progress in the application of AI to the law, and can be utilized by scholars in academic pursuits of AI legal reasoning, along with being used by law practitioners and legal professionals in gauging how advances in AI are aiding the practice of law and the realization of aspirational versus achieved results. A set of seven levels of autonomy for AI and Legal Reasoning are meticulously proffered and mindfully discussed.", "pdf_url": "https://arxiv.org/pdf/2008.07328", "subject": "Computers and Society (cs.CY)"},
{"title": "Interactive Visualization for Debugging RL", "author": "Shuby Deshpande, Benjamin Eysenbach, Jeff Schneider", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "Visualization tools for supervised learning allow users to interpret, introspect, and gain an intuition for the successes and failures of their models. While reinforcement learning practitioners ask many of the same questions, existing tools are not applicable to the RL setting as these tools address challenges typically found in the supervised learning regime. In this work, we design and implement an interactive visualization tool for debugging and interpreting RL algorithms. Our system addresses many features missing from previous tools such as (1) tools for supervised learning often are not interactive; (2) while debugging RL policies researchers use state representations that are different from those seen by the agent; (3) a framework designed to make the debugging RL policies more conducive. We provide an example workflow of how this system could be used, along with ideas for future extensions.", "pdf_url": "https://arxiv.org/pdf/2008.07331", "subject": "Machine Learning (cs.LG)"},
{"title": "On Improving Throughput of Multichannel ALOHA using Preamble-based Exploration", "author": "Jinho Choi", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Machine-type communication (MTC) has been extensively studied to provide connectivity for devices and sensors in the Internet-of-Thing (IoT). Thanks to the sparse activity, random access, e.g., ALOHA, is employed for MTC to lower signaling overhead. In this paper, we propose to adopt exploration for multichannel ALOHA by transmitting preambles before transmitting data packets in MTC, and show that the maximum throughput can be improved by a factor of 2 - exp(-1) = 1.632, In the proposed approach, a base station (BS) needs to send the feedback information to active users to inform the numbers of transmitted preambles in multiple channels, which can be reliably estimated as in compressive random access. A steady-state analysis is also performed with fast retrial, which shows that the probability of packet collision becomes lower and, as a result, the delay outage probability is greatly reduced for a lightly loaded system. Simulation results also confirm the results from analysis.", "pdf_url": "https://arxiv.org/pdf/2008.07333", "subject": "Information Theory (cs.IT)"},
{"title": "Simpler Hyperparameter Optimization for Software Analytics: Why, How, When?", "author": "Amritanshu Agrawal, Xueqi Yang, Rishabh Agrawal, Xipeng Shen, Tim Menzies", "pub_date": "Submitted on 14 Aug 2020", "abstract": "How to make software analytics simpler and faster? One method is to match the complexity of analysis to the intrinsic complexity of the data being explored. For example, hyperparameter optimizers find the control settings for data miners that improve for improving the predictions generated via software analytics. Sometimes, very fast hyperparameter optimization can be achieved by just DODGE-ing away from things tried before. But when is it wise to use DODGE and when must we use more complex (and much slower) optimizers? To answer this, we applied hyperparameter optimization to 120 SE data sets that explored bad smell detection, predicting Github ssue close time, bug report analysis, defect prediction, and dozens of other non-SE problems. We find that DODGE works best for data sets with low \"intrinsic dimensionality\" (D = 3) and very poorly for higher-dimensional data (D over 8). Nearly all the SE data seen here was intrinsically low-dimensional, indicating that DODGE is applicable for many SE analytics tasks.", "pdf_url": "https://arxiv.org/pdf/2008.07334", "subject": "Software Engineering (cs.SE)"},
{"title": "Can the app contain the spread? An agent-based model of COVID-19 and the effectiveness of smartphone-based contact tracing", "author": "Jonatan Almagor, Stefano Picascia", "pub_date": "Submitted on 27 Jul 2020", "abstract": "A contact-tracing strategy has been deemed necessary to contain the spread of COVID-19 following the relaxation of lockdown measures. Using an agent-based model, we explore one of the technology-based strategies proposed, a contact-tracing smartphone app. The model simulates the spread of COVID-19 in a population of agents on an urban scale. Agents are heterogeneous in their characteristics and are linked in a multi-layered network representing the social structure - including households, friendships, employment and schools. We explore the interplay of various adoption rates of the contact-tracing app, different levels of testing capacity, and behavioural factors, to assess the ability of this track-and-trace strategy to mitigate the epidemic. Results suggest that the app can contribute substantially to the reduction of infections in the population, although complete suppression of the virus is unlikely to be achieved. The model also shows that, while adopting the app is beneficial for epidemic control in most cases, a high adoption rate is likely to generate an extensive increase in the demand for testing, which, if not met with adequate supply, may render the app counterproductive. This points to the crucial role of an efficient testing policy and the necessity to upscale testing capacity.", "pdf_url": "https://arxiv.org/pdf/2008.07336", "subject": "Computers and Society (cs.CY)"},
{"title": "Predicting United States policy outcomes with Random Forests", "author": "Shawn McGuire, Charles Delahunt", "pub_date": "Submitted on 2 Aug 2020", "abstract": "Two decades of U.S. government legislative outcomes, as well as the policy preferences of rich people, the general population, and diverse interest groups, were captured in a detailed dataset curated and analyzed by Gilens, Page et al. (2014). They found that the preferences of the rich correlated strongly with policy outcomes, while the preferences of the general population did not, except via a linkage with rich people's preferences. Their analysis applied the tools of classical statistical inference, in particular logistic regression. In this paper we analyze the Gilens dataset using the complementary tools of Random Forest classifiers (RFs), from Machine Learning. We present two primary findings, concerning respectively prediction and inference: (i) Holdout test sets can be predicted with approximately 70% balanced accuracy by models that consult only the preferences of rich people and a small number of powerful interest groups, as well as policy area labels. These results include retrodiction, where models trained on pre-1997 cases predicted \"future\" (post-1997) cases. The 20% gain in accuracy over baseline (chance), in this detailed but noisy dataset, indicates the high importance of a few wealthy players in U.S. policy outcomes, and aligns with a body of research indicating that the U.S. government has significant plutocratic tendencies. (ii) The feature selection methods of RF models identify especially salient subsets of interest groups (economic players). These can be used to further investigate the dynamics of governmental policy making, and also offer an example of the potential value of RF feature selection methods for inference on datasets such as this.", "pdf_url": "https://arxiv.org/pdf/2008.07338", "subject": "Computers and Society (cs.CY)"},
{"title": "Data, Power and Bias in Artificial Intelligence", "author": "Susan Leavy, Barry O'Sullivan, Eugenia Siapera", "pub_date": "Submitted on 28 Jul 2020", "abstract": "Artificial Intelligence has the potential to exacerbate societal bias and set back decades of advances in equal rights and civil liberty. Data used to train machine learning algorithms may capture social injustices, inequality or discriminatory attitudes that may be learned and perpetuated in society. Attempts to address this issue are rapidly emerging from different perspectives involving technical solutions, social justice and data governance measures. While each of these approaches are essential to the development of a comprehensive solution, often discourse associated with each seems disparate. This paper reviews ongoing work to ensure data justice, fairness and bias mitigation in AI systems from different domains exploring the interrelated dynamics of each and examining whether the inevitability of bias in AI training data may in fact be used for social good. We highlight the complexity associated with defining policies for dealing with bias. We also consider technical challenges in addressing issues of societal bias.", "pdf_url": "https://arxiv.org/pdf/2008.07341", "subject": "Computers and Society (cs.CY)"},
{"title": "Statistical Analytics and Regional Representation Learning for COVID-19 Pandemic Understanding", "author": "Shayan Fazeli, Babak Moatamed, Majid Sarrafzadeh", "pub_date": "Submitted on 8 Aug 2020", "abstract": "The rapid spread of the novel coronavirus (COVID-19) has severely impacted almost all countries around the world. It not only has caused a tremendous burden on health-care providers to bear, but it has also brought severe impacts on the economy and social life. The presence of reliable data and the results of in-depth statistical analyses provide researchers and policymakers with invaluable information to understand this pandemic and its growth pattern more clearly. This paper combines and processes an extensive collection of publicly available datasets to provide a unified information source for representing geographical regions with regards to their pandemic-related behavior. The features are grouped into various categories to account for their impact based on the higher-level concepts associated with them. This work uses several correlation analysis techniques to observe value and order relationships between features, feature groups, and COVID-19 occurrences. Dimensionality reduction techniques and projection methodologies are used to elaborate on individual and group importance of these representative features. A specific RNN-based inference pipeline called DoubleWindowLSTM-CP is proposed in this work for predictive event modeling. It utilizes sequential patterns and enables concise record representation while using but a minimal amount of historical data. The quantitative results of our statistical analytics indicated critical patterns reflecting on many of the expected collective behavior and their associated outcomes. Predictive modeling with DoubleWindowLSTM-CP instance exhibits efficient performance in quantitative and qualitative assessments while reducing the need for extended and reliable historical information on the pandemic.", "pdf_url": "https://arxiv.org/pdf/2008.07342", "subject": "Computers and Society (cs.CY)"},
{"title": "Artificial Intelligence in the Battle against Coronavirus (COVID-19): A Survey and Future Research Directions", "author": "Thanh Thi Nguyen", "pub_date": "Submitted on 30 Jul 2020", "abstract": "Artificial intelligence (AI) has been applied widely in our daily lives in a variety of ways with numerous successful stories. AI has also contributed to dealing with the coronavirus disease (COVID-19) pandemic, which has been happening around the globe. This paper presents a survey of AI methods being used in various applications in the fight against the COVID-19 outbreak and outlines the crucial roles of AI research in this unprecedented battle. We touch on a number of areas where AI plays as an essential component, from medical image processing, data analytics, text mining and natural language processing, the Internet of Things, to computational biology and medicine. A summary of COVID-19 related data sources that are available for research purposes is also presented. Research directions on exploring the potentials of AI and enhancing its capabilities and power in the battle are thoroughly discussed. We highlight 13 groups of problems related to the COVID-19 pandemic and point out promising AI methods and tools that can be used to solve those problems. It is envisaged that this study will provide AI researchers and the wider community an overview of the current status of AI applications and motivate researchers in harnessing AI potentials in the fight against COVID-19.", "pdf_url": "https://arxiv.org/pdf/2008.07343", "subject": "Computers and Society (cs.CY)"},
{"title": "An Algorithmic Study of the Hypergraph Tur\u00e1n Problem", "author": "Venkatesan Guruswami, Sai Sandeep", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We propose an algorithmic version of the hypergraph Tur\u00e1n problem (AHTP): given a $t$-uniform hypergraph $H=(V,E)$, the goal is to find the smallest collection of $(t-1)$-element subsets of $V$ such that every hyperedge $e \\in E$ contains one of these subsets. In addition to its inherent combinatorial interest---for instance, the $t=3$ case is connected to Tuza's famous conjecture on covering triangles of a graph with edges---variants of AHTP arise in recently proposed reductions to fundamental Euclidean clustering problems. AHTP admits a trivial factor $t$ approximation algorithm as it can be cast as an instance of vertex cover on a structured $t$-uniform hypergraph that is a ``blown-up'' version of $H$. Our main result is an approximation algorithm with ratio $\\frac{t}{2}+o(t)$. The algorithm is based on rounding the natural LP relaxation using a careful combination of thresholding and color coding. We also present results motivated by structural aspects of the blown-up hypergraph. The blown-up is a $\\textit{simple}$ hypergraph with hyperedges intersecting in at most one element. We prove that vertex cover on simple $t$-uniform hypergraphs is as hard to approximate as general $t$-uniform hypergraphs. The blown-up hypergraph further has many forbidden structures, including a ``tent'' structure for the case $t=3$. Whether a generalization of Tuza's conjecture could also hold for tent-free $3$-uniform hypergraphs was posed in a recent work. We answer this question in the negative by giving a construction based on combinatorial lines that is tent-free, and yet needs to include most of the vertices in a vertex cover.", "pdf_url": "https://arxiv.org/pdf/2008.07344", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Memory networks for consumer protection:unfairness exposed", "author": "Federico Ruggeri, Francesca Lagioia, Marco Lippi, Paolo Torroni", "pub_date": "Submitted on 24 Jul 2020", "abstract": "Recent work has demonstrated how data-driven AI methods can leverage consumer protection by supporting the automated analysis of legal documents. However, a shortcoming of data-driven approaches is poor explainability. We posit that in this domain useful explanations of classifier outcomes can be provided by resorting to legal rationales. We thus consider several configurations of memory-augmented neural networks where rationales are given a special role in the modeling of context knowledge. Our results show that rationales not only contribute to improve the classification accuracy, but are also able to offer meaningful, natural language explanations of otherwise opaque classifier outcomes.", "pdf_url": "https://arxiv.org/pdf/2008.07346", "subject": "Computers and Society (cs.CY)"},
{"title": "HunFlair: An Easy-to-Use Tool for State-of-the-Art Biomedical Named Entity Recognition", "author": "Leon Weber, Mario S\u00e4nger, Jannes M\u00fcnchmeyer, Maryam Habibi, Ulf Leser, Alan Akbik", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "Summary: Named Entity Recognition (NER) is an important step in biomedical information extraction pipelines. Tools for NER should be easy to use, cover multiple entity types, highly accurate, and robust towards variations in text genre and style. To this end, we propose HunFlair, an NER tagger covering multiple entity types integrated into the widely used NLP framework Flair. HunFlair outperforms other state-of-the-art standalone NER tools with an average gain of 7.26 pp over the next best tool, can be installed with a single command and is applied with only four lines of code. Availability: HunFlair is freely available through the Flair framework under an MIT license: and is compatible with all major operating systems. Contact:{weberple,saengema,alan.akbik}@informatik.", "pdf_url": "https://arxiv.org/pdf/2008.07347", "subject": "Computation and Language (cs.CL)"},
{"title": "Binarised Regression with Instance-Varying Costs: Evaluation using Impact Curves", "author": "Matthew Dirks, David Poole", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Many evaluation methods exist, each for a particular prediction task, and there are a number of prediction tasks commonly performed including classification and regression. In binarised regression, binary decisions are generated from a learned regression model (or real-valued dependent variable), which is useful when the division between instances that should be predicted positive or negative depends on the utility. For example, in mining, the boundary between a valuable rock and a waste rock depends on the market price of various metals, which varies with time. This paper proposes impact curves to evaluate binarised regression with instance-varying costs, where some instances are much worse to be classified as positive (or negative) than other instances; e.g., it is much worse to throw away a high-grade gold rock than a medium-grade copper-ore rock, even if the mine wishes to keep both because both are profitable. We show how to construct an impact curve for a variety of domains, including examples from healthcare, mining, and entertainment. Impact curves optimize binary decisions across all utilities of the chosen utility function, identify the conditions where one model may be favoured over another, and quantitatively assess improvement between competing models.", "pdf_url": "https://arxiv.org/pdf/2008.07349", "subject": "Machine Learning (cs.LG)"},
{"title": "On the Sample Complexity of Reinforcement Learning with Policy Space Generalization", "author": "Wenlong Mou, Zheng Wen, Xi Chen", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We study the optimal sample complexity in large-scale Reinforcement Learning (RL) problems with policy space generalization, i.e. the agent has a prior knowledge that the optimal policy lies in a known policy space. Existing results show that without a generalization model, the sample complexity of an RL algorithm will inevitably depend on the cardinalities of state space and action space, which are intractably large in many practical problems. To avoid such undesirable dependence on the state and action space sizes, this paper proposes a new notion of eluder dimension for the policy space, which characterizes the intrinsic complexity of policy learning in an arbitrary Markov Decision Process (MDP). Using a simulator oracle, we prove a near-optimal sample complexity upper bound that only depends linearly on the eluder dimension. We further prove a similar regret bound in deterministic systems without the simulator.", "pdf_url": "https://arxiv.org/pdf/2008.07353", "subject": "Machine Learning (cs.LG)"},
{"title": "SoftPoolNet: Shape Descriptor for Point Cloud Completion and Classification", "author": "Yida Wang, David Joseph Tan, Nassir Navab, Federico Tombari", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Point clouds are often the default choice for many applications as they exhibit more flexibility and efficiency than volumetric data. Nevertheless, their unorganized nature -- points are stored in an unordered way -- makes them less suited to be processed by deep learning pipelines. In this paper, we propose a method for 3D object completion and classification based on point clouds. We introduce a new way of organizing the extracted features based on their activations, which we name soft pooling. For the decoder stage, we propose regional convolutions, a novel operator aimed at maximizing the global activation entropy. Furthermore, inspired by the local refining procedure in Point Completion Network (PCN), we also propose a patch-deforming operation to simulate deconvolutional operations for point clouds. This paper proves that our regional activation can be incorporated in many point cloud architectures like AtlasNet and PCN, leading to better performance for geometric completion. We evaluate our approach on different 3D tasks such as object completion and classification, achieving state-of-the-art accuracy.", "pdf_url": "https://arxiv.org/pdf/2008.07358", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Patient-Centric Dataset of Images and Metadata for Identifying Melanomas Using Clinical Context", "author": "Veronica Rotemberg, Nicholas Kurtansky, Brigid Betz-Stablein, Liam Caffery, Emmanouil Chousakos, Noel Codella, Marc Combalia, Stephen Dusza, Pascale Guitera, David Gutman, Allan Halpern, Harald Kittler, Kivanc Kose, Steve Langer, Konstantinos Lioprys, Josep Malvehy, Shenara Musthaq, Jabpani Nanda, Ofer Reiter, George Shih, Alexander Stratigos, Philipp Tschandl, Jochen Weber, H. Peter Soyer", "pub_date": "Submitted on 7 Aug 2020", "abstract": "Prior skin image datasets have not addressed patient-level information obtained from multiple skin lesions from the same patient. Though artificial intelligence classification algorithms have achieved expert-level performance in controlled studies examining single images, in practice dermatologists base their judgment holistically from multiple lesions on the same patient. The 2020 SIIM-ISIC Melanoma Classification challenge dataset described herein was constructed to address this discrepancy between prior challenges and clinical practice, providing for each image in the dataset an identifier allowing lesions from the same patient to be mapped to one another. This patient-level contextual information is frequently used by clinicians to diagnose melanoma and is especially useful in ruling out false positives in patients with many atypical nevi. The dataset represents 2,056 patients from three continents with an average of 16 lesions per patient, consisting of 33,126 dermoscopic images and 584 histopathologically confirmed melanomas compared with benign melanoma mimickers.", "pdf_url": "https://arxiv.org/pdf/2008.07360", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Predicting Account Receivables with Machine Learning", "author": "Ana Paula Appel, Gabriel Louzada Malfatti, Renato Luiz de Freitas Cunha, Bruno Lima, Rogerio de Paula", "pub_date": "Submitted on 11 Aug 2020", "abstract": "Being able to predict when invoices will be paid is valuable in multiple industries and supports decision-making processes in most financial workflows. However, due to the complexity of data related to invoices and the fact that the decision-making process is not registered in the accounts receivable system, performing this prediction becomes a challenge. In this paper, we present a prototype able to support collectors in predicting the payment of invoices. This prototype is part of a solution developed in partnership with a multinational bank and it has reached up to 81% of prediction accuracy, which improved the prioritization of customers and supported the daily work of collectors. Our simulations show that the adoption of our model to prioritize the work o collectors saves up to ~1.75 million dollars per month. The methodology and results presented in this paper will allow researchers and practitioners in dealing with the problem of invoice payment prediction, providing insights and examples of how to tackle issues present in real data.", "pdf_url": "https://arxiv.org/pdf/2008.07363", "subject": "Machine Learning (cs.LG)"},
{"title": "Predicting Individual Treatment Effects of Large-scale Team Competitions in a Ride-sharing Economy", "author": "Teng Ye, Wei Ai, Lingyu Zhang, Ning Luo, Lulu Zhang, Jieping Ye, Qiaozhu Mei", "pub_date": "Submitted on 7 Aug 2020", "abstract": "Millions of drivers worldwide have enjoyed financial benefits and work schedule flexibility through a ride-sharing economy, but meanwhile they have suffered from the lack of a sense of identity and career achievement. Equipped with social identity and contest theories, financially incentivized team competitions have been an effective instrument to increase drivers' productivity, job satisfaction, and retention, and to improve revenue over cost for ride-sharing platforms. While these competitions are overall effective, the decisive factors behind the treatment effects and how they affect the outcomes of individual drivers have been largely mysterious. In this study, we analyze data collected from more than 500 large-scale team competitions organized by a leading ride-sharing platform, building machine learning models to predict individual treatment effects. Through a careful investigation of features and predictors, we are able to reduce out-sample prediction error by more than 24%. Through interpreting the best-performing models, we discover many novel and actionable insights regarding how to optimize the design and the execution of team competitions on ride-sharing platforms. A simulated analysis demonstrates that by simply changing a few contest design options, the average treatment effect of a real competition is expected to increase by as much as 26%. Our procedure and findings shed light on how to analyze and optimize large-scale online field experiments in general.", "pdf_url": "https://arxiv.org/pdf/2008.07364", "subject": "Computers and Society (cs.CY)"},
{"title": "Using LDA and LSTM Models to Study Public Opinions and Critical Groups Towards Congestion Pricing in New York City through 2007 to 2019", "author": "Qian Ye, Xiaohong Chen, Onur Kalan, Kaan Ozbay", "pub_date": "Submitted on 1 Aug 2020", "abstract": "This study explores how people view and respond to the proposals of NYC congestion pricing evolve in time. To understand these responses, Twitter data is collected and analyzed. Critical groups in the recurrent process are detected by statistically analyzing the active users and the most mentioned accounts, and the trends of people's attitudes and concerns over the years are identified with text mining and hybrid Nature Language Processing techniques, including LDA topic modeling and LSTM sentiment classification. The result shows that multiple interest groups were involved and played crucial roles during the proposal, especially Mayor and Governor, MTA, and outer-borough representatives. The public shifted the concern of focus from the plan details to a wider city's sustainability and fairness. Furthermore, the plan's approval relies on several elements, the joint agreement reached in the political process, strong motivation in the real-world, the scheme based on balancing multiple interests, and groups' awareness of tolling's benefits and necessity.", "pdf_url": "https://arxiv.org/pdf/2008.07366", "subject": "Computers and Society (cs.CY)"},
{"title": "Continuous Patrolling Games", "author": "Steve Alpern, Thomas Lidbetter, Katerina Papadaki", "pub_date": "Submitted on 13 Aug 2020", "abstract": "The continuous patrolling game studied here was first proposed in Alpern et al. (2011), which studied a discrete time game where facilities to be protected were modeled as the nodes of a graph. Here we consider protecting roads or pipelines, modeled as the arcs of a continuous network $Q$. The Attacker chooses a point of $Q$ to attack during a chosen time interval of fixed duration (the attack time, $\\alpha$). The Patroller chooses a unit speed path on $Q$ and intercepts the attack (and wins) if she visits the attacked point during the attack time interval. Solutions to the game have previously been given in certain special cases. Here, we analyze the game on arbitrary networks. Our results include the following: (i) a solution to the game for any network $Q$, as long as $\\alpha$ is sufficiently short, generalizing the known solutions for circle or Eulerian networks and the network with two nodes joined by three arcs; (ii) a solution to the game for all tree networks that satisfy a condition on their extremities. We present a conjecture on the solution of the game for arbitrary trees and establish it in certain cases.", "pdf_url": "https://arxiv.org/pdf/2008.07369", "subject": "Discrete Mathematics (cs.DM)"},
{"title": "Corona-Warn-App: Tracing the Start of the Official COVID-19 Exposure Notification App for Germany", "author": "Jens Helge Reelfs, Oliver Hohlfeld, Ingmar Poese", "pub_date": "Submitted on 25 Jul 2020", "abstract": "On June 16, 2020, Germany launched an open-source smartphone contact tracing app (\"Corona-Warn-App\") to help tracing SARS-CoV-2 (coronavirus) infection chains. It uses a decentralized, privacy-preserving design based on the Exposure Notification APIs in which a centralized server is only used to distribute a list of keys of SARS-CoV-2 infected users that is fetched by the app once per day. Its success, however, depends on its adoption. In this poster, we characterize the early adoption of the app using Netflow traces captured directly at its hosting infrastructure. We show that the app generated traffic from allover Germany---already on the first day. We further observe that local COVID-19 outbreaks do not result in noticeable traffic increases.", "pdf_url": "https://arxiv.org/pdf/2008.07370", "subject": "Computers and Society (cs.CY)"},
{"title": "Artificial Intelligence is stupid and causal reasoning won't fix it", "author": "John Mark Bishop", "pub_date": "Submitted on 20 Jul 2020", "abstract": "Artificial Neural Networks have reached Grandmaster and even super-human performance across a variety of games: from those involving perfect-information (such as Go) to those involving imperfect-information (such as Starcraft). Such technological developments from AI-labs have ushered concomitant applications across the world of business - where an AI brand tag is fast becoming ubiquitous. A corollary of such widespread commercial deployment is that when AI gets things wrong - an autonomous vehicle crashes; a chatbot exhibits racist behaviour; automated credit scoring processes discriminate on gender etc. - there are often significant financial, legal and brand consequences and the incident becomes major news. As Judea Pearl sees it, the underlying reason for such mistakes is that, 'all the impressive achievements of deep learning amount to just curve fitting'. The key, Judea Pearl suggests, is to replace reasoning by association with causal-reasoning - the ability to infer causes from observed phenomena. It is a point that was echoed by Gary Marcus and Ernest Davis in a recent piece for the New York Times: 'we need to stop building computer systems that merely get better and better at detecting statistical patterns in data sets - often using an approach known as Deep Learning - and start building computer systems that from the moment of their assembly innately grasp three basic concepts: time, space and causality'. In this paper, foregrounding what in 1949 Gilbert Ryle termed a category mistake, I will offer an alternative explanation for AI errors: it is not so much that AI machinery cannot grasp causality, but that AI machinery - qua computation - cannot understand anything at all.", "pdf_url": "https://arxiv.org/pdf/2008.07371", "subject": "Computers and Society (cs.CY)"},
{"title": "Maximum Customers' Satisfaction in One-way Car-sharing: Modeling, Exact and Heuristic Solving", "author": "Welverton R. Silva, Rafael C. S. Schouery", "pub_date": "Submitted on 13 Aug 2020", "abstract": "One-way car-sharing systems are transportation systems that allow customers to rent cars at stations scattered around the city, use them for a short journey, and return them at any station. The maximum customers' satisfaction problem concerns the task of assigning the cars, initially located at given stations, to maximize the number of satisfied customers. We consider the problem with two stations where each customer has exactly two demands in opposite directions between both stations, and a customer is satisfied only if both their demands are fulfilled. For solving this problem, we propose mixed-integer programming (MIP) models and matheuristics based on local search. We created a benchmark of instances used to test the exact and heuristic approaches. Additionally, we proposed a preprocessing procedure to reduce the size of the instance. Our MIP models can solve to optimality 85% of the proposed instances with 1000 customers in 10 minutes, with an average gap smaller than 0.1% for all these instances. For larger instances (2500 and 5000 customers), except for some particular cases, they presented an average gap smaller than 0.8%. Also, our local-based matheuristics presented small average gaps which are better than the MIP models in some larger instances.", "pdf_url": "https://arxiv.org/pdf/2008.07372", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Displacement field estimation from OCT images utilizing speckle information with applications in quantitative elastography", "author": "Ekaterina Sherina, Lisa Krainz, Simon Hubmer, Wolfgang Drexler, Otmar Scherzer", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper, we consider the problem of estimating the internal displacement field of an object which is being subjected to a deformation, from Optical Coherence Tomography (OCT) images before and after compression. For the estimation of the internal displacement field we propose a novel algorithm, which utilizes particular speckle information to enhance the quality of the motion estimation. We present numerical results based on both simulated and experimental data in order to demonstrate the usefulness of our approach, in particular when applied for quantitative elastography, when the material parameters are estimated in a second step based on the internal displacement field.", "pdf_url": "https://arxiv.org/pdf/2008.07373", "subject": "Numerical Analysis (math.NA)"},
{"title": "Explainable AI based Interventions for Pre-season Decision Making in Fashion Retail", "author": "Shravan Sajja, Nupur Aggarwal, Sumanta Mukherjee, Kushagra Manglik, Satyam Dwivedi, Vikas Raykar", "pub_date": "Submitted on 27 Jul 2020", "abstract": "Future of sustainable fashion lies in adoption of AI for a better understanding of consumer shopping behaviour and using this understanding to further optimize product design, development and sourcing to finally reduce the probability of overproducing inventory. Explainability and interpretability are highly effective in increasing the adoption of AI based tools in creative domains like fashion. In a fashion house, stakeholders like buyers, merchandisers and financial planners have a more quantitative approach towards decision making with primary goals of high sales and reduced dead inventory. Whereas, designers have a more intuitive approach based on observing market trends, social media and runways shows. Our goal is to build an explainable new product forecasting tool with capabilities of interventional analysis such that all the stakeholders (with competing goals) can participate in collaborative decision making process of new product design, development and launch.", "pdf_url": "https://arxiv.org/pdf/2008.07376", "subject": "Computers and Society (cs.CY)"},
{"title": "[not Rp] Reproducibility of 'Poincare dodecahedral space parameter estimates'", "author": "Boudewijn F. Roukema", "pub_date": "Submitted on 23 Jul 2020", "abstract": "Is a scientific research paper based on (i) public, online observational data files and (ii) providing free-licensed software for reproducing its results easy to reproduce by the same author a decade later? This paper attempts to reproduce a cosmic topology observational paper published in 2008 and satisfying both criteria (i) and (ii). The reproduction steps are defined formally in a free-licensed git repository package \" \" and qualitatively in the current paper. It was found that the effort in upgrading the Fortran 77 code at the heart of the software, interfaced with a C front end, and originally compiled with g77, in the content of the contemporary gfortran compiler, risked being too great to be justified on any short time scale. In this sense, the results of RBG08 are not as reproducible as they appeared to be, despite both (i) data availability and (ii) free-licensing and public availability of the software. The software and a script to reproduce the steps of this incomplete reproduction are combined in a new git repository named , following the ArXiv identity code ( ) of RBG08.", "pdf_url": "https://arxiv.org/pdf/2008.07380", "subject": "Computers and Society (cs.CY)"},
{"title": "Dissecting liabilities in adversarial surgical robot failures: A national (Danish) and European law perspective", "author": "Kaspar Rosager Ludvigsen, Shishir Nagaraja", "pub_date": "Submitted on 27 Jul 2020", "abstract": "Being connected to a network exposes surgical robots to cyberattacks, which can damage the patient or the operator. These injuries are normally caused by safety failures, such as accidents with industrial robots, but cyberattacks are caused by security failures instead. Surgical robots are increasingly sold and used in the European Union, so we decide to uncover whether this change has been considered by EU law, and which legal remedies and actions a patient or manufacturer would have in a single national legal system in the union. We first conduct a case study, where we analyse which legal remedies a patient can make use of, if they are injured by a surgical robot caused by a cyberattack in the national legal system. We also explore whether cybersecurity and cyberattacks are considered by the upcoming Medical Device Regulation of the EU. We show that the selected national legal system is adequate. This is because of its flexibility and in a certain approach even to ignore the distinction between safety and security to the benefit of the patient, and in one situation to remove liability from the manufacturer by erasing its status as party. Otherwise, unless the operator or other parties have made the cyberattack more likely to occur, the manufacturer is liable. We find that the regulation does not directly consider security defects, requiring interpretation and use of guidance to show it. Due to the risk cyberattacks pose on medical equipment, we find this to not be adequate. We further find that the regulators of medical devices, including surgical robots, will not necessarily have adequate staff or rules of enforcement, as this has been left to the member states to solve. But, we also find, due to the comprehensive number of rules that can be applied cumulatively, together with the possibility for further rules and compliance later on, that these issues could be solved in the future.", "pdf_url": "https://arxiv.org/pdf/2008.07381", "subject": "Computers and Society (cs.CY)"},
{"title": "On Digital Currency and the Transfer of World Wealth and Technology Centers", "author": "Hengjin Cai", "pub_date": "Submitted on 13 Aug 2020", "abstract": "The emergence and transfer of wealth promote the evolution of civilizations. Through the pursuit of the form of wealth valued by the members of society, the self-assertiveness demands of a society can be met and thus stimulate creativity. As means of overdrawing the future, sovereign currency and bonds have gradually become modern forms of wealth and have strongly promoted scientific and technological progress and social development. However, due to the unequal distribution of wealth, the sustainability of sovereign currency and bonds is not certain. The world has been changing rapidly since the outbreak of COVID-19, and new forms of wealth need to be constructed as an extension of the Self of the masses, among which digital currency may be an effective carrier of value. China is on an upward trajectory, and the complex and volatile global environment can provide an opportunity for China to focus on developing aspects of its science and technology, optimize its system of governance and strengthen its internal driving force.", "pdf_url": "https://arxiv.org/pdf/2008.07383", "subject": "Computers and Society (cs.CY)"},
{"title": "Extended mathematical derivations for the decentralized loss minimization algorithm with the use of inverters", "author": "Ilgiz Murzakhanov, Spyros Chatzivasileiadis", "pub_date": "Submitted on 14 Aug 2020", "abstract": "This document contains extended mathematical derivations for the communication- and model-free loss minimization algorithm. The algorithm is applied in the distribution grids and exploits the capabilities of the inverters to control the reactive power output.", "pdf_url": "https://arxiv.org/pdf/2008.07384", "subject": "Systems and Control (eess.SY)"},
{"title": "Using Subjective Logic to Estimate Uncertainty in Multi-Armed Bandit Problems", "author": "Fabio Massimo Zennaro, Audun J\u00f8sang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The multi-armed bandit problem is a classical decision-making problem where an agent has to learn an optimal action balancing exploration and exploitation. Properly managing this trade-off requires a correct assessment of uncertainty; in multi-armed bandits, as in other machine learning applications, it is important to distinguish between stochasticity that is inherent to the system (aleatoric uncertainty) and stochasticity that derives from the limited knowledge of the agent (epistemic uncertainty). In this paper we consider the formalism of subjective logic, a concise and expressive framework to express Dirichlet-multinomial models as subjective opinions, and we apply it to the problem of multi-armed bandits. We propose new algorithms grounded in subjective logic to tackle the multi-armed bandit problem, we compare them against classical algorithms from the literature, and we analyze the insights they provide in evaluating the dynamics of uncertainty. Our preliminary results suggest that subjective logic quantities enable useful assessment of uncertainty that may be exploited by more refined agents.", "pdf_url": "https://arxiv.org/pdf/2008.07386", "subject": "Machine Learning (cs.LG)"},
{"title": "Deep Networks with Fast Retraining", "author": "Wandong Zhang, Yimin Yang, Jonathan Wu", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Recent wor [1] has utilized Moore-Penrose (MP) inverse in deep convolutional neural network (DCNN) training, which achieves better generalization performance over the DCNN with a stochastic gradient descent (SGD) pipeline. However, the MP technique cannot be processed in the GPU environment due to its high demands of computational resources. This paper proposes a fast DCNN learning strategy with MP inverse to achieve better testing performance without introducing a large calculation burden. We achieve this goal through an SGD and MP inverse-based two-stage training procedure. In each training epoch, a random learning strategy that controls the number of convolutional layers trained in backward pass is utilized, and an MP inverse-based batch-by-batch learning strategy is developed that enables the network to be implemented with GPU acceleration and to refine the parameters in dense layer. Through experiments on image classification datasets with various training images ranging in amount from 3,060 (Caltech101) to 1,803,460 (Place365), we empirically demonstrate that the fast retraining is a unified strategy that can be utilized in all DCNNs. Our method obtains up to 1% Top-1 testing accuracy boosts over the state-of-the-art DCNN learning pipeline, yielding a savings in training time of 15% to 25% over the work in [1]. [1] Y. Yang, J. Wu, X. Feng, and A. Thangarajah, \"Recomputation of dense layers for the perfor-238mance improvement of dcnn,\" IEEE Trans. Pattern Anal. Mach. Intell., 2019.", "pdf_url": "https://arxiv.org/pdf/2008.07387", "subject": "Machine Learning (cs.LG)"},
{"title": "Rotation-Invariant Gait Identification with Quaternion Convolutional Neural Networks", "author": "Bowen Jing, Vinay Prabhu, Angela Gu, John Whaley", "pub_date": "Submitted on 4 Aug 2020", "abstract": "A desireable property of accelerometric gait-based identification systems is robustness to new device orientations presented by users during testing but unseen during the training phase. However, traditional Convolutional neural networks (CNNs) used in these systems compensate poorly for such transformations. In this paper, we target this problem by introducing Quaternion CNN, a network architecture which is intrinsically layer-wise equivariant and globally invariant under 3D rotations of an array of input vectors. We show empirically that this network indeed significantly outperforms a traditional CNN in a multi-user rotation-invariant gait classification setting .Lastly, we demonstrate how the kernels learned by this QCNN can also be visualized as basis-independent but origin- and chirality-dependent trajectory fragments in the euclidean space, thus yielding a novel mode of feature visualization and extraction.", "pdf_url": "https://arxiv.org/pdf/2008.07393", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Study of a Genetic Algorithm for Polydisperse Spray Flames", "author": "Daniel Engelsman", "pub_date": "Submitted on 11 Aug 2020", "abstract": "Modern technological advancements constantly push forward the human-machine interaction. Evolutionary Algorithms (EA) are an machine learning (ML) subclass inspired by the process of natural selection - Survival of the Fittest, as stated by the Darwinian Theory of Evolution. The most notable algorithm in that class is the Genetic Algorithm (GA) - a powerful heuristic tool which enables the generation of a high-quality solutions to optimization problems. In recent decades the algorithm underwent remarkable improvement, which adapted it into a wide range of engineering problems, by heuristically searching for the optimal solution. Despite being well-defined, many engineering problems may suffer from heavy analytical entanglement when approaching the derivation process, as required in classic optimization methods. Therefore, the main motivation here, is to work around that obstacle. In this piece of work, I would like to harness the GA capabilities to examine optimality with respect to a unique combustion problem, in a way that was never performed before. To be more precise, I would like to utilize it to answer the question : What form of an initial droplet size distribution (iDSD) will guarantee an optimal flame ? To answer this question, I will first provide a general introduction to the GA method, then develop the combustion model, and eventually merge both into an optimization problem.", "pdf_url": "https://arxiv.org/pdf/2008.07397", "subject": "Neural and Evolutionary Computing (cs.NE)"},
{"title": "Spatial Temporal Transformer Network for Skeleton-based Action Recognition", "author": "Chiara Plizzari, Marco Cannici, Matteo Matteucci", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Skeleton-based Human Activity Recognition has achieved a great interest in recent years, as skeleton data has been demonstrated to be robust to illumination changes, body scales, dynamic camera views and complex background. In particular, Spatial-Temporal Graph Convolutional Networks (ST-GCN) demonstrated to be effective in learning both spatial and temporal dependencies on non-Euclidean data such as skeleton graphs. Nevertheless, an effective encoding of the latent information underlying the 3D skeleton is still an open problem, especially how to extract effective information from joint motion patterns and their correlations. In this work, we propose a novel Spatial-Temporal Transformer network (ST-TR) which models dependencies between joints using the Transformer self-attention operator. In our ST-TR model a Spatial Self-Attention module (SSA) is used to understand intra-frame interactions between different body parts, and a Temporal Self-Attention module (TSA) to model inter-frame correlations. The two are combined in a two-stream network, whose performance is evaluated on three large-scale datasets, NTU-RGB+D 60, NTU-RGB+D 120 and Kinetics Skeleton 400, outperforming the state-of-the-art on NTU-RGB+D w.r.t. models using the same input data consisting of joint information.", "pdf_url": "https://arxiv.org/pdf/2008.07404", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Network Intrusion Detection Using Wrapper-based Decision Tree for Feature Selection", "author": "Mubarak Albarka Umar, Chen Zhanfang, Yan Liu", "pub_date": "Submitted on 11 Aug 2020", "abstract": "One of the key challenges of machine learning (ML) based intrusion detection system (IDS) is the expensive computational complexity which is largely due to redundant, incomplete, and irrelevant features contain in the IDS datasets. To overcome such challenge and ensure building an efficient and more accurate IDS models, many researchers utilize preprocessing techniques such as normalization and feature selection in a hybrid modeling approach. In this work, we propose a hybrid IDS modeling approach with an algorithm for feature selection (FS) and another for building an IDS. The FS algorithm is a wrapper-based with a decision tree as the feature evaluator. The propose FS method is used in combination with some selected ML algorithms to build IDS models using the UNSW-NB15 dataset. Some IDS models are built as a baseline in a single modeling approach using the full features of the dataset. We evaluate the effectiveness of our propose method by comparing it with the baseline models and also with state-of-the-art works. Our method achieves the best DR of 97.95% and shown to be quite effective in comparison to state-of-the-art works. We, therefore, recommend its usage especially in IDS modeling with the UNSW-NB15 dataset.", "pdf_url": "https://arxiv.org/pdf/2008.07405", "subject": "Cryptography and Security (cs.CR)"},
{"title": "A deep active inference model of the rubber-hand illusion", "author": "Thomas Rood, Marcel van Gerven, Pablo Lanillos", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Understanding how perception and action deal with sensorimotor conflicts, such as the rubber-hand illusion (RHI), is essential to understand how the body adapts to uncertain situations. Recent results in humans have shown that the RHI not only produces a change in the perceived arm location, but also causes involuntary forces. Here, we describe a deep active inference agent in a virtual environment, which we subjected to the RHI, that is able to account for these results. We show that our model, which deals with visual high-dimensional inputs, produces similar perceptual and force patterns to those found in humans.", "pdf_url": "https://arxiv.org/pdf/2008.07408", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Versatile Filamentary Resistive Switching Model", "author": "Iosif-Angelos Fyrigos, Vasileios Ntinas, Georgios Ch. Sirakoulis, Panagiotis Dimitrakis, Ioannis G. Karafyllidis", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Memristors as emergent nano-electronic devices have been successfully fabricated and used in non-conventional and neuromorphic computing systems in the last years. Several behavioral or physical based models have been developed to explain their operation and to optimize their fabrication parameters. All existing memristor models are trade-offs between accuracy, universality and realism, but, to the best of our knowledge, none of them is purely characterized as quantum mechanical, despite the fact that quantum mechanical processes are a major part of the memristor operation. In this paper, we employ quantum mechanical methods to develop a complete and accurate filamentary model for the resistance variation during memristor's operating cycle. More specifically, we apply quantum walks to model and compute the motion of atoms forming the filament, tight-binding Hamiltonians to capture the filament structure and the Non-Equilibrium Green's Function (NEGF) method to compute the conductance of the device. Furthermore, we proceeded with the parallelization of the overall model through Graphical Processing Units (GPUs) to accelerate our computations and enhance the model's performance adequately. Our simulation results successfully reproduce the resistive switching characteristics of memristors devices, match with existing fabricated devices experimental data, prove the efficacy and robustness of the proposed model in terms of multi-parameterization, and provide a new and useful insight into its operation.", "pdf_url": "https://arxiv.org/pdf/2008.07409", "subject": "Emerging Technologies (cs.ET)"},
{"title": "Towards Smart Sustainable Cities: Addressing semantic heterogeneity in building management systems using discriminative models", "author": "Chidubem Iddianozie, Paulito Palmes", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Building Management Systems (BMS) are crucial in the drive towards smart sustainable cities. This is due to the fact that they have been effective in significantly reducing the energy consumption of buildings. A typical BMS is composed of smart devices that communicate with one another in order to achieve their purpose. However, the heterogeneity of these devices and their associated meta-data impede the deployment of solutions that depend on the interactions among these devices. Nonetheless, automatically inferring the semantics of these devices using data-driven methods provides an ideal solution to the problems brought about by this heterogeneity. In this paper, we undertake a multi-dimensional study to address the problem of inferring the semantics of IoT devices using machine learning models. Using two datasets with over 67 million data points collected from IoT devices, we developed discriminative models that produced competitive results. Particularly, our study highlights the potential of Image Encoded Time Series (IETS) as a robust alternative to statistical feature-based inference methods. Leveraging just a fraction of the data required by feature-based methods, our evaluations show that this encoding competes with and even outperforms traditional methods in many cases.", "pdf_url": "https://arxiv.org/pdf/2008.07414", "subject": "Computers and Society (cs.CY)"},
{"title": "Grundy Distinguishes Treewidth from Pathwidth", "author": "R\u00e9my Belmonte, Eun Jung Kim, Michael Lampis, Valia Mitsou, Yota Otachi", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Structural graph parameters, such as treewidth, pathwidth, and clique-width, are a central topic of study in parameterized complexity. A main aim of research in this area is to understand the \"price of generality\" of these widths: as we transition from more restrictive to more general notions, which are the problems that see their complexity status deteriorate from fixed-parameter tractable to intractable? This type of question is by now very well-studied, but, somewhat strikingly, the algorithmic frontier between the two (arguably) most central width notions, treewidth and pathwidth, is still not understood: currently, no natural graph problem is known to be W-hard for one but FPT for the other. Indeed, a surprising development of the last few years has been the observation that for many of the most paradigmatic problems, their complexities for the two parameters actually coincide exactly, despite the fact that treewidth is a much more general parameter. It would thus appear that the extra generality of treewidth over pathwidth often comes \"for free\". Our main contribution in this paper is to uncover the first natural example where this generality comes with a high price. We consider Grundy Coloring, a variation of coloring where one seeks to calculate the worst possible coloring that could be assigned to a graph by a greedy First-Fit algorithm. We show that this well-studied problem is FPT parameterized by pathwidth; however, it becomes significantly harder (W[1]-hard) when parameterized by treewidth. Furthermore, we show that Grundy Coloring makes a second complexity jump for more general widths, as it becomes para-NP-hard for clique-width. Hence, Grundy Coloring nicely captures the complexity trade-offs between the three most well-studied parameters. Completing the picture, we show that Grundy Coloring is FPT parameterized by modular-width.", "pdf_url": "https://arxiv.org/pdf/2008.07425", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Hey Human, If your Facial Emotions are Uncertain, You Should Use Bayesian Neural Networks!", "author": "Maryam Matin, Matias Valdenegro-Toro", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Facial emotion recognition is the task to classify human emotions in face images. It is a difficult task due to high aleatoric uncertainty and visual ambiguity. A large part of the literature aims to show progress by increasing accuracy on this task, but this ignores the inherent uncertainty and ambiguity in the task. In this paper we show that Bayesian Neural Networks, as approximated using MC-Dropout, MC-DropConnect, or an Ensemble, are able to model the aleatoric uncertainty in facial emotion recognition, and produce output probabilities that are closer to what a human expects. We also show that calibration metrics show strange behaviors for this task, due to the multiple classes that can be considered correct, which motivates future work. We believe our work will motivate other researchers to move away from Classical and into Bayesian Neural Networks.", "pdf_url": "https://arxiv.org/pdf/2008.07426", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Dynamical reduced basis methods for Hamiltonian systems", "author": "Cecilia Pagliantini", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We consider model order reduction of parameterized Hamiltonian systems describing nondissipative phenomena, like wave-type and transport dominated problems. The development of reduced basis methods for such models is challenged by two main factors: the rich geometric structure encoding the physical and stability properties of the dynamics and its local low-rank nature. To address these aspects, we propose a nonlinear structure-preserving model reduction where the reduced phase space evolves in time. In the spirit of dynamical low-rank approximation, the reduced dynamics is obtained by a symplectic projection of the Hamiltonian vector field onto the tangent space of the approximation manifold at each reduced state. A priori error estimates are established in terms of the projection error of the full model solution onto the reduced manifold. For the temporal discretization of the reduced dynamics we employ splitting techniques. The reduced basis satisfies an evolution equation on the manifold of symplectic and orthogonal rectangular matrices having one dimension equal to the size of the full model. We recast the problem on the tangent space of the matrix manifold and develop intrinsic temporal integrators based on Lie group techniques together with explicit Runge-Kutta (RK) schemes. The resulting methods are shown to converge with the order of the RK integrator and their computational complexity depends only linearly on the dimension of the full model, provided the evaluation of the reduced flow velocity has a comparable cost.", "pdf_url": "https://arxiv.org/pdf/2008.07427", "subject": "Numerical Analysis (math.NA)"},
{"title": "An Overview on the Web of Clinical Data", "author": "Marco Gori", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In the last few years there has been an impressive growth of connections between medicine and artificial intelligence (AI) that have been characterized by the specific focus on single problems along with corresponding clinical data. This paper proposes a new perspective in which the focus is on the progressive accumulation of a universal repository of clinical hyperlinked data in the spirit that gave rise to the birth of the Web. The underlining idea is that this repository, that is referred to as the Web of Clinical Data (WCD), will dramatically change the AI approach to medicine and its effectiveness. It is claimed that research and AI-based applications will undergo an evolution process that will likely reinforce systematically the solutions implemented in medical apps made available in the WCD. The distinctive architectural feature of the WCD is that this universal repository will be under control of clinical units and hospitals, which is claimed to be the natural context for dealing with the critical issues of clinical data.", "pdf_url": "https://arxiv.org/pdf/2008.07432", "subject": "Computers and Society (cs.CY)"},
{"title": "LiFT: A Scalable Framework for Measuring Fairness in ML Applications", "author": "Sriram Vasudevan, Krishnaram Kenthapadi", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Many internet applications are powered by machine learned models, which are usually trained on labeled datasets obtained through either implicit / explicit user feedback signals or human judgments. Since societal biases may be present in the generation of such datasets, it is possible for the trained models to be biased, thereby resulting in potential discrimination and harms for disadvantaged groups. Motivated by the need for understanding and addressing algorithmic bias in web-scale ML systems and the limitations of existing fairness toolkits, we present the LinkedIn Fairness Toolkit (LiFT), a framework for scalable computation of fairness metrics as part of large ML systems. We highlight the key requirements in deployed settings, and present the design of our fairness measurement system. We discuss the challenges encountered in incorporating fairness tools in practice and the lessons learned during deployment at LinkedIn. Finally, we provide open problems based on practical experience.", "pdf_url": "https://arxiv.org/pdf/2008.07433", "subject": "Machine Learning (cs.LG)"},
{"title": "Integrating Deep Reinforcement Learning Networks with Health System Simulations", "author": "Michael Allen, Thomas Monks", "pub_date": "Submitted on 21 Jul 2020", "abstract": "Background and motivation: Combining Deep Reinforcement Learning (Deep RL) and Health Systems Simulations has significant potential, for both research into improving Deep RL performance and safety, and in operational practice. While individual toolkits exist for Deep RL and Health Systems Simulations, no framework to integrate the two has been established. Aim: Provide a framework for integrating Deep RL Networks with Health System Simulations, and to ensure this framework is compatible with Deep RL agents that have been developed and tested using OpenAI Gym. Methods: We developed our framework based on the OpenAI Gym framework, and demonstrate its use on a simple hospital bed capacity model. We built the Deep RL agents using PyTorch, and the Hospital Simulatation using SimPy. Results: We demonstrate example models using a Double Deep Q Network or a Duelling Double Deep Q Network as the Deep RL agent. Conclusion: SimPy may be used to create Health System Simulations that are compatible with agents developed and tested on OpenAI Gym environments. GitHub repository of code:", "pdf_url": "https://arxiv.org/pdf/2008.07434", "subject": "Machine Learning (cs.LG)"},
{"title": "Multi-Agent Coverage in Urban Environments", "author": "Shivang Patel, Senthil Hariharan, Pranav Dhulipala, Ming C Lin, Dinesh Manocha, Huan Xu, Michael Otte", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We study multi-agent coverage algorithms for autonomous monitoring and patrol in urban environments. We consider scenarios in which a team of flying agents uses downward facing cameras (or similar sensors) to observe the environment outside of buildings at street-level. Buildings are considered obstacles that impede movement, and cameras are assumed to be ineffective above a maximum altitude. We study multi-agent urban coverage problems related to this scenario, including: (1) static multi-agent urban coverage, in which agents are expected to observe the environment from static locations, and (2) dynamic multi-agent urban coverage where agents move continuously through the environment. We experimentally evaluate six different multi-agent coverage methods, including: three types of ergodic coverage (that avoid buildings in different ways), lawn-mower sweep, voronoi region based control, and a naive grid method. We evaluate all algorithms with respect to four performance metrics (percent coverage, revist count, revist time, and the integral of area viewed over time), across four types of urban environments [low density, high density] x [short buildings, tall buildings], and for team sizes ranging from 2 to 25 agents. We believe this is the first extensive comparison of these methods in an urban setting. Our results highlight how the relative performance of static and dynamic methods changes based on the ratio of team size to search area, as well the relative effects that different characteristics of urban environments (tall, short, dense, sparse, mixed) have on each algorithm.", "pdf_url": "https://arxiv.org/pdf/2008.07436", "subject": "Robotics (cs.RO)"},
{"title": "High Performance Multivariate Spatial Modeling for Geostatistical Data on Manycore Systems", "author": "Mary Lai O. Salva\u00f1a, Sameh Abdulah, Huang Huang, Hatem Ltaief, Ying Sun, Marc G. Genton, David E. Keyes", "pub_date": "Submitted on 3 Aug 2020", "abstract": "Modeling and inferring spatial relationships and predicting missing values of environmental data are some of the main tasks of geospatial statisticians. These routine tasks are accomplished using multivariate geospatial models and the cokriging technique. The latter requires the evaluation of the expensive Gaussian log-likelihood function, which has impeded the adoption of multivariate geospatial models for large multivariate spatial datasets. However, this large-scale cokriging challenge provides a fertile ground for supercomputing implementations for the geospatial statistics community as it is paramount to scale computational capability to match the growth in environmental data coming from the widespread use of different data collection technologies. In this paper, we develop and deploy large-scale multivariate spatial modeling and inference on parallel hardware architectures. To tackle the increasing complexity in matrix operations and the massive concurrency in parallel systems, we leverage low-rank matrix approximation techniques with task-based programming models and schedule the asynchronous computational tasks using a dynamic runtime system. The proposed framework provides both the dense and the approximated computations of the Gaussian log-likelihood function. It demonstrates accuracy robustness and performance scalability on a variety of computer systems. Using both synthetic and real datasets, the low-rank matrix approximation shows better performance compared to exact computation, while preserving the application requirements in both parameter estimation and prediction accuracy. We also propose a novel algorithm to assess the prediction accuracy after the online parameter estimation. The algorithm quantifies prediction performance and provides a benchmark for measuring the efficiency and accuracy of several approximation techniques in multivariate spatial modeling.", "pdf_url": "https://arxiv.org/pdf/2008.07437", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Analysis and Optimization for Large-Scale LoRa Networks: Throughput Fairness and Scalability", "author": "Jiangbin Lyu, Dan Yu, Liqun Fu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "With growing popularity, LoRa networks are pivotally enabling Long Range connectivity to low-cost and power-constrained user equipments (UEs). Due to its wide coverage area, a critical issue is to effectively allocate wireless resources to support potentially massive UEs while resolving the prominent near-far fairness problem in the LoRa network, which is challenging due to the lack of tractable analytical model and its practical requirement for low-complexity and low-overhead design. To achieve massive connectivity with fairness, we aim to maximize the minimum throughput of all UEs, and propose high-level policies of joint spreading factor (SF) allocation, power control, and duty cycle adjustment based only on average channel statistics and spatial UE distribution. By leveraging on the Poisson rain model along with tailored modifications to our considered LoRa network under both single-cell and multi-cell setups, we are able to account for channel fading, aggregate interference, accurate packet overlapping, and/or multi-gateway packet reception, and still obtain tractable and accurate formulas for the packet success probability and hence throughput. We further propose an iterative balancing (IB) method to allocate the SFs in the cell such that the overall max-min throughput can be achieved. Numerical results show that the proposed scheme with optimized design greatly alleviates the near-far fairness issue and also reduces the spatial power consumption, while significantly improving the cell-edge throughput as well as the spatial (sum) throughput for the majority of UEs, especially for large-scale LoRa networks with massive UEs and high gateway density.", "pdf_url": "https://arxiv.org/pdf/2008.07438", "subject": "Information Theory (cs.IT)"},
{"title": "Zero Shot Domain Generalization", "author": "Udit Maniyar, Joseph K J, Aniket Anand Deshmukh, Urun Dogan, Vineeth N Balasubramanian", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Standard supervised learning setting assumes that training data and test data come from the same distribution (domain). Domain generalization (DG) methods try to learn a model that when trained on data from multiple domains, would generalize to a new unseen domain. We extend DG to an even more challenging setting, where the label space of the unseen domain could also change. We introduce this problem as Zero-Shot Domain Generalization (to the best of our knowledge, the first such effort), where the model generalizes across new domains and also across new classes in those domains. We propose a simple strategy which effectively exploits semantic information of classes, to adapt existing DG methods to meet the demands of Zero-Shot Domain Generalization. We evaluate the proposed methods on CIFAR-10, CIFAR-100, F-MNIST and PACS datasets, establishing a strong baseline to foster interest in this new research direction.", "pdf_url": "https://arxiv.org/pdf/2008.07443", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Parallel repetition with a threshold in quantum interactive proofs", "author": "Abel Molina", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this note, we show that $O(\\log (1/\\epsilon))$ rounds of parallel repetition with a threshold suffice to reduce completeness and soundness error to $\\epsilon$ for single-prover quantum interactive proof systems. This improves on a previous $O(\\log (1/\\epsilon) \\log \\log (1/\\epsilon))$ bound from Hornby (2018), while also simplifying its proof. A key element in our proof is a concentration bound from Impagliazzo and Kabanets (2010).", "pdf_url": "https://arxiv.org/pdf/2008.07445", "subject": "Computational Complexity (cs.CC)"},
{"title": "A Survey on the Use of AI and ML for Fighting the COVID-19 Pandemic", "author": "Muhammad Nazrul Islam, Toki Tahmid Inan, Suzzana Rafi, Syeda Sabrina Akter, Iqbal H. Sarker, A. K. M. Najmul Islam", "pub_date": "Submitted on 3 Aug 2020", "abstract": "Artificial intelligence (AI) and machine learning (ML) have made a paradigm shift in health care which, eventually can be used for decision support and forecasting by exploring the medical data. Recent studies showed that AI and ML can be used to fight against the COVID-19 pandemic. Therefore, the objective of this review study is to summarize the recent AI and ML based studies that have focused to fight against COVID-19 pandemic. From an initial set of 634 articles, a total of 35 articles were finally selected through an extensive inclusion-exclusion process. In our review, we have explored the objectives/aims of the existing studies (i.e., the role of AI/ML in fighting COVID-19 pandemic); context of the study (i.e., study focused to a specific country-context or with a global perspective); type and volume of dataset; methodology, algorithms or techniques adopted in the prediction or diagnosis processes; and mapping the algorithms/techniques with the data type highlighting their prediction/classification accuracy. We particularly focused on the uses of AI/ML in analyzing the pandemic data in order to depict the most recent progress of AI for fighting against COVID-19 and pointed out the potential scope of further research.", "pdf_url": "https://arxiv.org/pdf/2008.07449", "subject": "Machine Learning (cs.LG)"},
{"title": "Effects of Internship on Fresh Graduates: A case study on IIT, DU students", "author": "Amit Seal Ami, Asif Imran, Alim Ul Gias, Kazi Sakib", "pub_date": "Submitted on 3 Aug 2020", "abstract": "The aim of any curriculum is to produce industry ready students. The effectiveness of curricular activities, thus, can be measured by the performances of fresh graduates at their job sectors. To evaluate the Software Engineering (SE) syllabus, Institute of Information Technology (IIT), University of Dhaka, has taken an initiative, under the project IQAC, HEQEP, where a survey based study has been performed. The uniqueness of this SE syllabus is having a six month long internship semester inside the curriculum. Considering all the other courses and activities as traditional, the outcome of the study can fairly be considered as the effect of the Internship program. The result shows that the students having internship experiences, performed above the level of expectation from the industries.", "pdf_url": "https://arxiv.org/pdf/2008.07450", "subject": "Computers and Society (cs.CY)"},
{"title": "Learning to Actively Reduce Memory Requirements for Robot Control Tasks", "author": "Meghan Booker, Anirudha Majumdar", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Robots equipped with rich sensing modalities (e.g., RGB-D cameras) performing long-horizon tasks motivate the need for policies that are highly memory-efficient. State-of-the-art approaches for controlling robots often use memory representations that are excessively rich for the task or rely on hand-crafted tricks for memory efficiency. Instead, this work provides a general approach for jointly synthesizing memory representations and policies; the resulting policies actively seek to reduce memory requirements (i.e., take actions that reduce memory usage). Specifically, we present a reinforcement learning framework that leverages an implementation of the group LASSO regularization to synthesize policies that employ low-dimensional and task-centric memory representations. We demonstrate the efficacy of our approach with simulated examples including navigation in discrete and continuous spaces as well as vision-based indoor navigation set in a photo-realistic simulator. The results on these examples indicate that our method is capable of finding policies that rely only on low-dimensional memory representations and actively reduce memory requirements.", "pdf_url": "https://arxiv.org/pdf/2008.07451", "subject": "Robotics (cs.RO)"},
{"title": "Gathering in 1-Interval Connected Graphs", "author": "Othon Michail, Paul G. Spirakis, Michail Theofilatos", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We examine the problem of gathering $k \\geq 2$ agents (or multi-agent rendezvous) in dynamic graphs which may change in every synchronous round but remain always connected ($1$-interval connectivity) [KLO10]. The agents are identical and without explicit communication capabilities, and are initially positioned at different nodes of the graph. The problem is for the agents to gather at the same node, not fixed in advance. We first show that the problem becomes impossible to solve if the graph has a cycle. In light of this, we study a relaxed version of this problem, called weak gathering. We show that only in unicyclic graphs weak gathering is solvable, and we provide a deterministic algorithm for this problem that runs in polynomial number of rounds.", "pdf_url": "https://arxiv.org/pdf/2008.07455", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Herramientas tecnol\u00f3gicas en Android para la formaci\u00f3n de mapeadores y promotores de Mapa Verde", "author": "Yosvany Medina Carb\u00f3, C. \u00c1lvaro Celestino Alonso V\u00e1zquez, Reina Mar\u00eda Rodr\u00edguez Garc\u00eda", "pub_date": "Submitted on 21 Jul 2020", "abstract": "When you talk about technologies and the environment, you usually imagine a lot of equipment, techniques, technologies and tools polluting the natural environment. The good and bad consequences of our development have been projected on the planet for years, and part of that development is reflected in the new technologies, among which is the mobile phone. In the municipality of Consolaci\u00f3n del Sur and from the Municipal University Center, the project Implementation of the Green Map Methodology in the management of environmental education in console communities for the formation of an environmental culture for sustainable development is created, creating awareness of care and protection of the environment. The present work is given to solve the following problem: how to contribute in the construction of a package of computer tools for the implementation of the Green Map methodology in environmental management in console communities and the training of mappers and promoters of Green Map for the development of green maps of the communities of the municipality Consolaci\u00f3n del Sur? For this purpose, two Android applications for mobile devices based on the Green Map methodology were developed, thus responding to the following objective: Develop a package of computer applications for the implementation of the Green Map methodology in the management of environmental education in console communities and the formation of mappers and promoters of the Green Map that allows the development of the green maps of the communities of the Consolaci\u00f3n del Sur municipality.", "pdf_url": "https://arxiv.org/pdf/2008.07458", "subject": "Other Computer Science (cs.OH)"},
{"title": "Automated Reasoning in Temporal DL-Lite", "author": "Sabiha Tahrat, German Braun, Alessandro Artale, Marco Gario, Ana Ozaki", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This paper investigates the feasibility of automated reasoning over temporal DL-Lite (TDL-Lite) knowledge bases (KBs). We test the usage of off-the-shelf LTL reasoners to check satisfiability of TDL-Lite KBs. In particular, we test the robustness and the scalability of reasoners when dealing with TDL-Lite TBoxes paired with a temporal ABox. We conduct various experiments to analyse the performance of different reasoners by randomly generating TDL-Lite KBs and then measuring the running time and the size of the translations. Furthermore, in an effort to make the usage of TDL-Lite KBs a reality, we present a fully fledged tool with a graphical interface to design them. Our interface is based on conceptual modelling principles and it is integrated with our translation tool and a temporal reasoner.", "pdf_url": "https://arxiv.org/pdf/2008.07463", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Narrative Interpolation for Generating and Understanding Stories", "author": "Su Wang, Greg Durrett, Katrin Erk", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We propose a method for controlled narrative/story generation where we are able to guide the model to produce coherent narratives with user-specified target endings by interpolation: for example, we are told that Jim went hiking and at the end Jim needed to be rescued, and we want the model to incrementally generate steps along the way. The core of our method is an interpolation model based on GPT-2 which conditions on a previous sentence and a next sentence in a narrative and fills in the gap. Additionally, a reranker helps control for coherence of the generated text. With human evaluation, we show that ending-guided generation results in narratives which are coherent, faithful to the given ending guide, and require less manual effort on the part of the human guide writer than past approaches.", "pdf_url": "https://arxiv.org/pdf/2008.07466", "subject": "Computation and Language (cs.CL)"},
{"title": "Learning to Create Better Ads: Generation and Ranking Approaches for Ad Creative Refinement", "author": "Shaunak Mishra, Manisha Verma, Yichao Zhou, Kapil Thadani, Wei Wang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In the online advertising industry, the process of designing an ad creative (i.e., ad text and image) requires manual labor. Typically, each advertiser launches multiple creatives via online A/B tests to infer effective creatives for the target audience, that are then refined further in an iterative fashion. Due to the manual nature of this process, it is time-consuming to learn, refine, and deploy the modified creatives. Since major ad platforms typically run A/B tests for multiple advertisers in parallel, we explore the possibility of collaboratively learning ad creative refinement via A/B tests of multiple advertisers. In particular, given an input ad creative, we study approaches to refine the given ad text and image by: (i) generating new ad text, (ii) recommending keyphrases for new ad text, and (iii) recommending image tags (objects in image) to select new ad image. Based on A/B tests conducted by multiple advertisers, we form pairwise examples of inferior and superior ad creatives, and use such pairs to train models for the above tasks. For generating new ad text, we demonstrate the efficacy of an encoder-decoder architecture with copy mechanism, which allows some words from the (inferior) input text to be copied to the output while incorporating new words associated with higher click-through-rate. For the keyphrase and image tag recommendation task, we demonstrate the efficacy of a deep relevance matching model, as well as the relative robustness of ranking approaches compared to ad text generation in cold-start scenarios with unseen advertisers. We also share broadly applicable insights from our experiments using data from the Yahoo Gemini ad platform.", "pdf_url": "https://arxiv.org/pdf/2008.07467", "subject": "Computation and Language (cs.CL)"},
{"title": "A unified algorithm for colouring graphs of bounded clique-width", "author": "Bruno Courcelle, Ir\u00e8ne Durand, Michael Raskin", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Clique-width is one of the graph complexity measures leading to polynomial special-case algorithms for generally NP-complete problems, e.g. graph colourability. The best two currently known algorithms for verifying c-colourability of graphs represented as clique-width terms are optimised towards two different extreme cases, a constant number of colours and a very large number of colours. We present a way to unify these approaches in a single relatively simple algorithm that achieves the state of the art complexity in both cases. The unified algorithm also provides a speed-up for a large number of colours.", "pdf_url": "https://arxiv.org/pdf/2008.07468", "subject": "Computational Complexity (cs.CC)"},
{"title": "Absorption in Time-Varying Markov Chains: Graph-Based Conditions", "author": "Yasin Yazicioglu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We investigate absorption, i.e., almost sure convergence to an absorbing state, in time-varying (non-homogeneous) discrete-time Markov chains with finite state space. We consider systems that can switch among a finite set of transition matrices, which we call the modes. Our analysis is focused on two properties: 1) almost sure convergence to an absorbing state under any switching, and 2) almost sure convergence to a desired set of absorbing states via a proper switching policy. We derive necessary and sufficient conditions based on the structures of the transition graphs of modes. More specifically, we show that a switching policy that ensures almost sure convergence to a desired set of absorbing states from any initial state exists if and only if those absorbing states are reachable from any state on the union of simplified transition graphs. We then show three sufficient conditions for absorption under arbitrary switching. While the first two conditions depend on the acyclicity (weak acyclicity) of the union (intersection) of simplified transition graphs, the third condition is based on the distances of each state to the absorbing states in all the modes. These graph theoretic conditions can verify the stability and stabilizability of absorbing states based only on the feasibility of transitions in each mode.", "pdf_url": "https://arxiv.org/pdf/2008.07475", "subject": "Systems and Control (eess.SY)"},
{"title": "Emotion Carrier Recognition from Personal Narratives", "author": "Aniruddha Tammewar, Alessandra Cervone, Giuseppe Riccardi", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Personal Narratives (PN) - recollections of facts, events, and thoughts from one's own experience - are often used in everyday conversations. So far, PNs have mainly been explored for tasks such as valence prediction or emotion classification (i.e. happy, sad). However, these tasks might overlook more fine-grained information that could nevertheless prove relevant for understanding PNs. In this work, we propose a novel task for Narrative Understanding: Emotion Carrier Recognition (ECR). We argue that automatic recognition of emotion carriers, the text fragments that carry the emotions of the narrator (i.e. 'loss of a grandpa', 'high school reunion'), from PNs, provides a deeper level of emotion analysis needed, for instance, in the mental healthcare domain. In this work, we explore the task of ECR using a corpus of PNs manually annotated with emotion carriers and investigate different baseline models for the task. Furthermore, we propose several evaluation strategies for the task. Based on the inter-annotator agreement, the task in itself was found to be complex and subjective for humans. Nevertheless, we discuss evaluation metrics that could be suitable for applications based on ECR.", "pdf_url": "https://arxiv.org/pdf/2008.07481", "subject": "Computation and Language (cs.CL)"},
{"title": "On the Latency of IEEE 802.11ax WLANs with Parameterized Spatial Reuse", "author": "Eloise de Carvalho Rodrigues, Adrian Garcia-Rodriguez, Lorenzo Galati Giordano, Giovanni Geraci", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this article, we evaluate the performance of the parameterized spatial reuse (PSR) framework of IEEE 802.11ax, mainly focusing on its impact on transmission latency. Based on detailed standard-compliant system-level simulations, we provide a realistic analysis of the effects of PSR considering different scenario densities, traffic loads, and access points (APs) antenna capabilities to quantify its performance gains under various scenarios. Our results show that, in medium-density scenarios, PSR can offer up to a 3.8x reduction in the 5% worst-case latencies for delay-sensitive stations with respect to an 802.11ax system without PSR. Moreover, our study demonstrates that, for low-latency communications, providing the network with PSR capabilities may be an appealing alternative to the deployment of more costly multi-antenna APs.", "pdf_url": "https://arxiv.org/pdf/2008.07482", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "CheckDP: An Automated and Integrated Approach for Proving Differential Privacy or Finding Precise Counterexamples", "author": "Yuxin Wang, Zeyu Ding, Daniel Kifer, Danfeng Zhang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We propose CheckDP, the first automated and integrated approach for proving or disproving claims that a mechanism is differentially private. CheckDP can find counterexamples for mechanisms with subtle bugs for which prior counterexample generators have failed. Furthermore, it was able to \\emph{automatically} generate proofs for correct mechanisms for which no formal verification was reported before. CheckDP is built on static program analysis, allowing it to be more efficient and more precise in catching infrequent events than existing counterexample generators (which run mechanisms hundreds of thousands of times to estimate their output distribution). Moreover, its sound approach also allows automatic verification of correct mechanisms. When evaluated on standard benchmarks and newer privacy mechanisms, CheckDP generates proofs (for correct mechanisms) and counterexamples (for incorrect mechanisms) within 70 seconds without any false positives or false negatives.", "pdf_url": "https://arxiv.org/pdf/2008.07485", "subject": "Programming Languages (cs.PL)"},
{"title": "Control Communication Co-Design for Wide Area Cyber-Physical Systems", "author": "Laksh Bhatia, Ivana Tomi\u0107, Anqi Fu, Michael Breza, Julie A. McCann", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Wide Area Cyber-Physical Systems (WA-CPSs) are a class of control systems that integrate low-powered sensors, heterogeneous actuators and computer controllers into large infrastructure that span multi-kilometre distances. Current wireless communication technologies are incapable of meeting the communication requirements of range and bounded delays needed for the control of WA-CPSs. To solve this problem, we use a Control-Communication Co-design approach for WA-CPSs, that we refer to as the $C^3$ approach, to design a novel Low-Power Wide Area (LPWA) MAC protocol called \\textit{Ctrl-MAC} and its associated event-triggered controller that can guarantee the closed-loop stability of a WA-CPS. This is the first paper to show that LPWA wireless communication technologies can support the control of WA-CPSs. LPWA technologies are designed to support one-way communication for monitoring and are not appropriate for control. We present this work using an example of a water distribution network application which we evaluate both through a co-simulator (modelling both physical and cyber subsystems) and testbed deployments. Our evaluation demonstrates full control stability, with up to $50$\\% better packet delivery ratios and $80$\\% less average end-to-end delays when compared to a state of the art LPWA technology. We also evaluate our scheme against an idealised, wired, centralised, control architecture and show that the controller maintains stability and the overshoots remain within bounds.", "pdf_url": "https://arxiv.org/pdf/2008.07492", "subject": "Systems and Control (eess.SY)"},
{"title": "Strong Structural Controllability of Diffusively Coupled Networks: Comparison of Bounds Based on Distances and Zero Forcing", "author": "Yasin Yazicioglu, Mudassir Shabbir, Waseem Abbas, Xenofon Koutsoukos", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We study the strong structural controllability (SSC) of diffusively coupled networks, where the external control inputs are injected to only some nodes, namely the leaders. For such systems, one measure of controllability is the dimension of strong structurally controllable subspace, which is equal to the smallest possible rank of controllability matrix under admissible (positive) coupling weights. In this paper, we compare two tight lower bounds on the dimension of strong structurally controllable subspace: one based on the distances of followers to leaders, and the other based on the graph coloring process known as zero forcing. We show that the distance-based lower bound is usually better than the zero-forcing-based bound when the leaders do not constitute a zero-forcing set. On the other hand, we also show that any set of leaders that can be shown to achieve complete SSC via the distance-based bound is necessarily a zero-forcing set. These results indicate that while the zero-forcing based approach may be preferable when the focus is only on verifying complete SSC, the distance-based approach is usually more informative when partial SSC is also of interest. Furthermore, we also present a novel bound based on the combination of these two approaches, which is always at least as good as, and in some cases strictly greater than, the maximum of the two bounds. We support our analysis with numerical results for various graphs and leader sets.", "pdf_url": "https://arxiv.org/pdf/2008.07495", "subject": "Systems and Control (eess.SY)"},
{"title": "Intelligence plays dice: Stochasticity is essential for machine learning", "author": "Mert R. Sabuncu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Many fields view stochasticity as a way to gain computational efficiency, while often having to trade off accuracy. In this perspective article, we argue that stochasticity plays a fundamentally different role in machine learning (ML) and is likely a critical ingredient of intelligent systems. As we review the ML literature, we notice that stochasticity features in many ML methods, affording them robustness, generalizability, and calibration. We also note that randomness seems to be prominent in biological intelligence, from the spiking patterns of individual neurons to the complex behavior of animals. We conclude with a discussion of how we believe stochasticity might shape the future of ML.", "pdf_url": "https://arxiv.org/pdf/2008.07496", "subject": "Machine Learning (cs.LG)"},
{"title": "Wireless Powered Mobile Edge Computing: Offloading Or Local Computation?", "author": "Constantinos Psomas, Ioannis Krikidis", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Mobile-edge computing (MEC) and wireless power transfer are technologies that can assist in the implementation of next generation wireless networks, which will deploy a large number of computational and energy limited devices. In this letter, we consider a point-to-point MEC system, where the device harvests energy from the access point's (AP's) transmitted signal to power the offloading and/or the local computation of a task. By taking into account the non-linearities of energy harvesting, we provide analytical expressions for the probability of successful computation and for the average number of successfully computed bits. Our results show that a hybrid scheme of partial offloading and local computation is not always efficient. In particular, the decision to offload and/or compute locally, depends on the system's parameters such as the distance to the AP and the number of bits that need to be computed.", "pdf_url": "https://arxiv.org/pdf/2008.07500", "subject": "Information Theory (cs.IT)"},
{"title": "Multi-Party Private Set Intersection: An Information-Theoretic Approach", "author": "Zhusheng Wang, Karim Banawan, Sennur Ulukus", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We investigate the problem of multi-party private set intersection (MP-PSI). In MP-PSI, there are $M$ parties, each storing a data set $\\mathcal{p}_i$ over $N_i$ replicated and non-colluding databases, and we want to calculate the intersection of the data sets $\\cap_{i=1}^M \\mathcal{p}_i$ without leaking any information beyond the set intersection to any of the parties. We consider a specific communication protocol where one of the parties, called the leader party, initiates the MP-PSI protocol by sending queries to the remaining parties which are called client parties. The client parties are not allowed to communicate with each other. We propose an information-theoretic scheme that privately calculates the intersection $\\cap_{i=1}^M \\mathcal{p}_i$ with a download cost of $D = \\min_{t \\in \\{1, \\cdots, M\\}} \\sum_{i \\in \\{1, \\cdots M\\}\\setminus {t}} \\left\\lceil \\frac{|\\mathcal{p}_t|N_i}{N_i-1}\\right\\rceil$. Similar to the 2-party PSI problem, our scheme builds on the connection between the PSI problem and the multi-message symmetric private information retrieval (MM-SPIR) problem. Our scheme is a non-trivial generalization of the 2-party PSI scheme as it needs an intricate design of the shared common randomness. Interestingly, in terms of the download cost, our scheme does not incur any penalty due to the more stringent privacy constraints in the MP-PSI problem compared to the 2-party PSI problem.", "pdf_url": "https://arxiv.org/pdf/2008.07504", "subject": "Information Theory (cs.IT)"},
{"title": "When Lipschitz Walks Your Dog: Algorithm Engineering of the Discrete Fr\u00e9chet Distance under Translation", "author": "Karl Bringmann, Marvin K\u00fcnnemann, Andr\u00e9 Nusser", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Consider the natural question of how to measure the similarity of curves in the plane by a quantity that is invariant under translations of the curves. Such a measure is justified whenever we aim to quantify the similarity of the curves' shapes rather than their positioning in the plane, e.g., to compare the similarity of handwritten characters. Perhaps the most natural such notion is the (discrete) Fr\u00e9chet distance under translation. Unfortunately, the algorithmic literature on this problem yields a very pessimistic view: On polygonal curves with $n$ vertices, the fastest algorithm runs in time $O(n^{4.667})$ and cannot be improved below $n^{4-o(1)}$ unless the Strong Exponential Time Hypothesis fails. Can we still obtain an implementation that is efficient on realistic datasets? Spurred by the surprising performance of recent implementations for the Fr\u00e9chet distance, we perform algorithm engineering for the Fr\u00e9chet distance under translation. Our solution combines fast, but inexact tools from continuous optimization (specifically, branch-and-bound algorithms for global Lipschitz optimization) with exact, but expensive algorithms from computational geometry (specifically, problem-specific algorithms based on an arrangement construction). We combine these two ingredients to obtain an exact decision algorithm for the Fr\u00e9chet distance under translation. For the related task of computing the distance value up to a desired precision, we engineer and compare different methods. On a benchmark set involving handwritten characters and route trajectories, our implementation answers a typical query for either task in the range of a few milliseconds up to a second on standard desktop hardware. We believe that our implementation will enable the use of the Fr\u00e9chet distance under translation in applications, whereas previous approaches would have been computationally infeasible.", "pdf_url": "https://arxiv.org/pdf/2008.07510", "subject": "Computational Geometry (cs.CG)"},
{"title": "Cybersecurity of Electric Vehicle Smart Charging Management Systems", "author": "Narayan Bhusal, Mukesh Gautam, Mohammed Benidris", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In concept, a smart charging management system (SCMS) optimizes the charging of plug-in vehicles (PEVs) and provides various grid services including voltage control, frequency regulation, peak shaving, renewable energy integration support, spinning reserve, and emergency demand response. These functionalities largely depend upon data collected from various entities such as PEVs, electric vehicle supply equipment (EVSE), service providers, and utilities. SCMS can be susceptible to both cyber and physical threats (e.g. man-in-the-middle attack, data intrigued attack, denial of charging, physical-attack) due to interactions of and interdependencies between cyber and physical components. Cyber-physical threats through highly connected malware vectors raise various concerns including public safety hazards to vehicle operators and those in the immediate vicinity as well as disruptions to electric grid operations. This paper describes the concept of SCMS and provides a comprehensive review of the cybersecurity aspects of EVSEs and SCMSs with their possible impacts on the power grid and society. It also contributes to the development of cybersecurity measures to the SCMSs. Various functions of SCMS are reviewed in detail including peak shaving, demand charge reduction, frequency regulation, spinning reserve, renewable integration support, distribution congestion management, reactive power compensation, and emergency demand response with unidirectional PEVs charging. Also, a critical literature survey on current practices of SCMS cybersecurity is provided to explore major impacts and challenges of cyber-physical attacks and to identify research gaps and vulnerabilities in currently available SCMSs technologies.", "pdf_url": "https://arxiv.org/pdf/2008.07511", "subject": "Systems and Control (eess.SY)"},
{"title": "A Realistic Example in 2 Dimension that Gradient Descent Takes Exponential Time to Escape Saddle Points", "author": "Shiliang Zuo", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Gradient descent is a popular algorithm in optimization, and its performance in convex settings is mostly well understood. In non-convex settings, it has been shown that gradient descent is able to escape saddle points asymptotically and converge to local minimizers [Lee et. al. 2016]. Recent studies also show a perturbed version of gradient descent is enough to escape saddle points efficiently [Jin et. al. 2015, Ge et. al. 2017]. In this paper we show a negative result: gradient descent may take exponential time to escape saddle points, with non-pathological two dimensional functions. While our focus is theoretical, we also conduct experiments verifying our theoretical result. Through our analysis we demonstrate that stochasticity is essential to escape saddle points efficiently.", "pdf_url": "https://arxiv.org/pdf/2008.07513", "subject": "Machine Learning (cs.LG)"},
{"title": "Source Free Domain Adaptation with Image Translation", "author": "Yunzhong Hou, Liang Zheng", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Effort in releasing large-scale datasets may be compromised by privacy and intellectual property considerations. A feasible alternative is to release pre-trained models instead. While these models are strong on their original task (source domain), their performance might degrade significantly when deployed directly in a new environment (target domain), which might not contain labels for training under realistic settings. Domain adaptation (DA) is a known solution to the domain gap problem, but usually requires labeled source data. In this paper, we study the problem of source free domain adaptation (SFDA), whose distinctive feature is that the source domain only provides a pre-trained model, but no source data. Being source free adds significant challenges to DA, especially when considering that the target dataset is unlabeled. To solve the SFDA problem, we propose an image translation approach that transfers the style of target images to that of unseen source images. To this end, we align the batch-wise feature statistics of generated images to that stored in batch normalization layers of the pre-trained model. Compared with directly classifying target images, higher accuracy is obtained with these style transferred images using the pre-trained model. On several image classification datasets, we show that the above-mentioned improvements are consistent and statistically significant.", "pdf_url": "https://arxiv.org/pdf/2008.07514", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "V2VNet: Vehicle-to-Vehicle Communication for Joint Perception and Prediction", "author": "Tsun-Hsuan Wang, Sivabalan Manivasagam, Ming Liang, Bin Yang, Wenyuan Zeng, James Tu, Raquel Urtasun", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper, we explore the use of vehicle-to-vehicle (V2V) communication to improve the perception and motion forecasting performance of self-driving vehicles. By intelligently aggregating the information received from multiple nearby vehicles, we can observe the same scene from different viewpoints. This allows us to see through occlusions and detect actors at long range, where the observations are very sparse or non-existent. We also show that our approach of sending compressed deep feature map activations achieves high accuracy while satisfying communication bandwidth requirements.", "pdf_url": "https://arxiv.org/pdf/2008.07519", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Reinforcement Learning with Quantum Variational Circuits", "author": "Owen Lockwood, Mei Si", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The development of quantum computational techniques has advanced greatly in recent years, parallel to the advancements in techniques for deep reinforcement learning. This work explores the potential for quantum computing to facilitate reinforcement learning problems. Quantum computing approaches offer important potential improvements in time and space complexity over traditional algorithms because of its ability to exploit the quantum phenomena of superposition and entanglement. Specifically, we investigate the use of quantum variational circuits, a form of quantum machine learning. We present our techniques for encoding classical data for a quantum variational circuit, we further explore pure and hybrid quantum algorithms for DQN and Double DQN. Our results indicate both hybrid and pure quantum variational circuit have the ability to solve reinforcement learning tasks with a smaller parameter space. These comparison are conducted with two OpenAI Gym environments: CartPole and Blackjack, The success of this work is indicative of a strong future relationship between quantum machine learning and deep reinforcement learning.", "pdf_url": "https://arxiv.org/pdf/2008.07524", "subject": "Quantum Physics (quant-ph)"},
{"title": "Music Boundary Detection using Convolutional Neural Networks: A comparative analysis of combined input features", "author": "Carlos Hernandez-Olivan, Jose R. Beltran, David Diaz-Guerra", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The analysis of the structure of musical pieces is a task that remains a challenge for Artificial Intelligence, especially in the field of Deep Learning. It requires prior identification of structural boundaries of the music pieces. This structural boundary analysis has recently been studied with unsupervised methods and \\textit{end-to-end} techniques such as Convolutional Neural Networks (CNN) using Mel-Scaled Log-magnitude Spectograms features (MLS), Self-Similarity Matrices (SSM) or Self-Similarity Lag Matrices (SSLM) as inputs and trained with human annotations. Several studies have been published divided into unsupervised and \\textit{end-to-end} methods in which pre-processing is done in different ways, using different distance metrics and audio characteristics, so a generalized pre-processing method to compute model inputs is missing. The objective of this work is to establish a general method of pre-processing these inputs by comparing the inputs calculated from different pooling strategies, distance metrics and audio characteristics, also taking into account the computing time to obtain them. We also establish the most effective combination of inputs to be delivered to the CNN in order to establish the most efficient way to extract the limits of the structure of the music pieces. With an adequate combination of input matrices and pooling strategies we obtain a measurement accuracy $F_1$ of 0.411 that outperforms the current one obtained under the same conditions.", "pdf_url": "https://arxiv.org/pdf/2008.07527", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "On the Complexity Reduction of Uplink Sparse Code Multiple Access for Spatial Modulation", "author": "Ibrahim Al-Nahhal, Octavia A. Dobre, Salama Ikki", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Multi-user spatial modulation (SM) assisted by sparse code multiple access (SCMA) has been recently proposed to provide uplink high spectral efficiency transmission. The message passing algorithm (MPA) is employed to detect the transmitted signals, which suffers from high complexity. This paper proposes three low-complexity algorithms for the first time to the SM-SCMA. The first algorithm is referred to as successive user detection (SUD), while the second algorithm is the modified version of SUD, namely modified SUD (MSUD). Then, for the first time, the tree-search of the SM-SCMA is constructed. Based on that tree-search, another variant of the sphere decoder (SD) is proposed for the SM-SCMA, referred to as fixed-complexity SD (FCSD). SUD provides a benchmark for decoding complexity at the expense of bit-error-rate (BER) performance. Further, MSUD slightly increases the complexity of SUD with a significant improvement in BER performance. Finally, FCSD provides a near-optimum BER with a considerable reduction of the complexity compared to the MPA decoder and also supports parallel hardware implementation. The proposed algorithms provide flexible design choices for practical implementation based on system design demands. The complexity analysis and Monte-Carlo simulations of the BER are provided for the proposed algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.07556", "subject": "Signal Processing (eess.SP)"},
{"title": "Load Balancing Under Strict Compatibility Constraints", "author": "Daan Rutten, Debankur Mukherjee", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We study large-scale systems operating under the JSQ$(d)$ policy in the presence of stringent task-server compatibility constraints. Consider a system with $N$ identical single-server queues and $M(N)$ task types, where each server is able to process only a small subset of possible task types. Each arriving task selects $d\\geq 2$ random servers compatible to its type, and joins the shortest queue among them. The compatibility constraint is naturally captured by a fixed bipartite graph $G_N$ between the servers and the task types. When $G_N$ is complete bipartite, the meanfield approximation is proven to be accurate. However, such dense compatibility graphs are infeasible due to their overwhelming implementation cost and prohibitive storage capacity requirement at the servers. Our goal in this paper is to characterize the class of sparse compatibility graphs for which the meanfield approximation remains valid. To achieve this, first, we introduce a novel graph expansion-based notion, called proportional sparsity, and establish that systems with proportionally sparse compatibility graphs match the performance of a fully flexible system, asymptotically in the large-system limit. Furthermore, for any $c(N)$ satisfying $$\\frac{Nc(N)}{M(N)\\ln(N)}\\to \\infty\\quad \\text{and}\\quad c(N)\\to \\infty,$$ as $N\\to\\infty$, we show that proportionally sparse random compatibility graphs can be designed, so that the degree of each server is at most $c(N)$. This reduces the server-degree almost by a factor $N/\\ln(N)$, compared to the complete bipartite compatibility graph, while maintaining the same asymptotic performance. Extensive simulation experiments are conducted to corroborate the theoretical results.", "pdf_url": "https://arxiv.org/pdf/2008.07562", "subject": "Probability (math.PR)"},
{"title": "Anatomy-Aware Cardiac Motion Estimation", "author": "Pingjun Chen, Xiao Chen, Eric Z. Chen, Hanchao Yu, Terrence Chen, Shanhui Sun", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Cardiac motion estimation is critical to the assessment of cardiac function. Myocardium feature tracking (FT) can directly estimate cardiac motion from cine MRI, which requires no special scanning procedure. However, current deep learning-based FT methods may result in unrealistic myocardium shapes since the learning is solely guided by image intensities without considering anatomy. On the other hand, motion estimation through learning is challenging because ground-truth motion fields are almost impossible to obtain. In this study, we propose a novel Anatomy-Aware Tracker (AATracker) for cardiac motion estimation that preserves anatomy by weak supervision. A convolutional variational autoencoder (VAE) is trained to encapsulate realistic myocardium shapes. A baseline dense motion tracker is trained to approximate the motion fields and then refined to estimate anatomy-aware motion fields under the weak supervision from the VAE. We evaluate the proposed method on long-axis cardiac cine MRI, which has more complex myocardium appearances and motions than short-axis. Compared with other methods, AATracker significantly improves the tracking performance and provides visually more realistic tracking results, demonstrating the effectiveness of the proposed weakly-supervision scheme in cardiac motion estimation.", "pdf_url": "https://arxiv.org/pdf/2008.07579", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Uncertainty Quantification using Variational Inference for Biomedical Image Segmentation", "author": "Abhinav Sagar", "pub_date": "Submitted on 12 Aug 2020", "abstract": "Deep learning motivated by convolutional neural networks has been highly successful in a range of medical imaging problems like image classification, image segmentation, image synthesis etc. However for validation and interpretability, not only do we need the predictions made by the model but also how confident it is while making those predictions. This is important in safety critical applications for the people to accept it. In this work, we used an encoder decoder architecture based on variational inference techniques for segmenting brain tumour images. We compare different backbones architectures like U-Net, V-Net and FCN as sampling data from the conditional distribution for the encoder. We evaluate our work on the publicly available BRATS dataset using Dice Similarity Coefficient (DSC) and Intersection Over Union (IOU) as the evaluation metrics. Our model outperforms previous state of the art results while making use of uncertainty quantification in a principled bayesian manner.", "pdf_url": "https://arxiv.org/pdf/2008.07588", "subject": "Image and Video Processing (eess.IV)"},
{"title": "SWAN: Swarm-Based Low-Complexity Scheme for PAPR Reduction", "author": "Luis F. Abanto-Leon, Gek Hong Sim, Matthias Hollick, Amnart Boonkajay, Fumiyuki Adachi", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Cyclically shifted partial transmit sequences (CSPTS) has conventionally been used in SISO systems for PAPR reduction of OFDM signals. Compared to other techniques, CS-PTS attains superior performance. Nevertheless, due to the exhaustive search requirement, it demands excessive computational complexity. In this paper, we adapt CS-PTS to operate in a MIMO framework, where singular value decomposition (SVD) precoding is employed. We also propose SWAN, a novel optimization method based on swarm intelligence to circumvent the exhaustive search. SWAN not only provides a significant reduction in computational complexity, but it also attains a fair balance between optimality and complexity. Through simulations, we show that SWAN achieves near-optimal performance at a much lower complexity than other competing approaches.", "pdf_url": "https://arxiv.org/pdf/2008.07600", "subject": "Signal Processing (eess.SP)"},
{"title": "Hydrogen Supply Chain Planning with Flexible Transmission and Storage Scheduling", "author": "Guannan He, Dharik S. Mallapragada, Abhishek Bose, Clara F. Heuberger, Emre Gen\u00e7er", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Hydrogen is becoming an increasingly appealing energy carrier, as the costs of renewable energy generation and water electrolysis continue to decline. Developing modelling and decision tools for the H$_{2}$ supply chain that fully capture the flexibility of various resources is essential to understanding the overall cost-competitiveness of H$_{2}$ use. To address this need, we have developed a H$_{2}$ supply chain planning model that determines the least-cost mix of H$_{2}$ generation, storage, transmission, and compression facilities to meet H$_{2}$ demands and is coupled with power systems through electricity prices. We incorporate flexible scheduling for H$_{2}$ trucks and pipeline, allowing them to serve as both H$_{2}$ transmission and storage resources to shift H$_{2}$ demand/production across space and time. The case study results in the U.S. Northeast indicate that the proposed framework for flexible scheduling of H$_{2}$ transmission and storage resources is critical not only to cost minimization but also to the choice of H$_{2}$ production pathways between electrolyzer and centralized natural-gas-based production facilities. Trucks as mobile storage could make electrolyzer more competitive by providing extra spatiotemporal flexibility to respond to the electricity price variability while meeting H$_{2}$ demands. The proposed model also provides a reasonable trade-off between modeling accuracy and solution times.", "pdf_url": "https://arxiv.org/pdf/2008.07611", "subject": "Optimization and Control (math.OC)"},
{"title": "DeepSlicing: Deep Reinforcement Learning Assisted Resource Allocation for Network Slicing", "author": "Qiang Liu, Tao Han, Ning Zhang, Ye Wang", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Network slicing enables multiple virtual networks run on the same physical infrastructure to support various use cases in 5G and beyond. These use cases, however, have very diverse network resource demands, e.g., communication and computation, and various performance metrics such as latency and throughput. To effectively allocate network resources to slices, we propose DeepSlicing that integrates the alternating direction method of multipliers (ADMM) and deep reinforcement learning (DRL). DeepSlicing decomposes the network slicing problem into a master problem and several slave problems. The master problem is solved based on convex optimization and the slave problem is handled by DRL method which learns the optimal resource allocation policy. The performance of the proposed algorithm is validated through network simulations.", "pdf_url": "https://arxiv.org/pdf/2008.07614", "subject": "Signal Processing (eess.SP)"},
{"title": "Comparative study of variational quantum circuit and quantum backpropagation multilayer perceptron for COVID-19 outbreak predictions", "author": "Pranav Kairon, Siddhartha Bhattacharyya", "pub_date": "Submitted on 8 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "There are numerous models of quantum neural networks that have been applied to variegated problems such as image classification, pattern recognition etc.Quantum inspired algorithms have been relevant for quite awhile. More recently, in the NISQ era, hybrid quantum classical models have shown promising results. Multi-feature regression is common problem in classical machine learning. Hence we present a comparative analysis of continuous variable quantum neural networks (Variational circuits) and quantum backpropagating multi layer perceptron (QBMLP). We have chosen the contemporary problem of predicting rise in COVID-19 cases in India and USA. We provide a statistical comparison between two models , both of which perform better than the classical artificial neural networks.", "pdf_url": "https://arxiv.org/pdf/2008.07617", "subject": "Quantum Physics (quant-ph)"},
{"title": "Incorporating Broad Phonetic Information for Speech Enhancement", "author": "Yen-Ju Lu, Chien-Feng Liao, Xugang Lu, Jeih-weih Hung, Yu Tsao", "pub_date": "Submitted on 13 Aug 2020", "abstract": "In noisy conditions, knowing speech contents facilitates listeners to more effectively suppress background noise components and to retrieve pure speech signals. Previous studies have also confirmed the benefits of incorporating phonetic information in a speech enhancement (SE) system to achieve better denoising performance. To obtain the phonetic information, we usually prepare a phoneme-based acoustic model, which is trained using speech waveforms and phoneme labels. Despite performing well in normal noisy conditions, when operating in very noisy conditions, however, the recognized phonemes may be erroneous and thus misguide the SE process. To overcome the limitation, this study proposes to incorporate the broad phonetic class (BPC) information into the SE process. We have investigated three criteria to build the BPC, including two knowledge-based criteria: place and manner of articulatory and one data-driven criterion. Moreover, the recognition accuracies of BPCs are much higher than that of phonemes, thus providing more accurate phonetic information to guide the SE process under very noisy conditions. Experimental results demonstrate that the proposed SE with the BPC information framework can achieve notable performance improvements over the baseline system and an SE system using monophonic information in terms of both speech quality intelligibility on the TIMIT dataset.", "pdf_url": "https://arxiv.org/pdf/2008.07618", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Speech Recognition using EEG signals recorded using dry electrodes", "author": "Gautam Krishna, Co Tran, Mason Carnahan, Morgan M Hagood, Ahmed H Tewfik", "pub_date": "Submitted on 13 Aug 2020", "abstract": "In this paper, we demonstrate speech recognition using electroencephalography (EEG) signals obtained using dry electrodes on a limited English vocabulary consisting of three vowels and one word using a deep learning model. We demonstrate a test accuracy of 79.07 percent on a subset vocabulary consisting of two English vowels. Our results demonstrate the feasibility of using EEG signals recorded using dry electrodes for performing the task of speech recognition.", "pdf_url": "https://arxiv.org/pdf/2008.07621", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "A Deep Network for Joint Registration and Reconstruction of Images with Pathologies", "author": "Xu Han, Zhengyang Shen, Zhenlin Xu, Spyridon Bakas, Hamed Akbari, Michel Bilello, Christos Davatzikos, Marc Niethammer", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Registration of images with pathologies is challenging due to tissue appearance changes and missing correspondences caused by the pathologies. Moreover, mass effects as observed for brain tumors may displace tissue, creating larger deformations over time than what is observed in a healthy brain. Deep learning models have successfully been applied to image registration to offer dramatic speed up and to use surrogate information (e.g., segmentations) during training. However, existing approaches focus on learning registration models using images from healthy patients. They are therefore not designed for the registration of images with strong pathologies for example in the context of brain tumors, and traumatic brain injuries. In this work, we explore a deep learning approach to register images with brain tumors to an atlas. Our model learns an appearance mapping from images with tumors to the atlas, while simultaneously predicting the transformation to atlas space. Using separate decoders, the network disentangles the tumor mass effect from the reconstruction of quasi-normal images. Results on both synthetic and real brain tumor scans show that our approach outperforms cost function masking for registration to the atlas and that reconstructed quasi-normal images can be used for better longitudinal registrations.", "pdf_url": "https://arxiv.org/pdf/2008.07628", "subject": "Image and Video Processing (eess.IV)"},
{"title": "The economics of utility-scale portable energy storage systems in a high-renewable grid", "author": "Guannan He, Jeremy Michalek, Soummya Kar, Qixin Chen, Da Zhang, Jay F. Whitacre", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Battery storage is expected to play a crucial role in the low-carbon transformation of energy systems. The deployment of battery storage in the power gird, however, is currently severely limited by its low economic viability, which results from not only high capital costs but also the lack of flexible and efficient utilization schemes and business models. Making utility-scale battery storage portable through trucking unlocks its capability to provide various on-demand services. We introduce the potential applications of utility-scale portable energy storage and investigate its economics in California using a spatiotemporal decision model that determines the optimal operation and transportation schedules of portable storage. We show that mobilizing energy storage can increase its life-cycle revenues by 70% in some areas and improve renewable energy integration by relieving local transmission congestion. The life-cycle revenue of spatiotemporal arbitrage can fully compensate for the costs of portable energy storage system in several regions in California, including San Diego and the San Francisco Bay Area.", "pdf_url": "https://arxiv.org/pdf/2008.07635", "subject": "Optimization and Control (math.OC)"},
{"title": "Nonparametric Conditional Density Estimation In A Deep Learning Framework For Short-Term Forecasting", "author": "David B. Huberman, Brian J. Reich, Howard D. Bondell", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Short-term forecasting is an important tool in understanding environmental processes. In this paper, we incorporate machine learning algorithms into a conditional distribution estimator for the purposes of forecasting tropical cyclone intensity. Many machine learning techniques give a single-point prediction of the conditional distribution of the target variable, which does not give a full accounting of the prediction variability. Conditional distribution estimation can provide extra insight on predicted response behavior, which could influence decision-making and policy. We propose a technique that simultaneously estimates the entire conditional distribution and flexibly allows for machine learning techniques to be incorporated. A smooth model is fit over both the target variable and covariates, and a logistic transformation is applied on the model output layer to produce an expression of the conditional density function. We provide two examples of machine learning models that can be used, polynomial regression and deep learning models. To achieve computational efficiency we propose a case-control sampling approximation to the conditional distribution. A simulation study for four different data distributions highlights the effectiveness of our method compared to other machine learning-based conditional distribution estimation techniques. We then demonstrate the utility of our approach for forecasting purposes using tropical cyclone data from the Atlantic Seaboard. This paper gives a proof of concept for the promise of our method, further computational developments can fully unlock its insights in more complex forecasting and other applications.", "pdf_url": "https://arxiv.org/pdf/2008.07653", "subject": "Machine Learning (stat.ML)"},
{"title": "Information theory and player deck choice in online Collectable Card Games", "author": "Mathew Zuparic, Duy Khuu, Tzachi Zach", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Using three years of player data of the online Collectible Card Game Hearthstone, we perform an in-depth analysis of the evolution of the game's online landscape over the period 2016--2019. Specifically, by considering the frequencies that deck archetypes are played, and their corresponding win-rates, we are able to provide narratives of the system-wide changes that were made over time, and how players reacted to those changes via their choices regarding deck construction and tactics. Applying the deck frequencies to analyse the system's Shannon entropy, we characterise the salient features of player deck choice over time. Paying particular attention to how system entropy is affected during periods of both small and large-scale change, we are able to demonstrate the effects of increased player experimentation before clear viable decks and tactics emerge. Furthermore, guided by the concept of local active information storage, we construct conditional probabilities that particular decks are chosen, given previous deck frequencies and win-rates. Importantly, these conditional probabilities can be interpreted to simulate understandable player behaviour. Then comparing the Shannon entropy with the expectation value of the local active information storage over all past and current deck choices and win-rates, we are able to test the explain-ability of current player choice based on previous player decision-making.", "pdf_url": "https://arxiv.org/pdf/2008.07663", "subject": "Adaptation and Self-Organizing Systems (nlin.AO)"},
{"title": "Adversarial Attack and Defense Strategies for Deep Speaker Recognition Systems", "author": "Arindam Jati, Chin-Cheng Hsu, Monisankha Pal, Raghuveer Peri, Wael AbdAlmageed, Shrikanth Narayanan", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Robust speaker recognition, including in the presence of malicious attacks, is becoming increasingly important and essential, especially due to the proliferation of several smart speakers and personal agents that interact with an individual's voice commands to perform diverse, and even sensitive tasks. Adversarial attack is a recently revived domain which is shown to be effective in breaking deep neural network-based classifiers, specifically, by forcing them to change their posterior distribution by only perturbing the input samples by a very small amount. Although, significant progress in this realm has been made in the computer vision domain, advances within speaker recognition is still limited. The present expository paper considers several state-of-the-art adversarial attacks to a deep speaker recognition system, employing strong defense methods as countermeasures, and reporting on several ablation studies to obtain a comprehensive understanding of the problem. The experiments show that the speaker recognition systems are vulnerable to adversarial attacks, and the strongest attacks can reduce the accuracy of the system from 94% to even 0%. The study also compares the performances of the employed defense methods in detail, and finds adversarial training based on Projected Gradient Descent (PGD) to be the best defense method in our setting. We hope that the experiments presented in this paper provide baselines that can be useful for the research community interested in further studying adversarial robustness of speaker recognition systems.", "pdf_url": "https://arxiv.org/pdf/2008.07685", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Estimation of causal effects of multiple treatments in healthcare database studies with rare outcomes", "author": "Liangyuan Hu, Chenyang Gu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The preponderance of large-scale healthcare databases provide abundant opportunities for comparative effectiveness research. Evidence necessary to making informed treatment decisions often relies on comparing effectiveness of multiple treatment options on outcomes of interest observed in a small number of individuals. Causal inference with multiple treatments and rare outcomes is a subject that has been treated sparingly in the literature. This paper designs three sets of simulations, representative of the structure of our healthcare database study, and propose causal analysis strategies for such settings. We investigate and compare the operating characteristics of three types of methods and their variants: Bayesian Additive Regression Trees (BART), regression adjustment on multivariate spline of generalized propensity scores (RAMS) and inverse probability of treatment weighting (IPTW) with multinomial logistic regression or generalized boosted models. Our results suggest that BART and RAMS provide lower bias and mean squared error, and the widely used IPTW methods deliver unfavorable operating characteristics. We illustrate the methods using a case study evaluating the comparative effectiveness of robotic-assisted surgery, video-assisted thoracoscopic surgery and open thoracotomy for treating non-small cell lung cancer.", "pdf_url": "https://arxiv.org/pdf/2008.07687", "subject": "Methodology (stat.ME)"},
{"title": "A Real-time Robot-based Auxiliary System for Risk Evaluation of COVID-19 Infection", "author": "Wenqi Wei, Jianzong Wang, Jiteng Ma, Ning Cheng, Jing Xiao", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this paper, we propose a real-time robot-based auxiliary system for risk evaluation of COVID-19 infection. It combines real-time speech recognition, temperature measurement, keyword detection, cough detection and other functions in order to convert live audio into actionable structured data to achieve the COVID-19 infection risk assessment function. In order to better evaluate the COVID-19 infection, we propose an end-to-end method for cough detection and classification for our proposed system. It is based on real conversation data from human-robot, which processes speech signals to detect cough and classifies it if detected. The structure of our model are maintained concise to be implemented for real-time applications. And we further embed this entire auxiliary diagnostic system in the robot and it is placed in the communities, hospitals and supermarkets to support COVID-19 testing. The system can be further leveraged within a business rules engine, thus serving as a foundation for real-time supervision and assistance applications. Our model utilizes a pretrained, robust training environment that allows for efficient creation and customization of customer-specific health states.", "pdf_url": "https://arxiv.org/pdf/2008.07695", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Hidden order in online extremism and its disruption by nudging collective chemistry", "author": "N.F. Johnson, N. Velasquez, P. Manrique, R. Sear, R. Leahy, N. Johnson Restrepo, L. Illari, Y. Lupu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We show that the eclectic \"Boogaloo\" extremist movement that is now rising to prominence in the U.S., has a hidden online mathematical order that is identical to ISIS during its early development, despite their stark ideological, geographical and cultural differences. The evolution of each across scales follows a single shockwave equation that accounts for individual heterogeneity in online interactions. This equation predicts how to disrupt the onset and 'flatten the curve' of such online extremism by nudging its collective chemistry.", "pdf_url": "https://arxiv.org/pdf/2008.07701", "subject": "Physics and Society (physics.soc-ph)"},
{"title": "UDC 2020 Challenge on Image Restoration of Under-Display Camera: Methods and Results", "author": "Yuqian Zhou, Michael Kwan, Kyle Tolentino, Neil Emerton, Sehoon Lim, Tim Large, Lijiang Fu, Zhihong Pan, Baopu Li, Qirui Yang, Yihao Liu, Jigang Tang, Tao Ku, Shibin Ma, Bingnan Hu, Jiarong Wang, Densen Puthussery, Hrishikesh P S, Melvin Kuriakose, Jiji C V, Varun Sundar, Sumanth Hegde, Divya Kothandaraman, Kaushik Mitra, Akashdeep Jassal, Nisarg A. Shah, Sabari Nathan, Nagat Abdalla Esiad Rahel, Dafan Chen, Shichao Nie, Shuting Yin, Chengconghui Ma, Haoran Wang, Tongtong Zhao, Shanshan Zhao, Joshua Rego, Huaijin Chen, Shuai Li, Zhenhua Hu, Kin Wai Lau, Lai-Man Po, Dahai Yu, Yasar Abbas Ur Rehman, Yiqun Li, Lianping Xing", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This paper is the report of the first Under-Display Camera (UDC) image restoration challenge in conjunction with the RLQ workshop at ECCV 2020. The challenge is based on a newly-collected database of Under-Display Camera. The challenge tracks correspond to two types of display: a 4k Transparent OLED (T-OLED) and a phone Pentile OLED (P-OLED). Along with about 150 teams registered the challenge, eight and nine teams submitted the results during the testing phase for each track. The results in the paper are state-of-the-art restoration performance of Under-Display Camera Restoration. Datasets and paper are available at .", "pdf_url": "https://arxiv.org/pdf/2008.07742", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Massively Distributed Antenna Systems with Non-Ideal Optical Fiber Front-hauls: A Promising Technology for 6G Wireless Communication Systems", "author": "Lisu Yu, Jingxian Wu, Andong Zhou, Erik G. Larsson, Pingzhi Fan", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Employing massively distributed antennas brings radio access points (RAPs) closer to users, thus enables aggressive spectrum reuse that can bridge gaps between the scarce spectrum resource and extremely high connection densities in future wireless systems. Examples include cloud radio access network (C-RAN), ultra-dense network (UDN), and cell-free massive multiple-input multiple-output (MIMO) systems. These systems are usually designed in the form of fiber-wireless communications (FWC), where distributed antennas or RAPs are connected to a central unit (CU) through optical front-hauls. A large number of densely deployed antennas or RAPs requires an extensive infrastructure of optical front-hauls. Consequently, the cost, complexity, and power consumption of the network of optical front-hauls may dominate the performance of the entire system. This article provides an overview and outlook on the architecture, modeling, design, and performance of massively distributed antenna systems with non-ideal optical front-hauls. Complex interactions between optical front-hauls and wireless access links require optimum designs across the optical and wireless domains by jointly exploiting their unique characteristics. It is demonstrated that systems with analog radio-frequency-over-fiber (RFoF) links outperform their baseband-over-fiber (BBoF) or intermediate-frequency-over-fiber (IFoF) counterparts for systems with shorter fiber length and more RAPs, which are all desired properties for future wireless communication systems.", "pdf_url": "https://arxiv.org/pdf/2008.07745", "subject": "Signal Processing (eess.SP)"},
{"title": "Open-Loop Distributed Beamforming Using Scalable High Accuracy Localization", "author": "Sean M. Ellison, Jeffrey A. Nanzer", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We present a distributed antenna array supporting open-loop distributed beamforming at 1.5 GHz. Based on a scalable, high-accuracy internode ranging technique, we demonstrate open-loop beamforming experiments using three transmitting nodes. To support distributed beamforming without feedback from the destination, the relative positions of the nodes in the distributed array must be known with accuracies below $\\lambda/15$ of the beamforming carrier frequency to ensure that the array maintains at least 90\\% coherent beamforming gain at the receive location. For operations in the microwave range, this leads to range estimation accuracies of centimeters or lower. We present a scalable, high-accuracy waveform and new approaches to refine range measurements to significantly improve the estimation accuracy. Using this waveform with a three-node array, we demonstrate high-accuracy ranging simultaneously between multiple nodes, from which phase corrections on two secondary nodes are implemented to maintain beamforming with the primary node, thereby supporting open-loop distributed beamforming. Upon movement of the nodes, the range estimation is used to dynamically update the phase correction, maintaining beamforming as the nodes move. We show the first open-loop distributed beamforming at 1.5 GHz with two-node and three-node arrays, demonstrating the ability to implement and maintain phase-based beamforming without feedback from the destination.", "pdf_url": "https://arxiv.org/pdf/2008.07748", "subject": "Signal Processing (eess.SP)"},
{"title": "Fully automated deep learning based segmentation of normal, infarcted and edema regions from multiple cardiac MRI sequences", "author": "Xiaoran Zhang, Michelle Noga, Kumaradevan Punithakumar", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Myocardial characterization is essential for patients with myocardial infarction and other myocardial diseases, and the assessment is often performed using cardiac magnetic resonance (CMR) sequences. In this study, we propose a fully automated approach using deep convolutional neural networks (CNN) for cardiac pathology segmentation, including left ventricular (LV) blood pool, right ventricular blood pool, LV normal myocardium, LV myocardial edema (ME) and LV myocardial scars (MS). The input to the network consists of three CMR sequences, namely, late gadolinium enhancement (LGE), T2 and balanced steady state free precession (bSSFP). The proposed approach utilized the data provided by the MyoPS challenge hosted by MICCAI 2020 in conjunction with STACOM. The training set for the CNN model consists of images acquired from 25 cases, and the gold standard labels are provided by trained raters and validated by radiologists. The proposed approach introduces a data augmentation module, linear encoder and decoder module and a network module to increase the number of training samples and improve the prediction accuracy for LV ME and MS. The proposed approach is evaluated by the challenge organizers with a test set including 20 cases and achieves a mean dice score of $46.8\\%$ for LV MS and $55.7\\%$ for LV ME+MS", "pdf_url": "https://arxiv.org/pdf/2008.07770", "subject": "Image and Video Processing (eess.IV)"},
{"title": "CinC-GAN for Effective F0 prediction for Whisper-to-Normal Speech Conversion", "author": "Maitreya Patel, Mirali Purohit, Jui Shah, Hemant A. Patil", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Recently, Generative Adversarial Networks (GAN)-based methods have shown remarkable performance for the Voice Conversion and WHiSPer-to-normal SPeeCH (WHSP2SPCH) conversion. One of the key challenges in WHSP2SPCH conversion is the prediction of fundamental frequency (F0). Recently, authors have proposed state-of-the-art method Cycle-Consistent Generative Adversarial Networks (CycleGAN) for WHSP2SPCH conversion. The CycleGAN-based method uses two different models, one for Mel Cepstral Coefficients (MCC) mapping, and another for F0 prediction, where F0 is highly dependent on the pre-trained model of MCC mapping. This leads to additional non-linear noise in predicted F0. To suppress this noise, we propose Cycle-in-Cycle GAN (i.e., CinC-GAN). It is specially designed to increase the effectiveness in F0 prediction without losing the accuracy of MCC mapping. We evaluated the proposed method on a non-parallel setting and analyzed on speaker-specific, and gender-specific tasks. The objective and subjective tests show that CinC-GAN significantly outperforms the CycleGAN. In addition, we analyze the CycleGAN and CinC-GAN for unseen speakers and the results show the clear superiority of CinC-GAN.", "pdf_url": "https://arxiv.org/pdf/2008.07788", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Score-Based Parameter Estimation for a Class of Continuous-Time State Space Models", "author": "Alexandros Beskos, Dan Crisan, Ajay Jasra, Nikolas Kantas, Hamza Ruzayqat", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We consider the problem of parameter estimation for a class of continuous-time state space models. In particular, we explore the case of a partially observed diffusion, with data also arriving according to a diffusion process. Based upon a standard identity of the score function, we consider two particle filter based methodologies to estimate the score function. Both methods rely on an online estimation algorithm for the score function of $\\mathcal{O}(N^2)$ cost, with $N\\in\\mathbb{N}$ the number of particles. The first approach employs a simple Euler discretization and standard particle smoothers and is of cost $\\mathcal{O}(N^2 + N\\Delta_l^{-1})$ per unit time, where $\\Delta_l=2^{-l}$, $l\\in\\mathbb{N}_0$, is the time-discretization step. The second approach is new and based upon a novel diffusion bridge construction. It yields a new backward type Feynman-Kac formula in continuous-time for the score function and is presented along with a particle method for its approximation. Considering a time-discretization, the cost is $\\mathcal{O}(N^2\\Delta_l^{-1})$ per unit time. To improve computational costs, we then consider multilevel methodologies for the score function. We illustrate our parameter estimation method via stochastic gradient approaches in several numerical examples.", "pdf_url": "https://arxiv.org/pdf/2008.07803", "subject": "Computation (stat.CO)"},
{"title": "A Relation Analysis of Markov Decision Process Frameworks", "author": "Tien Mai, Patrick Jaillet", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We study the relation between different Markov Decision Process (MDP) frameworks in the machine learning and econometrics literatures, including the standard MDP, the entropy and general regularized MDP, and stochastic MDP, where the latter is based on the assumption that the reward function is stochastic and follows a given distribution. We show that the entropy-regularized MDP is equivalent to a stochastic MDP model, and is strictly subsumed by the general regularized MDP. Moreover, we propose a distributional stochastic MDP framework by assuming that the distribution of the reward function is ambiguous. We further show that the distributional stochastic MDP is equivalent to the regularized MDP, in the sense that they always yield the same optimal policies. We also provide a connection between stochastic/regularized MDP and constrained MDP. Our work gives a unified view on several important MDP frameworks, which would lead new ways to interpret the (entropy/general) regularized MDP frameworks through the lens of stochastic rewards and vice-versa. Given the recent popularity of regularized MDP in (deep) reinforcement learning, our work brings new understandings of how such algorithmic schemes work and suggest ideas to develop new ones.", "pdf_url": "https://arxiv.org/pdf/2008.07820", "subject": "Optimization and Control (math.OC)"},
{"title": "Grading Loss: A Fracture Grade-based Metric Loss for Vertebral Fracture Detection", "author": "Malek Husseini, Anjany Sekuboyina, Maximilian Loeffler, Fernando Navarro, Bjoern H. Menze, Jan S. Kirschke", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Osteoporotic vertebral fractures have a severe impact on patients' overall well-being but are severely under-diagnosed. These fractures present themselves at various levels of severity measured using the Genant's grading scale. Insufficient annotated datasets, severe data-imbalance, and minor difference in appearances between fractured and healthy vertebrae make naive classification approaches result in poor discriminatory performance. Addressing this, we propose a representation learning-inspired approach for automated vertebral fracture detection, aimed at learning latent representations efficient for fracture detection. Building on state-of-art metric losses, we present a novel Grading Loss for learning representations that respect Genant's fracture grading scheme. On a publicly available spine dataset, the proposed loss function achieves a fracture detection F1 score of 81.5%, a 10% increase over a naive classification baseline.", "pdf_url": "https://arxiv.org/pdf/2008.07831", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Fast Agent-Based Simulation Framework of Limit Order Books with Applications to Pro-Rata Markets and the Study of Latency Effects", "author": "Peter Belcak, Peter Belcak, Jan-Peter Calliess, Stefan Zohren", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We introduce a new software toolbox, called Multi-Agent eXchange Environment (MAXE), for agent-based simulation of limit order books. Offering both efficient C++ implementations and Python APIs, it allows the user to simulate large-scale agent-based market models while providing user-friendliness for rapid prototyping. Furthermore, it benefits from a versatile message-driven architecture that offers the flexibility to simulate a range of different (easily customisable) market rules and to study the effect of auxiliary factors, such as delays, on the market dynamics. Showcasing its utility for research, we employ our simulator to investigate the influence the choice of the matching algorithm has on the behaviour of artificial trader agents in a zero-intelligence model. In addition, we investigate the role of the order processing delay in normal trading on an exchange and in the scenario of a significant price change. Our results include the findings that (i) the variance of the bid-ask spread exhibits a behavior similar to resonance of a damped harmonic oscillator with respect to the processing delay and that (ii) the delay markedly affects the impact a large trade has on the limit order book.", "pdf_url": "https://arxiv.org/pdf/2008.07871", "subject": "Computational Finance (q-fin.CP)"},
{"title": "Bayesian geoacoustic inversion using mixture density network", "author": "Guoli Wu, Hefeng Dong, Junqiang Song, Jingya Zhang", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Bayesian geoacoustic inversion problems are conventionally solved by Markov chain Monte Carlo methods or its variants, which are computationally expensive. This paper extends the classic Bayesian geoacoustic inversion framework using the mixture density network (MDN), which provides a much more efficient way to solve geoacoustic inversion problems in Bayesian inference framework. Some important geoacoustic statistics of Bayesian geoacoustic inversion are derived from the multidimensional posterior probability density (PPD) using the MDN theory. These statistics make it convenient to train the network directly on the whole parameter space and get the multidimensional PPD of model parameters. The network is trained on a simulated dataset of surface-wave dispersion curves with shear-wave velocities as labels. The results show that the network gives reliable predictions and has good generalization performance on unseen data. Once trained, the network can rapidly (within seconds) give a fully probabilistic solution which is comparable to Monte Carlo methods. It provides an promissing approach for real-time inversion.", "pdf_url": "https://arxiv.org/pdf/2008.07902", "subject": "Machine Learning (stat.ML)"},
{"title": "Comparison of Convolutional neural network training parameters for detecting Alzheimers disease and effect on visualization", "author": "Arjun Haridas Pallath, Martin Dyrba", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Convolutional neural networks (CNN) have become a powerful tool for detecting patterns in image data. Recent papers report promising results in the domain of disease detection using brain MRI data. Despite the high accuracy obtained from CNN models for MRI data so far, almost no papers provided information on the features or image regions driving this accuracy as adequate methods were missing or challenging to apply. Recently, the toolbox iNNvestigate has become available, implementing various state of the art methods for deep learning visualizations. Currently, there is a great demand for a comparison of visualization algorithms to provide an overview of the practical usefulness and capability of these algorithms. Therefore, this thesis has two goals: 1. To systematically evaluate the influence of CNN hyper-parameters on model accuracy. 2. To compare various visualization methods with respect to the quality (i.e. randomness/focus, soundness).", "pdf_url": "https://arxiv.org/pdf/2008.07981", "subject": "Image and Video Processing (eess.IV)"},
{"title": "A port-Hamiltonian approach to modeling the structural dynamics of complex systems", "author": "Alexander Warsewa, Michael B\u00f6hm, Oliver Sawodny, Cristina Tar\u00edn", "pub_date": "Submitted on 18 Aug 2020", "abstract": "With this contribution, we give a complete and comprehensive framework for modeling the dynamics of complex mechanical structures as port-Hamiltonian systems. This is motivated by research on the potential of lightweight construction using active load-bearing elements integrated into the structure. Such adaptive structures are of high complexity and very heterogeneous in nature. Port-Hamiltonian systems theory provides a promising approach for their modeling and control. Subsystem dynamics can be formulated in a domain-independent way and interconnected by means of power flows. The modular approach is also suitable for robust decentralized control schemes. Starting from a distributed-parameter port-Hamiltonian formulation of beam dynamics, we show the application of an existing structure-preserving mixed finite element method to arrive at finite-dimensional approximations. In contrast to the modeling of single bodies with a single boundary, we consider complex structures composed of many simple elements interconnected at the boundary. This is analogous to the usual way of modeling civil engineering structures which has not been transferred to port-Hamiltonian systems before. A block diagram representation of the interconnected systems is used to generate coupling constraints which leads to differential algebraic equations of index one. After the elimination of algebraic constraints, systems in input-state-output(ISO) port-Hamiltonian form are obtained. Port-Hamiltonian system models for the considered class of systems can also be constructed from the mass and stiffness matrices obtained via conventional finite element methods. We show how this relates to the presented approach and discuss the differences, promoting a better understanding across engineering disciplines.", "pdf_url": "https://arxiv.org/pdf/2008.07985", "subject": "Computational Physics (physics.comp-ph)"},
{"title": "Offloading Optimization in Edge Computing for Deep Learning Enabled Target Tracking by Internet-of-UAVs", "author": "Bo Yang, Xuelin Cao, Chau Yuen, Lijun Qian", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The empowering unmanned aerial vehicles (UAVs) have been extensively used in providing intelligence such as target tracking. In our field experiments, a pre-trained convolutional neural network (CNN) is deployed at the UAV to identify a target (a vehicle) from the captured video frames and enable the UAV to keep tracking. However, this kind of visual target tracking demands a lot of computational resources due to the desired high inference accuracy and stringent delay requirement. This motivates us to consider offloading this type of deep learning (DL) tasks to a mobile edge computing (MEC) server due to limited computational resource and energy budget of the UAV, and further improve the inference accuracy. Specifically, we propose a novel hierarchical DL tasks distribution framework, where the UAV is embedded with lower layers of the pre-trained CNN model, while the MEC server with rich computing resources will handle the higher layers of the CNN model. An optimization problem is formulated to minimize the weighted-sum cost including the tracking delay and energy consumption introduced by communication and computing of the UAVs, while taking into account the quality of data (e.g., video frames) input to the DL model and the inference errors. Analytical results are obtained and insights are provided to understand the tradeoff between the weighted-sum cost and inference error rate in the proposed framework. Numerical results demonstrate the effectiveness of the proposed offloading framework.", "pdf_url": "https://arxiv.org/pdf/2008.08001", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Forecasting day-ahead electricity prices: A review of state-of-the-art algorithms, best practices and an open-access benchmark", "author": "Jesus Lago, Grzegorz Marcjasz, Bart De Schutter, Rafa\u0142 Weron", "pub_date": "Submitted on 18 Aug 2020", "abstract": "While the field of electricity price forecasting has benefited from plenty of contributions in the last two decades, it arguably lacks a rigorous approach to evaluating new predictive algorithms. The latter are often compared using unique, not publicly available datasets and across too short and limited to one market test samples. The proposed new methods are rarely benchmarked against well established and well performing simpler models, the accuracy metrics are sometimes inadequate and testing the significance of differences in predictive performance is seldom conducted. Consequently, it is not clear which methods perform well nor what are the best practices when forecasting electricity prices. In this paper, we tackle these issues by performing a literature survey of state-of-the-art models, comparing state-of-the-art statistical and deep learning methods across multiple years and markets, and by putting forward a set of best practices. In addition, we make available the considered datasets, forecasts of the state-of-the-art models, and a specifically designed python toolbox, so that new algorithms can be rigorously evaluated in future studies.", "pdf_url": "https://arxiv.org/pdf/2008.08004", "subject": "Applications (stat.AP)"},
{"title": "Neural networks in day-ahead electricity price forecasting: Single vs. multiple outputs", "author": "Grzegorz Marcjasz, Jesus Lago, Rafa\u0142 Weron", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Recent advancements in the fields of artificial intelligence and machine learning methods resulted in a significant increase of their popularity in the literature, including electricity price forecasting. Said methods cover a very broad spectrum, from decision trees, through random forests to various artificial neural network models and hybrid approaches. In electricity price forecasting, neural networks are the most popular machine learning method as they provide a non-linear counterpart for well-tested linear regression models. Their application, however, is not straightforward, with multiple implementation factors to consider. One of such factors is the network's structure. This paper provides a comprehensive comparison of two most common structures when using the deep neural networks -- one that focuses on each hour of the day separately, and one that reflects the daily auction structure and models vectors of the prices. The results show a significant accuracy advantage of using the latter, confirmed on data from five distinct power exchanges.", "pdf_url": "https://arxiv.org/pdf/2008.08006", "subject": "Applications (stat.AP)"},
{"title": "Self-supervised Denoising via Diffeomorphic Template Estimation: Application to Optical Coherence Tomography", "author": "Guillaume Gisbert, Neel Dey, Hiroshi Ishikawa, Joel Schuman, James Fishbaugh, Guido Gerig", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Optical Coherence Tomography (OCT) is pervasive in both the research and clinical practice of Ophthalmology. However, OCT images are strongly corrupted by noise, limiting their interpretation. Current OCT denoisers leverage assumptions on noise distributions or generate targets for training deep supervised denoisers via averaging of repeat acquisitions. However, recent self-supervised advances allow the training of deep denoising networks using only repeat acquisitions without clean targets as ground truth, reducing the burden of supervised learning. Despite the clear advantages of self-supervised methods, their use is precluded as OCT shows strong structural deformations even between sequential scans of the same subject due to involuntary eye motion. Further, direct nonlinear alignment of repeats induces correlation of the noise between images. In this paper, we propose a joint diffeomorphic template estimation and denoising framework which enables the use of self-supervised denoising for motion deformed repeat acquisitions, without empirically registering their noise realizations. Strong qualitative and quantitative improvements are achieved in denoising OCT images, with generic utility in any imaging modality amenable to multiple exposures.", "pdf_url": "https://arxiv.org/pdf/2008.08024", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Predicting Coordinated Actuated Traffic Signal Change Times using LSTM Neural Networks", "author": "Seifeldeen Eteifa, Hesham A. Rakha, Hoda Eldardiry", "pub_date": "Submitted on 10 Aug 2020", "abstract": "Vehicle acceleration and deceleration maneuvers at traffic signals results in significant fuel and energy consumption levels. Green light optimal speed advisory systems require reliable estimates of signal switching times to improve vehicle fuel efficiency. Obtaining these estimates is difficult for actuated signals where the length of each green indication changes to accommodate varying traffic conditions. This study details a four-step Long Short-Term Memory deep learning-based methodology that can be used to provide reasonable switching time estimates from green to red and vice versa while being robust to missing data. The four steps are data gathering, data preparation, machine learning model tuning, and model testing and evaluation. The input to the models included controller logic, signal timing parameters, time of day, traffic state from detectors, vehicle actuation data, and pedestrian actuation data. The methodology is applied and evaluated on data from an intersection in Northern Virginia. A comparative analysis is conducted between different loss functions including the mean squared error, mean absolute error, and mean relative error used in LSTM and a new loss function is proposed. The results show that while the proposed loss function outperforms conventional loss functions in terms of overall absolute error values, the choice of the loss function is dependent on the prediction horizon. In particular, the proposed loss function is outperformed by the mean relative error for very short prediction horizons and mean squared error for very long prediction horizons.", "pdf_url": "https://arxiv.org/pdf/2008.08035", "subject": "Signal Processing (eess.SP)"},
{"title": "Fast Approximate Bayesian Contextual Cold Start Learning (FAB-COST)", "author": "Jack R. McKenzie, Peter A. Appleby, Thomas House, Neil Walton", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Cold-start is a notoriously difficult problem which can occur in recommendation systems, and arises when there is insufficient information to draw inferences for users or items. To address this challenge, a contextual bandit algorithm -- the Fast Approximate Bayesian Contextual Cold Start Learning algorithm (FAB-COST) -- is proposed, which is designed to provide improved accuracy compared to the traditionally used Laplace approximation in the logistic contextual bandit, while controlling both algorithmic complexity and computational cost. To this end, FAB-COST uses a combination of two moment projection variational methods: Expectation Propagation (EP), which performs well at the cold start, but becomes slow as the amount of data increases; and Assumed Density Filtering (ADF), which has slower growth of computational cost with data size but requires more data to obtain an acceptable level of accuracy. By switching from EP to ADF when the dataset becomes large, it is able to exploit their complementary strengths. The empirical justification for FAB-COST is presented, and systematically compared to other approaches on simulated data. In a benchmark against the Laplace approximation on real data consisting of over $670,000$ impressions from , FAB-COST demonstrates at one point increase of over $16\\%$ in user clicks. On the basis of these results, it is argued that FAB-COST is likely to be an attractive approach to cold-start recommendation systems in a variety of contexts.", "pdf_url": "https://arxiv.org/pdf/2008.08038", "subject": "Machine Learning (stat.ML)"},
{"title": "Just another quantum assembly language (Jaqal)", "author": "Benjamin C. A. Morrison, Andrew J. Landahl, Daniel S. Lobser, Kenneth M. Rudinger, Antonio E. Russo, Jay W. Van Der Wall, Peter Maunz", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The Quantum Scientific Computing Open User Testbed (QSCOUT) is a trapped-ion quantum computer testbed realized at Sandia National Laboratories on behalf of the Department of Energy's Office of Science and its Advanced Scientific Computing (ASCR) program. Here we describe Jaqal, for Just another quantum assembly language, the programming language we invented to specify programs executed on QSCOUT. Jaqal is useful beyond QSCOUT---it can support mutliple hardware targets because it offloads gate names and their pulse-sequence definitions to external files. We describe the capabilities of the Jaqal language, our approach in designing it, and the reasons for its creation. To learn more about QSCOUT, Jaqal, or JaqalPaq, the metaprogramming Python package we developed for Jaqal, please visit , , or send an e-mail to qscout@sandia.gov.", "pdf_url": "https://arxiv.org/pdf/2008.08042", "subject": "Quantum Physics (quant-ph)"},
{"title": "Bayesian neural networks and dimensionality reduction", "author": "Deborshee Sen, Theodore Papamarkou, David Dunson", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "In conducting non-linear dimensionality reduction and feature learning, it is common to suppose that the data lie near a lower-dimensional manifold. A class of model-based approaches for such problems includes latent variables in an unknown non-linear regression function; this includes Gaussian process latent variable models and variational auto-encoders (VAEs) as special cases. VAEs are artificial neural networks (ANNs) that employ approximations to make computation tractable; however, current implementations lack adequate uncertainty quantification in estimating the parameters, predictive densities, and lower-dimensional subspace, and can be unstable and lack interpretability in practice. We attempt to solve these problems by deploying Markov chain Monte Carlo sampling algorithms (MCMC) for Bayesian inference in ANN models with latent variables. We address issues of identifiability by imposing constraints on the ANN parameters as well as by using anchor points. This is demonstrated on simulated and real data examples. We find that current MCMC sampling schemes face fundamental challenges in neural networks involving latent variables, motivating new research directions.", "pdf_url": "https://arxiv.org/pdf/2008.08044", "subject": "Machine Learning (stat.ML)"},
{"title": "Algorithm Based on One Monocular Video Delivers Highly Valid and Reliable Gait Parameters Compared to a Gold-Standard Assessment Tool", "author": "Dr. Arash Azhand, Dr. Sophie Rabe, Dr. Swantje M\u00fcller, Igor Sattler, Dr. Anika Steinert", "pub_date": "Submitted on 5 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Despite its paramount importance for manifold use cases, sufficiently valid and reliable gait parameter measurement is still limited to high-tech gait laboratories in large clinics. This is largely because the majority of gold-standard assessment tools are very costly and highly complex in their setup and daily operations. Here, we demonstrate the excellent validity and test-retest repeatability of a novel gait assessment system which is built upon modern convolutional neuronal networks to extract three-dimensional skeleton joints from monocular frontal-view videos of walking humans. The present validity study is achieved in comparison to a previously validated pressure-sensitive walkway system (GAITRite, GS). All measured gait parameters showed excellent level of concurrent validity. This is proven by Inter-Class-Correlations possessing values between 0.958 and 0.987 for multiple walk trials, at normal and fast gait speeds. Furthermore, the average measure of difference between the two systems is below 3.5% of corresponding gait parameter mean value across all measured parameters (0.04% - 3.25%). The percentage error values of the assessed system in relation to GS are between 5% and 13.5% of corresponding gait parameter mean values, hence being significantly below the threshold of clinical acceptability (30%). The test-retest-repeatability yields ICC values between 0.915 and 0.950, being on the same level with the GS system. In conclusion, we are convinced that our results can pave the way for cost, space and operation effective gait analysis in the broad mainstream. Most sensor-based systems are costly, have to be operated by extensively trained personnel or possess considerable complexity (e.g. wearable sensors). In contrast, a sufficient video for the assessment method presented here can be acquired by anyone, without much training, via a smartphone camera.", "pdf_url": "https://arxiv.org/pdf/2008.08045", "subject": "Signal Processing (eess.SP)"},
{"title": "TactileSGNet: A Spiking Graph Neural Network for Event-based Tactile Object Recognition", "author": "Fuqiang Gu, Weicong Sng, Tasbolat Taunyazov, Harold Soh", "pub_date": "Submitted on 1 Aug 2020", "abstract": "Tactile perception is crucial for a variety of robot tasks including grasping and in-hand manipulation. New advances in flexible, event-driven, electronic skins may soon endow robots with touch perception capabilities similar to humans. These electronic skins respond asynchronously to changes (e.g., in pressure, temperature), and can be laid out irregularly on the robot's body or end-effector. However, these unique features may render current deep learning approaches such as convolutional feature extractors unsuitable for tactile learning. In this paper, we propose a novel spiking graph neural network for event-based tactile object recognition. To make use of local connectivity of taxels, we present several methods for organizing the tactile data in a graph structure. Based on the constructed graphs, we develop a spiking graph convolutional network. The event-driven nature of spiking neural network makes it arguably more suitable for processing the event-based data. Experimental results on two tactile datasets show that the proposed method outperforms other state-of-the-art spiking methods, achieving high accuracies of approximately 90\\% when classifying a variety of different household objects.", "pdf_url": "https://arxiv.org/pdf/2008.08046", "subject": "Signal Processing (eess.SP)"},
{"title": "Learning Structure in Nested Logit Models", "author": "Youssef M. Aboutaleb, Moshe Ben-Akiva, Patrick Jaillet", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This paper introduces a new data-driven methodology for nested logit structure discovery. Nested logit models allow the modeling of positive correlations between the error terms of the utility specifications of the different alternatives in a discrete choice scenario through the specification of a nesting structure. Current nested logit model estimation practices require an a priori specification of a nesting structure by the modeler. In this we work we optimize over all possible specifications of the nested logit model that are consistent with rational utility maximization. We formulate the problem of learning an optimal nesting structure from the data as a mixed integer nonlinear programming (MINLP) optimization problem and solve it using a variant of the linear outer approximation algorithm. We exploit the tree structure of the problem and utilize the latest advances in integer optimization to bring practical tractability to the optimization problem we introduce. We demonstrate the ability of our algorithm to correctly recover the true nesting structure from synthetic data in a Monte Carlo experiment. In an empirical illustration using a stated preference survey on modes of transportation in the U.S. state of Massachusetts, we use our algorithm to obtain an optimal nesting tree representing the correlations between the unobserved effects of the different travel mode choices. We provide our implementation as a customizable and open-source code base written in the Julia programming language.", "pdf_url": "https://arxiv.org/pdf/2008.08048", "subject": "Methodology (stat.ME)"},
{"title": "Efficient planning of peen-forming patterns via artificial neural networks", "author": "Wassime Siguerdidjane, Farbod Khameneifar, Fr\u00e9d\u00e9rick P. Gosselin", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Robust automation of the shot peen forming process demands a closed-loop feedback in which a suitable treatment pattern needs to be found in real-time for each treatment iteration. In this work, we present a method for finding the peen-forming patterns, based on a neural network (NN), which learns the nonlinear function that relates a given target shape (input) to its optimal peening pattern (output), from data generated by finite element simulations. The trained NN yields patterns with an average binary accuracy of 98.8\\% with respect to the ground truth in microseconds.", "pdf_url": "https://arxiv.org/pdf/2008.08049", "subject": "Computational Physics (physics.comp-ph)"},
{"title": "Multi-Scale Merge-Split Markov Chain Monte Carlo for Redistricting", "author": "Eric A. Autry, Daniel Carter, Gregory Herschlag, Zach Hunter, Jonathan C. Mattingly", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We develop a Multi-Scale Merge-Split Markov chain on redistricting plans. The chain is designed to be usable as the proposal in a Markov Chain Monte Carlo (MCMC) algorithm. Sampling the space of plans amounts to dividing a graph into a partition with a specified number of elements which each correspond to a different district. The districts satisfy a collection of hard constraints and the measure may be weighted with regard to a number of other criteria. The multi-scale algorithm is similar to our previously developed Merge-Split proposal, however, this algorithm provides improved scaling properties and may also be used to preserve nested communities of interest such as counties and precincts. Both works use a proposal which extends the ReCom algorithm which leveraged spanning trees merge and split districts. In this work we extend the state space so that each district is defined by a hierarchy of trees. In this sense, the proposal step in both algorithms can be seen as a \"Forest ReCom.\" We also expand the state space to include edges that link specified districts, which further improves the computational efficiency of our algorithm. The collection of plans sampled by the MCMC algorithm can serve as a baseline against which a particular plan of interest is compared. If a given plan has different racial or partisan qualities than what is typical of the collection of plans, the given plan may have been gerrymandered and is labeled as an outlier.", "pdf_url": "https://arxiv.org/pdf/2008.08054", "subject": "Probability (math.PR)"},
{"title": "On the Evolution of Subjective Experience", "author": "Jerome A. Feldman", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Subjective Experience (SE) is part of the ancient mind-body problem, which continues to be one of deepest mysteries of science. Despite major advances in many fields, there is still no plausible causal link between SE and its realization in the body. The core issue is the incompatibility of objective (3rd person) public science with subjective (1st person) private experience. Any scientific approach to SE assumes that it arose from extended evolutionary processes and that examining evolutionary history should help us understand it. While the core mystery remains, converging evidence from theoretical, experimental, and computational studies yields strong constraints on SE and some suggestions for further research. All animals confront many of the same fitness challenges. They all need some kind of internal model to relate their life goals and actionable sensed information to action. We understand the evolution of the bodily aspects of human perception and emotion, but not the SE. The first evolutionary evidence for SE appears in vertebrates and much of its neural substrate and simulation mechanism is preserved in mammals and humans. People exhibit the same phenomena, but there are remaining mysteries of everyday experience that are demonstrably incompatible with current neuroscience. In spite of this limitation, there is considerable progress on understanding the role of SE in the success of prostheses.", "pdf_url": "https://arxiv.org/pdf/2008.08073", "subject": "Neurons and Cognition (q-bio.NC)"},
{"title": "Closed-Loop Design of Proton Donors for Lithium-Mediated Ammonia Synthesis with Interpretable Models and Molecular Machine Learning", "author": "Dilip Krishnamurthy, Nikifar Lazouski, Michal L. Gala, Karthish Manthiram, Venkatasubramanian Viswanathan", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "In this work, we experimentally determined the efficacy of several classes of proton donors for lithium-mediated electrochemical nitrogen reduction in a tetrahydrofuran-based electrolyte, an attractive alternative method for producing ammonia. We then built an interpretable data-driven classification model which identified solvatochromic Kamlet-Taft parameters as important for distinguishing between active and inactive proton donors. After curating a dataset for the Kamlet-Taft parameters, we trained a deep learning model to predict the Kamlet-Taft parameters. The combination of classification model and deep learning model provides a predictive mapping from a given proton donor to the ability to produce ammonia. We demonstrate that this combination of classification model with deep learning is superior to a purely mechanistic or data-driven approach in accuracy and experimental data efficiency.", "pdf_url": "https://arxiv.org/pdf/2008.08078", "subject": "Chemical Physics (physics.chem-ph)"},
{"title": "Whitening and second order optimization both destroy information about the dataset, and can make generalization impossible", "author": "Neha S. Wadia, Daniel Duckworth, Samuel S. Schoenholz, Ethan Dyer, Jascha Sohl-Dickstein", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Machine learning is predicated on the concept of generalization: a model achieving low error on a sufficiently large training set should also perform well on novel samples from the same distribution. We show that both data whitening and second order optimization can harm or entirely prevent generalization. In general, model training harnesses information contained in the sample-sample second moment matrix of a dataset. We prove that for models with a fully connected first layer, the information contained in this matrix is the only information which can be used to generalize. Models trained using whitened data, or with certain second order optimization schemes, have less access to this information; in the high dimensional regime they have no access at all, producing models that generalize poorly or not at all. We experimentally verify these predictions for several architectures, and further demonstrate that generalization continues to be harmed even when theoretical requirements are relaxed. However, we also show experimentally that regularized second order optimization can provide a practical tradeoff, where training is still accelerated but less information is lost, and generalization can in some circumstances even improve.", "pdf_url": "https://arxiv.org/pdf/2008.07545", "subject": "Machine Learning (cs.LG)"},
{"title": "Sizing of Movable Energy Resources for Service Restoration and Reliability Enhancement", "author": "Narayan Bhusal, Mukesh Gautam, Mohammed Benidris", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The frequency of extreme events (e.g., hurricanes, earthquakes, and floods) and man-made attacks (cyber and physical attacks) has increased dramatically in recent years. These events have severely impacted power systems ranging from long outage times to major equipment (e.g., substations, transmission lines, power plants, and distribution system) destruction. Distribution system failures and outages are major contributors to power supply interruptions. Network reconfiguration and movable energy resources (MERs) can play a vital role in supplying loads during and after contingencies. This paper proposes a two-stage strategy to determine the minimum sizes of MERs with network reconfiguration for distribution service restoration and supplying local and isolated loads. Sequential Monte Carlo simulations are used to model the outages of distribution system components. After a contingency, the first stage determines the network reconfiguration based on the spanning tree search algorithm. In the second stage, if some system loads cannot be fed by network reconfiguration, MERs are deployed and the optimal routes to reach isolated areas are determined based on the DSPA. The traveling time obtained from the DSPA is incorporated with the proposed sequential Monte Carlo simulation-based approach to determine the sizes of MERs. The proposed method is applied on several distribution systems including the IEEE-13 and IEEE-123 node test feeders. The results show that network reconfiguration can reduce the required sizes of MERs to supply isolated areas.", "pdf_url": "https://arxiv.org/pdf/2008.07557", "subject": "Systems and Control (eess.SY)"},
{"title": "Resolving Intent Ambiguities by Retrieving Discriminative Clarifying Questions", "author": "Kaustubh D. Dhole", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Task oriented Dialogue Systems generally employ intent detection systems in order to map user queries to a set of pre-defined intents. However, user queries appearing in natural language can be easily ambiguous and hence such a direct mapping might not be straightforward harming intent detection and eventually the overall performance of a dialogue system. Moreover, acquiring domain-specific clarification questions is costly. In order to disambiguate queries which are ambiguous between two intents, we propose a novel method of generating discriminative questions using a simple rule based system which can take advantage of any question generation system without requiring annotated data of clarification questions. Our approach aims at discrimination between two intents but can be easily extended to clarification over multiple intents. Seeking clarification from the user to classify user intents not only helps understand the user intent effectively, but also reduces the roboticity of the conversation and makes the interaction considerably natural.", "pdf_url": "https://arxiv.org/pdf/2008.07559", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Modeling of Natural Disasters and Extreme Events in Power System Resilience Enhancement and Evaluation Methods", "author": "Narayan Bhusal, Mukesh Gautam, Michael Abdelmalak, Mohammed Benidris", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The frequency of disruptive and newly emerging threats (e.g. man-made attacks--cyber and physical attacks; extreme natural events--hurricanes, earthquakes, and floods) has escalated dramatically in the last decade. Impacts of these events are very severe ranging from long power outage duration, major power system equipment (e.g. power generation plants, transmission and distribution lines, and substation) destruction, and complete blackout. Accurate modeling of these events is vitally important as they serve as mathematical tools for the assessment and evaluation of various operations and planning investment strategies to harden power systems against these events. This paper provides a comprehensive and critical review of current practices in the modeling of extreme events, system components, and system response for resilience evaluation and enhancement, which is a very important stepping stone toward the development of complete, accurate, and computationally attractive modeling techniques. The paper starts with reviewing existing technologies to model the propagation of extreme events and then discusses the approaches used to model impacts of these events on power system components and system response. This paper also discusses the research gaps and associated challenges, and potential solutions to the limitations of the existing modeling approaches.", "pdf_url": "https://arxiv.org/pdf/2008.07560", "subject": "Systems and Control (eess.SY)"},
{"title": "Poisson Receivers: a Probabilistic Framework for Analyzing Coded Random Access", "author": "Che-Hao Yu, Lin Huang, Cheng-Shang Chang, Duan-Shin Lee", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper, we develop a probabilistic framework for analyzing coded random access. Our framework is based on a new abstract receiver (decoder), called a Poisson receiver, that is characterized by a success probability function of a tagged packet subject to a Poisson offered load. We show that various coded slotted ALOHA (CSA) systems are Poisson receivers. Moreover, Poisson receivers have two elegant closure properties: (i) Poisson receivers with packet routing are still Poisson receivers, and (ii) Poisson receivers with packet coding are still Poisson receivers. These two closure properties enable us to use smaller Poisson receivers as building blocks for analyzing a larger Poisson receiver. As such, we can analyze complicated systems that are not possible by the classical tree evaluation method. In particular, for CSA systems with both spatial diversity and temporal diversity, we can use the framework of Poisson receivers to compute the exact (asymptotic) throughput. We demonstrate that our framework can be used to provide differentiated services between ultra-reliable low-latency communication (URLLC) traffic and enhanced mobile broadband (eMBB) traffic. By conducting extensive simulations, we also verify that our theoretical results match extremely well with the simulation results.", "pdf_url": "https://arxiv.org/pdf/2008.07561", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "PROTEUS: Rule-Based Self-Adaptation in Photonic NoCs for Loss-Aware Co-Management of Laser Power and Performance", "author": "Sairam Sri Vatsavai, Venkata Sai Praneeth Karempudi, Ishan Thakkar", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "The performance of on-chip communication in the state-of-the-art multi-core processors that use the traditional electron-ic NoCs has already become severely energy-constrained. To that end, emerging photonic NoCs (PNoC) are seen as a po-tential solution to improve the energy-efficiency (performance per watt) of on-chip communication. However, existing PNoC designs cannot realize their full potential due to their exces-sive laser power consumption. Prior works that attempt to improve laser power efficiency in PNoCs do not consider all key factors that affect the laser power requirement of PNoCs. Therefore, they cannot yield the desired balance between the reduction in laser power, achieved performance and energy-efficiency in PNoCs. In this paper, we present PROTEUS framework that employs rule-based self-adaptation in PNoCs. Our approach not only reduces the laser power consumption, but also minimizes the average packet latency by opportunis-tically increasing the communication data rate in PNoCs, and thus, yields the desired balance between the laser power re-duction, performance, and energy-efficiency in PNoCs. Our evaluation with PARSEC benchmarks shows that our PROTEUS framework can achieve up to 24.5% less laser power consumption, up to 31% less average packet latency, and up to 20% less energy-per-bit, compared to another laser power management technique from prior work.", "pdf_url": "https://arxiv.org/pdf/2008.07566", "subject": "Emerging Technologies (cs.ET)"},
{"title": "Superconvergence of time invariants for the Gross-Pitaevskii equation", "author": "Patrick Henning, Johan W\u00e4rneg\u00e5rd", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This paper considers the numerical treatment of the time-dependent Gross-Pitaevskii equation. In order to conserve the time invariants of the equation as accurately as possible, we propose a Crank-Nicolson-type time discretization that is combined with a suitable generalized finite element discretization in space. The space discretization is based on the technique of Localized Orthogonal Decompositions (LOD) and allows to capture the time invariants with an accuracy of order $\\mathcal{O}(H^6)$ with respect to the chosen mesh size $H$. This accuracy is preserved due to the conservation properties of the time stepping method. Furthermore, we prove that the resulting scheme approximates the exact solution in the $L^{\\infty}(L^2)$-norm with order $\\mathcal{O}(\\tau^2 + H^4)$, where $\\tau$ denotes the step size. The computational efficiency of the method is demonstrated in numerical experiments for a benchmark problem with known exact solution.", "pdf_url": "https://arxiv.org/pdf/2008.07575", "subject": "Numerical Analysis (math.NA)"},
{"title": "Joint Variational Autoencoders for Recommendation with Implicit Feedback", "author": "Bahare Askari, Jaroslaw Szlichta, Amirali Salehi-Abari", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Variational Autoencoders (VAEs) have recently shown promising performance in collaborative filtering with implicit feedback. These existing recommendation models learn user representations to reconstruct or predict user preferences. We introduce joint variational autoencoders (JoVA), an ensemble of two VAEs, in which VAEs jointly learn both user and item representations and collectively reconstruct and predict user preferences. This design allows JoVA to capture user-user and item-item correlations simultaneously. By extending the objective function of JoVA with a hinge-based pairwise loss function (JoVA-Hinge), we further specialize it for top-k recommendation with implicit feedback. Our extensive experiments on several real-world datasets show that JoVA-Hinge outperforms a broad set of state-of-the-art collaborative filtering methods, under a variety of commonly-used metrics. Our empirical results also confirm the outperformance of JoVA-Hinge over existing methods for cold-start users with a limited number of training data.", "pdf_url": "https://arxiv.org/pdf/2008.07577", "subject": "Machine Learning (cs.LG)"},
{"title": "A Microservices Architecture for Distributed Complex Event Processing in Smart Cities", "author": "Fernando Freire Scattone, Kelly Rosa Braghetto", "pub_date": "Submitted on 17 Aug 2020", "abstract": "A considerable volume of data is collected from sensors today and needs to be processed in real time. Complex Event Processing (CEP) is one of the most important techniques developed for this purpose. In CEP, each new sensor measurement is considered an event and new event types can be defined based on other events occurrence. There exists several open-source CEP implementations currently available, but all of them use orchestration to distribute event processing. This kind of architectural organization may harm system resilience, since it relies on a central core (i.e. the orchestrator). Any failures in the core might impact the whole system. Moreover, the core can become a bottleneck on system performance. In this work, a choreography-based microservices architecture is proposed for distributed CEP, in order to benefit from the low coupling and greater horizontal scalability this kind of architecture provides.", "pdf_url": "https://arxiv.org/pdf/2008.07585", "subject": "Software Engineering (cs.SE)"},
{"title": "Stochastic Bayesian Neural Networks", "author": "Abhinav Sagar", "pub_date": "Submitted on 12 Aug 2020", "abstract": "Bayesian neural networks perform variational inference over the weights however calculation of the posterior distribution remains a challenge. Our work builds on variational inference techniques for bayesian neural networks using the original Evidence Lower Bound. In this paper, we present a stochastic bayesian neural network in which we maximize Evidence Lower Bound using a new objective function which we name as Stochastic Evidence Lower Bound. We evaluate our network on 5 publicly available UCI datasets using test RMSE and log likelihood as the evaluation metrics. We demonstrate that our work not only beats the previous state of the art algorithms but is also scalable to larger datasets.", "pdf_url": "https://arxiv.org/pdf/2008.07587", "subject": "Machine Learning (cs.LG)"},
{"title": "Cardinality estimation using Gumbel distribution", "author": "Aleksander \u0141ukasiewicz, Przemys\u0142aw Uzna\u0144ski", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Cardinality estimation is the task of approximating the number of distinct elements in a large dataset with possibly repeating elements. LogLog and HyperLogLog (c.f. Durand and Flajolet [ESA 2003], Flajolet et al. [Discrete Math Theor. 2007]) are small space sketching schemes for cardinality estimation, which have both strong theoretical guarantees of performance and are highly effective in practice. This makes them a highly popular solution with many implementations in big-data systems (e.g. Algebird, Apache DataSketches, BigQuery, Presto and Redis). However, despite having simple and elegant formulation, both the analysis of LogLog and HyperLogLog are extremely involved -- spanning over tens of pages of analytic combinatorics and complex function analysis. We propose a modification to both LogLog and HyperLogLog that replaces discrete geometric distribution with a continuous Gumbel distribution. This leads to a very short, simple and elementary analysis of estimation guarantees, and smoother behavior of the estimator.", "pdf_url": "https://arxiv.org/pdf/2008.07590", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Polyth-Net: Classification of Polythene Bags for Garbage Segregation Using Deep Learning", "author": "Divyansh Singh", "pub_date": "Submitted on 12 Aug 2020", "abstract": "Polythene has always been a threat to the environment since its invention. It is non-biodegradable and very difficult to recycle. Even after many awareness campaigns and practices, Separation of polythene bags from waste has been a challenge for human civilization. The primary method of segregation deployed is manual handpicking, which causes a dangerous health hazards to the workers and is also highly inefficient due to human errors. In this paper I have designed and researched on image-based classification of polythene bags using a deep-learning model and its efficiency. This paper focuses on the architecture and statistical analysis of its performance on the data set as well as problems experienced in the classification. It also suggests a modified loss function to specifically detect polythene irrespective of its individual features. It aims to help the current environment protection endeavours and save countless lives lost to the hazards caused by current methods.", "pdf_url": "https://arxiv.org/pdf/2008.07592", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Nonlinear Attitude Filter on SO(3): Fast Adaptation and Robustness", "author": "Ajay Singh, Trenton S. Sieb, James H. Howe, Hashim A. Hashim", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Nonlinear attitude filters have been recognized to have simpler structure and better tracking performance when compared with Gaussian attitude filters and other methods of attitude determination. A key element of nonlinear attitude filter design is the selection of error criteria. The conventional design of nonlinear attitude filters has a trade-off between fast adaptation and robustness. In this work, a new functional approach based on fuzzy rules for on-line continuous tuning of the nonlinear attitude filter adaptation gain is proposed. The input and output membership functions are optimally tuned using artificial bee colony optimization algorithm taking into account both attitude error and rate of change of attitude error. The proposed approach results of high adaptation gain at large error and small adaptation gain at small error. Thereby, the proposed approach allows fast convergence properties with high measures of robustness. The simulation results demonstrate that the proposed approach offers robust and high convergence capabilities against large error in initialization and uncertain measurements.", "pdf_url": "https://arxiv.org/pdf/2008.07595", "subject": "Systems and Control (eess.SY)"},
{"title": "Learning from Irregularly-Sampled Time Series: A Missing Data Perspective", "author": "Steven Cheng-Xian Li, Benjamin M. Marlin", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Irregularly-sampled time series occur in many domains including healthcare. They can be challenging to model because they do not naturally yield a fixed-dimensional representation as required by many standard machine learning models. In this paper, we consider irregular sampling from the perspective of missing data. We model observed irregularly-sampled time series data as a sequence of index-value pairs sampled from a continuous but unobserved function. We introduce an encoder-decoder framework for learning from such generic indexed sequences. We propose learning methods for this framework based on variational autoencoders and generative adversarial networks. For continuous irregularly-sampled time series, we introduce continuous convolutional layers that can efficiently interface with existing neural network architectures. Experiments show that our models are able to achieve competitive or better classification results on irregularly-sampled multivariate time series compared to recent RNN models while offering significantly faster training times.", "pdf_url": "https://arxiv.org/pdf/2008.07599", "subject": "Machine Learning (cs.LG)"},
{"title": "Convergence analysis of collocation methods for computing periodic solutions of retarded functional differential equations", "author": "Alessia and\u00f2, Dimitri Breda", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We analyze the convergence of piecewise collocation methods for computing periodic solutions of general retarded functional differential equations under the abstract framework recently developed in [S. Maset, Numer. Math. (2016) 133(3):525-555], [S. Maset, SIAM J. Numer. Anal. (2015) 53(6):2771--2793] and [S. Maset, SIAM J. Numer. Anal. (2015) 53(6):2794--2821]. We rigorously show that a reformulation as a boundary value problem requires a proper infinite-dimensional boundary periodic condition in order to be amenable of such analysis. In this regard, we also highlight the role of the period acting as an unknown parameter, which is critical being it directly linked to the course of time. Finally, we prove that the finite element method is convergent, while limit ourselves to comment on the unfeasibility of this approach as far as the spectral element method is concerned.", "pdf_url": "https://arxiv.org/pdf/2008.07604", "subject": "Numerical Analysis (math.NA)"},
{"title": "Optimal Best-Arm Identification Methods for Tail-Risk Measures", "author": "Shubhada Agrawal, Wouter M. Koolen, Sandeep Juneja", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Conditional value-at-risk (CVaR) and value-at-risk (VaR) are popular tail-risk measures in finance and insurance industries where often the underlying probability distributions are heavy-tailed. We use the multi-armed bandit best-arm identification framework and consider the problem of identifying the arm-distribution from amongst finitely many that has the smallest CVaR or VaR. We first show that in the special case of arm-distributions belonging to a single-parameter exponential family, both these problems are equivalent to the best mean-arm identification problem, which is widely studied in the literature. This equivalence however is not true in general. We then propose optimal $\\delta$-correct algorithms that act on general arm-distributions, including heavy-tailed distributions, that match the lower bound on the expected number of samples needed, asymptotically (as $ \\delta$ approaches $0$). En-route, we also develop new non-asymptotic concentration inequalities for certain functions of these risk measures for the empirical distribution, that may have wider applicability.", "pdf_url": "https://arxiv.org/pdf/2008.07606", "subject": "Machine Learning (cs.LG)"},
{"title": "A framework for approximation of the Stokes equations in an axisymmetric domain", "author": "N. Ericsson", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We develop a framework for solving the stationary, incompressible Stokes equations in an axisymmetric domain. By means of Fourier expansion with respect to the angular variable, the three-dimensional Stokes problem is reduced to an equivalent, countable family of decoupled two-dimensional problems. By using decomposition of three-dimensional Sobolev norms we derive natural variational spaces for the two-dimensional problems, and show that the variational formulations are well-posed. We analyze the error due to Fourier truncation and conclude that, for data that are sufficiently regular, it suffices to solve a small number of two-dimensional problems.", "pdf_url": "https://arxiv.org/pdf/2008.07608", "subject": "Numerical Analysis (math.NA)"},
{"title": "Surveillance of COVID-19 Pandemic using Hidden Markov Model", "author": "Shreekanth M. Prabhu, Natarajan Subramaniam", "pub_date": "Submitted on 14 Aug 2020", "abstract": "COVID-19 pandemic has brought the whole world to a stand-still over the last few months. In particular the pace at which pandemic has spread has taken everybody off-guard. The Governments across the world have responded by imposing lock-downs, stopping/restricting travel and mandating social distancing. On the positive side there is wide availability of information on active cases, recoveries and deaths collected daily across regions. However, what has been particularly challenging is to track the spread of the disease by asymptomatic carriers termed as super-spreaders. In this paper we look at applying Hidden Markov Model to get a better assessment of extent of spread. The outcome of such analysis can be useful to Governments to design the required interventions/responses in a calibrated manner. The data we have chosen to analyze pertains to Indian scenario.", "pdf_url": "https://arxiv.org/pdf/2008.07609", "subject": "Machine Learning (cs.LG)"},
{"title": "PufferBot: Actuated Expandable Structures for Aerial Robots", "author": "Hooman Hedayati, Ryo Suzuki1, Daniel Leithinger, Daniel Szafir", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We present PufferBot, an aerial robot with an expandable structure that may expand to protect a drone's propellers when the robot is close to obstacles or collocated humans. PufferBot is made of a custom 3D-printed expandable scissor structure, which utilizes a one degree of freedom actuator with rack and pinion mechanism. We propose four designs for the expandable structure, each with unique characterizations for different situations. Finally, we present three motivating scenarios in which PufferBot may extend the utility of existing static propeller guard structures. The supplementary video can be found at:", "pdf_url": "https://arxiv.org/pdf/2008.07615", "subject": "Robotics (cs.RO)"},
{"title": "A Smartphone-based System for Real-time Early Childhood Caries Diagnosis", "author": "Yipeng Zhang, Haofu Liao, Jin Xiao, Nisreen Al Jallad, Oriana Ly-Mapes, Jiebo Luo", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Early childhood caries (ECC) is the most common, yet preventable chronic disease in children under the age of 6. Treatments on severe ECC are extremely expensive and unaffordable for socioeconomically disadvantaged families. The identification of ECC in an early stage usually requires expertise in the field, and hence is often ignored by parents. Therefore, early prevention strategies and easy-to-adopt diagnosis techniques are desired. In this study, we propose a multistage deep learning-based system for cavity detection. We create a dataset containing RGB oral images labeled manually by dental practitioners. We then investigate the effectiveness of different deep learning models on the dataset. Furthermore, we integrate the deep learning system into an easy-to-use mobile application that can diagnose ECC from an early stage and provide real-time results to untrained users.", "pdf_url": "https://arxiv.org/pdf/2008.07623", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Bridging the Gap between Optimal Trajectory Planning and Safety-Critical Control with Applications to Autonomous Vehicles", "author": "Wei Xiao, Christos G. Cassandras, Calin A. Belta", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We address the problem of optimizing the performance of a dynamic system while satisfying hard safety constraints at all times. Implementing an optimal control solution is limited by the computational cost required to derive it in real time, especially when constraints become active, as well as the need to rely on simple linear dynamics, simple objective functions, and ignoring noise. The recently proposed Control Barrier Function (CBF) method may be used for safety-critical control at the expense of sub-optimal performance. In this paper, we develop a real-time control framework that combines optimal trajectories generated through optimal control with the computationally efficient CBF method providing safety guarantees. We use Hamiltonian analysis to obtain a tractable optimal solution for a linear or linearized system, then employ High Order CBFs (HOCBFs) and Control Lyapunov Functions (CLFs) to account for constraints with arbitrary relative degrees and to track the optimal state, respectively. We further show how to deal with noise in arbitrary relative degree systems. The proposed framework is then applied to the optimal traffic merging problem for Connected and Automated Vehicles (CAVs) where the objective is to jointly minimize the travel time and energy consumption of each CAV subject to speed, acceleration, and speed-dependent safety constraints. In addition, when considering more complex objective functions, nonlinear dynamics and passenger comfort requirements for which analytical optimal control solutions are unavailable, we adapt the HOCBF method to such problems. Simulation examples are included to compare the performance of the proposed framework to optimal solutions (when available) and to a baseline provided by human-driven vehicles with results showing significant improvements in all metrics.", "pdf_url": "https://arxiv.org/pdf/2008.07632", "subject": "Systems and Control (eess.SY)"},
{"title": "SF-GRASS: Solver-Free Graph Spectral Sparsification", "author": "Ying Zhang, Zhiqiang Zhao, Zhuo Feng", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Recent spectral graph sparsification techniques have shown promising performance in accelerating many numerical and graph algorithms, such as iterative methods for solving large sparse matrices, spectral partitioning of undirected graphs, vectorless verification of power/thermal grids, representation learning of large graphs, etc. However, prior spectral graph sparsification methods rely on fast Laplacian matrix solvers that are usually challenging to implement in practice. This work, for the first time, introduces a solver-free approach (SF-GRASS) for spectral graph sparsification by leveraging emerging spectral graph coarsening and graph signal processing (GSP) techniques. We introduce a local spectral embedding scheme for efficiently identifying spectrally-critical edges that are key to preserving graph spectral properties, such as the first few Laplacian eigenvalues and eigenvectors. Since the key kernel functions in SF-GRASS can be efficiently implemented using sparse-matrix-vector-multiplications (SpMVs), the proposed spectral approach is simple to implement and inherently parallel friendly. Our extensive experimental results show that the proposed method can produce a hierarchy of high-quality spectral sparsifiers in nearly-linear time for a variety of real-world, large-scale graphs and circuit networks when compared with the prior state-of-the-art spectral method.", "pdf_url": "https://arxiv.org/pdf/2008.07633", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Drawing Shortest Paths in Geodetic Graphs", "author": "Sabine Cornelsen, Maximilian Pfister, Henry F\u00f6rster, Martin Gronemann, Michael Hoffmann, Stephen Kobourov, Thomas Schneck", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Motivated by the fact that in a space where shortest paths are unique, no two shortest paths meet twice, we study a question posed by Greg Bodwin: Given a geodetic graph $G$, i.e., an unweighted graph in which the shortest path between any pair of vertices is unique, is there a philogeodetic drawing of $G$, i.e., a drawing of $G$ in which the curves of any two shortest paths meet at most once? We answer this question in the negative by showing the existence of geodetic graphs that require some pair of shortest paths to cross at least four times. The bound on the number of crossings is tight for the class of graphs we construct. Furthermore, we exhibit geodetic graphs of diameter two that do not admit a philogeodetic drawing.", "pdf_url": "https://arxiv.org/pdf/2008.07637", "subject": "Discrete Mathematics (cs.DM)"},
{"title": "Control Node Selection Algorithm for Nonlinear Dynamic Networks", "author": "Aleksandar Haber, Sebastian A. Nugroho, Patricio Torres, Ahmad E. Taha", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The coupled problems of selecting control nodes and designing control actions for nonlinear network dynamics are fundamental scientific problems with applications in many diverse fields. These problems are thoroughly studied for linear dynamics; however, in spite of a number of open research questions, methods for nonlinear network dynamics are less developed. As observed by various studies, the prevailing graph-based controllability approaches for selecting control nodes might result in significantly suboptimal control performance for nonlinear dynamics. Herein we present a new, intuitive, and simple method for simultaneous control node selection and control sequence design for complex networks with nonlinear dynamics. The method is developed by incorporating the control node selection problem into an open-loop predictive control cost function and by solving the resulting mixed-integer optimization problem using a mesh adaptive direct search method. The developed framework is numerically robust and can deal with stiff networks, networks with non-smooth dynamics, as well as with control and actuator constraints. Good numerical performance of the method is demonstrated by testing it on prototypical Duffing oscillator and associative memory networks. The developed codes that can easily be adapted to models of other complex systems are available online.", "pdf_url": "https://arxiv.org/pdf/2008.07640", "subject": "Systems and Control (eess.SY)"},
{"title": "Learning Graph Edit Distance by Graph Neural Networks", "author": "Pau Riba, Andreas Fischer, Josep Llad\u00f3s, Alicia Forn\u00e9s", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The emergence of geometric deep learning as a novel framework to deal with graph-based representations has faded away traditional approaches in favor of completely new methodologies. In this paper, we propose a new framework able to combine the advances on deep metric learning with traditional approximations of the graph edit distance. Hence, we propose an efficient graph distance based on the novel field of geometric deep learning. Our method employs a message passing neural network to capture the graph structure, and thus, leveraging this information for its use on a distance computation. The performance of the proposed graph distance is validated on two different scenarios. On the one hand, in a graph retrieval of handwritten words~\\ie~keyword spotting, showing its superior performance when compared with (approximate) graph edit distance benchmarks. On the other hand, demonstrating competitive results for graph similarity learning when compared with the current state-of-the-art on a recent benchmark dataset.", "pdf_url": "https://arxiv.org/pdf/2008.07641", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Sequence-to-Sequence Predictive Model: From Prosody To Communicative Gestures", "author": "Fajrian Yunus, Chlo\u00e9 Clavel, Catherine Pelachaud", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Communicative gestures and speech prosody are tightly linked. Our objective is to predict the timing of gestures according to the prosody. That is, we want to predict when a certain gesture occurs. We develop a model based on a recurrent neural network with attention mechanism. The model is trained on a corpus of natural dyadic interaction where the speech prosody and the gesture phases and types have been annotated. The input of the model is a sequence of speech prosody and the output is a sequence of gesture classes. The classes we are using for the model output is based on a combination of gesture phases and gesture types. We use a sequence comparison technique to evaluate the model performance. We find that the model can predict better certain gesture classes than others. We also perform ablation studies which reveal that fundamental frequency is a pertinent feature. We also find that a model trained on the data of one speaker only also works for the other speaker of the same conversation. Lastly, we also find that including eyebrow movements as a form of beat gesture improves the performance.", "pdf_url": "https://arxiv.org/pdf/2008.07643", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Lazy caterer jigsaw puzzles: Models, properties, and a mechanical system-based solver", "author": "Peleg Harel, Ohad Ben-Shahar", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Jigsaw puzzle solving, the problem of constructing a coherent whole from a set of non-overlapping unordered fragments, is fundamental to numerous applications, and yet most of the literature has focused thus far on less realistic puzzles whose pieces are identical squares. Here we formalize a new type of jigsaw puzzle where the pieces are general convex polygons generated by cutting through a global polygonal shape with an arbitrary number of straight cuts, a generation model inspired by the celebrated Lazy caterer's sequence. We analyze the theoretical properties of such puzzles, including the inherent challenges in solving them once pieces are contaminated with geometrical noise. To cope with such difficulties and obtain tractable solutions, we abstract the problem as a multi-body spring-mass dynamical system endowed with hierarchical loop constraints and a layered reconstruction process. We define evaluation metrics and present experimental results to indicate that such puzzles are solvable completely automatically.", "pdf_url": "https://arxiv.org/pdf/2008.07644", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Learning Two-Layer Residual Networks with Nonparametric Function Estimation by Convex Programming", "author": "Zhunxuan Wang, Linyun He, Chunchuan Lyu, Shay B. Cohen", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We focus on learning a two-layer residual neural network with preactivation by ReLU (preReLU-TLRN): Suppose the input $\\mathbf{x}$ is from a distribution with support space $\\mathbb{R}^d$ and the ground-truth generative model is a preReLU-TLRN, given by $$\\mathbf{y} = \\boldsymbol{B}^\\ast\\left[\\left(\\boldsymbol{A}^\\ast\\mathbf{x}\\right)^+ + \\mathbf{x}\\right]\\text{,}$$ where ground-truth network parameters $\\boldsymbol{A}^\\ast \\in \\mathbb{R}^{d\\times d}$ is a nonnegative full-rank matrix and $\\boldsymbol{B}^\\ast \\in \\mathbb{R}^{m\\times d}$ is full-rank with $m \\geq d$. We design layerwise objectives as functionals whose analytic minimizers sufficiently express the exact ground-truth network in terms of its parameters and nonlinearities. Following this objective landscape, learning a preReLU-TLRN from finite samples can be formulated as convex programming with nonparametric function estimation: For each layer, we first formulate the corresponding empirical risk minimization (ERM) as convex quadratic programming (QP), then we show the solution space of the QP can be equivalently determined by a set of linear inequalities, which can then be efficiently solved by linear programming (LP). Experiments show the robustness and sample efficiency of our methods.", "pdf_url": "https://arxiv.org/pdf/2008.07648", "subject": "Machine Learning (cs.LG)"},
{"title": "A Deep Dive into Adversarial Robustness in Zero-Shot Learning", "author": "Mehmet Kerim Yucel, Ramazan Gokberk Cinbis, Pinar Duygulu", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Machine learning (ML) systems have introduced significant advances in various fields, due to the introduction of highly complex models. Despite their success, it has been shown multiple times that machine learning models are prone to imperceptible perturbations that can severely degrade their accuracy. So far, existing studies have primarily focused on models where supervision across all classes were available. In constrast, Zero-shot Learning (ZSL) and Generalized Zero-shot Learning (GZSL) tasks inherently lack supervision across all classes. In this paper, we present a study aimed on evaluating the adversarial robustness of ZSL and GZSL models. We leverage the well-established label embedding model and subject it to a set of established adversarial attacks and defenses across multiple datasets. In addition to creating possibly the first benchmark on adversarial robustness of ZSL models, we also present analyses on important points that require attention for better interpretation of ZSL robustness results. We hope these points, along with the benchmark, will help researchers establish a better understanding what challenges lie ahead and help guide their work.", "pdf_url": "https://arxiv.org/pdf/2008.07651", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A modified Allen-Cahn model for pattern synthesis on surfaces", "author": "Lorina Dascal, Gautam Pai, Ron Kimmel", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We propose an extension of the Allen-Cahn model for pattern synthesis on two dimensional curved surfaces. This model is based on a single PDE and it offers improved ability of controlling the type of generated surface patterns via the chosen reaction-diffusion coefficient, thus, obtaining patterns in form of spots, inverted spots, or stripes. We investigate the dependence of the type of the obtained pattern on the new proposed reaction term. An efficient operator splitting scheme is used to discretize the model on a surface. Experiments on surfaces with varying initial conditions illustrate a variety of patterns.", "pdf_url": "https://arxiv.org/pdf/2008.07654", "subject": "Numerical Analysis (math.NA)"},
{"title": "Information-Theoretic Privacy in Federated Submodel learning", "author": "Minchul Kim, Jungwoo Lee", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We consider information-theoretic privacy in federated submodel learning, where a global server has multiple submodels. Compared to the privacy considered in the conventional federated submodel learning where secure aggregation is adopted for ensuring privacy, information-theoretic privacy provides the stronger protection on submodel selection by the local machine. We propose an achievable scheme that partially adopts the conventional private information retrieval (PIR) scheme that achieves the minimum amount of download. With respect to computation and communication overhead, we compare the achievable scheme with a naive approach for federated submodel learning with information-theoretic privacy.", "pdf_url": "https://arxiv.org/pdf/2008.07656", "subject": "Information Theory (cs.IT)"},
{"title": "Revisiting the Application of Feature Selection Methods to Speech Imagery BCI Datasets", "author": "Javad Rahimipour Anaraki, Jae Moon, Tom Chau", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Brain-computer interface (BCI) aims to establish and improve human and computer interactions. There has been an increasing interest in designing new hardware devices to facilitate the collection of brain signals through various technologies, such as wet and dry electroencephalogram (EEG) and functional near-infrared spectroscopy (fNIRS) devices. The promising results of machine learning methods have attracted researchers to apply these methods to their data. However, some methods can be overlooked simply due to their inferior performance against a particular dataset. This paper shows how relatively simple yet powerful feature selection/ranking methods can be applied to speech imagery datasets and generate significant results. To do so, we introduce two approaches, horizontal and vertical settings, to use any feature selection and ranking methods to speech imagery BCI datasets. Our primary goal is to improve the resulting classification accuracies from support vector machines, $k$-nearest neighbour, decision tree, linear discriminant analysis and long short-term memory recurrent neural network classifiers. Our experimental results show that using a small subset of channels, we can retain and, in most cases, improve the resulting classification accuracies regardless of the classifier.", "pdf_url": "https://arxiv.org/pdf/2008.07660", "subject": "Machine Learning (cs.LG)"},
{"title": "Privacy-preserving feature selection: A survey and proposing a new set of protocols", "author": "Javad Rahimipour Anaraki, Saeed Samet", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Feature selection is the process of sieving features, in which informative features are separated from the redundant and irrelevant ones. This process plays an important role in machine learning, data mining and bioinformatics. However, traditional feature selection methods are only capable of processing centralized datasets and are not able to satisfy today's distributed data processing needs. These needs require a new category of data processing algorithms called privacy-preserving feature selection, which protects users' data by not revealing any part of the data neither in the intermediate processing nor in the final results. This is vital for the datasets which contain individuals' data, such as medical datasets. Therefore, it is rational to either modify the existing algorithms or propose new ones to not only introduce the capability of being applied to distributed datasets, but also act responsibly in handling users' data by protecting their privacy. In this paper, we will review three privacy-preserving feature selection methods and provide suggestions to improve their performance when any gap is identified. We will also propose a privacy-preserving feature selection method based on the rough set feature selection. The proposed method is capable of processing both horizontally and vertically partitioned datasets in two- and multi-parties scenarios.", "pdf_url": "https://arxiv.org/pdf/2008.07664", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Inverse Distance Aggregation for Federated Learning with Non-IID Data", "author": "Yousef Yeganeh, Azade Farshad, Nassir Navab, Shadi Albarqouni", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Federated learning (FL) has been a promising approach in the field of medical imaging in recent years. A critical problem in FL, specifically in medical scenarios is to have a more accurate shared model which is robust to noisy and out-of distribution clients. In this work, we tackle the problem of statistical heterogeneity in data for FL which is highly plausible in medical data where for example the data comes from different sites with different scanner settings. We propose IDA (Inverse Distance Aggregation), a novel adaptive weighting approach for clients based on meta-information which handles unbalanced and non-iid data. We extensively analyze and evaluate our method against the well-known FL approach, Federated Averaging as a baseline.", "pdf_url": "https://arxiv.org/pdf/2008.07665", "subject": "Machine Learning (cs.LG)"},
{"title": "Runtime-Safety-Guided Policy Repair", "author": "Weichao Zhou, Ruihan Gao, BaekGyu Kim, Eunsuk Kang, Wenchao Li", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We study the problem of policy repair for learning-based control policies in safety-critical settings. We consider an architecture where a high-performance learning-based control policy (e.g. one trained as a neural network) is paired with a model-based safety controller. The safety controller is endowed with the abilities to predict whether the trained policy will lead the system to an unsafe state, and take over control when necessary. While this architecture can provide added safety assurances, intermittent and frequent switching between the trained policy and the safety controller can result in undesirable behaviors and reduced performance. We propose to reduce or even eliminate control switching by `repairing' the trained policy based on runtime data produced by the safety controller in a way that deviates minimally from the original policy. The key idea behind our approach is the formulation of a trajectory optimization problem that allows the joint reasoning of policy update and safety constraints. Experimental results demonstrate that our approach is effective even when the system model in the safety controller is unknown and only approximated.", "pdf_url": "https://arxiv.org/pdf/2008.07667", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "REFORM: Recognizing F-formations for Social Robots", "author": "Hooman Hedayati, Annika Muehlbradt, Daniel J. Szafir, Sean Andrist", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Recognizing and understanding conversational groups, or F-formations, is a critical task for situated agents designed to interact with humans. F-formations contain complex structures and dynamics, yet are used intuitively by people in everyday face-to-face conversations. Prior research exploring ways of identifying F-formations has largely relied on heuristic algorithms that may not capture the rich dynamic behaviors employed by humans. We introduce REFORM (REcognize F-FORmations with Machine learning), a data-driven approach for detecting F-formations given human and agent positions and orientations. REFORM decomposes the scene into all possible pairs and then reconstructs F-formations with a voting-based scheme. We evaluated our approach across three datasets: the SALSA dataset, a newly collected human-only dataset, and a new set of acted human-robot scenarios, and found that REFORM yielded improved accuracy over a state-of-the-art F-formation detection algorithm. We also introduce symmetry and tightness as quantitative measures to characterize F-formations. Supplementary video: , Dataset available at:", "pdf_url": "https://arxiv.org/pdf/2008.07668", "subject": "Robotics (cs.RO)"},
{"title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections", "author": "Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, Christopher Re", "pub_date": "Submitted on 17 Aug 2020", "abstract": "A central problem in learning from sequential data is representing cumulative history in an incremental fashion as more data is processed. We introduce a general framework (HiPPO) for the online compression of continuous signals and discrete time series by projection onto polynomial bases. Given a measure that specifies the importance of each time step in the past, HiPPO produces an optimal solution to a natural online function approximation problem. As special cases, our framework yields a short derivation of the recent Legendre Memory Unit (LMU) from first principles, and generalizes the ubiquitous gating mechanism of recurrent neural networks such as GRUs. This formal framework yields a new memory update mechanism (HiPPO-LegS) that scales through time to remember all history, avoiding priors on the timescale. HiPPO-LegS enjoys the theoretical benefits of timescale robustness, fast updates, and bounded gradients. By incorporating the memory dynamics into recurrent neural networks, HiPPO RNNs can empirically capture complex temporal dependencies. On the benchmark permuted MNIST dataset, HiPPO-LegS sets a new state-of-the-art accuracy of 98.3%. Finally, on a novel trajectory classification task testing robustness to out-of-distribution timescales and missing data, HiPPO-LegS outperforms RNN and neural ODE baselines by 25-40% accuracy.", "pdf_url": "https://arxiv.org/pdf/2008.07669", "subject": "Machine Learning (cs.LG)"},
{"title": "Ensemble Node Embeddings using Tensor Decomposition: A Case-Study on DeepWalk", "author": "Jia Chen, Evangelos E. Papalexakis", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Node embeddings have been attracting increasing attention during the past years. In this context, we propose a new ensemble node embedding approach, called TenSemble2Vec, by first generating multiple embeddings using the existing techniques and taking them as multiview data input of the state-of-art tensor decomposition model namely PARAFAC2 to learn the shared lower-dimensional representations of the nodes. Contrary to other embedding methods, our TenSemble2Vec takes advantage of the complementary information from different methods or the same method with different hyper-parameters, which bypasses the challenge of choosing models. Extensive tests using real-world data validates the efficiency of the proposed method.", "pdf_url": "https://arxiv.org/pdf/2008.07672", "subject": "Machine Learning (cs.LG)"},
{"title": "An Annotated Corpus of Webtables for Information Extraction Tasks", "author": "Erin Macdonald, Denilson Barbosa", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Information Extraction is a well-researched area of Natural Language Processing with applications in web search and question answering concerned with identifying entities and relationships between them as expressed in a given context, usually a sentence of a paragraph of running text. Given the importance of the task, several datasets and benchmarks have been curated over the years. However, focusing on running text alone leaves out tables which are common in many structured documents and in which pairs of entities also co-occur in context (e.g., the same row of the table). While there are recent papers on relation extraction from tables in the literature, their experimental evaluations have been on ad-hoc datasets for the lack of a standard benchmark. This paper helps close that gap. We introduce an annotation framework and a dataset of 217,834 tables from Wikipedia which are annotated with 28 relations, using both classifiers and carefully designed queries over a reference knowledge graph. Binary classifiers are then applied to the resulting dataset to remove false positives, resulting in an average annotation accuracy of 94%. The resulting dataset is the first of its kind to be made publicly available.", "pdf_url": "https://arxiv.org/pdf/2008.07680", "subject": "Information Retrieval (cs.IR)"},
{"title": "Are Neural Open-Domain Dialog Systems Robust to Speech Recognition Errors in the Dialog History? An Empirical Study", "author": "Karthik Gopalakrishnan, Behnam Hedayatnia, Longshaokan Wang, Yang Liu, Dilek Hakkani-Tur", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Large end-to-end neural open-domain chatbots are becoming increasingly popular. However, research on building such chatbots has typically assumed that the user input is written in nature and it is not clear whether these chatbots would seamlessly integrate with automatic speech recognition (ASR) models to serve the speech modality. We aim to bring attention to this important question by empirically studying the effects of various types of synthetic and actual ASR hypotheses in the dialog history on TransferTransfo, a state-of-the-art Generative Pre-trained Transformer (GPT) based neural open-domain dialog system from the NeurIPS ConvAI2 challenge. We observe that TransferTransfo trained on written data is very sensitive to such hypotheses introduced to the dialog history during inference time. As a baseline mitigation strategy, we introduce synthetic ASR hypotheses to the dialog history during training and observe marginal improvements, demonstrating the need for further research into techniques to make end-to-end open-domain chatbots fully speech-robust. To the best of our knowledge, this is the first study to evaluate the effects of synthetic and actual ASR hypotheses on a state-of-the-art neural open-domain dialog system and we hope it promotes speech-robustness as an evaluation criterion in open-domain dialog.", "pdf_url": "https://arxiv.org/pdf/2008.07683", "subject": "Computation and Language (cs.CL)"},
{"title": "Ranking Clarification Questions via Natural Language Inference", "author": "Vaibhav Kumar, Vikas Raunak, Jamie Callan", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Given a natural language query, teaching machines to ask clarifying questions is of immense utility in practical natural language processing systems. Such interactions could help in filling information gaps for better machine comprehension of the query. For the task of ranking clarification questions, we hypothesize that determining whether a clarification question pertains to a missing entry in a given post (on QA forums such as StackExchange) could be considered as a special case of Natural Language Inference (NLI), where both the post and the most relevant clarification question point to a shared latent piece of information or context. We validate this hypothesis by incorporating representations from a Siamese BERT model fine-tuned on NLI and Multi-NLI datasets into our models and demonstrate that our best performing model obtains a relative performance improvement of 40 percent and 60 percent respectively (on the key metric of Precision@1), over the state-of-the-art baseline(s) on the two evaluation sets of the StackExchange dataset, thereby, significantly surpassing the state-of-the-art.", "pdf_url": "https://arxiv.org/pdf/2008.07688", "subject": "Machine Learning (cs.LG)"},
{"title": "Soft Multicopter Control using Neural Dynamics Identification", "author": "Yitong Deng, Yaorui Zhang, Xingzhe He, Shuqi Yang, Yunjin Tong, Michael Zhang, Daniel DiPietro, Bo Zhu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Dynamic control of a soft-body robot to deliver complex behaviors with low-dimensional actuation inputs is challenging. In this paper, we present a computational approach to automatically generate versatile, underactuated control policies that drives soft-bodied machines with complicated structures and nonlinear dynamics. Our target application is focused on the autonomous control of a soft multicopter, featured by its elastic material components, non-conventional shapes, and asymmetric rotor layouts, to precisely deliver compliant deformation and agile locomotion. The central piece of our approach lies in a lightweight neural surrogate model to identify and predict the temporal evolution of a set of geometric variables characterizing an elastic soft body. This physics-based learning model is further integrated into a Linear Quadratic Regulator (LQR) control loop enhanced by a novel online fixed-point relinearization scheme to accommodate the dynamic body balance, allowing an aggressive reduction of the computational overhead caused by the conventional full-scale sensing-simulation-control workflow. We demonstrate the efficacy of our approach by generating controllers for a broad spectrum of customized soft multicopter designs and testing them in a high-fidelity physics simulation environment. The control algorithm enables the multicopters to perform a variety of tasks, including hovering, trajectory tracking, cruising and active deforming.", "pdf_url": "https://arxiv.org/pdf/2008.07689", "subject": "Robotics (cs.RO)"},
{"title": "An a posteriori error estimate of the outer normal derivative using dual weights", "author": "Silvia Bertoluzza, Erik Burman, Cuiyu He", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We derive a residual based a-posteriori error estimate for the outer normal derivative of approximations to Poisson's problem. By analyzing the solution of the adjoint problem, we show that error indicators in the bulk may be defined to be of higher order than those close to the boundary, which lead to more economic meshes. The theory is illustrated with some numerical examples.", "pdf_url": "https://arxiv.org/pdf/2008.07690", "subject": "Numerical Analysis (math.NA)"},
{"title": "A Nonnested Augmented Subspace Method for Eigenvalue Problems with Curved Interfaces", "author": "Haikun Dang, Hehu Xie, Gang Zhao, Chenguang Zhou", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this paper, we present a nonnested augmented subspace algorithm and its multilevel correction method for solving eigenvalue problems with curved interfaces. The augmented subspace algorithm and the corresponding multilevel correction method are designed based on a coarse finite element space which is not the subset of the finer finite element space. The nonnested augmented subspace method can transform the eigenvalue problem solving on the finest mesh to the solving linear equation on the same mesh and small scale eigenvalue problem on the low dimensional augmented subspace. The corresponding theoretical analysis and numerical experiments are provided to demonstrate the efficiency of the proposed algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.07691", "subject": "Numerical Analysis (math.NA)"},
{"title": "On the Error Exponent of Approximate Sufficient Statistics for M-ary Hypothesis Testing", "author": "Jiachun Pan, Yonglong Li, Vincent Y. F. Tan, Yonina C. Eldar", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Consider the problem of detecting one of M i.i.d. Gaussian signals corrupted in white Gaussian noise. Conventionally, matched filters are used for detection. We first show that the outputs of the matched filter form a set of asymptotically optimal sufficient statistics in the sense of maximizing the error exponent of detecting the true signal. In practice, however, M may be large which motivates the design and analysis of a reduced set of N statistics which we term approximate sufficient statistics. Our construction of these statistics is based on a small set of filters that project the outputs of the matched filters onto a lower-dimensional vector using a sensing matrix. We consider a sequence of sensing matrices that has the desiderata of row orthonormality and low coherence. We analyze the performance of the resulting maximum likelihood (ML) detector, which leads to an achievable bound on the error exponent based on the approximate sufficient statistics; this bound recovers the original error exponent when N = M. We compare this to a bound that we obtain by analyzing a modified form of the Reduced Dimensionality Detector (RDD) proposed by Xie, Eldar, and Goldsmith [IEEE Trans. on Inform. Th., 59(6):3858-3874, 2013]. We show that by setting the sensing matrices to be column-normalized group Hadamard matrices, the exponents derived are ensemble-tight, i.e., our analysis is tight on the exponential scale given the sensing matrices and the decoding rule. Finally, we derive some properties of the exponents, showing, in particular, that they increase linearly in the compression ratio N/M.", "pdf_url": "https://arxiv.org/pdf/2008.07693", "subject": "Information Theory (cs.IT)"},
{"title": "Learning Complex Multi-Agent Policies in Presence of an Adversary", "author": "Siddharth Ghiya, Katia Sycara", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In recent years, there has been some outstanding work on applying deep reinforcement learning to multi-agent settings. Often in such multi-agent scenarios, adversaries can be present. We address the requirements of such a setting by implementing a graph-based multi-agent deep reinforcement learning algorithm. In this work, we consider the scenario of multi-agent deception in which multiple agents need to learn to cooperate and communicate in order to deceive an adversary. We have employed a two-stage learning process to get the cooperating agents to learn such deceptive behaviors. Our experiments show that our approach allows us to employ curriculum learning to increase the number of cooperating agents in the environment and enables a team of agents to learn complex behaviors to successfully deceive an adversary. Keywords: Multi-agent system, Graph neural network, Reinforcement learning", "pdf_url": "https://arxiv.org/pdf/2008.07698", "subject": "Multiagent Systems (cs.MA)"},
{"title": "Evaluating BBRv2 on the Dropbox Edge Network", "author": "Alexey Ivanov", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Nowadays, loss-based TCP congestion controls in general and CUBIC specifically became the de facto standard for the Internet. BBR congestion control challenges the loss-based approach by modeling the network based on estimated bandwidth and round-trip time. At Dropbox, we've been using BBRv1 since 2017 and are accustomed to its pros and cons. BBRv2 introduces a set of improvements to network modeling (explicit loss targets and inflight limits) and fairness (differential probing and headroom for new flows.) In this paper, we go over experimental data gathered on the Dropbox Edge Network. We compare BBRv2 to BBRv1 and CUBIC showing that BBRv2 is a definite improvement over both of them. We also show that BBRv2 experimental results match its theoretical design principles.", "pdf_url": "https://arxiv.org/pdf/2008.07699", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "VizCommender: Computing Text-Based Similarity in Visualization Repositories for Content-Based Recommendations", "author": "Michael Oppermann, Robert Kincaid, Tamara Munzner", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Cloud-based visualization services have made visual analytics accessible to a much wider audience than ever before. Systems such as Tableau have started to amass increasingly large repositories of analytical knowledge in the form of interactive visualization workbooks. When shared, these collections can form a visual analytic knowledge base. However, as the size of a collection increases, so does the difficulty in finding relevant information. Content-based recommendation (CBR) systems could help analysts in finding and managing workbooks relevant to their interests. Toward this goal, we focus on text-based content that is representative of the subject matter of visualizations rather than the visual encodings and style. We discuss the challenges associated with creating a CBR based on visualization specifications and explore more concretely how to implement the relevance measures required using Tableau workbook specifications as the source of content data. We also demonstrate what information can be extracted from these visualization specifications and how various natural language processing techniques can be used to compute similarity between workbooks as one way to measure relevance. We report on a crowd-sourced user study to determine if our similarity measure mimics human judgement. Finally, we choose latent Dirichlet allocation (LDA) as a specific model and instantiate it in a proof-of-concept recommender tool to demonstrate the basic function of our similarity measure.", "pdf_url": "https://arxiv.org/pdf/2008.07702", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "PopMAG: Pop Music Accompaniment Generation", "author": "Yi Ren, Jinzheng He, Xu Tan, Tao Qin, Zhou Zhao, Tie-Yan Liu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In pop music, accompaniments are usually played by multiple instruments (tracks) such as drum, bass, string and guitar, and can make a song more expressive and contagious by arranging together with its melody. Previous works usually generate multiple tracks separately and the music notes from different tracks not explicitly depend on each other, which hurts the harmony modeling. To improve harmony, in this paper, we propose a novel MUlti-track MIDI representation (MuMIDI), which enables simultaneous multi-track generation in a single sequence and explicitly models the dependency of the notes from different tracks. While this greatly improves harmony, unfortunately, it enlarges the sequence length and brings the new challenge of long-term music modeling. We further introduce two new techniques to address this challenge: 1) We model multiple note attributes (e.g., pitch, duration, velocity) of a musical note in one step instead of multiple steps, which can shorten the length of a MuMIDI sequence. 2) We introduce extra long-context as memory to capture long-term dependency in music. We call our system for pop music accompaniment generation as PopMAG. We evaluate PopMAG on multiple datasets (LMD, FreeMidi and CPMD, a private dataset of Chinese pop songs) with both subjective and objective metrics. The results demonstrate the effectiveness of PopMAG for multi-track harmony modeling and long-term context modeling. Specifically, PopMAG wins 42\\%/38\\%/40\\% votes when comparing with ground truth musical pieces on LMD, FreeMidi and CPMD datasets respectively and largely outperforms other state-of-the-art music accompaniment generation models and multi-track MIDI representations in terms of subjective and objective metrics.", "pdf_url": "https://arxiv.org/pdf/2008.07703", "subject": "Sound (cs.SD)"},
{"title": "RTFN: Robust Temporal Feature Network", "author": "Zhiwen Xiao, Xin Xu, Huanlai Xing, Juan Chen", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Time series analysis plays a vital role in various applications, for instance, healthcare, weather prediction, disaster forecast, etc. However, to obtain sufficient shapelets by a feature network is still challenging. To this end, we propose a novel robust temporal feature network (RTFN) that contains temporal feature networks and attentional LSTM networks. The temporal feature networks are built to extract basic features from input data while the attentional LSTM networks are devised to capture complicated shapelets and relationships to enrich features. In experiments, we embed RTFN into supervised structure as a feature extraction network and into unsupervised clustering as an encoder, respectively. The results show that the RTFN-based supervised structure is a winner of 40 out of 85 datasets and the RTFN-based unsupervised clustering performs the best on 4 out of 11 datasets in the UCR2018 archive.", "pdf_url": "https://arxiv.org/pdf/2008.07707", "subject": "Machine Learning (cs.LG)"},
{"title": "Selecting Data Adaptive Learner from Multiple Deep Learners using Bayesian Networks", "author": "Shusuke Kobayashi, Susumu Shirayama", "pub_date": "Submitted on 18 Aug 2020", "abstract": "A method to predict time-series using multiple deep learners and a Bayesian network is proposed. In this study, the input explanatory variables are Bayesian network nodes that are associated with learners. Training data are divided using K-means clustering, and multiple deep learners are trained depending on the cluster. A Bayesian network is used to determine which deep learner is in charge of predicting a time-series. We determine a threshold value and select learners with a posterior probability equal to or greater than the threshold value, which could facilitate more robust prediction. The proposed method is applied to financial time-series data, and the predicted results for the Nikkei 225 index are demonstrated.", "pdf_url": "https://arxiv.org/pdf/2008.07709", "subject": "Machine Learning (cs.LG)"},
{"title": "One-pixel Signature: Characterizing CNN Models for Backdoor Detection", "author": "Shanjiaoyang Huang, Weiqi Peng, Zhiwei Jia, Zhuowen Tu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We tackle the convolution neural networks (CNNs) backdoor detection problem by proposing a new representation called one-pixel signature. Our task is to detect/classify if a CNN model has been maliciously inserted with an unknown Trojan trigger or not. Here, each CNN model is associated with a signature that is created by generating, pixel-by-pixel, an adversarial value that is the result of the largest change to the class prediction. The one-pixel signature is agnostic to the design choice of CNN architectures, and how they were trained. It can be computed efficiently for a black-box CNN model without accessing the network parameters. Our proposed one-pixel signature demonstrates a substantial improvement (by around 30% in the absolute detection accuracy) over the existing competing methods for backdoored CNN detection/classification. One-pixel signature is a general representation that can be used to characterize CNN models beyond backdoor detection.", "pdf_url": "https://arxiv.org/pdf/2008.07711", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Contact Area Detector using Cross View Projection Consistency for COVID-19 Projects", "author": "Pan Zhang, Wilfredo Torres Calderon, Bokyung Lee, Alex Tessier, Jacky Bibliowicz, Liviu Calin, Michael Lee", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The ability to determine what parts of objects and surfaces people touch as they go about their daily lives would be useful in understanding how the COVID-19 virus spreads. To determine whether a person has touched an object or surface using visual data, images, or videos, is a hard problem. Computer vision 3D reconstruction approaches project objects and the human body from the 2D image domain to 3D and perform 3D space intersection directly. However, this solution would not meet the accuracy requirement in applications due to projection error. Another standard approach is to train a neural network to infer touch actions from the collected visual data. This strategy would require significant amounts of training data to generalize over scale and viewpoint variations. A different approach to this problem is to identify whether a person has touched a defined object. In this work, we show that the solution to this problem can be straightforward. Specifically, we show that the contact between an object and a static surface can be identified by projecting the object onto the static surface through two different viewpoints and analyzing their 2D intersection. The object contacts the surface when the projected points are close to each other; we call this cross view projection consistency. Instead of doing 3D scene reconstruction or transfer learning from deep networks, a mapping from the surface in the two camera views to the surface space is the only requirement. For planar space, this mapping is the Homography transformation. This simple method can be easily adapted to real-life applications. In this paper, we apply our method to do office occupancy detection for studying the COVID-19 transmission pattern from an office desk in a meeting room using the contact information.", "pdf_url": "https://arxiv.org/pdf/2008.07712", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Multiple View Generation and Classification of Mid-wave Infrared Images using Deep Learning", "author": "Maliha Arif, Abhijit Mahalanobis", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We propose a novel study of generating unseen arbitrary viewpoints for infrared imagery in the non-linear feature subspace . Current methods use synthetic images and often result in blurry and distorted outputs. Our approach on the contrary understands the semantic information in natural images and encapsulates it such that our predicted unseen views possess good 3D representations. We further explore the non-linear feature subspace and conclude that our network does not operate in the Euclidean subspace but rather in the Riemannian subspace. It does not learn the geometric transformation for predicting the position of the pixel in the new image but rather learns the manifold. To this end, we use t-SNE visualisations to conduct a detailed analysis of our network and perform classification of generated images as a low-shot learning task.", "pdf_url": "https://arxiv.org/pdf/2008.07714", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Age of Information in Random Access Networks: A Spatiotemporal Study", "author": "Howard H. Yang, Ahmed Arafa, Tony Q. S. Quek, H. Vincent Poor", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We investigate the age-of-information (AoI) in the context of random access networks, in which transmitters need to send a sequence of information packets to the intended receivers over a shared spectrum. We establish an analytical framework that accounts for the key features of a wireless system, including the fading, path loss, network topology, as well as the spatial interactions amongst the queues. A closed-form expression is derived to quantify the network average AoI and the accuracy is verified via simulations. Our analysis unveils several unconventional behaviors of AoI in such a setting. For instance, even when the packet transmissions are scheduled in a last-come first-serve (LCFS) order whereas the newly incoming packets can replace the undelivered ones, the network average AoI may not monotonically decline with respect to the packet arrival rates, if the infrastructure is densely deployed. Moreover, the ALOHA protocol is shown to be instrumental to reducing the AoI when the packet arrival rates are high, yet it cannot contribute to decreasing the AoI in the regime of infrequent packet arrivals.", "pdf_url": "https://arxiv.org/pdf/2008.07717", "subject": "Information Theory (cs.IT)"},
{"title": "Ordinal Pattern Kernel for Brain Connectivity Network Classification", "author": "Kai Ma, Biao Jie, Wei Shao, Daoqiang Zhang", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Brain connectivity networks, which characterize the functional or structural interaction of brain regions, has been widely used for brain disease classification. Kernel-based method, such as graph kernel (i.e., kernel defined on graphs), has been proposed for measuring the similarity of brain networks, and yields the promising classification performance. However, most of graph kernels are built on unweighted graph (i.e., network) with edge present or not, and neglecting the valuable weight information of edges in brain connectivity network, with edge weights conveying the strengths of temporal correlation or fiber connection between brain regions. Accordingly, in this paper, we present an ordinal pattern kernel for brain connectivity network classification. Different with existing graph kernels that measures the topological similarity of unweighted graphs, the proposed ordinal pattern kernels calculate the similarity of weighted networks by comparing ordinal patterns from weighted networks. To evaluate the effectiveness of the proposed ordinal kernel, we further develop a depth-first-based ordinal pattern kernel, and perform extensive experiments in a real dataset of brain disease from ADNI database. The results demonstrate that our proposed ordinal pattern kernel can achieve better classification performance compared with state-of-the-art graph kernels.", "pdf_url": "https://arxiv.org/pdf/2008.07719", "subject": "Machine Learning (cs.LG)"},
{"title": "Word2vec Skip-gram Dimensionality Selection via Sequential Normalized Maximum Likelihood", "author": "Pham Thuc Hung, Kenji Yamanishi", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this paper, we propose a novel information criteria-based approach to select the dimensionality of the word2vec Skip-gram (SG). From the perspective of the probability theory, SG is considered as an implicit probability distribution estimation under the assumption that there exists a true contextual distribution among words. Therefore, we apply information criteria with the aim of selecting the best dimensionality so that the corresponding model can be as close as possible to the true distribution. We examine the following information criteria for the dimensionality selection problem: the Akaike Information Criterion, Bayesian Information Criterion, and Sequential Normalized Maximum Likelihood (SNML) criterion. SNML is the total codelength required for the sequential encoding of a data sequence on the basis of the minimum description length. The proposed approach is applied to both the original SG model and the SG Negative Sampling model to clarify the idea of using information criteria. Additionally, as the original SNML suffers from computational disadvantages, we introduce novel heuristics for its efficient computation. Moreover, we empirically demonstrate that SNML outperforms both BIC and AIC. In comparison with other evaluation methods for word embedding, the dimensionality selected by SNML is significantly closer to the optimal dimensionality obtained by word analogy or word similarity tasks.", "pdf_url": "https://arxiv.org/pdf/2008.07720", "subject": "Machine Learning (cs.LG)"},
{"title": "Design of a Stochastic Traffic Regulator for End-to-End Network Delay Guarantees", "author": "Massieh Kordi Boroujeny, Brian L. Mark", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Providing end-to-end network delay guarantees in packet-switched networks such as the Internet is highly desirable for mission-critical and delay-sensitive data transmission, yet it remains a challenging open problem. Due to the looseness of the deterministic bounds, various frameworks for stochastic network calculus have been proposed to provide tighter, probabilistic bounds on network delay, at least in theory. However, little attention has been devoted to the problem of regulating traffic according to stochastic burstiness bounds, which is necessary in order to guarantee the delay bounds in practice. We design and analyze a stochastic traffic regulator that can be used in conjunction with results from stochastic network calculus to provide probabilistic guarantees on end-to-end network delay. Numerical results are provided to demonstrate the performance of the proposed traffic regulator.", "pdf_url": "https://arxiv.org/pdf/2008.07721", "subject": "Information Theory (cs.IT)"},
{"title": "NASE: Learning Knowledge Graph Embedding for Link Prediction via Neural Architecture Search", "author": "Xiaoyu Kou, Bingfeng Luo, Huang Hu, Yan Zhang", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Link prediction is the task of predicting missing connections between entities in the knowledge graph (KG). While various forms of models are proposed for the link prediction task, most of them are designed based on a few known relation patterns in several well-known datasets. Due to the diversity and complexity nature of the real-world KGs, it is inherently difficult to design a model that fits all datasets well. To address this issue, previous work has tried to use Automated Machine Learning (AutoML) to search for the best model for a given dataset. However, their search space is limited only to bilinear model families. In this paper, we propose a novel Neural Architecture Search (NAS) framework for the link prediction task. First, the embeddings of the input triplet are refined by the Representation Search Module. Then, the prediction score is searched within the Score Function Search Module. This framework entails a more general search space, which enables us to take advantage of several mainstream model families, and thus it can potentially achieve better performance. We relax the search space to be continuous so that the architecture can be optimized efficiently using gradient-based search strategies. Experimental results on several benchmark datasets demonstrate the effectiveness of our method compared with several state-of-the-art approaches.", "pdf_url": "https://arxiv.org/pdf/2008.07723", "subject": "Computation and Language (cs.CL)"},
{"title": "Domain Generalizer: A Few-shot Meta Learning Framework for Domain Generalization in Medical Imaging", "author": "Pulkit Khandelwal, Paul Yushkevich", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Deep learning models perform best when tested on target (test) data domains whose distribution is similar to the set of source (train) domains. However, model generalization can be hindered when there is significant difference in the underlying statistics between the target and source domains. In this work, we adapt a domain generalization method based on a model-agnostic meta-learning framework to biomedical imaging. The method learns a domain-agnostic feature representation to improve generalization of models to the unseen test distribution. The method can be used for any imaging task, as it does not depend on the underlying model architecture. We validate the approach through a computed tomography (CT) vertebrae segmentation task across healthy and pathological cases on three datasets. Next, we employ few-shot learning, i.e. training the generalized model using very few examples from the unseen domain, to quickly adapt the model to new unseen data distribution. Our results suggest that the method could help generalize models across different medical centers, image acquisition protocols, anatomies, different regions in a given scan, healthy and diseased populations across varied imaging modalities.", "pdf_url": "https://arxiv.org/pdf/2008.07724", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "SoDA: Multi-Object Tracking with Soft Data Association", "author": "Wei-Chih Hung, Henrik Kretzschmar, Tsung-Yi Lin, Yuning Chai, Ruichi Yu, Ming-Hsuan Yang, Dragomir Anguelov", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Robust multi-object tracking (MOT) is a prerequisite fora safe deployment of self-driving cars. Tracking objects, however, remains a highly challenging problem, especially in cluttered autonomous driving scenes in which objects tend to interact with each other in complex ways and frequently get occluded. We propose a novel approach to MOT that uses attention to compute track embeddings that encode the spatiotemporal dependencies between observed objects. This attention measurement encoding allows our model to relax hard data associations, which may lead to unrecoverable errors. Instead, our model aggregates information from all object detections via soft data associations. The resulting latent space representation allows our model to learn to reason about occlusions in a holistic data-driven way and maintain track estimates for objects even when they are occluded. Our experimental results on the Waymo OpenDataset suggest that our approach leverages modern large-scale datasets and performs favorably compared to the state of the art in visual multi-object tracking.", "pdf_url": "https://arxiv.org/pdf/2008.07725", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Equivalent Classification Mapping for Weakly Supervised Temporal Action Localization", "author": "Le Yang, Dingwen Zhang, Tao Zhao, Junwei Han", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Weakly supervised temporal action localization is a newly emerging yet widely studied topic in recent years. The existing methods can be categorized into two localization-by-classification pipelines, i.e., the pre-classification pipeline and the post-classification pipeline. The pre-classification pipeline first performs classification on each video snippet and then aggregate the snippet-level classification scores to obtain the video-level classification score, while the post-classification pipeline aggregates the snippet-level features first and then predicts the video-level classification score based on the aggregated feature. Although the classifiers in these two pipelines are used in different ways, the role they play is exactly the same---to classify the given features to identify the corresponding action categories. To this end, an ideal classifier can make both pipelines work. This inspires us to simultaneously learn these two pipelines in a unified framework to obtain an effective classifier. Specifically, in the proposed learning framework, we implement two parallel network streams to model the two localization-by-classification pipelines simultaneously and make the two network streams share the same classifier, thus achieving the novel Equivalent Classification Mapping (ECM) mechanism. Considering that an ideal classifier would make the classification results of the two network streams be identical and make the frame-level classification scores obtained from the pre-classification pipeline and the feature aggregation weights in the post-classification pipeline be consistent, we further introduce an equivalent classification loss and an equivalent weight transition module to endow the proposed learning framework with such properties. Comprehensive experiments are carried on three benchmarks and the proposed ECM achieves superior performance over other state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2008.07728", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Systematic Mapping Study on Microservices Architecture in DevOps", "author": "Muhammad Waseem, Peng Liang, Mojtaba Shahin", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Context: Applying Microservices Architecture (MSA) in DevOps has received significant attention in recent years. However, there exists no comprehensive review of the state of research on this topic. Objective: This work aims to systematically identify, analyze, and classify the literature on MSA in DevOps. Method: A Systematic Mapping Study (SMS) has been conducted on the literature published between January 2009 and July 2018. Results: Forty-seven studies were finally selected and the key results are: (1) Three themes on the research on MSA in DevOps are \"microservices development and operations in DevOps\", \"approaches and tool support for MSA based systems in DevOps\", and \"MSA migration experiences in DevOps\". (2) 24 problems with their solutions regarding implementing MSA in DevOps are identified. (3) MSA is mainly described by using boxes and lines. (4) Most of the quality attributes are positively affected when employing MSA in DevOps. (5) 50 tools that support building MSA based systems in DevOps are collected. (6) The combination of MSA and DevOps has been applied in a wide range of application domains. Conclusions: The results and findings will benefit researchers and practitioners to conduct further research and bring more dedicated solutions for the issues of MSA in DevOps.", "pdf_url": "https://arxiv.org/pdf/2008.07729", "subject": "Software Engineering (cs.SE)"},
{"title": "Trust and Medical AI: The challenges we face and the expertise needed to overcome them", "author": "Thomas P. Quinn, Manisha Senadeera, Stephan Jacobs, Simon Coghlan, Vuong Le", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Artificial intelligence (AI) is increasingly of tremendous interest in the medical field. However, failures of medical AI could have serious consequences for both clinical outcomes and the patient experience. These consequences could erode public trust in AI, which could in turn undermine trust in our healthcare institutions. This article makes two contributions. First, it describes the major conceptual, technical, and humanistic challenges in medical AI. Second, it proposes a solution that hinges on the education and accreditation of new expert groups who specialize in the development, verification, and operation of medical AI technologies. These groups will be required to maintain trust in our healthcare institutions.", "pdf_url": "https://arxiv.org/pdf/2008.07734", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Decoupled Modified Characteristic Finite Element Method with Different Subdomain Time Steps for Nonstationary Dual-Porosity-Navier-Stokes Model", "author": "Luling Cao, Yinnian He, Jian Li", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this paper, we develop the numerical theory of decoupled modified characteristic finite element method with different subdomain time steps for the mixed stabilized formulation of nonstationary dual-porosity-Navier-Stokes model. Based on partitioned time-stepping methods, the system is decoupled, which means that the Navier-Stokes equations and two different Darcy equations are solved independently at each time step of subdomain. In particular, the Navier-Stokes equations are solved by the modified characteristic finite element method, which overcome the computational difficulties caused by the nonlinear term. In order to increase the efficiency, different time steps are used to different subdomains. The stability of this method is proved. In addition, we verify the optimal $L^2$-norm error convergence order of the solutions by mathematical induction, whose proof implies the uniform $L^{\\infty}$-boundedness of the fully discrete velocity solution. Finally, some numerical tests are presented to show efficiency of the proposed method.", "pdf_url": "https://arxiv.org/pdf/2008.07736", "subject": "Numerical Analysis (math.NA)"},
{"title": "Provably Efficient Reward-Agnostic Navigation with Linear Value Iteration", "author": "Andrea Zanette, Alessandro Lazaric, Mykel J. Kochenderfer, Emma Brunskill", "pub_date": "Submitted on 18 Aug 2020", "abstract": "There has been growing progress on theoretical analyses for provably efficient learning in MDPs with linear function approximation, but much of the existing work has made strong assumptions to enable exploration by conventional exploration frameworks. Typically these assumptions are stronger than what is needed to find good solutions in the batch setting. In this work, we show how under a more standard notion of low inherent Bellman error, typically employed in least-square value iteration-style algorithms, we can provide strong PAC guarantees on learning a near optimal value function provided that the linear space is sufficiently ``explorable''. We present a computationally tractable algorithm for the reward-free setting and show how it can be used to learn a near optimal policy for any (linear) reward function, which is revealed only once learning has completed. If this reward function is also estimated from the samples gathered during pure exploration, our results also provide same-order PAC guarantees on the performance of the resulting policy for this setting.", "pdf_url": "https://arxiv.org/pdf/2008.07737", "subject": "Machine Learning (cs.LG)"},
{"title": "Usable Security for ML Systems in Mental Health: A Framework", "author": "Helen Jiang, Erwen Senge", "pub_date": "Submitted on 18 Aug 2020", "abstract": "While the applications and demands of Machine learning (ML) systems in mental health are growing, there is little discussion nor consensus regarding a uniquely challenging aspect: building security methods and requirements into these ML systems, and keep the ML system usable for end-users. This question of usable security is very important, because the lack of consideration in either security or usability would hinder large-scale user adoption and active usage of ML systems in mental health applications. In this short paper, we introduce a framework of four pillars, and a set of desired properties which can be used to systematically guide and evaluate security-related designs, implementations, and deployments of ML systems for mental health. We aim to weave together threads from different domains, incorporate existing views, and propose new principles and requirements, in an effort to lay out a clear framework where criteria and expectations are established, and are used to make security mechanisms usable for end-users of those ML systems in mental health. Together with this framework, we present several concrete scenarios where different usable security cases and profiles in ML-systems in mental health applications are examined and evaluated.", "pdf_url": "https://arxiv.org/pdf/2008.07738", "subject": "Computers and Society (cs.CY)"},
{"title": "Positive semidefinite support vector regression metric learning", "author": "Lifeng Gu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Most existing metric learning methods focus on learning a similarity or distance measure relying on similar and dissimilar relations between sample pairs. However, pairs of samples cannot be simply identified as similar or dissimilar in many real-world applications, e.g., multi-label learning, label distribution learning. To this end, relation alignment metric learning (RAML) framework is proposed to handle the metric learning problem in those scenarios. But RAML framework uses SVR solvers for optimization. It can't learn positive semidefinite distance metric which is necessary in metric learning. In this paper, we propose two methds to overcame the weakness. Further, We carry out several experiments on the single-label classification, multi-label classification, label distribution learning to demonstrate the new methods achieves favorable performance against RAML framework.", "pdf_url": "https://arxiv.org/pdf/2008.07739", "subject": "Machine Learning (cs.LG)"},
{"title": "Robust Low-rank Matrix Completion via an Alternating Manifold Proximal Gradient Continuation Method", "author": "Minhui Huang, Shiqian Ma, Lifeng Lai", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Robust low-rank matrix completion (RMC), or robust principal component analysis with partially observed data, has been studied extensively for computer vision, signal processing and machine learning applications. This problem aims to decompose a partially observed matrix into the superposition of a low-rank matrix and a sparse matrix, where the sparse matrix captures the grossly corrupted entries of the matrix. A widely used approach to tackle RMC is to consider a convex formulation, which minimizes the nuclear norm of the low-rank matrix (to promote low-rankness) and the l1 norm of the sparse matrix (to promote sparsity). In this paper, motivated by some recent works on low-rank matrix completion and Riemannian optimization, we formulate this problem as a nonsmooth Riemannian optimization problem over Grassmann manifold. This new formulation is scalable because the low-rank matrix is factorized to the multiplication of two much smaller matrices. We then propose an alternating manifold proximal gradient continuation (AManPGC) method to solve the proposed new formulation. The convergence rate of the proposed algorithm is rigorously analyzed. Numerical results on both synthetic data and real data on background extraction from surveillance videos are reported to demonstrate the advantages of the proposed new formulation and algorithm over several popular existing approaches.", "pdf_url": "https://arxiv.org/pdf/2008.07740", "subject": "Machine Learning (cs.LG)"},
{"title": "Turing Test and the Practice of Law: The Role of Autonomous Levels of AI Legal Reasoning", "author": "Lance Eliot", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Artificial Intelligence (AI) is increasingly being applied to law and a myriad of legal tasks amid attempts to bolster AI Legal Reasoning (AILR) autonomous capabilities. A major question that has generally been unaddressed involves how we will know when AILR has achieved autonomous capacities. The field of AI has grappled with similar quandaries over how to assess the attainment of Artificial General Intelligence (AGI), a persistently discussed issue among scholars since the inception of AI, with the Turing Test communally being considered as the bellwether for ascertaining such matters. This paper proposes a variant of the Turing Test that is customized for specific use in the AILR realm, including depicting how this famous gold standard of AI fulfillment can be robustly applied across the autonomous levels of AI Legal Reasoning.", "pdf_url": "https://arxiv.org/pdf/2008.07743", "subject": "Computers and Society (cs.CY)"},
{"title": "Deep Learning-based Signal Strength Prediction Using Geographical Images and Expert Knowledge", "author": "Jakob Thrane, Benjamin Sliwa, Christian Wietfeld, Henrik Christiansen", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Methods for accurate prediction of radio signal quality parameters are crucial for optimization of mobile networks, and a necessity for future autonomous driving solutions. The power-distance relation of current empirical models struggles with describing the specific local geo-statistics that influence signal quality parameters. The use of empirical models commonly results in an over- or under-estimation of the signal quality parameters and require additional calibration studies. In this paper, we present a novel model-aided deep learning approach for path loss prediction, which implicitly extracts radio propagation characteristics from top-view geographical images of the receiver location. In a comprehensive evaluation campaign, we apply the proposed method on an extensive real-world data set consisting of five different scenarios and more than 125.000 individual measurements. It is found that 1) the novel approach reduces the average prediction error by up to 53% in comparison to ray-tracing techniques, 2) A distance of 250-300 meters spanned by the images offer the necessary level of detail, 3) Predictions with a root-mean-squared error of approximately 6 dB is achieved across inherently different data sources.", "pdf_url": "https://arxiv.org/pdf/2008.07747", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Quo Vadis, Open Source? The Limits of Open Source Growth", "author": "Michael Dorner, Maximilian Capraro, Ann Barcomb", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Open source software plays a significant role in the software industry. Prior work described open source to be growing polynomially or even exponentially. However, such growth cannot be sustained infinitely given finite resources. In this study, we present the results of four accumulated measurements on size and growth of open source considering over 224,000 open source projects for the last 25 years. For each of those projects, we measured lines of code, commits, contributors and lifecycle state over time, which reproduces and replicates the measurements of three well-cited studies. We found the number of active open source projects has been shrinking since 2016 and the number of contributors and commits has decreased from a peak in 2013. Open source -- although initially growing at exponential rate -- is not growing anymore. We believe it has reached saturation.", "pdf_url": "https://arxiv.org/pdf/2008.07753", "subject": "Software Engineering (cs.SE)"},
{"title": "Efficient Private Machine Learning by Differentiable Random Transformations", "author": "Fei Zheng", "pub_date": "Submitted on 18 Aug 2020", "abstract": "With the increasing demands for privacy protection, many privacy-preserving machine learning systems were proposed in recent years. However, most of them cannot be put into production due to their slow training and inference speed caused by the heavy cost of homomorphic encryption and secure multiparty computation(MPC) methods. To circumvent this, I proposed a privacy definition which is suitable for large amount of data in machine learning tasks. Based on that, I showed that random transformations like linear transformation and random permutation can well protect privacy. Merging random transformations and arithmetic sharing together, I designed a framework for private machine learning with high efficiency and low computation cost.", "pdf_url": "https://arxiv.org/pdf/2008.07758", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Shared MF: A privacy-preserving recommendation system", "author": "Senci Ying", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Matrix factorization is one of the most commonly used technologies in recommendation system. With the promotion of recommendation system in e-commerce shopping, online video and other aspects, distributed recommendation system has been widely promoted, and the privacy problem of multi-source data becomes more and more important. Based on Federated learning technology, this paper proposes a shared matrix factorization scheme called SharedMF. Firstly, a distributed recommendation system is built, and then secret sharing technology is used to protect the privacy of local data. Experimental results show that compared with the existing homomorphic encryption methods, our method can have faster execution speed without privacy disclosure, and can better adapt to recommendation scenarios with large amount of data.", "pdf_url": "https://arxiv.org/pdf/2008.07759", "subject": "Machine Learning (cs.LG)"},
{"title": "Pix2Surf: Learning Parametric 3D Surface Models of Objects from Images", "author": "Jiahui Lei, Srinath Sridhar, Paul Guerrero, Minhyuk Sung, Niloy Mitra, Leonidas J. Guibas", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We investigate the problem of learning to generate 3D parametric surface representations for novel object instances, as seen from one or more views. Previous work on learning shape reconstruction from multiple views uses discrete representations such as point clouds or voxels, while continuous surface generation approaches lack multi-view consistency. We address these issues by designing neural networks capable of generating high-quality parametric 3D surfaces which are also consistent between views. Furthermore, the generated 3D surfaces preserve accurate image pixel to 3D surface point correspondences, allowing us to lift texture information to reconstruct shapes with rich geometry and appearance. Our method is supervised and trained on a public dataset of shapes from common object categories. Quantitative results indicate that our method significantly outperforms previous work, while qualitative results demonstrate the high quality of our reconstructions.", "pdf_url": "https://arxiv.org/pdf/2008.07760", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "New Quality Metrics for Dynamic Graph Drawing", "author": "Amyra Meidiana, Seok-Hee Hong, Peter Eades", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this paper, we present new quality metrics for dynamic graph drawings. Namely, we present a new framework for change faithfulness metrics for dynamic graph drawings, which compare the ground truth change in dynamic graphs and the geometric change in drawings. More specifically, we present two specific instances, cluster change faithfulness metrics and distance change faithfulness metrics. We first validate the effectiveness of our new metrics using deformation experiments. Then we compare various graph drawing algorithms using our metrics. Our experiments confirm that the best cluster (resp. distance) faithful graph drawing algorithms are also cluster (resp. distance) change faithful.", "pdf_url": "https://arxiv.org/pdf/2008.07764", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Very Deep Transformers for Neural Machine Translation", "author": "Xiaodong Liu, Kevin Duh, Liyuan Liu, Jianfeng Gao", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We explore the application of very deep Transformer models for Neural Machine Translation (NMT). Using a simple yet effective initialization technique that stabilizes training, we show that it is feasible to build standard Transformer-based models with up to 60 encoder layers and 12 decoder layers. These deep models outperform their baseline 6-layer counterparts by as much as 2.5 BLEU, and achieve new state-of-the-art benchmark results on WMT14 English-French (43.8 BLEU) and WMT14 English-German (30.1 BLEU).The code and trained models will be publicly available at: .", "pdf_url": "https://arxiv.org/pdf/2008.07772", "subject": "Computation and Language (cs.CL)"},
{"title": "Learning Fair Policies in Multiobjective (Deep) Reinforcement Learning with Average and Discounted Rewards", "author": "Umer Siddique, Paul Weng, Matthieu Zimmer", "pub_date": "Submitted on 18 Aug 2020", "abstract": "As the operations of autonomous systems generally affect simultaneously several users, it is crucial that their designs account for fairness considerations. In contrast to standard (deep) reinforcement learning (RL), we investigate the problem of learning a policy that treats its users equitably. In this paper, we formulate this novel RL problem, in which an objective function, which encodes a notion of fairness that we formally define, is optimized. For this problem, we provide a theoretical discussion where we examine the case of discounted rewards and that of average rewards. During this analysis, we notably derive a new result in the standard RL setting, which is of independent interest: it states a novel bound on the approximation error with respect to the optimal average reward of that of a policy optimal for the discounted reward. Since learning with discounted rewards is generally easier, this discussion further justifies finding a fair policy for the average reward by learning a fair policy for the discounted reward. Thus, we describe how several classic deep RL algorithms can be adapted to our fair optimization problem, and we validate our approach with extensive experiments in three different domains.", "pdf_url": "https://arxiv.org/pdf/2008.07773", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Predicting Future Sales of Retail Products using Machine Learning", "author": "Devendra Swami, Alay Dilipbhai Shah, Subhrajeet K B Ray", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Techniques for making future predictions based upon the present and past data, has always been an area with direct application to various real life problems. We are discussing a similar problem in this paper. The problem statement is provided by Kaggle, which also serves as an ongoing competition on the Kaggle platform. In this project, we worked with a challenging time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company. The objective is to predict the total sales for every product and store in the next month given the past data. In order to perform forecasting for next month, we have deployed eXtreme Gradient Boosting (XGBoost) and Long Short Term Memory (LSTM) based network architecture to perform learning task. Root mean squared error (RMSE) between the actual and predicted target values is used to evaluate the performance, and make comparisons between the deployed algorithms. It has been found that XGBoost fared better than LSTM over this dataset which can be attributed to its relatively higher sparsity.", "pdf_url": "https://arxiv.org/pdf/2008.07779", "subject": "Machine Learning (cs.LG)"},
{"title": "Mesh Guided One-shot Face Reenactment using Graph Convolutional Networks", "author": "Guangming Yao, Yi Yuan, Tianjia Shao, Kun Zhou", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Face reenactment aims to animate a source face image to a different pose and expression provided by a driving image. Existing approaches are either designed for a specific identity, or suffer from the identity preservation problem in the one-shot or few-shot scenarios. In this paper, we introduce a method for one-shot face reenactment, which uses the reconstructed 3D meshes (i.e., the source mesh and driving mesh) as guidance to learn the optical flow needed for the reenacted face synthesis. Technically, we explicitly exclude the driving face's identity information in the reconstructed driving mesh. In this way, our network can focus on the motion estimation for the source face without the interference of driving face shape. We propose a motion net to learn the face motion, which is an asymmetric autoencoder. The encoder is a graph convolutional network (GCN) that learns a latent motion vector from the meshes, and the decoder serves to produce an optical flow image from the latent vector with CNNs. Compared to previous methods using sparse keypoints to guide the optical flow learning, our motion net learns the optical flow directly from 3D dense meshes, which provide the detailed shape and pose information for the optical flow, so it can achieve more accurate expression and pose on the reenacted face. Extensive experiments show that our method can generate high-quality results and outperforms state-of-the-art methods in both qualitative and quantitative comparisons.", "pdf_url": "https://arxiv.org/pdf/2008.07783", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for Mobile Manipulation", "author": "Fei Xia, Chengshu Li, Roberto Mart\u00edn-Mart\u00edn, Or Litany, Alexander Toshev, Silvio Savarese", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Many Reinforcement Learning (RL) approaches use joint control signals (positions, velocities, torques) as action space for continuous control tasks. We propose to lift the action space to a higher level in the form of subgoals for a motion generator (a combination of motion planner and trajectory executor). We argue that, by lifting the action space and by leveraging sampling-based motion planners, we can efficiently use RL to solve complex, long-horizon tasks that could not be solved with existing RL methods in the original action space. We propose ReLMoGen -- a framework that combines a learned policy to predict subgoals and a motion generator to plan and execute the motion needed to reach these subgoals. To validate our method, we apply ReLMoGen to two types of tasks: 1) Interactive Navigation tasks, navigation problems where interactions with the environment are required to reach the destination, and 2) Mobile Manipulation tasks, manipulation tasks that require moving the robot base. These problems are challenging because they are usually long-horizon, hard to explore during training, and comprise alternating phases of navigation and interaction. Our method is benchmarked on a diverse set of seven robotics tasks in photo-realistic simulation environments. In all settings, ReLMoGen outperforms state-of-the-art Reinforcement Learning and Hierarchical Reinforcement Learning baselines. ReLMoGen also shows outstanding transferability between different motion generators at test time, indicating a great potential to transfer to real robots.", "pdf_url": "https://arxiv.org/pdf/2008.07792", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Utility-based Resource Allocation and Pricing for Serverless Computing", "author": "Vipul Gupta, Soham Phade, Thomas Courtade, Kannan Ramchandran", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Serverless computing platforms currently rely on basic pricing schemes that are static and do not reflect customer feedback. This leads to significant inefficiencies from a total utility perspective. As one of the fastest-growing cloud services, serverless computing provides an opportunity to better serve both users and providers through the incorporation of market-based strategies for pricing and resource allocation. With the help of utility functions to model the delay-sensitivity of customers, we propose a novel scheduler to allocate resources for serverless computing. The resulting resource allocation scheme is optimal in the sense that it maximizes the aggregate utility of all users across the system, thus maximizing social welfare. Our approach gives rise to a dynamic pricing scheme which is obtained by solving an optimization problem in its dual form. We further develop feedback mechanisms that allow the cloud provider to converge to optimal resource allocation, even when the users' utilities are unknown. Simulations show that our approach can track market demand and achieve significantly higher social welfare (or, equivalently, cost savings for customers) as compared to existing schemes.", "pdf_url": "https://arxiv.org/pdf/2008.07793", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Evaluation of Risk-based Re-Authentication Methods", "author": "Stephan Wiefling, Tanvi Patil, Markus D\u00fcrmuth, Luigi Lo Iacono", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Risk-based Authentication (RBA) is an adaptive security measure that improves the security of password-based authentication by protecting against credential stuffing, password guessing, or phishing attacks. RBA monitors extra features during login and requests for an additional authentication step if the observed feature values deviate from the usual ones in the login history. In state-of-the-art RBA re-authentication deployments, users receive an email with a numerical code in its body, which must be entered on the online service. Although this procedure has a major impact on RBA's time exposure and usability, these aspects were not studied so far. We introduce two RBA re-authentication variants supplementing the de facto standard with a link-based and another code-based approach. Then, we present the results of a between-group study (N=592) to evaluate these three approaches. Our observations show with significant results that there is potential to speed up the RBA re-authentication process without reducing neither its security properties nor its security perception. The link-based re-authentication via \"magic links\", however, makes users significantly more anxious than the code-based approaches when perceived for the first time. Our evaluations underline the fact that RBA re-authentication is not a uniform procedure. We summarize our findings and provide recommendations.", "pdf_url": "https://arxiv.org/pdf/2008.07795", "subject": "Cryptography and Security (cs.CR)"},
{"title": "A Hierarchical User Intention-Habit Extract Network for Credit Loan Overdue Risk Detection", "author": "Hao Guo, Xintao Ren, Rongrong Wang, Zhun Cai, Kai Shuang, Yue Sun", "pub_date": "Submitted on 18 Aug 2020", "abstract": "More personal consumer loan products are emerging in mobile banking APP. For ease of use, application process is always simple, which means that few application information is requested for user to fill when applying for a loan, which is not conducive to construct users' credit profile. Thus, the simple application process brings huge challenges to the overdue risk detection, as higher overdue rate will result in greater economic losses to the bank. In this paper, we propose a model named HUIHEN (Hierarchical User Intention-Habit Extract Network) that leverages the users' behavior information in mobile banking APP. Due to the diversity of users' behaviors, we divide behavior sequences into sessions according to the time interval, and use the field-aware method to extract the intra-field information of behaviors. Then, we propose a hierarchical network composed of time-aware GRU and user-item-aware GRU to capture users' short-term intentions and users' long-term habits, which can be regarded as a supplement to user profile. The proposed model can improve the accuracy without increasing the complexity of the original online application process. Experimental results demonstrate the superiority of HUIHEN and show that HUIHEN outperforms other state-of-art models on all datasets.", "pdf_url": "https://arxiv.org/pdf/2008.07796", "subject": "Machine Learning (cs.LG)"},
{"title": "DRGraph: An Efficient Graph Layout Algorithm for Large-scale Graphs by Dimensionality Reduction", "author": "Minfeng Zhu, Wei Chen, Yuanzhe Hu, Yuxuan Hou, Liangjun Liu, Kaiyuan Zhang", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Efficient layout of large-scale graphs remains a challenging problem: the force-directed and dimensionality reduction-based methods suffer from high overhead for graph distance and gradient computation. In this paper, we present a new graph layout algorithm, called DRGraph, that enhances the nonlinear dimensionality reduction process with three schemes: approximating graph distances by means of a sparse distance matrix, estimating the gradient by using the negative sampling technique, and accelerating the optimization process through a multi-level layout scheme. DRGraph achieves a linear complexity for the computation and memory consumption, and scales up to large-scale graphs with millions of nodes. Experimental results and comparisons with state-of-the-art graph layout methods demonstrate that DRGraph can generate visually comparable layouts with a faster running time and a lower memory requirement.", "pdf_url": "https://arxiv.org/pdf/2008.07799", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Transferring Complementary Operating Conditions for Anomaly Detection", "author": "Gabriel Michau, Olga Fink", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In complex industrial systems, the number of possible fault types is uncountable, making it impossible to train supervised models covering them all. Instead, anomaly detectors are trained on healthy operating condition data and raise an alarm when the data deviate from the healthy conditions, indicating the possible occurrence of faults. Data-driven anomaly detection performance relies on a representative collection of samples of the normal (healthy) class distribution. This means that the samples used to train the model should be sufficient in number and distributed so as to empirically determine the full healthy distribution. But for industrial systems in gradually varying environments or subject to changing usage, acquiring such a comprehensive set of samples would require a long collection period and delay the point at which the anomaly detector could be trained and operational. In this paper, we propose a framework for the transfer of complementary operating conditions between different units, to train more robust anomaly detectors. The domain shift due to different units' specificities needs to be accounted for. This problem is an extension of Unsupervised Domain Adaptation to the one-class classification task. We solve the problem with adversarial deep learning and replace the traditional classification loss, unavailable in one-class problems, with a new loss inspired by a dimensionality reduction tool. This loss enforces the conservation of the inherent variability of each dataset while the adversarial architecture ensures the alignment of the distributions, hence correcting the domain shift. We demonstrate the benefit of this approach using three open source datasets.", "pdf_url": "https://arxiv.org/pdf/2008.07815", "subject": "Machine Learning (cs.LG)"},
{"title": "Knowledge Transfer via Dense Cross-Layer Mutual-Distillation", "author": "Anbang Yao, Dawei Sun", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Knowledge Distillation (KD) based methods adopt the one-way Knowledge Transfer (KT) scheme in which training a lower-capacity student network is guided by a pre-trained high-capacity teacher network. Recently, Deep Mutual Learning (DML) presented a two-way KT strategy, showing that the student network can be also helpful to improve the teacher network. In this paper, we propose Dense Cross-layer Mutual-distillation (DCM), an improved two-way KT method in which the teacher and student networks are trained collaboratively from scratch. To augment knowledge representation learning, well-designed auxiliary classifiers are added to certain hidden layers of both teacher and student networks. To boost KT performance, we introduce dense bidirectional KD operations between the layers appended with classifiers. After training, all auxiliary classifiers are discarded, and thus there are no extra parameters introduced to final models. We test our method on a variety of KT tasks, showing its superiorities over related methods. Code is available at", "pdf_url": "https://arxiv.org/pdf/2008.07816", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "ConvGRU in Fine-grained Pitching Action Recognition for Action Outcome Prediction", "author": "Tianqi Ma, Lin Zhang, Xiumin Diao, Ou Ma", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Prediction of the action outcome is a new challenge for a robot collaboratively working with humans. With the impressive progress in video action recognition in recent years, fine-grained action recognition from video data turns into a new concern. Fine-grained action recognition detects subtle differences of actions in more specific granularity and is significant in many fields such as human-robot interaction, intelligent traffic management, sports training, health caring. Considering that the different outcomes are closely connected to the subtle differences in actions, fine-grained action recognition is a practical method for action outcome prediction. In this paper, we explore the performance of convolutional gate recurrent unit (ConvGRU) method on a fine-grained action recognition tasks: predicting outcomes of ball-pitching. Based on sequences of RGB images of human actions, the proposed approach achieved the performance of 79.17% accuracy, which exceeds the current state-of-the-art result. We also compared different network implementations and showed the influence of different image sampling methods, different fusion methods and pre-training, etc. Finally, we discussed the advantages and limitations of ConvGRU in such action outcome prediction and fine-grained action recognition tasks.", "pdf_url": "https://arxiv.org/pdf/2008.07819", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "AoI-based Multicast Routing over Voronoi Overlays with Minimal Overhead", "author": "Michele Albano, Matteo Mordacchini, Laura Ricci", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The increasing pervasive and ubiquitous presence of devices at the edge of the Internet is creating new scenarios for the emergence of novel services and applications. This is particularly true for location- and context-aware services. These services call for new decentralized, self-organizing communication schemes that are able to face issues related to demanding resource consumption constraints, while ensuring efficient locality-based information dissemination and querying. Voronoi-based communication techniques are among the most widely used solutions in this field. However, when used for forwarding messages inside closed areas of the network (called Areas of Interest, AoIs), these solutions generally require a significant overhead in terms of redundant and/or unnecessary communications. This fact negatively impacts both the devices' resource consumption levels, as well as the network bandwidth usage. In order to eliminate all unnecessary communications, in this paper we present the MABRAVO (Multicast Algorithm for Broadcast and Routing over AoIs in Voronoi Overlays) protocol suite. MABRAVO allows to forward information within an AoI in a Voronoi network using only local information, reaching all the devices in the area, and using the lowest possible number of messages, i.e., just one message for each node included in the AoI. The paper presents the mathematical and algorithmic descriptions of MABRAVO, as well as experimental findings of its performance, showing its ability to reduce communication costs to the strictly minimum required.", "pdf_url": "https://arxiv.org/pdf/2008.07821", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Mastering Large Scale Multi-label Image Recognition with high efficiency overCamera trap images", "author": "Miroslav Valan, Luk\u00e1\u0161 Picek", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Camera traps are crucial in biodiversity motivated studies, however dealing with large number of images while annotating these data sets is a tedious and time consuming task. To speed up this process, Machine Learning approaches are a reasonable asset. In this article we are proposing an easy, accessible, light-weight, fast and efficient approach based on our winning submission to the \"Hakuna Ma-data - Serengeti Wildlife Identification challenge\". Our system achieved an Accuracy of 97% and outperformed the human level performance. We show that, given relatively large data sets, it is effective to look at each image only once with little or no augmentation. By utilizing such a simple, yet effective baseline we were able to avoid over-fitting without extensive regularization techniques and to train a top scoring system on a very limited hardware featuring single GPU (1080Ti) despite the large training set (6.7M images and 6TB).", "pdf_url": "https://arxiv.org/pdf/2008.07828", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Tackling the Unannotated: Scene Graph Generation with Bias-Reduced Models", "author": "Tzu-Jui Julius Wang, Selen Pehlivan, Jorma Laaksonen", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Predicting a scene graph that captures visual entities and their interactions in an image has been considered a crucial step towards full scene comprehension. Recent scene graph generation (SGG) models have shown their capability of capturing the most frequent relations among visual entities. However, the state-of-the-art results are still far from satisfactory, e.g. models can obtain 31% in overall recall R@100, whereas the likewise important mean class-wise recall mR@100 is only around 8% on Visual Genome (VG). The discrepancy between R and mR results urges to shift the focus from pursuing a high R to a high mR with a still competitive R. We suspect that the observed discrepancy stems from both the annotation bias and sparse annotations in VG, in which many visual entity pairs are either not annotated at all or only with a single relation when multiple ones could be valid. To address this particular issue, we propose a novel SGG training scheme that capitalizes on self-learned knowledge. It involves two relation classifiers, one offering a less biased setting for the other to base on. The proposed scheme can be applied to most of the existing SGG models and is straightforward to implement. We observe significant relative improvements in mR (between +6.6% and +20.4%) and competitive or better R (between -2.4% and 0.3%) across all standard SGG tasks.", "pdf_url": "https://arxiv.org/pdf/2008.07832", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Planar L-Drawings of Bimodal Graphs", "author": "Patrizio Angelini, Steven Chaplick, Sabine Cornelsen, Giordano Da Lozzo", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In a planar L-drawing of a directed graph (digraph) each edge e is represented as a polyline composed of a vertical segment starting at the tail of e and a horizontal segment ending at the head of e. Distinct edges may overlap, but not cross. Our main focus is on bimodal graphs, i.e., digraphs admitting a planar embedding in which the incoming and outgoing edges around each vertex are contiguous. We show that every plane bimodal graph without 2-cycles admits a planar L-drawing. This includes the class of upward-plane graphs. Finally, outerplanar digraphs admit a planar L-drawing - although they do not always have a bimodal embedding - but not necessarily with an outerplanar embedding.", "pdf_url": "https://arxiv.org/pdf/2008.07834", "subject": "Computational Geometry (cs.CG)"},
{"title": "Improving adversarial robustness of deep neural networks by using semantic information", "author": "Lina Wang, Rui Tang, Yawei Yue, Xingshu Chen, Wei Wang, Yi Zhu, Xuemei Zeng", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The vulnerability of deep neural networks (DNNs) to adversarial attack, which is an attack that can mislead state-of-the-art classifiers into making an incorrect classification with high confidence by deliberately perturbing the original inputs, raises concerns about the robustness of DNNs to such attacks. Adversarial training, which is the main heuristic method for improving adversarial robustness and the first line of defense against adversarial attacks, requires many sample-by-sample calculations to increase training size and is usually insufficiently strong for an entire network. This paper provides a new perspective on the issue of adversarial robustness, one that shifts the focus from the network as a whole to the critical part of the region close to the decision boundary corresponding to a given class. From this perspective, we propose a method to generate a single but image-agnostic adversarial perturbation that carries the semantic information implying the directions to the fragile parts on the decision boundary and causes inputs to be misclassified as a specified target. We call the adversarial training based on such perturbations \"region adversarial training\" (RAT), which resembles classical adversarial training but is distinguished in that it reinforces the semantic information missing in the relevant regions. Experimental results on the MNIST and CIFAR-10 datasets show that this approach greatly improves adversarial robustness even using a very small dataset from the training data; moreover, it can defend against FGSM adversarial attacks that have a completely different pattern from the model seen during retraining.", "pdf_url": "https://arxiv.org/pdf/2008.07838", "subject": "Machine Learning (cs.LG)"},
{"title": "EASTER: Efficient and Scalable Text Recognizer", "author": "Kartik Chaudhary, Raghav Bali", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Recent progress in deep learning has led to the development of Optical Character Recognition (OCR) systems which perform remarkably well. Most research has been around recurrent networks as well as complex gated layers which make the overall solution complex and difficult to scale. In this paper, we present an Efficient And Scalable TExt Recognizer (EASTER) to perform optical character recognition on both machine printed and handwritten text. Our model utilises 1-D convolutional layers without any recurrence which enables parallel training with considerably less volume of data. We experimented with multiple variations of our architecture and one of the smallest variant (depth and number of parameter wise) performs comparably to RNN based complex choices. Our 20-layered deepest variant outperforms RNN architectures with a good margin on benchmarking datasets like IIIT-5k and SVT. We also showcase improvements over the current best results on offline handwritten text recognition task. We also present data generation pipelines with augmentation setup to generate synthetic datasets for both handwritten and machine printed text.", "pdf_url": "https://arxiv.org/pdf/2008.07839", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Oscillation Mitigation of Hyperbolicity-Preserving Intrusive Uncertainty Quantification Methods for Systems of Conservation Laws", "author": "Jonas Kusch, Louisa Schlachter", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this article we study intrusive uncertainty quantification schemes for systems of conservation laws with uncertainty. Standard intrusive methods lead to oscillatory solutions which sometimes even cause the loss of hyperbolicity. We consider the stochastic Galerkin scheme, in which we filter the coefficients of the polynomial expansion in order to reduce oscillations. We further apply the multi-element approach and ensure the preservation of hyperbolic solutions through the hyperbolicity limiter. In addition to that, we study the intrusive polynomial moment method, which guarantees hyperbolicity at the cost of solving an optimization problem in every spatial cell and every time step. To reduce numerical costs, we apply the multi-element ansatz to IPM. This ansatz decouples the optimization problems of all multi elements. Thus, we are able to significantly decrease computational costs while improving parallelizability. We finally evaluate these oscillation mitigating approaches on various numerical examples such as a NACA airfoil and a nozzle test case for the two-dimensional Euler equations. In our numerical experiments, we observe the mitigation of spurious artifacts. Furthermore, using the multi-element ansatz for IPM significantly reduces computational costs.", "pdf_url": "https://arxiv.org/pdf/2008.07845", "subject": "Numerical Analysis (math.NA)"},
{"title": "Image Pre-processing on NumtaDB for Bengali Handwritten Digit Recognition", "author": "Ovi Paul", "pub_date": "Submitted on 18 Aug 2020", "abstract": "NumtaDB is by far the largest data-set collection for handwritten digits in Bengali. This is a diverse dataset containing more than 85000 images. But this diversity also makes this dataset very difficult to work with. The goal of this paper is to find the benchmark for pre-processed images which gives good accuracy on any machine learning models. The reason being, there are no available pre-processed data for Bengali digit recognition to work with like the English digits for MNIST.", "pdf_url": "https://arxiv.org/pdf/2008.07853", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Depth Completion with RGB Prior", "author": "Yuri Feldman, Yoel Shapiro, Dotan Di Castro", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Depth cameras are a prominent perception system for robotics, especially when operating in natural unstructured environments. Industrial applications, however, typically involve reflective objects under harsh lighting conditions, a challenging scenario for depth cameras, as it induces numerous reflections and deflections, leading to loss of robustness and deteriorated accuracy. Here, we developed a deep model to correct the depth channel in RGBD images, aiming to restore the depth information to the required accuracy. To train the model, we created a novel industrial dataset that we now present to the public. The data was collected with low-end depth cameras and the ground truth depth was generated by multi-view fusion.", "pdf_url": "https://arxiv.org/pdf/2008.07861", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Exploring the Design Space of Aesthetics with the Repertory Grid Technique", "author": "David Baum", "pub_date": "Submitted on 18 Aug 2020", "abstract": "By optimizing aesthetics, graph diagrams can be generated that are easier to read and understand. However, the challenge lies in identifying suitable aesthetics. We present a novel approach based on repertory grids to explore the design space of aesthetics systematically. We applied our approach with three independent groups of participants to systematically identify graph aesthetics. In all three cases, we were able to reproduce the aesthetics with positively evaluated influence on readability without any prior knowledge. We also applied our approach to two- and three-dimensional domain-specific software visualizations to demonstrate its versatility. In this case, we were also able to acquire several aesthetics that are relevant for perceiving the visualization.", "pdf_url": "https://arxiv.org/pdf/2008.07862", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Ubiquitous Distributed Deep Reinforcement Learning at the Edge: Analyzing Byzantine Agents in Discrete Action Spaces", "author": "Wenshuai Zhao, Jorge Pe\u00f1a Queralta, Li Qingqing, Tomi Westerlund", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The integration of edge computing in next-generation mobile networks is bringing low-latency and high-bandwidth ubiquitous connectivity to a myriad of cyber-physical systems. This will further boost the increasing intelligence that is being embedded at the edge in various types of autonomous systems, where collaborative machine learning has the potential to play a significant role. This paper discusses some of the challenges in multi-agent distributed deep reinforcement learning that can occur in the presence of byzantine or malfunctioning agents. As the simulation-to-reality gap gets bridged, the probability of malfunctions or errors must be taken into account. We show how wrong discrete actions can significantly affect the collaborative learning effort. In particular, we analyze the effect of having a fraction of agents that might perform the wrong action with a given probability. We study the ability of the system to converge towards a common working policy through the collaborative learning process based on the number of experiences from each of the agents to be aggregated for each policy update, together with the fraction of wrong actions from agents experiencing malfunctions. Our experiments are carried out in a simulation environment using the Atari testbed for the discrete action spaces, and advantage actor-critic (A2C) for the distributed multi-agent training.", "pdf_url": "https://arxiv.org/pdf/2008.07863", "subject": "Robotics (cs.RO)"},
{"title": "The Relational Data Borg is Learning", "author": "Dan Olteanu", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This paper overviews an approach that addresses machine learning over relational data as a database problem. This is justified by two observations. First, the input to the learning task is commonly the result of a feature extraction query over the relational data. Second, the learning task requires the computation of group-by aggregates. This approach has been already investigated for a number of supervised and unsupervised learning tasks, including: ridge linear regression, factorisation machines, support vector machines, decision trees, principal component analysis, and k-means; and also for linear algebra over data matrices. The main message of this work is that the runtime performance of machine learning can be dramatically boosted by a toolbox of techniques that exploit the knowledge of the underlying data. This includes theoretical development on the algebraic, combinatorial, and statistical structure of relational data processing and systems development on code specialisation, low-level computation sharing, and parallelisation. These techniques aim at lowering both the complexity and the constant factors of the learning time. This work is the outcome of extensive collaboration of the author with colleagues from RelationalAI, in particular Mahmoud Abo Khamis, Molham Aref, Hung Ngo, and XuanLong Nguyen, and from the FDB research project, in particular Ahmet Kara, Milos Nikolic, Maximilian Schleich, Amir Shaikhha, Jakub Zavodny, and Haozhe Zhang. The author would also like to thank the members of the FDB project for the figures and examples used in this paper. The author is grateful for support from industry: Amazon Web Services, Google, Infor, LogicBlox, Microsoft Azure, RelationalAI; and from the funding agencies EPSRC and ERC. This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 682588.", "pdf_url": "https://arxiv.org/pdf/2008.07864", "subject": "Databases (cs.DB)"},
{"title": "A Formally Robust Time Series Distance Metric", "author": "Maximilian Toller, Bernhard C. Geiger, Roman Kern", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Distance-based classification is among the most competitive classification methods for time series data. The most critical component of distance-based classification is the selected distance function. Past research has proposed various different distance metrics or measures dedicated to particular aspects of real-world time series data, yet there is an important aspect that has not been considered so far: Robustness against arbitrary data contamination. In this work, we propose a novel distance metric that is robust against arbitrarily \"bad\" contamination and has a worst-case computational complexity of $\\mathcal{O}(n\\log n)$. We formally argue why our proposed metric is robust, and demonstrate in an empirical evaluation that the metric yields competitive classification accuracy when applied in k-Nearest Neighbor time series classification.", "pdf_url": "https://arxiv.org/pdf/2008.07865", "subject": "Machine Learning (cs.LG)"},
{"title": "Implementation of Course Recommender System for Virtual University of Pakistan", "author": "Aleem Akhtar", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Universities working in Pakistan are offering a comprehensive set of degree programs for different levels. Virtual University of Pakistan is country's first institution completely based on modern information and communication technologies. It offers education in many different majors and various areas of study are available. Multiple courses are offered in each program that satisfy several general requirements of degree. Selection of courses that align with competency and interest can become an important factor in determining final score (CGPA) of student. For this purpose, a web-based course recommender system specifically designed for courses offered at Virtual University is developed. User-based collaborative filtering and rating-prediction approach is used for calculation of expected marks and grades. System is tested against 470 currently available courses and simulated data of 2600 students. Test results showed that expected marks are somehow dependent on student's average marks in already studied courses and average marks of similar students in target course. Accuracy of implemented system is measured using Mean Absolute Error for 100 observations. MAE value came out to be in acceptable range.", "pdf_url": "https://arxiv.org/pdf/2008.07867", "subject": "Computers and Society (cs.CY)"},
{"title": "Multi-Modal Trajectory Prediction of NBA Players", "author": "Sandro Hauri, Nemanja Djuric, Vladan Radosavljevic, Slobodan Vucetic", "pub_date": "Submitted on 18 Aug 2020", "abstract": "National Basketball Association (NBA) players are highly motivated and skilled experts that solve complex decision making problems at every time point during a game. As a step towards understanding how players make their decisions, we focus on their movement trajectories during games. We propose a method that captures the multi-modal behavior of players, where they might consider multiple trajectories and select the most advantageous one. The method is built on an LSTM-based architecture predicting multiple trajectories and their probabilities, trained by a multi-modal loss function that updates the best trajectories. Experiments on large, fine-grained NBA tracking data show that the proposed method outperforms the state-of-the-art. In addition, the results indicate that the approach generates more realistic trajectories and that it can learn individual playing styles of specific players.", "pdf_url": "https://arxiv.org/pdf/2008.07870", "subject": "Machine Learning (cs.LG)"},
{"title": "Self-supervised Sparse to Dense Motion Segmentation", "author": "Amirhossein Kardoost, Kalun Ho, Peter Ochs, Margret Keuper", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Observable motion in videos can give rise to the definition of objects moving with respect to the scene. The task of segmenting such moving objects is referred to as motion segmentation and is usually tackled either by aggregating motion information in long, sparse point trajectories, or by directly producing per frame dense segmentations relying on large amounts of training data. In this paper, we propose a self supervised method to learn the densification of sparse motion segmentations from single video frames. While previous approaches towards motion segmentation build upon pre-training on large surrogate datasets and use dense motion information as an essential cue for the pixelwise segmentation, our model does not require pre-training and operates at test time on single frames. It can be trained in a sequence specific way to produce high quality dense segmentations from sparse and noisy input. We evaluate our method on the well-known motion segmentation datasets FBMS59 and DAVIS16.", "pdf_url": "https://arxiv.org/pdf/2008.07872", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "S^3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization", "author": "Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang, Zhongyuan Wang, Ji-Rong Wen", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Recently, significant progress has been made in sequential recommendation with deep learning. Existing neural sequential recommendation models usually rely on the item prediction loss to learn model parameters or data representations. However, the model trained with this loss is prone to suffer from data sparsity problem. Since it overemphasizes the final performance, the association or fusion between context data and sequence data has not been well captured and utilized for sequential recommendation. To tackle this problem, we propose the model S^3-Rec, which stands for Self-Supervised learning for Sequential Recommendation, based on the self-attentive neural architecture. The main idea of our approach is to utilize the intrinsic data correlation to derive self-supervision signals and enhance the data representations via pre-training methods for improving sequential recommendation. For our task, we devise four auxiliary self-supervised objectives to learn the correlations among attribute, item, subsequence, and sequence by utilizing the mutual information maximization (MIM) principle. MIM provides a unified way to characterize the correlation between different types of data, which is particularly suitable in our scenario. Extensive experiments conducted on six real-world datasets demonstrate the superiority of our proposed method over existing state-of-the-art methods, especially when only limited training data is available. Besides, we extend our self-supervised learning method to other recommendation models, which also improve their performance.", "pdf_url": "https://arxiv.org/pdf/2008.07873", "subject": "Information Retrieval (cs.IR)"},
{"title": "Towards Closing the Sim-to-Real Gap in Collaborative Multi-Robot Deep Reinforcement Learning", "author": "Wenshuai Zhao, Jorge Pe\u00f1a Queralta, Li Qingqing, Tomi Westerlund", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Current research directions in deep reinforcement learning include bridging the simulation-reality gap, improving sample efficiency of experiences in distributed multi-agent reinforcement learning, together with the development of robust methods against adversarial agents in distributed learning, among many others. In this work, we are particularly interested in analyzing how multi-agent reinforcement learning can bridge the gap to reality in distributed multi-robot systems where the operation of the different robots is not necessarily homogeneous. These variations can happen due to sensing mismatches, inherent errors in terms of calibration of the mechanical joints, or simple differences in accuracy. While our results are simulation-based, we introduce the effect of sensing, calibration, and accuracy mismatches in distributed reinforcement learning with proximal policy optimization (PPO). We discuss on how both the different types of perturbances and how the number of agents experiencing those perturbances affect the collaborative learning effort. The simulations are carried out using a Kuka arm model in the Bullet physics engine. This is, to the best of our knowledge, the first work exploring the limitations of PPO in multi-robot systems when considering that different robots might be exposed to different environments where their sensors or actuators have induced errors. With the conclusions of this work, we set the initial point for future work on designing and developing methods to achieve robust reinforcement learning on the presence of real-world perturbances that might differ within a multi-robot system.", "pdf_url": "https://arxiv.org/pdf/2008.07875", "subject": "Machine Learning (cs.LG)"},
{"title": "Modeling and Analysis of Boundary Objects and Methodological Islands in Large-Scale Systems Development", "author": "Rebekka Wohlrab, Jennifer Horkoff, Rashidah Kasauli, Salome Maro, Jan-Philipp Stegh\u00f6fer, Eric Knauss", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Large-scale companies commonly face the challenge of managing relevant knowledge between different organizational groups, particularly in increasingly agile contexts. In previous studies, we found the importance of analyzing methodological islands (i.e., groups using different development methods than the surrounding organization) and boundary objects between them. In this paper, we propose a metamodel to better capture and analyze coordination and knowledge management in practice. Such a metamodel can allow practitioners to describe current practices, analyze issues, and design better-suited coordination mechanisms. We evaluated the conceptual model together with four large-scale companies developing complex systems. In particular, we derived an initial list of bad smells that can be leveraged to detect issues and devise suitable improvement strategies for inter-team coordination in large-scale development. We present the model, smells, and our evaluation results.", "pdf_url": "https://arxiv.org/pdf/2008.07879", "subject": "Software Engineering (cs.SE)"},
{"title": "COVID-SEE: Scientific Evidence Explorer for COVID-19 Related Research", "author": "Karin Verspoor, Simon \u0160uster, Yulia Otmakhova, Shevon Mendis, Zenan Zhai, Biaoyan Fang, Jey Han Lau, Timothy Baldwin, Antonio Jimeno Yepes, David Martinez", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We present COVID-SEE, a system for medical literature discovery based on the concept of information exploration, which builds on several distinct text analysis and natural language processing methods to structure and organise information in publications, and augments search by providing a visual overview supporting exploration of a collection to identify key articles of interest. We developed this system over COVID-19 literature to help medical professionals and researchers explore the literature evidence, and improve findability of relevant information. COVID-SEE is available at .", "pdf_url": "https://arxiv.org/pdf/2008.07880", "subject": "Computation and Language (cs.CL)"},
{"title": "Modeling, Visualization, and Analysis of African Innovation Performance", "author": "Muhammad Omer, Moayad El-Amin, Ammar Nasr, Rami Ahmed", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this paper we discuss the concepts and emergence of Innovation Performance, and how to quantify it, primarily working with data from the Global Innovation Index, with emphasis on the African Innovation Performance. We briefly overview existing literature on using machine learning for modeling innovation performance, and use simple machine learning techniques, to analyze and predict the \"Mobile App Creation Indicator\" from the Global Innovation Index, by using insights from the stack-overflow developers survey. Also, we build and compare models to predict the Innovation Output Sub-index, also from the Global Innovation Index.", "pdf_url": "https://arxiv.org/pdf/2008.07882", "subject": "Computers and Society (cs.CY)"},
{"title": "Person image generation with semantic attention network for person re-identification", "author": "Meichen Liu, Kejun Wang, Juihang Ji, Shuzhi Sam Ge", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Pose variation is one of the key factors which prevents the network from learning a robust person re-identification (Re-ID) model. To address this issue, we propose a novel person pose-guided image generation method, which is called the semantic attention network. The network consists of several semantic attention blocks, where each block attends to preserve and update the pose code and the clothing textures. The introduction of the binary segmentation mask and the semantic parsing is important for seamlessly stitching foreground and background in the pose-guided image generation. Compared with other methods, our network can characterize better body shape and keep clothing attributes, simultaneously. Our synthesized image can obtain better appearance and shape consistency related to the original image. Experimental results show that our approach is competitive with respect to both quantitative and qualitative results on Market-1501 and DeepFashion. Furthermore, we conduct extensive evaluations by using person re-identification (Re-ID) systems trained with the pose-transferred person based augmented data. The experiment shows that our approach can significantly enhance the person Re-ID accuracy.", "pdf_url": "https://arxiv.org/pdf/2008.07884", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "From Zero to Fog: Efficient Engineering of Fog-Based IoT Applications", "author": "Tobias Pfandzelter, Jonathan Hasenburg, David Bermbach", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In IoT data processing, cloud computing alone does not suffice due to latency constraints, bandwidth limitations, and privacy concerns. By introducing intermediary nodes closer to the edge of the network that offer compute services in proximity to IoT devices, fog computing can reduce network strain and high access latency to application services. While this is the only viable approach to enable efficient IoT applications, the issue of component placement among cloud and intermediary nodes in the fog adds a new dimension to system design. State-of-the-art solutions to this issue rely on either simulation or solving a formalized assignment problem through heuristics, which are both inaccurate and fail to scale with a solution space that grows exponentially. In this paper, we present a three step process for designing practical fog-based IoT applications that uses best practices, simulation, and testbed analysis to converge towards an efficient system architecture. We then apply this process in a smart factory case study. By deploying filtered options to a physical testbed, we show that each step of our process converges towards more efficient application designs.", "pdf_url": "https://arxiv.org/pdf/2008.07891", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Minimum Eccentricity Shortest Path Problem with Respect to Structural Parameters", "author": "Martin Ku\u010dera, Ond\u0159ej Such\u00fd", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The Minimum Eccentricity Shortest Path Problem consists in finding a shortest path with minimum eccentricity in a given undirected graph. The problem is known to be NP-complete and W[2]-hard with respect to the desired eccentricity. We present fpt algorithms for the problem parameterized by the modular width, distance to cluster graph, the combination of distance to disjoint paths with the desired eccentricity, and maximum leaf number.", "pdf_url": "https://arxiv.org/pdf/2008.07898", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Optimal Sizing and Siting of Multi-purpose Utility-scale Shared Energy Storage Systems", "author": "Narayan Bhusal, Mukesh Gautam, Mohammed Benidris, Sushil J. Louis", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This paper proposes a nondominated sorting genetic algorithm II (NSGA-II) based approach to determine optimal or near-optimal sizing and siting of multi-purpose (e.g., voltage regulation and loss minimization), community-based, utility-scale shared energy storage in distribution systems with high penetration of solar photovoltaic energy systems. Small-scale behind-the-meter (BTM) batteries are expensive, not fully utilized, and their net value is difficult to generalize and to control for grid services. On the other hand, utility-scale shared energy storage (USSES) systems have the potential to provide primary (e.g., demand-side management, deferral of system upgrade, and demand charge reduction) as well as secondary (e.g., frequency regulation, resource adequacy, and energy arbitrage) grid services. Under the existing cost structure, storage deployed only for primary purpose cannot justify the economic benefit to owners. However, the delivery of storage for primary service utilizes only 1-50\\% of total battery lifetime capacity. In the proposed approach, for each candidate set of locations and sizes, the contribution of USSES systems to grid voltage deviation and power loss are evaluated and diverse Pareto-optimal front is created. USSES systems are dispersed through a new chromosome representation approach. From the list of Pareto-optimal front, distribution system planners will have the opportunity to select appropriate locations based on desired objectives. The proposed approach is demonstrated on the IEEE 123-node distribution test feeder with utility-scale PV and USSES systems.", "pdf_url": "https://arxiv.org/pdf/2008.07900", "subject": "Systems and Control (eess.SY)"},
{"title": "LPOP: Challenges and Advances in Logic and Practice of Programming", "author": "David S. Warren, Yanhong A. Liu", "pub_date": "Submitted on 15 Aug 2020", "abstract": "This article describes the work presented at the first Logic and Practice of Programming (LPOP) Workshop, which was held in Oxford, UK, on July 18, 2018, in conjunction with the Federated Logic Conference (FLoC) 2018. Its focus is challenges and advances in logic and practice of programming. The workshop was organized around a challenge problem that specifies issues in role-based access control (RBAC), with many participants proposing combined imperative and declarative solutions expressed in the languages of their choice.", "pdf_url": "https://arxiv.org/pdf/2008.07901", "subject": "Programming Languages (cs.PL)"},
{"title": "Glancing Transformer for Non-Autoregressive Neural Machine Translation", "author": "Lihua Qian, Hao Zhou, Yu Bao, Mingxuan Wang, Lin Qiu, Weinan Zhang, Yong Yu, Lei Li", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Non-autoregressive neural machine translation achieves remarkable inference acceleration compared to autoregressive models. However, current non-autoregressive models still fall behind their autoregressive counterparts in prediction accuracy. We attribute the accuracy gaps to two disadvantages of non-autoregressive models: a) learning simultaneous generation under the overly strong conditional independence assumption; b) lacking explicit target language modeling. In this paper, we propose Glancing Transformer (GLAT) to address the above disadvantages, which reduces the difficulty of learning simultaneous generation and introduces explicit target language modeling in the non-autoregressive setting at the same time. Experiments on several benchmarks demonstrate that our approach significantly improves the accuracy of non-autoregressive models without sacrificing any inference efficiency. In particular, GLAT achieves 30.91 BLEU on WMT 2014 German-English, which narrows the gap between autoregressive models and non-autoregressive models to less than 0.5 BLEU score.", "pdf_url": "https://arxiv.org/pdf/2008.07905", "subject": "Computation and Language (cs.CL)"},
{"title": "A Spanning Tree-based Genetic Algorithm for Distribution Network Reconfiguration", "author": "Mukesh Gautam, Narayan Bhusal, Mohammed Benidris, Sushil J. Louis", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This paper presents a spanning tree-based genetic algorithm (GA) for the reconfiguration of electrical distribution systems with the objective of minimizing active power losses. Due to low voltage levels at distribution systems, power losses are high and sensitive to system configuration. Therefore, optimal reconfiguration is an important factor in the operation of distribution systems to minimize active power losses. Smart and automated electric distribution systems are able to reconfigure as a response to changes in load levels to minimize active power losses. The proposed method searches spanning trees of potential configurations and finds the optimal spanning tree using a genetic algorithm in two steps. In the first step, all invalid combinations of branches and tie-lines (i.e., switching combinations that do not provide power to some of loads or violate the radiality and connectivity conditions) generated by initial population of GA are filtered out with the help of spanning-tree search algorithm. In the second step, power flow analyses are performed only for combinations that form spanning trees. The optimal configuration is then determined based on the amount of active power losses (optimal configuration is the one that results in minimum power losses). The proposed method is implemented on several systems including the well-known 33-node and 69-node systems. The results show that the proposed method is accurate and efficient in comparison with existing methods.", "pdf_url": "https://arxiv.org/pdf/2008.07908", "subject": "Systems and Control (eess.SY)"},
{"title": "Inductive logic programming at 30: a new introduction", "author": "Andrew Cropper, Sebastijan Duman\u010di\u0107", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Inductive logic programming (ILP) is a form of machine learning. The goal of ILP is to induce a logic program (a set of logical rules) that generalises training examples. As ILP approaches 30, we provide a new introduction to the field. We introduce the necessary logical notation and the main ILP learning settings. We describe the main building blocks of an ILP system. We compare several ILP systems on several dimensions. We detail four systems (Aleph, TILDE, ASPAL, and Metagol). We contrast ILP with other forms of machine learning. Finally, we summarise the current limitations and outline promising directions for future research.", "pdf_url": "https://arxiv.org/pdf/2008.07912", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "End-to-End Rate Enhancement in C-RAN Using Multi-Pair Two-Way Computation", "author": "Mahmoud Hasabelnaby, Anas Chaaban", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Cloud radio-access networks (C-RAN) have been proposed as an enabling technology for keeping up with the requirements of next-generation wireless networks. Most existing works on C-RAN consider the uplink or the downlink separately. However, designing the uplink and the downlink jointly may bring additional advantage, especially if message source-destination information is taken into account. In this paper, this idea is demonstrated by considering pairwise message exchange between users in a C-RAN. A multi-pair two-way transmission scheme is proposed which targets maximizing the end-to-end user data rates. In the proposed scheme, a lattice-based computation strategy is used, where the baseband processing unit (BBU) pool decodes integer linear combinations of paired users' codewords instead of decoding linear combinations of individual codewords. The BBU pool then compresses the computed signals and forwards them to the remote radio heads (RRHs), which decompress the signals and send them to the users. Finally, each user decodes its desired message using its own message as side information. The achievable rate of this scheme is derived, optimized, and evaluated numerically. Results reveal that significant end-to-end rate improvement can be achieved using the proposed scheme compared to existing schemes.", "pdf_url": "https://arxiv.org/pdf/2008.07918", "subject": "Information Theory (cs.IT)"},
{"title": "Linear Disentangled Representations and Unsupervised Action Estimation", "author": "Matthew Painter, Jonathon Hare, Adam Prugel-Bennett", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Disentangled representation learning has seen a surge in interest over recent times, generally focusing on new models to optimise one of many disparate disentanglement metrics. It was only with Symmetry Based Disentangled Representation Learning that a robust mathematical framework was introduced to define precisely what is meant by a \"linear disentangled representation\". This framework determines that such representations would depend on a particular decomposition of the symmetry group acting on the data, showing that actions would manifest through irreducible group representations acting on independent representational subspaces. ForwardVAE subsequently proposed the first model to induce and demonstrate a linear disentangled representation in a VAE model. In this work we empirically show that linear disentangled representations are not present in standard VAE models and that they instead require altering the loss landscape to induce them. We proceed to show that such representations are a desirable property with regard to classical disentanglement metrics. Finally we propose a method to induce irreducible representations which forgoes the need for labelled action sequences, as was required by prior work. We explore a number of properties of this method, including the ability to learn from action sequences without knowledge of intermediate states.", "pdf_url": "https://arxiv.org/pdf/2008.07922", "subject": "Machine Learning (cs.LG)"},
{"title": "Visibility-aware Multi-view Stereo Network", "author": "Jingyang Zhang, Yao Yao, Shiwei Li, Zixin Luo, Tian Fang", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Learning-based multi-view stereo (MVS) methods have demonstrated promising results. However, very few existing networks explicitly take the pixel-wise visibility into consideration, resulting in erroneous cost aggregation from occluded pixels. In this paper, we explicitly infer and integrate the pixel-wise occlusion information in the MVS network via the matching uncertainty estimation. The pair-wise uncertainty map is jointly inferred with the pair-wise depth map, which is further used as weighting guidance during the multi-view cost volume fusion. As such, the adverse influence of occluded pixels is suppressed in the cost fusion. The proposed framework Vis-MVSNet significantly improves depth accuracies in the scenes with severe occlusion. Extensive experiments are performed on DTU, BlendedMVS, and Tanks and Temples datasets to justify the effectiveness of the proposed framework.", "pdf_url": "https://arxiv.org/pdf/2008.07928", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Feature Products Yield Efficient Networks", "author": "Philipp Gr\u00fcning, Thomas Martinetz, Erhardt Barth", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We introduce Feature-Product networks (FP-nets) as a novel deep-network architecture based on a new building block inspired by principles of biological vision. For each input feature map, a so-called FP-block learns two different filters, the outputs of which are then multiplied. Such FP-blocks are inspired by models of end-stopped neurons, which are common in cortical areas V1 and especially in V2. Convolutional neural networks can be transformed into parameter-efficient FP-nets by substituting conventional blocks of regular convolutions with FP-blocks. In this way, we create several novel FP-nets based on state-of-the-art networks and evaluate them on the Cifar-10 and ImageNet challenges. We show that the use of FP-blocks reduces the number of parameters significantly without decreasing generalization capability. Since so far heuristics and search algorithms have been used to find more efficient networks, it seems remarkable that we can obtain even more efficient networks based on a novel bio-inspired design principle.", "pdf_url": "https://arxiv.org/pdf/2008.07930", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Motion Capture from Internet Videos", "author": "Junting Dong, Qing Shuai, Yuanqing Zhang, Xian Liu, Xiaowei Zhou, Hujun Bao", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Recent advances in image-based human pose estimation make it possible to capture 3D human motion from a single RGB video. However, the inherent depth ambiguity and self-occlusion in a single view prohibit the recovery of as high-quality motion as multi-view reconstruction. While multi-view videos are not common, the videos of a celebrity performing a specific action are usually abundant on the Internet. Even if these videos were recorded at different time instances, they would encode the same motion characteristics of the person. Therefore, we propose to capture human motion by jointly analyzing these Internet videos instead of using single videos separately. However, this new task poses many new challenges that cannot be addressed by existing methods, as the videos are unsynchronized, the camera viewpoints are unknown, the background scenes are different, and the human motions are not exactly the same among videos. To address these challenges, we propose a novel optimization-based framework and experimentally demonstrate its ability to recover much more precise and detailed motion from multiple videos, compared against monocular motion capture methods.", "pdf_url": "https://arxiv.org/pdf/2008.07931", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Describing Unseen Videos via Multi-ModalCooperative Dialog Agents", "author": "Ye Zhu, Yu Wu, Yi Yang, Yan Yan", "pub_date": "Submitted on 18 Aug 2020", "abstract": "With the arising concerns for the AI systems provided with direct access to abundant sensitive information, researchers seek to develop more reliable AI with implicit information sources. To this end, in this paper, we introduce a new task called video description via two multi-modal cooperative dialog agents, whose ultimate goal is for one conversational agent to describe an unseen video based on the dialog and two static frames. Specifically, one of the intelligent agents - Q-BOT - is given two static frames from the beginning and the end of the video, as well as a finite number of opportunities to ask relevant natural language questions before describing the unseen video. A-BOT, the other agent who has already seen the entire video, assists Q-BOT to accomplish the goal by providing answers to those questions. We propose a QA-Cooperative Network with a dynamic dialog history update learning mechanism to transfer knowledge from A-BOT to Q-BOT, thus helping Q-BOT to better describe the video. Extensive experiments demonstrate that Q-BOT can effectively learn to describe an unseen video by the proposed model and the cooperative learning method, achieving the promising performance where Q-BOT is given the full ground truth history dialog.", "pdf_url": "https://arxiv.org/pdf/2008.07935", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "FANG: Leveraging Social Context for Fake News Detection Using Graph Representation", "author": "Van-Hoang Nguyen, Kazunari Sugiyama, Preslav Nakov, Min-Yen Kan", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We propose Factual News Graph (FANG), a novel graphical social context representation and learning framework for fake news detection. Unlike previous contextual models that have targeted performance, our focus is on representation learning. Compared to transductive models, FANG is scalable in training as it does not have to maintain all nodes, and it is efficient at inference time, without the need to re-process the entire graph. Our experimental results show that FANG is better at capturing the social context into a high fidelity representation, compared to recent graphical and non-graphical models. In particular, FANG yields significant improvements for the task of fake news detection, and it is robust in the case of limited training data. We further demonstrate that the representations learned by FANG generalize to related tasks, such as predicting the factuality of reporting of a news medium.", "pdf_url": "https://arxiv.org/pdf/2008.07939", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Scalability of Network Visualisation from a Cognitive Load Perspective", "author": "Vahan Yoghourdjian, Yalong Yang, Tim Dwyer, Lee Lawrence, Michael Wybrow, Kim Marriott", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Node-link diagrams are widely used to visualise networks. However, even the best network layout algorithms ultimately result in 'hairball' visualisations when the graph reaches a certain degree of complexity, requiring simplification through aggregation or interaction (such as filtering) to remain usable. Until now, there has been little data to indicate at what level of complexity node-link diagrams become ineffective or how visual complexity affects cognitive load. To this end, we conducted a controlled study to understand workload limits for a task that requires a detailed understanding of the network topology---finding the shortest path between two nodes. We tested performance on graphs with 25 to 175 nodes with varying density. We collected performance measures (accuracy and response time), subjective feedback, and physiological measures (EEG, pupil dilation, and heart rate variability). To the best of our knowledge, this is the first network visualisation study to include physiological measures. Our results show that people have significant difficulty finding the shortest path in high-density node-link diagrams with more than 50 nodes and even low-density graphs with more than 100 nodes. From our collected EEG data we observe functional differences in brain activity between hard and easy tasks. We found that cognitive load increased up to a certain level of difficulty after which it decreased, likely because participants had given up. We also explored the effects of global network layout features such as size or number of crossings, and features of the shortest path such as length or straightness on task difficulty. We found that global features generally had a greater impact than those of the shortest path.", "pdf_url": "https://arxiv.org/pdf/2008.07944", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Differential coverage: automating coverage analysis", "author": "Henry Cox", "pub_date": "Submitted on 18 Aug 2020", "abstract": "While it is easy to automate coverage data collection, it is a time consuming/difficult/expensive manual process to analyze the data so that it can be acted upon. Complexity arises from numerous sources, of which untested or poorly tested legacy code and third-party libraries are two of the most common. Differential coverage and date binning are methods of combining coverage data and project/file history to determine if goals have been met and to identify areas of code which should be prioritized. These methods can be applied to any coverage metric which can be associated with a location -- statement, function, expression, toggle, etc. -- and to any language, including both software (C++, Python, etc.) and hardware description languages (SystemVerilog, VHDL). The goal of these approaches is to reduce the cost and the barrier to entry of using coverage data analysis in large-scale projects. The approach is realized in gendiffcov, a recently released open-source tool.", "pdf_url": "https://arxiv.org/pdf/2008.07947", "subject": "Software Engineering (cs.SE)"},
{"title": "Adaptive Distillation for Decentralized Learning from Heterogeneous Clients", "author": "Jiaxin Ma, Ryo Yonetani, Zahid Iqbal", "pub_date": "Submitted on 18 Aug 2020", "abstract": "This paper addresses the problem of decentralized learning to achieve a high-performance global model by asking a group of clients to share local models pre-trained with their own data resources. We are particularly interested in a specific case where both the client model architectures and data distributions are diverse, which makes it nontrivial to adopt conventional approaches such as Federated Learning and network co-distillation. To this end, we propose a new decentralized learning method called Decentralized Learning via Adaptive Distillation (DLAD). Given a collection of client models and a large number of unlabeled distillation samples, the proposed DLAD 1) aggregates the outputs of the client models while adaptively emphasizing those with higher confidence in given distillation samples and 2) trains the global model to imitate the aggregated outputs. Our extensive experimental evaluation on multiple public datasets (MNIST, CIFAR-10, and CINIC-10) demonstrates the effectiveness of the proposed method.", "pdf_url": "https://arxiv.org/pdf/2008.07948", "subject": "Machine Learning (cs.LG)"},
{"title": "Parameterized Complexity of Maximum Edge Colorable Subgraph", "author": "Akanksha Agrawal, Madhumita Kundu, Abhishek Sahu, Saket Saurabh, Prafullkumar Tale", "pub_date": "Submitted on 18 Aug 2020", "abstract": "A graph $H$ is {\\em $p$-edge colorable} if there is a coloring $\\psi: E(H) \\rightarrow \\{1,2,\\dots,p\\}$, such that for distinct $uv, vw \\in E(H)$, we have $\\psi(uv) \\neq \\psi(vw)$. The {\\sc Maximum Edge-Colorable Subgraph} problem takes as input a graph $G$ and integers $l$ and $p$, and the objective is to find a subgraph $H$ of $G$ and a $p$-edge-coloring of $H$, such that $|E(H)| \\geq l$. We study the above problem from the viewpoint of Parameterized Complexity. We obtain \\FPT\\ algorithms when parameterized by: $(1)$ the vertex cover number of $G$, by using {\\sc Integer Linear Programming}, and $(2)$ $l$, a randomized algorithm via a reduction to \\textsc{Rainbow Matching}, and a deterministic algorithm by using color coding, and divide and color. With respect to the parameters $p+k$, where $k$ is one of the following: $(1)$ the solution size, $l$, $(2)$ the vertex cover number of $G$, and $(3)$ $l - {\\mm}(G)$, where ${\\mm}(G)$ is the size of a maximum matching in $G$; we show that the (decision version of the) problem admits a kernel with $\\mathcal{O}(k \\cdot p)$ vertices. Furthermore, we show that there is no kernel of size $\\mathcal{O}(k^{1-\\epsilon} \\cdot f(p))$, for any $\\epsilon > 0$ and computable function $f$, unless $\\NP \\subseteq \\CONPpoly$.", "pdf_url": "https://arxiv.org/pdf/2008.07953", "subject": "Discrete Mathematics (cs.DM)"},
{"title": "Learning the Structure of Auto-Encoding Recommenders", "author": "Farhan Khawar, Leonard Kin Man Poon, Nevin Lianwen Zhang", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Autoencoder recommenders have recently shown state-of-the-art performance in the recommendation task due to their ability to model non-linear item relationships effectively. However, existing autoencoder recommenders use fully-connected neural network layers and do not employ structure learning. This can lead to inefficient training, especially when the data is sparse as commonly found in collaborative filtering. The aforementioned results in lower generalization ability and reduced performance. In this paper, we introduce structure learning for autoencoder recommenders by taking advantage of the inherent item groups present in the collaborative filtering domain. Due to the nature of items in general, we know that certain items are more related to each other than to other items. Based on this, we propose a method that first learns groups of related items and then uses this information to determine the connectivity structure of an auto-encoding neural network. This results in a network that is sparsely connected. This sparse structure can be viewed as a prior that guides the network training. Empirically we demonstrate that the proposed structure learning enables the autoencoder to converge to a local optimum with a much smaller spectral norm and generalization error bound than the fully-connected network. The resultant sparse network considerably outperforms the state-of-the-art methods like \\textsc{Mult-vae/Mult-dae} on multiple benchmarked datasets even when the same number of parameters and flops are used. It also has a better cold-start performance.", "pdf_url": "https://arxiv.org/pdf/2008.07956", "subject": "Information Retrieval (cs.IR)"},
{"title": "A blockchain-based Forensic Model for Financial Crime Investigation: The Embezzlement Scenario", "author": "Lamprini Zarpala, Fran Casino", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The financial crime landscape is evolving along with the digitization in financial services. In this context, laws and regulations cannot efficiently cope with a fast-moving industry such as finance, which translates in late adoption of measures and legal voids, providing a fruitful landscape for malicious actors. In parallel, blockchain technology and its promising features such as immutability, verifiability, and authentication, enhance the opportunities of financial forensics. In this paper, we focus on an embezzlement scheme and we provide a forensic-by-design methodology for its investigation. In addition, the feasibility and adaptability of our approach can be extended and embrace digital investigations on other types of schemes. We provide a functional implementation based on smart contracts and we integrate standardised forensic flows and chain of custody preservation mechanisms. Finally, we discuss the benefits and challenges of the symbiotic relationship between blockchain and financial investigations, along with future research directions.", "pdf_url": "https://arxiv.org/pdf/2008.07958", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Dataset Bias in Few-shot Image Recognition", "author": "Shuqiang Jiang, Yaohui Zhu, Chenlong Liu, Xinhang Song, Xiangyang Li, Weiqing Min", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The goal of few-shot image recognition (FSIR) is to identify novel categories with a small number of annotated samples by exploiting transferable knowledge from training data (base categories). Most current studies assume that the transferable knowledge can be well used to identify novel categories. However, such transferable capability may be impacted by the dataset bias, and this problem has rarely been investigated before. Besides, most of few-shot learning methods are biased to different datasets, which is also an important issue that needs to be investigated in depth. In this paper, we first investigate the impact of transferable capabilities learned from base categories. Specifically, we introduce relevance to describe relations of base and novel categories, along with instance diversity and category diversity to depict distributions of base categories. The FSIR model learns better transferable knowledge from relative training data. In the relative data, diverse instances or categories can further enrich the learned knowledge. We conduct experiments on different sub-datasets of ImagNet, and experimental results demonstrate category relevance and category/instance diversity can depict transferable bias from distributions of base categories. Second, we investigate performance differences on different datasets from dataset structures and few-shot learning methods. Specifically, we introduce image complexity, inner-concept visual consistency, and inter-concept visual similarity to quantify characteristics of dataset structures. We use these quantitative characteristics and four few-shot learning methods to analyze performance differences on five different datasets. Based on experimental analysis, some insightful observations are obtained from the perspective of both dataset structures and few-shot learning methods. These observations are useful to guide future FSIR research.", "pdf_url": "https://arxiv.org/pdf/2008.07960", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Hierarchical HMM for Eye Movement Classification", "author": "Ye Zhu, Yan Yan, Oleg Komogortsev", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this work, we tackle the problem of ternary eye movement classification, which aims to separate fixations, saccades and smooth pursuits from the raw eye positional data. The efficient classification of these different types of eye movements helps to better analyze and utilize the eye tracking data. Different from the existing methods that detect eye movement by several pre-defined threshold values, we propose a hierarchical Hidden Markov Model (HMM) statistical algorithm for detecting fixations, saccades and smooth pursuits. The proposed algorithm leverages different features from the recorded raw eye tracking data with a hierarchical classification strategy, separating one type of eye movement each time. Experimental results demonstrate the effectiveness and robustness of the proposed method by achieving competitive or better performance compared to the state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2008.07961", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Relational Reflection Entity Alignment", "author": "Xin Mao, Wenting Wang, Huimin Xu, Yuanbin Wu, Man Lan", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Entity alignment aims to identify equivalent entity pairs from different Knowledge Graphs (KGs), which is essential in integrating multi-source KGs. Recently, with the introduction of GNNs into entity alignment, the architectures of recent models have become more and more complicated. We even find two counter-intuitive phenomena within these methods: (1) The standard linear transformation in GNNs is not working well. (2) Many advanced KG embedding models designed for link prediction task perform poorly in entity alignment. In this paper, we abstract existing entity alignment methods into a unified framework, Shape-Builder & Alignment, which not only successfully explains the above phenomena but also derives two key criteria for an ideal transformation operation. Furthermore, we propose a novel GNNs-based method, Relational Reflection Entity Alignment (RREA). RREA leverages Relational Reflection Transformation to obtain relation specific embeddings for each entity in a more efficient way. The experimental results on real-world datasets show that our model significantly outperforms the state-of-the-art methods, exceeding by 5.8%-10.9% on Hits@1.", "pdf_url": "https://arxiv.org/pdf/2008.07962", "subject": "Information Retrieval (cs.IR)"},
{"title": "Analysis of Social Robotic Navigation approaches: CNN Encoder and Active Learning as an alternative to Deep Reinforcement Learning", "author": "Janderson Ferreira, Agostinho A. F. J\u00fanior, Let\u00edcia Castro, Yves M. Galv\u00e3o, Pablo Barros, Bruno J. T. Fernandes", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Dealing with social tasks in robotic scenarios is difficult, as having the human in the learning loop is incompatible with most of the current state-of-the-art machine learning algorithms. This is the case when exploring active learning models, in particular the ones involving reinforcement learning. In this work, we discuss this problem and possible solutions by providing a prior study on adaptive convolutional encoders for a social navigation task.", "pdf_url": "https://arxiv.org/pdf/2008.07965", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "On the Parameterized Complexity Of Grid Contraction", "author": "Saket Saurabh, U\u00e9verton dos Santos Souza, Prafullkumar Tale", "pub_date": "Submitted on 18 Aug 2020", "abstract": "For a family of graphs $\\mathcal{G}$, the $\\mathcal{G}$-\\textsc{Contraction} problem takes as an input a graph $G$ and an integer $k$, and the goal is to decide if there exists $F \\subseteq E(G)$ of size at most $k$ such that $G/F$ belongs to $\\mathcal{G}$. Here, $G/F$ is the graph obtained from $G$ by contracting all the edges in $F$. In this article, we initiate the study of \\textsc{Grid Contraction} from the parameterized complexity point of view. We present a fixed parameter tractable algorithm, running in time $c^k \\cdot |V(G)|^{\\mathcal{O}(1)}$, for this problem. We complement this result by proving that unless \u00d0 fails, there is no algorithm for \\textsc{Grid Contraction} with running time $c^{o(k)} \\cdot |V(G)|^{\\mathcal{O}(1)}$. We also present a polynomial kernel for this problem.", "pdf_url": "https://arxiv.org/pdf/2008.07967", "subject": "Discrete Mathematics (cs.DM)"},
{"title": "Access Structure Hiding Secret Sharing from Novel Set Systems and Vector Families", "author": "Vipin Singh Sehrawat, Yvo Desmedt", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Secret sharing provides a means to distribute shares of a secret such that any authorized subset of shares, specified by an access structure, can be pooled together to recompute the secret. The standard secret sharing model requires public access structures, which violates privacy and facilitates the adversary by revealing high-value targets. In this paper, we address this shortcoming by introducing \\emph{hidden access structures}, which remain secret until some authorized subset of parties collaborate. The central piece of this work is the construction of a set-system $\\mathcal{H}$ with strictly greater than $\\exp\\left(c \\dfrac{1.5 (\\log h)^2}{\\log \\log h}\\right)$ subsets of a set of $h$ elements. Our set-system $\\mathcal{H}$ is defined over $\\mathbb{Z}_m$, where $m$ is a non-prime-power, such that the size of each set in $\\mathcal{H}$ is divisible by $m$ but the sizes of their pairwise intersections are not divisible by $m$, unless one set is a subset of another. We derive a vector family $\\mathcal{V}$ from $\\mathcal{H}$ such that superset-subset relationships in $\\mathcal{H}$ are represented by inner products in $\\mathcal{V}$. We use $\\mathcal{V}$ to \"encode\" the access structures and thereby develop the first \\emph{access structure hiding} secret sharing scheme. The information rate (secret-size/maximum-share-size) of our scheme is $1/2$. For a setting with $\\ell$ parties, our scheme supports $2^{\\ell}$ out of the $2^{2^{\\ell - O(\\log \\ell)}}$ possible access structures. The scheme assumes semi-honest polynomial-time parties, and its security relies on the Generalized Diffie-Hellman assumption.", "pdf_url": "https://arxiv.org/pdf/2008.07969", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Training Deep Neural Networks Without Batch Normalization", "author": "Divya Gaur, Joachim Folz, Andreas Dengel", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Training neural networks is an optimization problem, and finding a decent set of parameters through gradient descent can be a difficult task. A host of techniques has been developed to aid this process before and during the training phase. One of the most important and widely used class of method is normalization. It is generally favorable for neurons to receive inputs that are distributed with zero mean and unit variance, so we use statistics about dataset to normalize them before the first layer. However, this property cannot be guaranteed for the intermediate activations inside the network. A widely used method to enforce this property inside the network is batch normalization. It was developed to combat covariate shift inside networks. Empirically it is known to work, but there is a lack of theoretical understanding about its effectiveness and potential drawbacks it might have when used in practice. This work studies batch normalization in detail, while comparing it with other methods such as weight normalization, gradient clipping and dropout. The main purpose of this work is to determine if it is possible to train networks effectively when batch normalization is removed through adaption of the training process.", "pdf_url": "https://arxiv.org/pdf/2008.07970", "subject": "Machine Learning (cs.LG)"},
{"title": "Super-Human Performance in Gran Turismo Sport Using Deep Reinforcement Learning", "author": "Florian Fuchs, Yunlong Song, Elia Kaufmann, Davide Scaramuzza, Peter Duerr", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Autonomous car racing raises fundamental robotics challenges such as planning minimum-time trajectories under uncertain dynamics and controlling the car at its friction limits. In this project, we consider the task of autonomous car racing in the top-selling car racing game Gran Turismo Sport. Gran Turismo Sport is known for its detailed physics simulation of various cars and tracks. Our approach makes use of maximum-entropy deep reinforcement learning and a new reward design to train a sensorimotor policy to complete a given race track as fast as possible. We evaluate our approach in three different time trial settings with different cars and tracks. Our results show that the obtained controllers not only beat the built-in non-player character of Gran Turismo Sport, but also outperform the fastest known times in a dataset of personal best lap times of over 50,000 human drivers.", "pdf_url": "https://arxiv.org/pdf/2008.07971", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Fast algorithms for robust principal component analysis with an upper bound on the rank", "author": "Ningyu Sha, Lei Shi, Ming Yan", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The robust principal component analysis (RPCA) decomposes a data matrix into a low-rank part and a sparse part. There are mainly two types of algorithms for RPCA. The first type of algorithm applies regularization terms on the singular values of a matrix to obtain a low-rank matrix. However, calculating singular values can be very expensive for large matrices. The second type of algorithm replaces the low-rank matrix as the multiplication of two small matrices. They are faster than the first type because no singular value decomposition (SVD) is required. However, the rank of the low-rank matrix is required, and an accurate rank estimation is needed to obtain a reasonable solution. In this paper, we propose algorithms that combine both types. Our proposed algorithms require an upper bound of the rank and SVD on small matrices. First, they are faster than the first type because the cost of SVD on small matrices is negligible. Second, they are more robust than the second type because an upper bound of the rank instead of the exact rank is required. Furthermore, we apply the Gauss-Newton method to increase the speed of our algorithms. Numerical experiments show the better performance of our proposed algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.07972", "subject": "Numerical Analysis (math.NA)"},
{"title": "Stochastic Adaptive Line Search for Differentially Private Optimization", "author": "Chen Chen, Jaewoo Lee", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The performance of private gradient-based optimization algorithms is highly dependent on the choice of step size (or learning rate) which often requires non-trivial amount of tuning. In this paper, we introduce a stochastic variant of classic backtracking line search algorithm that satisfies R\u00e9nyi differential privacy. Specifically, the proposed algorithm uses the Armijo line search to adaptively choose step size and to effectively adjust per-iteration privacy budget according to the reliability of noisy gradient. A naive implementation of the backtracking search algorithm may end up using unacceptably large privacy budget as the ability of adaptive step size selection comes at the cost of extra function evaluations. The proposed algorithm avoids this problem by using the sparse vector technique combined with the recent privacy amplification lemma. We also introduce a privacy budget adaptation strategy in which the algorithm adaptively increases the budget when it detects that directions pointed by consecutive gradients are drastically different. Extensive experiments on both convex and non-convex problems show that the adaptively chosen step sizes allow the proposed algorithm to efficiently use the privacy budget and show competitive performance against existing private optimizers.", "pdf_url": "https://arxiv.org/pdf/2008.07978", "subject": "Machine Learning (cs.LG)"},
{"title": "Reinforcement Learning Evaluation and Solution for the Feedback Capacity of the Ising Channel with Large Alphabet", "author": "Ziv Aharoni, Oron Sabag, Haim Henri Permuter", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We propose a new method to compute the feedback capacity of unifilar finite state channels (FSCs) with memory using reinforcement learning (RL). The feedback capacity was previously estimated using its formulation as a Markov decision process (MDP) with dynamic programming (DP) algorithms. However, their computational complexity grows exponentially with the channel alphabet size. Therefore, we use RL, and specifically its ability to parameterize value functions and policies with neural networks, to evaluate numerically the feedback capacity of channels with a large alphabet size. The outcome of the RL algorithm is a numerical lower bound on the feedback capacity, which is used to reveal the structure of the optimal solution. The structure is modeled by a graph-based auxiliary random variable that is utilized to derive an analytic upper bound on the feedback capacity with the duality bound. The capacity computation is concluded by verifying the tightness of the upper bound by testing whether it is BCJR invariant. We demonstrate this method on the Ising channel with an arbitrary alphabet size. For an alphabet size smaller than or equal to 8, we derive the analytic solution of the capacity. Next, the structure of the numerical solution is used to deduce a simple coding scheme that achieves the feedback capacity and serves as a lower bound for larger alphabets. For an alphabet size greater than 8, we present an upper bound on the feedback capacity. For an asymptotically large alphabet size, we present an asymptotic optimal coding scheme.", "pdf_url": "https://arxiv.org/pdf/2008.07983", "subject": "Information Theory (cs.IT)"},
{"title": "Password Guessers Under a Microscope: An In-Depth Analysis to Inform Deployments", "author": "Zach Parish, Connor Cushing, Shourya Aggarwal, Amirali Salehi-Abari, Julie Thorpe", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Password guessers are instrumental for assessing the strength of passwords. Despite their diversity and abundance, little is known about how different guessers compare to each other. We perform in-depth analyses and comparisons of the guessing abilities and behavior of password guessers. To extend analyses beyond number of passwords cracked, we devise an analytical framework to compare the types of passwords that guessers generate under various conditions (e.g., limited training data, limited number of guesses, and dissimilar training and target data). Our results show that guessers often produce dissimilar guesses, even when trained on the same data. We leverage this result to show that combinations of computationally-cheap guessers are as effective as computationally intensive guessers, but more efficient. Our insights allow us to provide a concrete set of recommendations for system administrators when performing password checking.", "pdf_url": "https://arxiv.org/pdf/2008.07986", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Anomaly Detection with Convolutional Autoencoders for Fingerprint Presentation Attack Detection", "author": "Jascha Kolberg, Marcel Grimmer, Marta Gomez-Barrero, Christoph Busch", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In recent years, the popularity of fingerprint-based biometric authentication systems has significantly increased. However, together with many advantages, biometric systems are still vulnerable to presentation attacks (PAs). In particular, this applies for unsupervised applications, where new attacks unknown to the system operator may occur. Therefore, presentation attack detection (PAD) methods are used to determine whether samples stem from a live subject (bona fide) or from a presentation attack instrument (PAI). In this context, most works are dedicated to solve PAD as a two-class classification problem, which includes training a model on both bona fide and PA samples. In spite of the good detection rates reported, these methods still face difficulties detecting PAIs from unknown materials. To address this issue, we propose a new PAD technique based on autoencoders (AEs) trained only on bona fide samples (i.e. one-class). On the experimental evaluation over a database of 19,711 bona fide and 4,339 PA images, including 45 different PAI species, a detection equal error rate (D-EER) of 2.00% was achieved. Additionally, our best performing AE model is compared to further one-class classifiers (support vector machine, Gaussian mixture model). The results show the effectiveness of the AE model as it significantly outperforms the previously proposed methods.", "pdf_url": "https://arxiv.org/pdf/2008.07989", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "XNAP: Making LSTM-based Next Activity Predictions Explainable by Using LRP", "author": "Sven Weinzierl, Sandra Zilker, Jens Brunk, Kate Revoredo, Martin Matzner, J\u00f6rg Becker", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Predictive business process monitoring (PBPM) is a class of techniques designed to predict behaviour, such as next activities, in running traces. PBPM techniques aim to improve process performance by providing predictions to process analysts, supporting them in their decision making. However, the PBPM techniques` limited predictive quality was considered as the essential obstacle for establishing such techniques in practice. With the use of deep neural networks (DNNs), the techniques` predictive quality could be improved for tasks like the next activity prediction. While DNNs achieve a promising predictive quality, they still lack comprehensibility due to their hierarchical approach of learning representations. Nevertheless, process analysts need to comprehend the cause of a prediction to identify intervention mechanisms that might affect the decision making to secure process performance. In this paper, we propose XNAP, the first explainable, DNN-based PBPM technique for the next activity prediction. XNAP integrates a layer-wise relevance propagation method from the field of explainable artificial intelligence to make predictions of a long short-term memory DNN explainable by providing relevance values for activities. We show the benefit of our approach through two real-life event logs.", "pdf_url": "https://arxiv.org/pdf/2008.07993", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Mining Large Quasi-cliques with Quality Guarantees from Vertex Neighborhoods", "author": "Aritra Konar, Nicholas D. Sidiropoulos", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Mining dense subgraphs is an important primitive across a spectrum of graph-mining tasks. In this work, we formally establish that two recurring characteristics of real-world graphs, namely heavy-tailed degree distributions and large clustering coefficients, imply the existence of substantially large vertex neighborhoods with high edge-density. This observation suggests a very simple approach for extracting large quasi-cliques: simply scan the vertex neighborhoods, compute the clustering coefficient of each vertex, and output the best such subgraph. The implementation of such a method requires counting the triangles in a graph, which is a well-studied problem in graph mining. When empirically tested across a number of real-world graphs, this approach reveals a surprise: vertex neighborhoods include maximal cliques of non-trivial sizes, and the density of the best neighborhood often compares favorably to subgraphs produced by dedicated algorithms for maximizing subgraph density. For graphs with small clustering coefficients, we demonstrate that small vertex neighborhoods can be refined using a local-search method to ``grow'' larger cliques and near-cliques. Our results indicate that contrary to worst-case theoretical results, mining cliques and quasi-cliques of non-trivial sizes from real-world graphs is often not a difficult problem, and provides motivation for further work geared towards a better explanation of these empirical successes.", "pdf_url": "https://arxiv.org/pdf/2008.07996", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Deepcode and Modulo-SK are Designed for Different Settings", "author": "Hyeji Kim, Yihan Jiang, Sreeram Kannan, Sewoong Oh, Pramod Viswanath", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We respond to [1] which claimed that \"Modulo-SK scheme outperforms Deepcode [2]\". We demonstrate that this statement is not true: the two schemes are designed and evaluated for entirely different settings. DeepCode is designed and evaluated for the AWGN channel with (potentially delayed) uncoded output feedback. Modulo-SK is evaluated on the AWGN channel with coded feedback and unit delay. [1] also claimed an implementation of Schalkwijk and Kailath (SK) [3] which was numerically stable for any number of information bits and iterations. However, we observe that while their implementation does marginally improve over ours, it also suffers from a fundamental issue with precision. Finally, we show that Deepcode dominates the optimized performance of SK, over a natural choice of parameterizations when the feedback is noisy.", "pdf_url": "https://arxiv.org/pdf/2008.07997", "subject": "Information Theory (cs.IT)"},
{"title": "Reinforcement Learning for Improving Object Detection", "author": "Siddharth Nayak, Balaraman Ravindran", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The performance of a trained object detection neural network depends a lot on the image quality. Generally, images are pre-processed before feeding them into the neural network and domain knowledge about the image dataset is used to choose the pre-processing techniques. In this paper, we introduce an algorithm called ObjectRL to choose the amount of a particular pre-processing to be applied to improve the object detection performances of pre-trained networks. The main motivation for ObjectRL is that an image which looks good to a human eye may not necessarily be the optimal one for a pre-trained object detector to detect objects.", "pdf_url": "https://arxiv.org/pdf/2008.08005", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Differentially Private Clustering: Tight Approximation Ratios", "author": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We study the task of differentially private clustering. For several basic clustering problems, including Euclidean DensestBall, 1-Cluster, k-means, and k-median, we give efficient differentially private algorithms that achieve essentially the same approximation ratios as those that can be obtained by any non-private algorithm, while incurring only small additive errors. This improves upon existing efficient algorithms that only achieve some large constant approximation factors. Our results also imply an improved algorithm for the Sample and Aggregate privacy framework. Furthermore, we show that one of the tools used in our 1-Cluster algorithm can be employed to get a faster quantum algorithm for ClosestPair in a moderate number of dimensions.", "pdf_url": "https://arxiv.org/pdf/2008.08007", "subject": "Machine Learning (cs.LG)"},
{"title": "Linguistically-aware Attention for Reducing the Semantic-Gap in Vision-Language Tasks", "author": "Gouthaman KV, Athira Nambiar, Kancheti Sai Srinivas, Anurag Mittal", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Attention models are widely used in Vision-language (V-L) tasks to perform the visual-textual correlation. Humans perform such a correlation with a strong linguistic understanding of the visual world. However, even the best performing attention model in V-L tasks lacks such a high-level linguistic understanding, thus creating a semantic gap between the modalities. In this paper, we propose an attention mechanism - Linguistically-aware Attention (LAT) - that leverages object attributes obtained from generic object detectors along with pre-trained language models to reduce this semantic gap. LAT represents visual and textual modalities in a common linguistically-rich space, thus providing linguistic awareness to the attention process. We apply and demonstrate the effectiveness of LAT in three V-L tasks: Counting-VQA, VQA, and Image captioning. In Counting-VQA, we propose a novel counting-specific VQA model to predict an intuitive count and achieve state-of-the-art results on five datasets. In VQA and Captioning, we show the generic nature and effectiveness of LAT by adapting it into various baselines and consistently improving their performance.", "pdf_url": "https://arxiv.org/pdf/2008.08012", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Deconstructing the Decentralization Trilemma", "author": "Harry Halpin", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The vast majority of applications at this moment rely on centralized servers to relay messages between clients, where these servers are considered trusted third-parties. With the rise of blockchain technologies over the last few years, there has been a move away from both centralized servers and traditional federated models to more decentralized peer-to-peer alternatives. However, there appears to be a trilemma between security, scalability, and decentralization in blockchain-based systems. Deconstructing this trilemma using well-known threat models, we define a typology of centralized, federated, and decentralized architectures. Each of the different architectures has this trilemma play out differently. Facing a possible decentralized future, we outline seven hard problems facing decentralization and theorize that the differences between centralized, federated, and decentralized architectures depend on differing social interpretations of trust.", "pdf_url": "https://arxiv.org/pdf/2008.08014", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "MaskedFace-Net -- A Dataset of Correctly/Incorrectly Masked Face Images in the Context of COVID-19", "author": "Adnane Cabani, Karim Hammoudi, Halim Benhabiles, Mahmoud Melkemi", "pub_date": "Submitted on 18 Aug 2020", "abstract": "The wearing of the face masks appears as a solution for limiting the spread of COVID-19. In this context, efficient recognition systems are expected for checking that people faces are masked in regulated areas. To perform this task, a large dataset of masked faces is necessary for training deep learning models towards detecting people wearing masks and those not wearing masks. Some large datasets of masked faces are available in the literature. However, at the moment, there are no available large dataset of masked face images that permits to check if detected masked faces are correctly worn or not. Indeed, many people are not correctly wearing their masks due to bad practices, bad behaviors or vulnerability of individuals (e.g., children, old people). For these reasons, several mask wearing campaigns intend to sensitize people about this problem and good practices. In this sense, this work proposes three types of masked face detection dataset; namely, the Correctly Masked Face Dataset (CMFD), the Incorrectly Masked Face Dataset (IMFD) and their combination for the global masked face detection (MaskedFace-Net). Realistic masked face datasets are proposed with a twofold objective: i) to detect people having their faces masked or not masked, ii) to detect faces having their masks correctly worn or incorrectly worn (e.g.; at airport portals or in crowds). To the best of our knowledge, no large dataset of masked faces provides such a granularity of classification towards permitting mask wearing analysis. Moreover, this work globally presents the applied mask-to-face deformable model for permitting the generation of other masked face images, notably with specific masks. Our datasets of masked face images (137,016 images) are available at .", "pdf_url": "https://arxiv.org/pdf/2008.08016", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Multilanguage Number Plate Detection using Convolutional Neural Networks", "author": "Jatin Gupta, Vandana Saini, Kamaldeep Garg", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Object Detection is a popular field of research for recent technologies. In recent years, profound learning performance attracts the researchers to use it in many applications. Number plate (NP) detection and classification is analyzed over decades however, it needs approaches which are more precise and state, language and design independent since cars are now moving from state to another easily. In this paperwe suggest a new strategy to detect NP and comprehend the nation, language and layout of NPs. YOLOv2 sensor with ResNet attribute extractor heart is proposed for NP detection and a brand new convolutional neural network architecture is suggested to classify NPs. The detector achieves average precision of 99.57% and country, language and layout classification precision of 99.33%. The results outperforms the majority of the previous works and can move the area forward toward international NP detection and recognition.", "pdf_url": "https://arxiv.org/pdf/2008.08023", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "How to organize a hackathon -- A planning kit", "author": "Alexander Nolte, Ei Pa Pa Pe-Than, Abasi-amefon Obot Affia, Chalalai Chaihirunkarn, Anna Filippova, Arun Kalyanasundaram, Maria Angelica Medina Angarita, Erik Trainer, James D. Herbsleb", "pub_date": "Submitted on 18 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "Hackathons and similar time-bounded events have become a global phenomenon. Their proliferation in various domains and their usefulness for a variety of goals has subsequently led to the emergence of different formats. While there are a multitude of guidelines available on how to prepare and run a hackathon, most of them focus on a particular format that was created for a specific purpose within a domain for a certain type of participants. This makes it difficult in particular for novice organizers to decide how to run an event that fits their needs. To address this gap we developed a planning kit that is organized around 12 key decision that organizers need to make when preparing and running a hackathon, and the tradeoffs that drive decision-making. The main planning kit is available online while this report is meant as a downloadable and citable resource.", "pdf_url": "https://arxiv.org/pdf/2008.08025", "subject": "Computers and Society (cs.CY)"},
{"title": "Gradients as a Measure of Uncertainty in Neural Networks", "author": "Jinsol Lee, Ghassan AlRegib", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Despite tremendous success of modern neural networks, they are known to be overconfident even when the model encounters inputs with unfamiliar conditions. Detecting such inputs is vital to preventing models from making naive predictions that may jeopardize real-world applications of neural networks. In this paper, we address the challenging problem of devising a simple yet effective measure of uncertainty in deep neural networks. Specifically, we propose to utilize backpropagated gradients to quantify the uncertainty of trained models. Gradients depict the required amount of change for a model to properly represent given inputs, thus providing a valuable insight into how familiar and certain the model is regarding the inputs. We demonstrate the effectiveness of gradients as a measure of model uncertainty in applications of detecting unfamiliar inputs, including out-of-distribution and corrupted samples. We show that our gradient-based method outperforms state-of-the-art methods by up to 4.8% of AUROC score in out-of-distribution detection and 35.7% in corrupted input detection.", "pdf_url": "https://arxiv.org/pdf/2008.08030", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A Two Stage Generalized Block Orthogonal Matching Pursuit (TSGBOMP) Algorithm", "author": "Samrat Mukhopadhyay, Mrityunjoy Chakraborty", "pub_date": "Submitted on 18 Aug 2020", "abstract": "Recovery of an unknown sparse signal from a few of its projections is the key objective of compressed sensing. Often one comes across signals that are not ordinarily sparse but are sparse blockwise. Existing block sparse recovery algorithms like BOMP make the assumption of uniform block size and known block boundaries, which are, however, not very practical in many applications. This paper addresses this problem and proposes a two step procedure, where the first stage is a coarse block location identification stage while the second stage carries out finer localization of a non-zero cluster within the window selected in the first stage. A detailed convergence analysis of the proposed algorithm is carried out by first defining the so-called pseudoblock-interleaved block RIP of the given generalized block sparse signal and then imposing upper bounds on the corresponding RIC. We also extend the analysis for complex vector as well as matrix entries where it turns out that the extension is non-trivial and requires special care. Furthermore, assuming real Gaussian sensing matrix entries, we find a lower bound on the probability that the derived recovery bounds are satisfied. The lower bound suggests that there are sets of parameters such that the derived bound is satisfied with high probability. Simulation results confirm significantly improved performance of the proposed algorithm as compared to BOMP.", "pdf_url": "https://arxiv.org/pdf/2008.08031", "subject": "Information Theory (cs.IT)"},
{"title": "Amortized Edge Sampling", "author": "Talya Eden, Saleet Mossel, Ronitt Rubinfeld", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We present a sublinear time algorithm that allows one to sample multiple edges from a distribution that is pointwise $\\epsilon$-close to the uniform distribution, in an \\emph{amortized-efficient} fashion. We consider the adjacency list query model, where access to a graph $G$ is given via degree and neighbor queries. The problem of sampling a single edge in this model has been considered by Eden and Rosenbaum (SOSA 18). Let $n$ and $m$ denote the number of vertices and edges of $G$, respectively. Eden and Rosenbaum provided upper and lower bounds of $\\Theta^*(n/\\sqrt m)$ for sampling a single edge in general graphs (where $O^*(\\cdot)$ suppresses $\\textrm{poly}(1/\\epsilon)$ and $\\textrm{poly}(\\log n)$ dependencies). We ask whether the query complexity lower bound for sampling a single edge can be circumvented when multiple samples are required. That is, can we get an improved amortized per-sample cost if we allow a more costly preprocessing phase? We answer in the affirmative. We present an algorithm that, if one knows the number of required samples $q$ in advance, has an overall cost of $O^*(\\sqrt q \\cdot(n/\\sqrt m))$, which is strictly preferable to $O^*(q\\cdot (n/\\sqrt m))$ cost resulting from $q$ invocations of the algorithm by Eden and Rosenbaum. More generally, for an input parameter $x>1$, our algorithm has a preprocessing phase with $O^*(n/(x\\cdot d_{avg}))$ cost, which then allows an $O(x/\\epsilon)$ per-sample cost, where $d_{avg}$ denotes the average degree of the graph.", "pdf_url": "https://arxiv.org/pdf/2008.08032", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Moment Multicalibration for Uncertainty Estimation", "author": "Christopher Jung, Changhwa Lee, Mallesh M. Pai, Aaron Roth, Rakesh Vohra", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We show how to achieve the notion of \"multicalibration\" from H\u00e9bert-Johnson et al. [2018] not just for means, but also for variances and other higher moments. Informally, it means that we can find regression functions which, given a data point, can make point predictions not just for the expectation of its label, but for higher moments of its label distribution as well-and those predictions match the true distribution quantities when averaged not just over the population as a whole, but also when averaged over an enormous number of finely defined subgroups. It yields a principled way to estimate the uncertainty of predictions on many different subgroups-and to diagnose potential sources of unfairness in the predictive power of features across subgroups. As an application, we show that our moment estimates can be used to derive marginal prediction intervals that are simultaneously valid as averaged over all of the (sufficiently large) subgroups for which moment multicalibration has been obtained.", "pdf_url": "https://arxiv.org/pdf/2008.08037", "subject": "Machine Learning (cs.LG)"},
{"title": "A class of Finite difference Methods for solving inhomogeneous damped wave equations", "author": "Fazel Hadadifard, Satbir Malhi, Zhengyi Xiao", "pub_date": "Submitted on 18 Aug 2020", "abstract": "In this paper, a class of finite difference numerical technique is presented for the solution of the second-order linear inhomogeneous damped wave equation. The consistency, stability and convergences of these numerical schemes are discussed. The results obtained are compared to the exact solution as well as ordinary explicit, implicit finite difference methods, and the fourth-order compact method (FOCM) of \\cite{hussain2012fourth}. The general idea of these methods is developed by using $C_0$-semigroups operator theory. We also showed that the stability region for the explicit finite difference scheme depends on the damping coefficient.", "pdf_url": "https://arxiv.org/pdf/2008.08043", "subject": "Numerical Analysis (math.NA)"},
{"title": "The MRS UAV System: Pushing the Frontiers of Reproducible Research, Real-world Deployment, and Education with Autonomous Unmanned Aerial Vehicles", "author": "Tomas Baca, Matej Petrlik, Matous Vrba, Vojtech Spurny, Robert Penicka, Daniel Hert, Martin Saska", "pub_date": "Submitted on 18 Aug 2020", "abstract": "We present a multirotor Unmanned Aerial Vehicle control (UAV) and estimation system for supporting replicable research through realistic simulations and real-world experiments. We propose a unique multi-frame localization paradigm for estimating the states of a UAV in various frames of reference using multiple sensors simultaneously. The system enables complex missions in GNSS and GNSS-denied environments, including outdoor-indoor transitions and the execution of redundant estimators for backing up unreliable localization sources. Two feedback control designs are presented: one for precise and aggressive maneuvers, and the other for stable and smooth flight with a noisy state estimate. The proposed control and estimation pipeline are constructed without using the Euler/Tait-Bryan angle representation of orientation in 3D. Instead, we rely on rotation matrices and a novel heading-based convention to represent the one free rotational degree-of-freedom in 3D of a standard multirotor helicopter. We provide an actively maintained and well-documented open-source implementation, including realistic simulation of UAV, sensors, and localization systems. The proposed system is the product of years of applied research on multi-robot systems, aerial swarms, aerial manipulation, motion planning, and remote sensing. All our results have been supported by real-world system deployment that shaped the system into the form presented here. In addition, the system was utilized during the participation of our team from the CTU in Prague in the prestigious MBZIRC 2017 and 2020 robotics competitions, and also in the DARPA SubT challenge. Each time, our team was able to secure top places among the best competitors from all over the world. On each occasion, the challenges has motivated the team to improve the system and to gain a great amount of high-quality experience within tight deadlines.", "pdf_url": "https://arxiv.org/pdf/2008.08050", "subject": "Robotics (cs.RO)"},
{"title": "Modification of Gesture-Determined-Dynamic Function with Consideration of Margins for Motion Planning of Humanoid Robots", "author": "Zhijun Zhang, Lingdong Kong, Yaru Niu, Ziang Liang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "The gesture-determined-dynamic function (GDDF) offers an effective way to handle the control problems of humanoid robots. Specifically, GDDF is utilized to constrain the movements of dual arms of humanoid robots and steer specific gestures to conduct demanding tasks under certain conditions. However, there is still a deficiency in this scheme. Through experiments, we found that the joints of the dual arms, which can be regarded as the redundant manipulators, could exceed their limits slightly at the joint angle level. The performance straightly depends on the parameters designed beforehand for the GDDF, which causes a lack of adaptability to the practical applications of this method. In this paper, a modified scheme of GDDF with consideration of margins (MGDDF) is proposed. This MGDDF scheme is based on quadratic programming (QP) framework, which is widely applied to solving the redundancy resolution problems of robot arms. Moreover, three margins are introduced in the proposed MGDDF scheme to avoid joint limits. With consideration of these margins, the joints of manipulators of the humanoid robots will not exceed their limits, and the potential damages which might be caused by exceeding limits will be completely avoided. Computer simulations conducted on MATLAB further verify the feasibility and superiority of the proposed MGDDF scheme.", "pdf_url": "https://arxiv.org/pdf/2008.06899", "subject": "Robotics (cs.RO)"},
{"title": "SPL-MLL: Selecting Predictable Landmarks for Multi-Label Learning", "author": "Junbing Li, Changqing Zhang, Pengfei Zhu, Baoyuan Wu, Lei Chen, Qinghua Hu", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Although significant progress achieved, multi-label classification is still challenging due to the complexity of correlations among different labels. Furthermore, modeling the relationships between input and some (dull) classes further increases the difficulty of accurately predicting all possible labels. In this work, we propose to select a small subset of labels as landmarks which are easy to predict according to input (predictable) and can well recover the other possible labels (representative). Different from existing methods which separate the landmark selection and landmark prediction in the 2-step manner, the proposed algorithm, termed Selecting Predictable Landmarks for Multi-Label Learning (SPL-MLL), jointly conducts landmark selection, landmark prediction, and label recovery in a unified framework, to ensure both the representativeness and predictableness for selected landmarks. We employ the Alternating Direction Method (ADM) to solve our problem. Empirical studies on real-world datasets show that our method achieves superior classification performance over other state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2008.06883", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Erlang Redux: An Ansatz Method for Solving the M/M/m Queue", "author": "Neil J. Gunther", "pub_date": "Submitted on 16 Aug 2020", "abstract": "This exposition presents a novel approach to solving an M/M/m queue for the waiting time and the residence time. The motivation comes from an algebraic solution for the residence time of the M/M/1 queue. The key idea is the introduction of an ansatz transformation, defined in terms of the Erlang B function, that avoids the more opaque derivation based on applied probability theory. The only prerequisite is an elementary knowledge of the Poisson distribution, which is already necessary for understanding the M/M/1 queue. The approach described here supersedes our earlier approximate morphing transformation.", "pdf_url": "https://arxiv.org/pdf/2008.06823", "subject": "Performance (cs.PF)"},
{"title": "Obtaining Adjustable Regularization for Free via Iterate Averaging", "author": "Jingfeng Wu, Vladimir Braverman, Lin F. Yang", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Regularization for optimization is a crucial technique to avoid overfitting in machine learning. In order to obtain the best performance, we usually train a model by tuning the regularization parameters. It becomes costly, however, when a single round of training takes significant amount of time. Very recently, Neu and Rosasco show that if we run stochastic gradient descent (SGD) on linear regression problems, then by averaging the SGD iterates properly, we obtain a regularized solution. It left open whether the same phenomenon can be achieved for other optimization problems and algorithms. In this paper, we establish an averaging scheme that provably converts the iterates of SGD on an arbitrary strongly convex and smooth objective function to its regularized counterpart with an adjustable regularization parameter. Our approaches can be used for accelerated and preconditioned optimization methods as well. We further show that the same methods work empirically on more general optimization objectives including neural networks. In sum, we obtain adjustable regularization for free for a large class of optimization problems and resolve an open question raised by Neu and Rosasco.", "pdf_url": "https://arxiv.org/pdf/2008.06736", "subject": "Machine Learning (cs.LG)"},
{"title": "A VCG-based Fair Incentive Mechanism for Federated Learning", "author": "Mingshu Cong, Han Yu, Xi Weng, Jiabao Qu, Yang Liu, Siu Ming Yiu", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Federated learning (FL) has shown great potential for addressing the challenge of isolated data islands while preserving data privacy. It allows artificial intelligence (AI) models to be trained on locally stored data in a distributed manner. In order to build an ecosystem for FL to operate in a sustainable manner, it has to be economically attractive to data owners. This gives rise to the problem of FL incentive mechanism design, which aims to find the optimal organizational and payment structure for the federation in order to achieve a series of economic objectives. In this paper, we present a VCG-based FL incentive mechanism, named FVCG, specifically designed for incentivizing data owners to contribute all their data and truthfully report their costs in FL settings. It maximizes the social surplus and minimizes unfairness of the federation. We provide an implementation of FVCG with neural networks and theoretic proofs on its performance bounds. Extensive numerical experiment results demonstrated the effectiveness and economic reasonableness of FVCG.", "pdf_url": "https://arxiv.org/pdf/2008.06680", "subject": "Computer Science and Game Theory (cs.GT)"},
{"title": "Key principles for workforce upskilling via online learning: a learning analytics study of a professional course in additive manufacturing", "author": "Kylie Peppler, Joey Huang, Michael C. Richey, Michael Ginda, Katy B\u00f6rner, Haden Quinlan, A. John Hart", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Effective adoption of online platforms for teaching, learning, and skill development is essential to both academic institutions and workplaces. Adoption of online learning has been abruptly accelerated by COVID19 pandemic, drawing attention to research on pedagogy and practice for effective online instruction. Online learning requires a multitude of skills and resources spanning from learning management platforms to interactive assessment tools, combined with multimedia content, presenting challenges to instructors and organizations. This study focuses on ways that learning sciences and visual learning analytics can be used to design, and to improve, online workforce training in advanced manufacturing. Scholars and industry experts, educational researchers, and specialists in data analysis and visualization collaborated to study the performance of a cohort of 900 professionals enrolled in an online training course focused on additive manufacturing. The course was offered through MITxPro, MIT Open Learning is a professional learning organization which hosts in a dedicated instance of the edX platform. This study combines learning objective analysis and visual learning analytics to examine the relationships among learning trajectories, engagement, and performance. The results demonstrate how visual learning analytics was used for targeted course modification, and interpretation of learner engagement and performance, such as by more direct mapping of assessments to learning objectives, and to expected and actual time needed to complete each segment of the course. The study also emphasizes broader strategies for course designers and instructors to align course assignments, learning objectives, and assessment measures with learner needs and interests, and argues for a synchronized data infrastructure to facilitate effective just in time learning and continuous improvement of online courses.", "pdf_url": "https://arxiv.org/pdf/2008.06610", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "MatryODShka: Real-time 6DoF Video View Synthesis using Multi-Sphere Images", "author": "Benjamin Attal, Selena Ling, Aaron Gokaslan, Christian Richardt, James Tompkin", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We introduce a method to convert stereo 360\u00b0 (omnidirectional stereo) imagery into a layered, multi-sphere image representation for six degree-of-freedom (6DoF) rendering. Stereo 360\u00b0 imagery can be captured from multi-camera systems for virtual reality (VR), but lacks motion parallax and correct-in-all-directions disparity cues. Together, these can quickly lead to VR sickness when viewing content. One solution is to try and generate a format suitable for 6DoF rendering, such as by estimating depth. However, this raises questions as to how to handle disoccluded regions in dynamic scenes. Our approach is to simultaneously learn depth and disocclusions via a multi-sphere image representation, which can be rendered with correct 6DoF disparity and motion parallax in VR. This significantly improves comfort for the viewer, and can be inferred and rendered in real time on modern GPU hardware. Together, these move towards making VR video a more comfortable immersive medium.", "pdf_url": "https://arxiv.org/pdf/2008.06534", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Deterministic concurrent systems", "author": "Samy Abbes", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We introduce deterministic concurrent systems as a subclass of concurrent systems. Deterministic concurrent system are \"locally commutative\" concurrent systems. We prove that irreducible and deterministic concurrent systems have a unique probabilistic dynamics, and we characterise these systems by means of their Analytic combinatorics properties.", "pdf_url": "https://arxiv.org/pdf/2008.07233", "subject": "Combinatorics (math.CO)"},
{"title": "Physical Action Categorization using Signal Analysis and Machine Learning", "author": "Asad Mansoor Khan, Ayesha Sadiq, Sajid Gul Khawaja, Muhammad Usman Akram, Ali Saeed", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Daily life of thousands of individuals around the globe suffers due to physical or mental disability related to limb movement. The quality of life for such individuals can be made better by use of assistive applications and systems. In such scenario, mapping of physical actions from movement to a computer aided application can lead the way for solution. Surface Electromyography (sEMG) presents a non-invasive mechanism through which we can translate the physical movement to signals for classification and use in applications. In this paper, we propose a machine learning based framework for classification of 4 physical actions. The framework looks into the various features from different modalities which contribution from time domain, frequency domain, higher order statistics and inter channel statistics. Next, we conducted a comparative analysis of k-NN, SVM and ELM classifier using the feature set. Effect of different combinations of feature set has also been recorded. Finally, the classifier accuracy with SVM and 1-NN based classifier for a subset of features gives an accuracy of 95.21 and 95.83 respectively. Additionally, we have also proposed that dimensionality reduction by use of PCA leads to only a minor drop of less than 5.55% in accuracy while using only 9.22% of the original feature set. These finding are useful for algorithm designer to choose the best approach keeping in mind the resources available for execution of algorithm.", "pdf_url": "https://arxiv.org/pdf/2008.06971", "subject": "Signal Processing (eess.SP)"},
{"title": "Joint Policy Search for Multi-agent Collaboration with Imperfect Information", "author": "Yuandong Tian, Qucheng Gong, Tina Jiang", "pub_date": "Submitted on 14 Aug 2020", "abstract": "To learn good joint policies for multi-agent collaboration with imperfect information remains a fundamental challenge. While for two-player zero-sum games, coordinate-ascent approaches (optimizing one agent's policy at a time, e.g., self-play) work with guarantees, in multi-agent cooperative setting they often converge to sub-optimal Nash equilibrium. On the other hand, directly modeling joint policy changes in imperfect information game is nontrivial due to complicated interplay of policies (e.g., upstream updates affect downstream state reachability). In this paper, we show global changes of game values can be decomposed to policy changes localized at each information set, with a novel term named policy-change density. Based on this, we propose Joint Policy Search(JPS) that iteratively improves joint policies of collaborative agents in imperfect information games, without re-evaluating the entire game. On multi-agent collaborative tabular games, JPS is proven to never worsen performance and can improve solutions provided by unilateral approaches (e.g, CFR), outperforming algorithms designed for collaborative policy learning (e.g. BAD). Furthermore, for real-world games, JPS has an online form that naturally links with gradient updates. We test it to Contract Bridge, a 4-player imperfect-information game where a team of $2$ collaborates to compete against the other. In its bidding phase, players bid in turn to find a good contract through a limited information channel. Based on a strong baseline agent that bids competitive bridge purely through domain-agnostic self-play, JPS improves collaboration of team players and outperforms WBridge5, a championship-winning software, by $+0.63$ IMPs (International Matching Points) per board over 1k games, substantially better than previous SoTA ($+0.41$ IMPs/b). Note that $+0.1$ IMPs/b is regarded as a nontrivial improvement in Computer Bridge.", "pdf_url": "https://arxiv.org/pdf/2008.06495", "subject": "Machine Learning (cs.LG)"},
{"title": "Supervised Topological Maps", "author": "Francesco Mannella", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Controlling the internal representation space of a neural network is a desirable feature because it allows to generate new data in a supervised manner. In this paper we will show how this can be achieved while building a low-dimensional mapping of the input stream, by deriving a generalized algorithm starting from Self Organizing Maps (SOMs). SOMs are a kind of neural network which can be trained with unsupervised learning to produce a low-dimensional discretized mapping of the input space. They can be used for the generation of new data through backward propagation of interpolations made from the mapping grid. Unfortunately the final topology of the mapping space of a SOM is not known before learning, so interpolating new data in a supervised way is not an easy task. Here we will show a variation from the SOM algorithm consisting in constraining the update of prototypes so that it is also a function of the distance of its prototypes from extrinsically given targets in the mapping space. We will demonstrate how such variants, that we will call Supervised Topological Maps (STMs), allow for a supervised mapping where the position of internal representations in the mapping space is determined by the experimenter. Controlling the internal representation space in STMs reveals to be an easier task than what is currently done using other algorithms such as variational or adversarial autoencoders.", "pdf_url": "https://arxiv.org/pdf/2008.06395", "subject": "Machine Learning (cs.LG)"},
{"title": "Proving Almost-Sure Termination of Probabilistic Programs via Incremental Pruning", "author": "Krishnendu Chatterjee, Ehsan Kafshdar Goharshady, Petr Novotn\u00fd, Ji\u0159i Z\u00e1rev\u00facky, \u0110or\u0111e \u017dikeli\u0107", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The extension of classical imperative programs with real-valued random variables and random branching gives rise to probabilistic programs. The termination problem is one of the most fundamental liveness properties for such programs. The qualitative (aka almost-sure) termination problem asks whether a given program terminates with probability 1. Ranking functions provide a sound and complete approach for termination of non-probabilistic programs, and their extension to probabilistic programs is achieved via ranking supermartingales (RSMs). RSMs have been extended to lexicographic RSMs to handle programs with involved control-flow structure, as well as for compositional approach. There are two key limitations of the existing RSM-based approaches: First, the lexicographic RSM-based approach requires a strong nonnegativity assumption, which need not always be satisfied. The second key limitation of the existing RSM-based algorithmic approaches is that they rely on pre-computed invariants. The main drawback of relying on pre-computed invariants is the insufficiency-inefficiency trade-off: weak invariants might be insufficient for RSMs to prove termination, while using strong invariants leads to inefficiency in computing them. Our contributions are twofold: First, we show how to relax the strong nonnegativity condition and still provide soundness guarantee for almost-sure termination. Second, we present an incremental approach where the process of computing lexicographic RSMs proceeds by iterative pruning of parts of the program that were already shown to be terminating, in cooperation with a safety prover. In particular, our technique does not rely on strong pre-computed invariants. We present experimental results to show the applicability of our approach to examples of probabilistic programs from the literature.", "pdf_url": "https://arxiv.org/pdf/2008.06295", "subject": "Programming Languages (cs.PL)"},
{"title": "Challenges of Linking Organizational Information in Open Government Data to Knowledge Graphs", "author": "Jan Portisch, Omaima Fallatah, Sebastian Neumaier, Mohamad Yaser Jaradeh, Axel Polleres", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Open Government Data (OGD) is being published by various public administration organizations around the globe. Within the metadata of OGD data catalogs, the publishing organizations (1) are not uniquely and unambiguously identifiable and, even worse, (2) change over time, by public administration units being merged or restructured. In order to enable fine-grained analyses or searches on Open Government Data on the level of publishing organizations, linking those from OGD portals to publicly available knowledge graphs (KGs) such as Wikidata and DBpedia seems like an obvious solution. Still, as we show in this position paper, organization linking faces significant challenges, both in terms of available (portal) metadata and KGs in terms of data quality and completeness. We herein specifically highlight five main challenges, namely regarding (1) temporal changes in organizations and in the portal metadata, (2) lack of a base ontology for describing organizational structures and changes in public knowledge graphs, (3) metadata and KG data quality, (4) multilinguality, and (5) disambiguating public sector organizations. Based on available OGD portal metadata from the Open Data Portal Watch, we provide an in-depth analysis of these issues, make suggestions for concrete starting points on how to tackle them along with a call to the community to jointly work on these open challenges.", "pdf_url": "https://arxiv.org/pdf/2008.06232", "subject": "Computers and Society (cs.CY)"},
{"title": "First Step Towards Modeling Unbreakable Malware", "author": "Tiantian Ji, Binxing Fang, Xiang Cui, Zhongru Wang, Jiawen Diao, Tian Wang, Weiqiang Yu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Currently, the construction of concealed malicious code has become a trend, and attackers try to use this to hide their attack intentions. However, the building of stealthy malware is still unable to counter the reverse analysis of security experts. In response to this problem, this paper models a class of malware with \"unbreakable\" security attributes--UBM (UnBreakable Malware). We have systematically studied such threats from models, methods, experiments, evaluations, and defenses. Specifically, first, we conducted a formal definition and security attribute research on UBM. We proposed two key characteristics that must be met in order to achieve \"unbreakable\" security attributes and their corresponding evaluation quaternions. Second, we summarized and implemented four algorithms that can be used to construct UBM, and verified the \"unhackable\" security attributes based on the evaluation of the two key features. Furthermore, we completed the construction of UBM using the implementation of four verified algorithms and proved the practical applicability of UBM by calculating the volume increment and analyzing the actual counter defense capabilities. Finally, for UBM, a new threat to cyberspace, this article discusses possible defense measures and hopes to promote the establishment of a corresponding defense system.", "pdf_url": "https://arxiv.org/pdf/2008.06163", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Infinite Divisibility of Information", "author": "Cheuk Ting Li", "pub_date": "Submitted on 13 Aug 2020", "abstract": "We study an information analogue of infinitely divisible probability distributions, where the i.i.d. sum is replaced by the joint distribution of an i.i.d. sequence. A random variable $X$ is called informationally infinitely divisible if, for any $n\\ge1$, there exists an i.i.d. sequence of random variables $Z_{1},\\ldots,Z_{n}$ that contains the same information as $X$, i.e., there exists an injective function $f$ such that $X=f(Z_{1},\\ldots,Z_{n})$. While there does not exist informationally infinitely divisible discrete random variable, we show that any discrete random variable $X$ has a bounded multiplicative gap to infinite divisibility, that is, if we remove the injectivity requirement on $f$, then there exists i.i.d. $Z_{1},\\ldots,Z_{n}$ and $f$ satisfying $X=f(Z_{1},\\ldots,Z_{n})$, and the entropy satisfies $H(X)/n\\le H(Z_{1})\\le1.59H(X)/n+2.43$. We also study a new class of discrete probability distributions, called spectral infinitely divisible distributions, where we can remove the multiplicative gap $1.59$. Furthermore, we study the case where $X=(Y_{1},\\ldots,Y_{m})$ is itself an i.i.d. sequence, $m\\ge2$, for which the multiplicative gap $1.59$ can be replaced by $1+5\\sqrt{(\\log m)/m}$. This means that as $m$ increases, $(Y_{1},\\ldots,Y_{m})$ becomes closer to being spectral infinitely divisible in a uniform manner. This can be regarded as an information analogue of Kolmogorov's uniform theorem. Applications of our result include independent component analysis, distributed storage with a secrecy constraint, and distributed random number generation.", "pdf_url": "https://arxiv.org/pdf/2008.06092", "subject": "Information Theory (cs.IT)"},
{"title": "Homotopic Gradients of Generative Density Priors for MR Image Reconstruction", "author": "Cong Quan, Jinjie Zhou, Yuanzheng Zhu, Yang Chen, Shanshan Wang, Dong Liang, Qiegen Liu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Deep learning, particularly the generative model, has demonstrated tremendous potential to significantly speed up image reconstruction with reduced measurements recently. Rather than the existing generative models that often optimize the density priors, in this work, by taking advantage of the denoising score matching, homotopic gradients of generative density priors (HGGDP) are proposed for magnetic resonance imaging (MRI) reconstruction. More precisely, to tackle the low-dimensional manifold and low data density region issues in generative density prior, we estimate the target gradients in higher-dimensional space. We train a more powerful noise conditional score network by forming high-dimensional tensor as the network input at the training phase. More artificial noise is also injected in the embedding space. At the reconstruction stage, a homotopy method is employed to pursue the density prior, such as to boost the reconstruction performance. Experiment results imply the remarkable performance of HGGDP in terms of high reconstruction accuracy; only 10% of the k-space data can still generate images of high quality as effectively as standard MRI reconstruction with the fully sampled data.", "pdf_url": "https://arxiv.org/pdf/2008.06284", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Minimum-gain Pole Placement with Sparse Static Feedback", "author": "Vaibhav Katewa, Fabio Pasqualetti", "pub_date": "Submitted on 22 May 2018 ( ), last revised 14 Aug 2020 (this version, v2)", "abstract": "The minimum-gain eigenvalue assignment/pole placement problem (MGEAP) is a classical problem in LTI systems with static state feedback. In this paper, we study the MGEAP when the state feedback has arbitrary sparsity constraints. We formulate the sparse MGEAP problem as an equality-constrained optimization problem and present an analytical characterization of its locally optimal solution in terms of eigenvector matrices of the closed loop system. This result is used to provide a geometric interpretation of the solution of the non-sparse MGEAP, thereby providing additional insights for this classical problem. Further, we develop an iterative projected gradient descent algorithm to obtain local solutions for the sparse MGEAP using a parametrization based on the Sylvester equation. We present a heuristic algorithm to compute the projections, which also provides a novel method to solve the sparse EAP. Also, a relaxed version of the sparse MGEAP is presented and an algorithm is developed to obtain approximately sparse local solutions to the MGEAP. Finally, numerical studies are presented to compare the properties of the algorithms, which suggest that the proposed projection algorithm converges in most cases.", "pdf_url": "https://arxiv.org/pdf/1805.08762", "subject": "Optimization and Control (math.OC)"},
{"title": "An In-Depth Analysis of Ride-Hailing Travel Using a Large-scale Trip-Based Dataset", "author": "Jianhe Du, Hesham A. Rakha, Helena Breuer", "pub_date": "Submitted on 13 Aug 2020", "abstract": "With the rapid increase in ride-hailing (RH) use, a need to better understand and regulate the industry arises. This paper analyzes a year's worth of RH trip data from the Greater Chicago Area to study RH trip patterns. More than 104 million trips were analyzed. For trip rates, the results show that the total number of trips remained stable over the year, with pooled trips steadily decreasing from 20 to 9 percent. People tend to use RH more on weekends compared to weekdays. Specifically, weekend RH trip counts (per day) are, on average, 20 percent higher than weekday trip counts. The results of this work will help policy makers and transportation administrators better understand the nature of RH trips, which in turn allows for the design of a better regulation and guidance system for the ride-hailing industry.", "pdf_url": "https://arxiv.org/pdf/2008.06050", "subject": "Physics and Society (physics.soc-ph)"},
{"title": "Bilinear matrix equation characterizes Laplacian and distance matrices of weighted trees", "author": "Mikhail Goubko, Alexander Veremyev", "pub_date": "Submitted on 13 Aug 2020", "abstract": "It is known from the algebraic graph theory that if $L$ is the Laplacian matrix of some tree $G$ with a vertex degree sequence $\\vec{d}=(d_1, ..., d_n)^\\top$ and $D$ is its distance matrix, then $LD+2I=(2\\cdot\\vec{1}-\\vec{d})\\vec{1}^\\top$, where $\\vec{1}$ is an all-ones column vector. We prove that if this matrix identity holds for the Laplacian matrix of some graph $G$ with a degree sequence $\\vec{d}$ and for some matrix $D$, then $G$ is essentially a tree, and $D$ is its distance matrix. This result immediately generalizes to weighted graphs. If the matrix $D$ is symmetric, the lower triangular part of this matrix identity is redundant and can be omitted. Therefore, the above bilinear matrix equation in $L$, $D$, and $\\vec{d}$ characterizes trees in terms of their Laplacian and distance matrices. Applications to the extremal graph theory (especially, to topological index optimization and to optimal tree problems) and to road topology design are discussed.", "pdf_url": "https://arxiv.org/pdf/2008.06068", "subject": "Combinatorics (math.CO)"},
{"title": "MIXCAPS: A Capsule Network-based Mixture of Experts for Lung Nodule Malignancy Prediction", "author": "Parnian Afshar, Farnoosh Naderkhani, Anastasia Oikonomou, Moezedin Javad Rafiee, Arash Mohammadi, Konstantinos N. Plataniotis", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Lung diseases including infections such as Pneumonia, Tuberculosis, and novel Coronavirus (COVID-19), together with Lung Cancer are significantly widespread and are, typically, considered life threatening. In particular, lung cancer is among the most common and deadliest cancers with a low 5-year survival rate. Timely diagnosis of lung cancer is, therefore, of paramount importance as it can save countless lives. In this regard, deep learning radiomics solutions have the promise of extracting the most useful features on their own in an end-to-end fashion without having access to the annotated boundaries. Among different deep learning models, Capsule Networks are proposed to overcome shortcomings of the Convolutional Neural Networks (CNN) such as their inability to recognize detailed spatial relations. Capsule networks have so far shown satisfying performance in medical imaging problems. Capitalizing on their success, in this study, we propose a novel capsule network-based mixture of experts, referred to as the MIXCAPS. The proposed MIXCAPS architecture takes advantage of not only the capsule network's capabilities to handle small datasets, but also automatically splitting dataset through a convolutional gating network. MIXCAPS enables capsule network experts to specialize on different subsets of the data. Our results show that MIXCAPS outperforms a single capsule network and a mixture of CNNs, with an accuracy of 92.88%, sensitivity of 93.2%, specificity of 92.3% and area under the curve of 0.963. Our experiments also show that there is a relation between the gate outputs and a couple of hand-crafted features, illustrating explainable nature of the proposed MIXCAPS. To further evaluate generalization capabilities of the proposed MIXCAPS architecture, additional experiments on a brain tumor dataset are performed showing potentials of MIXCAPS for detection of tumors related to other organs.", "pdf_url": "https://arxiv.org/pdf/2008.06072", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Technical Considerations when using Verasonics Research Ultrasound Platform for Developing a Photoacoustic Imaging System", "author": "Karl Kratkiewicz, Rayyan Manwara, Yang Zhou, Moein Mozaffarzadeh, Kamran Avanaki", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Photoacoustic imaging (PAI) is an emerging functional and molecular imaging technology that has attracted much attention in the past decade. Recently, many researchers have used the Vantage Verasonics research system for simultaneous ultrasound (US) and photoacoustic (PA) imaging. This was the motivation to write on the details of US/PA imaging system implementation and characterization using Verasonics platform. We describe the subtle details of US/PA imaging system setup, study the performance parameters of the system, and explain sequencing of the US/PA signal generation and signal amplification as well as the details required for efficient use of the hardware of the system and data processing protocols. We focused on linear-array based PAI due to its popularity and simple setup, as well as its high potential for clinical translatability. We have shown the sequencing of the US/PA signal generation, signal amplification, and related data processing protocols. A step-by-step guideline to develop and characterize PAI system using Vantage 128 has been presented. Some of the limitations of the vantage system are also listed. Photoacoustic imaging is a complement to the already established US imaging technique and may significantly increase its scope of application in diagnostic imaging and therapeutic monitoring. Combining with commercial medical US systems, the development of PAI can be accelerated by taking advantage of US image reconstruction and processing. With the information we presented in the body of this review and the four appendices, we described most of the experimental considerations one should know when working with the Vantage system for PAI tests.", "pdf_url": "https://arxiv.org/pdf/2008.06086", "subject": "Applied Physics (physics.app-ph)"},
{"title": "Synthesizing Property & Casualty Ratemaking Datasets using Generative Adversarial Networks", "author": "Marie-Pier Cote, Brian Hartman, Olivier Mercier, Joshua Meyers, Jared Cummings, Elijah Harmon", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Due to confidentiality issues, it can be difficult to access or share interesting datasets for methodological development in actuarial science, or other fields where personal data are important. We show how to design three different types of generative adversarial networks (GANs) that can build a synthetic insurance dataset from a confidential original dataset. The goal is to obtain synthetic data that no longer contains sensitive information but still has the same structure as the original dataset and retains the multivariate relationships. In order to adequately model the specific characteristics of insurance data, we use GAN architectures adapted for multi-categorical data: a Wassertein GAN with gradient penalty (MC-WGAN-GP), a conditional tabular GAN (CTGAN) and a Mixed Numerical and Categorical Differentially Private GAN (MNCDP-GAN). For transparency, the approaches are illustrated using a public dataset, the French motor third party liability data. We compare the three different GANs on various aspects: ability to reproduce the original data structure and predictive models, privacy, and ease of use. We find that the MC-WGAN-GP synthesizes the best data, the CTGAN is the easiest to use, and the MNCDP-GAN guarantees differential privacy.", "pdf_url": "https://arxiv.org/pdf/2008.06110", "subject": "Machine Learning (stat.ML)"},
{"title": "LSTM Acoustic Models Learn to Align and Pronounce with Graphemes", "author": "Arindrima Datta, Guanlong Zhao, Bhuvana Ramabhadran, Eugene Weinstein", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Automated speech recognition coverage of the world's languages continues to expand. However, standard phoneme based systems require handcrafted lexicons that are difficult and expensive to obtain. To address this problem, we propose a training methodology for a grapheme-based speech recognizer that can be trained in a purely data-driven fashion. Built with LSTM networks and trained with the cross-entropy loss, the grapheme-output acoustic models we study are also extremely practical for real-world applications as they can be decoded with conventional ASR stack components such as language models and FST decoders, and produce good quality audio-to-grapheme alignments that are useful in many speech applications. We show that the grapheme models are competitive in WER with their phoneme-output counterparts when trained on large datasets, with the advantage that grapheme models do not require explicit linguistic knowledge as an input. We further compare the alignments generated by the phoneme and grapheme models to demonstrate the quality of the pronunciations learnt by them using four Indian languages that vary linguistically in spoken and written forms.", "pdf_url": "https://arxiv.org/pdf/2008.06121", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Sequential Monte Carlo for Sampling Balanced and Compact Redistricting Plans", "author": "Cory McCartan, Kosuke Imai", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Random sampling of graph partitions under constraints has become a popular tool for evaluating legislative redistricting plans. Analysts detect partisan gerrymandering by comparing a proposed redistricting plan with an ensemble of sampled alternative plans. For successful application, sampling methods must scale to large maps with many districts, incorporate realistic legal constraints, and accurately sample from a selected target distribution. Unfortunately, most existing methods struggle in at least one of these three areas. We present a new Sequential Monte Carlo (SMC) algorithm that draws representative redistricting plans from a realistic target distribution of choice. Because it yields nearly independent samples, the SMC algorithm can efficiently explore the relevant space of redistricting plans than the existing Markov chain Monte Carlo algorithms that yield dependent samples. Our algorithm can simultaneously incorporate several constraints commonly imposed in real-world redistricting problems, including equal population, compactness, and preservation of administrative boundaries. We validate the accuracy of the proposed algorithm by using a small map where all redistricting plans can be enumerated. We then apply the SMC algorithm to evaluate the partisan implications of several maps submitted by relevant parties in a recent high-profile redistricting case in the state of Pennsylvania. Open-source software is available for implementing the proposed methodology.", "pdf_url": "https://arxiv.org/pdf/2008.06131", "subject": "Applications (stat.AP)"},
{"title": "Landmark detection in Cardiac Magnetic Resonance Imaging Using A Convolutional Neural Network", "author": "Hui Xue, Jessica Artico, Marianna Fontana, James C Moon, Rhodri H Davies, Peter Kellman", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Purpose: To develop a convolutional neural network (CNN) solution for robust landmark detection in cardiac MR images. Methods: This retrospective study included cine, LGE and T1 mapping scans from two hospitals. The training set included 2,329 patients and 34,019 images. A hold-out test set included 531 patients and 7,723 images. CNN models were developed to detect two mitral valve plane and apical points on long-axis (LAX) images. On short-axis (SAX) images, anterior and posterior RV insertion points and LV center were detected. Model outputs were compared to manual labels by two operators for accuracy with a t-test for statistical significance. The trained model was deployed to MR scanners. Results: For the LAX images, success detection was 99.8% for cine, 99.4% for LGE. For the SAX, success rate was 96.6%, 97.6% and 98.9% for cine, LGE and T1-mapping. The L2 distances between model and manual labels were 2 to 3.5 mm, indicating close agreement between model landmarks to manual labels. No significant differences were found for the anterior RV insertion angle and LV length by the models and operators for all views and imaging sequences. Model inference on MR scanner took 610ms/5.6s on GPU/CPU, respectively, for a typical cardiac cine series. Conclusions: This study developed, validated and deployed a CNN solution for robust landmark detection in both long and short-axis CMR images for cine, LGE and T1 mapping sequences, with the accuracy comparable to the inter-operator variation.", "pdf_url": "https://arxiv.org/pdf/2008.06142", "subject": "Image and Video Processing (eess.IV)"},
{"title": "End-to-End Trainable Self-Attentive Shallow Network for Text-Independent Speaker Verification", "author": "Hyeonmook Park, Jungbae Park, Sang Wan Lee", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Generalized end-to-end (GE2E) model is widely used in speaker verification (SV) fields due to its expandability and generality regardless of specific languages. However, the long-short term memory (LSTM) based on GE2E has two limitations: First, the embedding of GE2E suffers from vanishing gradient, which leads to performance degradation for very long input sequences. Secondly, utterances are not represented as a properly fixed dimensional vector. In this paper, to overcome issues mentioned above, we propose a novel framework for SV, end-to-end trainable self-attentive shallow network (SASN), incorporating a time-delay neural network (TDNN) and a self-attentive pooling mechanism based on the self-attentive x-vector system during an utterance embedding phase. We demonstrate that the proposed model is highly efficient, and provides more accurate speaker verification than GE2E. For VCTK dataset, with just less than half the size of GE2E, the proposed model showed significant performance improvement over GE2E of about 63%, 67%, and 85% in EER (Equal error rate), DCF (Detection cost function), and AUC (Area under the curve), respectively. Notably, when the input length becomes longer, the DCF score improvement of the proposed model is about 17 times greater than that of GE2E.", "pdf_url": "https://arxiv.org/pdf/2008.06146", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Complexity aspects of local minima and related notions", "author": "Amir Ali Ahmadi, Jeffrey Zhang", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We consider the notions of (i) critical points, (ii) second-order points, (iii) local minima, and (iv) strict local minima for multivariate polynomials. For each type of point, and as a function of the degree of the polynomial, we study the complexity of deciding (1) if a given point is of that type, and (2) if a polynomial has a point of that type. Our results characterize the complexity of these two questions for all degrees left open by prior literature. Our main contributions reveal that many of these questions turn out to be tractable for cubic polynomials. In particular, we present an efficiently-checkable necessary and sufficient condition for local minimality of a point for a cubic polynomial. We also show that a local minimum of a cubic polynomial can be efficiently found by solving semidefinite programs of size linear in the number of variables. By contrast, we show that it is strongly NP-hard to decide if a cubic polynomial has a critical point. We also prove that the set of second-order points of any cubic polynomial is a spectrahedron, and conversely that any spectrahedron is the projection of the set of second-order points of a cubic polynomial. In our final section, we briefly present a potential application of finding local minima of cubic polynomials to the design of a third-order Newton method.", "pdf_url": "https://arxiv.org/pdf/2008.06148", "subject": "Optimization and Control (math.OC)"},
{"title": "Interpretation of Brain Morphology in Association to Alzheimer's Disease Dementia Classification Using Graph Convolutional Networks on Triangulated Meshes", "author": "Emanuel A. Azcona, Pierre Besson, Yunan Wu, Arjun Punjabi, Adam Martersteck, Amil Dravid, Todd B. Parrish, S. Kathleen Bandt, Aggelos K. Katsaggelos", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v3)", "abstract": "We propose a mesh-based technique to aid in the classification of Alzheimer's disease dementia (ADD) using mesh representations of the cortex and subcortical structures. Deep learning methods for classification tasks that utilize structural neuroimaging often require extensive learning parameters to optimize. Frequently, these approaches for automated medical diagnosis also lack visual interpretability for areas in the brain involved in making a diagnosis. This work: (a) analyzes brain shape using surface information of the cortex and subcortical structures, (b) proposes a residual learning framework for state-of-the-art graph convolutional networks which offer a significant reduction in learnable parameters, and (c) offers visual interpretability of the network via class-specific gradient information that localizes important regions of interest in our inputs. With our proposed method leveraging the use of cortical and subcortical surface information, we outperform other machine learning methods with a 96.35% testing accuracy for the ADD vs. healthy control problem. We confirm the validity of our model by observing its performance in a 25-trial Monte Carlo cross-validation. The generated visualization maps in our study show correspondences with current knowledge regarding the structural localization of pathological changes in the brain associated to dementia of the Alzheimer's type.", "pdf_url": "https://arxiv.org/pdf/2008.06151", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Unsupervised Image Restoration Using Partially Linear Denoisers", "author": "Rihuan Ke, Carola-Bibiane Sch\u00f6nlieb", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Deep neural network based methods are the state of the art in various image restoration problems. Standard supervised learning frameworks require a set of noisy measurement and clean image pairs for which a distance between the output of the restoration model and the ground truth, clean images is minimized. The ground truth images, however, are often unavailable or very expensive to acquire in real-world applications. We circumvent this problem by proposing a class of structured denoisers that can be decomposed as the sum of a nonlinear image-dependent mapping, a linear noise-dependent term and a small residual term. We show that these denoisers can be trained with only noisy images under the condition that the noise has zero mean and known variance. The exact distribution of the noise, however, is not assumed to be known. We show the superiority of our approach for image denoising, and demonstrate its extension to solving other restoration problems such as blind deblurring where the ground truth is not available. Our method outperforms some recent unsupervised and self-supervised deep denoising models that do not require clean images for their training. For blind deblurring problems, the method, using only one noisy and blurry observation per image, reaches a quality not far away from its fully supervised counterparts on a benchmark dataset.", "pdf_url": "https://arxiv.org/pdf/2008.06164", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Weakly-supervised Learning for Single-step Quantitative Susceptibility Mapping", "author": "Juan Liu, Kevin M Koch", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Quantitative susceptibility mapping (QSM) utilizes MRI phase information to estimate tissue magnetic susceptibility. The generation of QSM requires solving ill-posed background field removal (BFR) and field-to-source inversion problems. Because current QSM techniques struggle to generate reliable QSM in clinical contexts, QSM clinical translation is greatly hindered. Recently, deep learning (DL) approaches for QSM reconstruction have shown impressive performance. Due to inherent non-existent ground-truth, these DL techniques use either calculation of susceptibility through multiple orientation sampling (COSMOS) maps or synthetic data for training, which are constrained by the availability and accuracy of COSMOS maps or domain shift when training data and testing data have different domains. To address these limitations, we propose a weakly-supervised single-step QSM reconstruction method, denoted as wTFI, to directly reconstruct QSM from the total field without BFR. wTFI uses the BFR method RESHARP local fields as supervision to perform a multi-task learning of local tissue fields and QSM, and is capable of recovering magnetic susceptibility estimates near the edges of the brain where are eroded in RESHARP and realize whole brain QSM estimation. Quantitative and qualitative evaluation shows that wTFI can generate high-quality local field and susceptibility maps in a variety of neuroimaging contexts.", "pdf_url": "https://arxiv.org/pdf/2008.06187", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Adaptable Multi-Domain Language Model for Transformer ASR", "author": "Taewoo Lee, Min-Joong Lee, Tae Gyoon Kang, Seokyeoung Jung, Minseok Kwon, Yeona Hong, Jungin Lee, Kyoung-Gu Woo, Ho-Gyeong Kim, Jiseung Jeong, Jihyun Lee, Hosik Lee, Young Sang Choi", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We propose an adapter based multi-domain Transformer based language model (LM) for Transformer ASR. The model consists of a big size common LM and small size adapters. The model can perform multi-domain adaptation with only the small size adapters and its related layers. The proposed model can reuse the full fine-tuned LM which is fine-tuned using all layers of an original model. The proposed LM can be expanded to new domains by adding about 2% of parameters for a first domain and 13% parameters for after second domain. The proposed model is also effective in reducing the model maintenance cost because it is possible to omit the costly and time-consuming common LM pre-training process. Using proposed adapter based approach, we observed that a general LM with adapter can outperform a dedicated music domain LM in terms of word error rate (WER).", "pdf_url": "https://arxiv.org/pdf/2008.06208", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Neural Network-based Automatic Factor Construction", "author": "Jie Fang, Jianwu Lin, Shutao Xia, Yong Jiang, Zhikang Xia, Xiang Liu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Instead of conducting manual factor construction based on traditional and behavioural finance analysis, academic researchers and quantitative investment managers have leveraged Genetic Programming (GP) as an automatic feature construction tool in recent years, which builds reverse polish mathematical expressions from trading data into new factors. However, with the development of deep learning, more powerful feature extraction tools are available. This paper proposes Neural Network-based Automatic Factor Construction (NNAFC), a tailored neural network framework that can automatically construct diversified financial factors based on financial domain knowledge and a variety of neural network structures. The experiment results show that NNAFC can construct more informative and diversified factors than GP, to effectively enrich the current factor pool. For the current market, both fully connected and recurrent neural network structures are better at extracting information from financial time series than convolution neural network structures. Moreover, new factors constructed by NNAFC can always improve the return, Sharpe ratio, and the max draw-down of a multi-factor quantitative investment strategy due to their introducing more information and diversification to the existing factor pool.", "pdf_url": "https://arxiv.org/pdf/2008.06225", "subject": "Statistical Finance (q-fin.ST)"},
{"title": "A novel three party Quantum secret sharing scheme based on Bell state sequential measurements with application in quantum image sharing", "author": "Farhan Musanna, Sanjeev Kumar", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this work, we present a quantum secret sharing scheme based on Bell state entanglement and sequential projection measurements. The protocol verifies the $n$ out of $n$ scheme and supports the aborting of the protocol in case all the parties do not divulge in their valid measurement outcomes. The operator-qubit pair forms an integral part of the scheme determining the classical secret to be shared. The protocol is robust enough to neutralize any eavesdropping on a particular qubit of the dealer. The experimental demonstration of the scheme is done on IBM-QE cloud platform with backends \\texttt{IBMQ\\_16\\_Melbourne} and \\texttt{IBMQ\\_QASM\\_SIMULATOR\\_V0.1.547} simulator. The security analysis performed on the scheme and the comparative analysis supports our claim of a stringent and an efficient scheme as compared to some recent quantum and semi-quantum techniques of secret sharing.", "pdf_url": "https://arxiv.org/pdf/2008.06228", "subject": "Quantum Physics (quant-ph)"},
{"title": "The Impact of Label Noise on a Music Tagger", "author": "Katharina Prinz, Arthur Flexer, Gerhard Widmer", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We explore how much can be learned from noisy labels in audio music tagging. Our experiments show that carefully annotated labels result in highest figures of merit, but even high amounts of noisy labels contain enough information for successful learning. Artificial corruption of curated data allows us to quantize this contribution of noisy labels.", "pdf_url": "https://arxiv.org/pdf/2008.06273", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Balancing Accuracy and Complexity in Optimisation Models of Distributed Energy Systems and Microgrids: A Review", "author": "Ishanki A. De Mel, Oleksiy V. Klymenko, Michael Short", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Optimisation and simulation models presented in literature for the design and operation of distributed energy systems (DES) often exclude the inherent nonlinearities related to power flow and generation and storage units, to maintain an accuracy-complexity balance. Such models may provide sub-optimal or even infeasible designs and dispatch schedules. In DES, optimal power flow (OPF) is often treated as a standalone problem, consisting of highly nonlinear, nonconvex constraints related to the underlying distribution network. This aspect of the optimisation problem has often been overlooked by researchers in the process systems and optimisation area. In this review we address the disparity between OPF and DES models, highlighting the importance of including elements of OPF in DES design and operational models to obtain feasible designs and operational schedules. We identify a subset of models that contribute to bridging this gap and provide recommendations for future work based on the different optimisation approaches. We also highlight simulation tools and popular software packages with OPF capabilities that can be utilised alongside DES optimisation models. Detailed representation of commonly used technologies within DES optimisation models is also discussed. The review is aimed at a multidisciplinary audience of researchers and stakeholders who are interested in modelling DES to support the development of more robust and accurate optimisation models for the future.", "pdf_url": "https://arxiv.org/pdf/2008.06278", "subject": "Optimization and Control (math.OC)"},
{"title": "Provable More Data Hurt in High Dimensional Least Squares Estimator", "author": "Zeng Li, Chuanlong Xie, Qinwen Wang", "pub_date": "Submitted on 14 Aug 2020", "abstract": "This paper investigates the finite-sample prediction risk of the high-dimensional least squares estimator. We derive the central limit theorem for the prediction risk when both the sample size and the number of features tend to infinity. Furthermore, the finite-sample distribution and the confidence interval of the prediction risk are provided. Our theoretical results demonstrate the sample-wise nonmonotonicity of the prediction risk and confirm \"more data hurt\" phenomenon.", "pdf_url": "https://arxiv.org/pdf/2008.06296", "subject": "Machine Learning (stat.ML)"},
{"title": "Feature Selection Methods for Cost-Constrained Classification in Random Forests", "author": "Rudolf Jagdhuber, Michel Lang, J\u00f6rg Rahnenf\u00fchrer", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 17 Aug 2020 (this version, v2)", "abstract": "Cost-sensitive feature selection describes a feature selection problem, where features raise individual costs for inclusion in a model. These costs allow to incorporate disfavored aspects of features, e.g. failure rates of as measuring device, or patient harm, in the model selection process. Random Forests define a particularly challenging problem for feature selection, as features are generally entangled in an ensemble of multiple trees, which makes a post hoc removal of features infeasible. Feature selection methods therefore often either focus on simple pre-filtering methods, or require many Random Forest evaluations along their optimization path, which drastically increases the computational complexity. To solve both issues, we propose Shallow Tree Selection, a novel fast and multivariate feature selection method that selects features from small tree structures. Additionally, we also adapt three standard feature selection algorithms for cost-sensitive learning by introducing a hyperparameter-controlled benefit-cost ratio criterion (BCR) for each method. In an extensive simulation study, we assess this criterion, and compare the proposed methods to multiple performance-based baseline alternatives on four artificial data settings and seven real-world data settings. We show that all methods using a hyperparameterized BCR criterion outperform the baseline alternatives. In a direct comparison between the proposed methods, each method indicates strengths in certain settings, but no one-fits-all solution exists. On a global average, we could identify preferable choices among our BCR based methods. Nevertheless, we conclude that a practical analysis should never rely on a single method only, but always compare different approaches to obtain the best results.", "pdf_url": "https://arxiv.org/pdf/2008.06298", "subject": "Machine Learning (stat.ML)"},
{"title": "An Exact Quantum Query Algorithm Beyond Parity using Maiorana-McFarland (MM) type Bent functions", "author": "Chandra Sekhar Mukherjee, Subhamoy Maitra", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 17 Aug 2020 (this version, v2)", "abstract": "The Exact Quantum Query model is the least explored query model, and almost all of the functions for which non-trivial query algorithms exist are symmetric in nature. In this paper we explore the Maiorana-McFarland(MM) type Bent functions, defined on all even $n$ variables. The (classical) Deterministic Query Complexity ($D(f)$) of all functions in this class is $n$. In this regard we construct an $\\frac{n}{2} + \\lceil \\frac{n}{8} \\rceil$ query exact quantum algorithm that is not a parity decision tree and evaluates a non-symmetric subclass of MM type Bent functions on $n$ variables consisting of $\\left(2^{\\lfloor \\frac{n}{4} \\rfloor}!\\right)\\left(2^{\\lceil \\frac{n}{4} \\rceil}!\\right) 2^{2^{\\lfloor \\frac{n}{4} \\rfloor}}$ functions. Finally we also extend this technique for functions defined on odd values of $n$ using the Bent concatenation method. To the best of our knowledge, this is the first algorithm beyond parity for a general class of non-symmetric functions.", "pdf_url": "https://arxiv.org/pdf/2008.06317", "subject": "Quantum Physics (quant-ph)"},
{"title": "Automated detection and quantification of COVID-19 airspace disease on chest radiographs: A novel approach achieving radiologist-level performance using a CNN trained on digital reconstructed radiographs (DRRs) from CT-based ground-truth", "author": "Eduardo Mortani Barbosa Jr., Warren B. Gefter, Rochelle Yang, Florin C. Ghesu, Siqi Liu, Boris Mailhe, Awais Mansoor, Sasa Grbic, Sebastian Piat, Guillaume Chabin, Vishwanath R S., Abishek Balachandran, Sebastian Vogt, Valentin Ziebandt, Steffen Kappler, Dorin Comaniciu", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Purpose: To leverage volumetric quantification of airspace disease (AD) derived from a superior modality (CT) serving as ground truth, projected onto digitally reconstructed radiographs (DRRs) to: 1) train a convolutional neural network to quantify airspace disease on paired CXRs; and 2) compare the DRR-trained CNN to expert human readers in the CXR evaluation of patients with confirmed COVID-19. Materials and Methods: We retrospectively selected a cohort of 86 COVID-19 patients (with positive RT-PCR), from March-May 2020 at a tertiary hospital in the northeastern USA, who underwent chest CT and CXR within 48 hrs. The ground truth volumetric percentage of COVID-19 related AD (POv) was established by manual AD segmentation on CT. The resulting 3D masks were projected into 2D anterior-posterior digitally reconstructed radiographs (DRR) to compute area-based AD percentage (POa). A convolutional neural network (CNN) was trained with DRR images generated from a larger-scale CT dataset of COVID-19 and non-COVID-19 patients, automatically segmenting lungs, AD and quantifying POa on CXR. CNN POa results were compared to POa quantified on CXR by two expert readers and to the POv ground-truth, by computing correlations and mean absolute errors. Results: Bootstrap mean absolute error (MAE) and correlations between POa and POv were 11.98% [11.05%-12.47%] and 0.77 [0.70-0.82] for average of expert readers, and 9.56%-9.78% [8.83%-10.22%] and 0.78-0.81 [0.73-0.85] for the CNN, respectively. Conclusion: Our CNN trained with DRR using CT-derived airspace quantification achieved expert radiologist level of accuracy in the quantification of airspace disease on CXR, in patients with positive RT-PCR for COVID-19.", "pdf_url": "https://arxiv.org/pdf/2008.06330", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Integrating uncertainty in deep neural networks for MRI based stroke analysis", "author": "Lisa Herzog, Elvis Murina, Oliver D\u00fcrr, Susanne Wegener, Beate Sick", "pub_date": "Submitted on 13 Aug 2020", "abstract": "At present, the majority of the proposed Deep Learning (DL) methods provide point predictions without quantifying the models uncertainty. However, a quantification of the reliability of automated image analysis is essential, in particular in medicine when physicians rely on the results for making critical treatment decisions. In this work, we provide an entire framework to diagnose ischemic stroke patients incorporating Bayesian uncertainty into the analysis procedure. We present a Bayesian Convolutional Neural Network (CNN) yielding a probability for a stroke lesion on 2D Magnetic Resonance (MR) images with corresponding uncertainty information about the reliability of the prediction. For patient-level diagnoses, different aggregation methods are proposed and evaluated, which combine the single image-level predictions. Those methods take advantage of the uncertainty in image predictions and report model uncertainty at the patient-level. In a cohort of 511 patients, our Bayesian CNN achieved an accuracy of 95.33% at the image-level representing a significant improvement of 2% over a non-Bayesian counterpart. The best patient aggregation method yielded 95.89% of accuracy. Integrating uncertainty information about image predictions in aggregation models resulted in higher uncertainty measures to false patient classifications, which enabled to filter critical patient diagnoses that are supposed to be closer examined by a medical doctor. We therefore recommend using Bayesian approaches not only for improved image-level prediction and uncertainty estimation but also for the detection of uncertain aggregations at the patient-level.", "pdf_url": "https://arxiv.org/pdf/2008.06332", "subject": "Image and Video Processing (eess.IV)"},
{"title": "On the finite representation of group equivariant operators via permutant measures", "author": "Stefano Botteghi, Martina Brasini, Patrizio Frosini, Nicola Quercioli", "pub_date": "Submitted on 7 Aug 2020", "abstract": "The study of $G$-equivariant operators is of great interest to explain and understand the architecture of neural networks. In this paper we show that each linear $G$-equivariant operator can be produced by a suitable permutant measure, provided that the group $G$ transitively acts on a finite signal domain $X$. This result makes available a new method to build linear $G$-equivariant operators in the finite setting.", "pdf_url": "https://arxiv.org/pdf/2008.06340", "subject": "Group Theory (math.GR)"},
{"title": "Probabilistic Cellular Automata for Granular Media in Video Games", "author": "Jonathan Devlin, Micah D. Schuster", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Granular materials are very common in the everyday world. Media such as sand, soil, gravel, food stuffs, pharmaceuticals, etc. all have similar irregular flow since they are composed of numerous small solid particles. In video games, simulating these materials increases immersion and can be used for various game mechanics. Computationally, full scale simulation is not typically feasible except on the most powerful hardware and tends to be reduced in priority to favor other, more integral, gameplay features. Here we study the computational and qualitative aspects of side profile flow of sand-like particles using cellular automata (CA). Our CA uses a standard square lattice that updates via a custom, modified Margolus neighborhood. Each update occurs using a set of probabilistic transitions that can be tuned to simulate friction between particles. We focus on the look of the sandpile structure created from an hourglass shape over time using different transition probabilities and the computational impact of such a simulation.", "pdf_url": "https://arxiv.org/pdf/2008.06341", "subject": "Cellular Automata and Lattice Gases (nlin.CG)"},
{"title": "Spatiotemporal Prediction of COVID--19 Mortality and Risk Assessment", "author": "A. Torres-Signes, M. P. Fr\u00edas, M. D. Ruiz-Medina", "pub_date": "Submitted on 7 Aug 2020", "abstract": "This paper presents a multivariate functional data statistical approach, for spatiotemporal prediction of COVID-19 mortality counts. Specifically, spatial heterogeneous nonlinear parametric functional regression trend model fitting is first implemented. Classical and Bayesian infinite-dimensional log-Gaussian linear residual correlation analysis is then applied. The nonlinear regression predictor of the mortality risk is combined with the plug-in predictor of the multiplicative error term. An empirical model ranking, based on random K-fold validation, is established for COVID-19 mortality risk forecasting and assessment, involving Machine Learning (ML) models, and the adopted Classical and Bayesian semilinear estimation approach. This empirical analysis also determines the ML models favored by the spatial multivariate Functional Data Analysis (FDA) framework. The results could be extrapolated to other countries.", "pdf_url": "https://arxiv.org/pdf/2008.06344", "subject": "Machine Learning (stat.ML)"},
{"title": "A study of uncompensated latency in ADS-B reports", "author": "Michelle George, Saurav Tuladhar, Siva Sivananthan", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The total latency (TL) in ADS-B is the difference between the true TOA of the original position measured by the onboard GPS and the TOA in the ADS-B report at the GS. We processed the ADS-B reports extracted from live-data recorded at the Chicago to produce the results in this report. We observed that 99% of aircraft in our data set were broadcasting in non-UTC coupled mode. For these aircraft, STARS exclusively used ADS-B reports to update tracks when available. The calculated ULs for the non-UTC coupled ADS-B reports were well within the budget (-200 ms to +400 ms) allowed by the DO-260B MOPS. Moreover, the mean latencies from both methods were less than +/-50 ms. The latencies obtained from the MTPES method were observed to be in close agreement with the means from the ATPE method. About 1% of aircraft were broadcasting in UTC coupled mode. The reports from these aircraft were identified to have a non-compliant link version, causing STARS to reject these reports for tracking. Moreover, the reported position and TOA were found to be unsynchronized, which conflicts with the MOPS requirement for UTC coupled operation.", "pdf_url": "https://arxiv.org/pdf/2008.06352", "subject": "Signal Processing (eess.SP)"},
{"title": "Semi-supervised learning using teacher-student models for vocal melody extraction", "author": "Sangeun Kum, Jing-Hua Lin, Li Su, Juhan Nam", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The lack of labeled data is a major obstacle in many music information retrieval tasks such as melody extraction, where labeling is extremely laborious or costly. Semi-supervised learning (SSL) provides a solution to alleviate the issue by leveraging a large amount of unlabeled data. In this paper, we propose an SSL method using teacher-student models for vocal melody extraction. The teacher model is pre-trained with labeled data and guides the student model to make identical predictions given unlabeled input in a self-training setting. We examine three setups of teacher-student models with different data augmentation schemes and loss functions. Also, considering the scarcity of labeled data in the test phase, we artificially generate large-scale testing data with pitch labels from unlabeled data using an analysis-synthesis method. The results show that the SSL method significantly increases the performance against supervised learning only and the improvement depends on the teacher-student models, the size of unlabeled data, the number of self-training iterations, and other training details. We also find that it is essential to ensure that the unlabeled audio has vocal parts. Finally, we show that the proposed SSL method enables a baseline convolutional recurrent neural network model to achieve performance comparable to state-of-the-arts.", "pdf_url": "https://arxiv.org/pdf/2008.06358", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Comparison and Application of non-Conforming Mesh Models for Flow in Fractured Porous Media using dual {L}agrange multipliers", "author": "Patrick Zulian, Philipp Sch\u00e4dle, Liudmila Karagyaur, Maria Nestola", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Geological settings with reservoir characteristics include fractures with different material and geometrical properties. Hence, numerical simulations in applied geophysics demands for computational frameworks which efficiently allow to integrate various fracture geometries in a porous medium matrix. This study presents a modeling approach for single-phase flow in fractured porous media and its application to different types of non-conforming mesh models. We propose a combination of the Lagrange multiplier method with variational transfer to allow for complex non-conforming geometries as well as hybrid- and equi-dimensional models and discretizations of flow through fractured porous media. The variational transfer is based on the $L^2$-projection and enables an accurate and highly efficient parallel projection of fields between non-conforming meshes (e.g.,\\ between fracture and porous matrix domain). We present the different techniques as a unified mathematical framework with a practical perspective. By means of numerical examples we discuss both, performance and applicability of the particular strategies. Comparisons of finite element simulation results to widely adopted 2D benchmark cases show good agreement and the dual Lagrange multiplier spaces show good performance. In an extension to 3D fracture networks, we first provide complementary results to a recently developed benchmark case, before we explore a complex scenario which leverages the different types of fracture meshes. Complex and highly conductive fracture networks are found more suitable in combination with embedded hybrid-dimensional fractures. However, thick and blocking fractures are better approximated by equi-dimensional embedded fractures and the equi-dimensional mortar method, respectively.", "pdf_url": "https://arxiv.org/pdf/2008.06360", "subject": "Computational Physics (physics.comp-ph)"},
{"title": "Fan-out and Fan-in properties of superconducting neuromorphic circuits", "author": "M. L. Schneider, K. Segall", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Neuromorphic computing has the potential to further the success of software-based artificial neural networks (ANNs) by designing hardware from a different perspective. Current research in neuromorphic hardware targets dramatic improvements to ANN performance by increasing energy efficiency, speed of operation, and even seeks to extend the utility of ANNs by natively adding functionality such as spiking operation. One promising neuromorphic hardware platform is based on superconductive electronics, which has the potential to incorporate all of these advantages at the device level in addition to offering the potential of near lossless communications both within the neuromorphic circuits as well as between disparate superconductive chips. Here we explore one of the fundamental brain-inspired architecture components, the fan-in and fan-out as realized in superconductive circuits based on Josephson junctions. From our calculations and WRSPICE simulations we find that the fan-out should be limited only by junction count and circuit size limitations, and we demonstrate results in simulation at a level of 1-to-10,000, similar to that of the human brain. We find that fan-in has more limitations, but a fan-in level on the order of a few 100-to-1 should be achievable based on current technology. We discuss our findings and the critical parameters that set the limits on fan-in and fan-out in the context of superconductive neuromorphic circuits.", "pdf_url": "https://arxiv.org/pdf/2008.06409", "subject": "Applied Physics (physics.app-ph)"},
{"title": "Efficient hyperparameter optimization by way of PAC-Bayes bound minimization", "author": "John J. Cherian, Andrew G. Taube, Robert T. McGibbon, Panagiotis Angelikopoulos, Guy Blanc, Michael Snarski, Daniel D. Richman, John L. Klepeis, David E. Shaw", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Identifying optimal values for a high-dimensional set of hyperparameters is a problem that has received growing attention given its importance to large-scale machine learning applications such as neural architecture search. Recently developed optimization methods can be used to select thousands or even millions of hyperparameters. Such methods often yield overfit models, however, leading to poor performance on unseen data. We argue that this overfitting results from using the standard hyperparameter optimization objective function. Here we present an alternative objective that is equivalent to a Probably Approximately Correct-Bayes (PAC-Bayes) bound on the expected out-of-sample error. We then devise an efficient gradient-based algorithm to minimize this objective; the proposed method has asymptotic space and time complexity equal to or better than other gradient-based hyperparameter optimization methods. We show that this new method significantly reduces out-of-sample error when applied to hyperparameter optimization problems known to be prone to overfitting.", "pdf_url": "https://arxiv.org/pdf/2008.06431", "subject": "Machine Learning (stat.ML)"},
{"title": "The Projected Belief Network Classfier : both Generative and Discriminative", "author": "Paul M Baggenstoss", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The projected belief network (PBN) is a layered generative network with tractable likelihood function, and is based on a feed-forward neural network (FF-NN). It can therefore share an embodiment with a discriminative classifier and can inherit the best qualities of both types of network. In this paper, a convolutional PBN is constructed that is both fully discriminative and fully generative and is tested on spectrograms of spoken commands. It is shown that the network displays excellent qualities from either the discriminative or generative viewpoint. Random data synthesis and visible data reconstruction from low-dimensional hidden variables are shown, while classifier performance approaches that of a regularized discriminative network. Combination with a conventional discriminative CNN is also demonstrated.", "pdf_url": "https://arxiv.org/pdf/2008.06434", "subject": "Machine Learning (stat.ML)"},
{"title": "Quantum advantage for computations with limited space", "author": "Dmitri Maslov, Jin-Sung Kim, Sergey Bravyi, Theodore J. Yoder, Sarah Sheldon", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Quantum computations promise the ability to solve problems intractable in the classical setting. Restricting the types of computations considered often allows to establish a provable theoretical advantage by quantum computations, and later demonstrate it experimentally. In this paper, we consider space-restricted computations, where input is a read-only memory and only one (qu)bit can be computed on. We show that $n$-bit symmetric Boolean functions can be implemented exactly through the use of quantum signal processing as restricted space quantum computations using $O(n^2)$ gates, but some of them may only be evaluated with probability $\\frac{1}{2} {+} \\tilde{O}(\\frac{1}{\\sqrt{n}})$ by analogously defined classical computations. We experimentally demonstrate computations of $3$- and a $4$-bit symmetric Boolean functions by quantum circuits, leveraging custom two-qubit gates, with algorithmic success probability exceeding the best possible classically. This establishes and experimentally verifies a different kind of quantum advantage -- one where a quantum bit stores more useful information for the purpose of computation than a classical bit. This suggests that in computations, quantum scrap space is more valuable than analogous classical space and calls for an in-depth exploration of space-time tradeoffs in quantum circuits.", "pdf_url": "https://arxiv.org/pdf/2008.06478", "subject": "Quantum Physics (quant-ph)"},
{"title": "A Deep Convolutional Neural Network Model for improving WRF Forecasts", "author": "Alqamah Sayeed, Yunsoo Choi, Jia Jung, Yannic Lops, Ebrahim Eslami, Ahmed Khan Salman", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Advancements in numerical weather prediction models have accelerated, fostering a more comprehensive understanding of physical phenomena pertaining to the dynamics of weather and related computing resources. Despite these advancements, these models contain inherent biases due to parameterization and linearization of the differential equations that reduce forecasting accuracy. In this work, we investigate the use of a computationally efficient deep learning method, the Convolutional Neural Network (CNN), as a post-processing technique that improves mesoscale Weather and Research Forecasting (WRF) one day forecast (with a one-hour temporal resolution) outputs. Using the CNN architecture, we bias-correct several meteorological parameters calculated by the WRF model for all of 2018. We train the CNN model with a four-year history (2014-2017) to investigate the patterns in WRF biases and then reduce these biases in forecasts for surface wind speed and direction, precipitation, relative humidity, surface pressure, dewpoint temperature, and surface temperature. The WRF data, with a spatial resolution of 27 km, covers South Korea. We obtain ground observations from the Korean Meteorological Administration station network for 93 weather station locations. The results indicate a noticeable improvement in WRF forecasts in all station locations. The average of annual index of agreement for surface wind, precipitation, surface pressure, temperature, dewpoint temperature and relative humidity of all stations are 0.85 (WRF:0.67), 0.62 (WRF:0.56), 0.91 (WRF:0.69), 0.99 (WRF:0.98), 0.98 (WRF:0.98), and 0.92 (WRF:0.87), respectively. While this study focuses on South Korea, the proposed approach can be applied for any measured weather parameters at any location.", "pdf_url": "https://arxiv.org/pdf/2008.06489", "subject": "Atmospheric and Oceanic Physics (physics.ao-ph)"},
{"title": "MMM : Exploring Conditional Multi-Track Music Generation with the Transformer", "author": "Jeff Ens, Philippe Pasquier", "pub_date": "Submitted on 13 Aug 2020", "abstract": "We propose the Multi-Track Music Machine (MMM), a generative system based on the Transformer architecture that is capable of generating multi-track music. In contrast to previous work, which represents musical material as a single time-ordered sequence, where the musical events corresponding to different tracks are interleaved, we create a time-ordered sequence of musical events for each track and concatenate several tracks into a single sequence. This takes advantage of the attention-mechanism, which can adeptly handle long-term dependencies. We explore how various representations can offer the user a high degree of control at generation time, providing an interactive demo that accommodates track-level and bar-level inpainting, and offers control over track instrumentation and note density.", "pdf_url": "https://arxiv.org/pdf/2008.06048", "subject": "Sound (cs.SD)"},
{"title": "Constructed emotions and superinformation: a constructor-theoretic approach", "author": "Riccardo Franco", "pub_date": "Submitted on 13 Aug 2020", "abstract": "In this paper we apply the constructor-theoretic approach to the theory of constructed emotions, showing that core affect valence and knowledge can be considered as two different observables, leading to information or superinformation conditions: this depends on subject's strategy, coherently with the affect infusion model. In the second part of the article we show that additional hypotheses on the structure of information allows to study emotions in terms of the contructor-theoretic version of phase task. Quantum algorithms are presented as an example of the connection between emotions and memory tasks.", "pdf_url": "https://arxiv.org/pdf/2008.06052", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Full-Duplex Amplify-and-Forward MIMO Relaying: Impairments Aware Design and Performance Analysis", "author": "Omid Taghizadeh, Slawomir Stanczak, Hiroki Iimori, Giuseppe Abreu", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Full-Duplex (FD) Amplify-and-Forward (AF) Multiple-Input Multiple-Output (MIMO) relaying has been the focus of several recent studies, due to the potential for achieving a higher spectral efficiency and lower latency, together with inherent processing simplicity. However, when the impact of hardware distortions are considered, such relays suffer from a distortion-amplification loop, due to the inter-dependent nature of the relay transmit signal covariance and the residual self-interference covariance. The aforementioned behavior leads to a significant performance degradation for a system with a low or medium hardware accuracy. In this work, we analyse the relay transfer function as well as the Mean Squared-Error (MSE) performance of an FD-AF MIMO relaying communication, under the impact of collective sources of additive and multiplicative transmit and receive impairments. Building on the performed analysis, an optimization problem is devised to minimize the communication MSE and solved by employing the recently proposed Penalty Dual Decomposition (PDD) framework. The proposed solution converges to a stationary point of the original problem via a sequence of convex quadratic programs (CQP)s, thereby enjoying an acceptable arithmatic complexity as the problem dimensions grow large. Numerical simulations verify the significance of the proposed distortion-aware design and analysis, compared to the common simplified approaches, as the hardware accuracy degrades.", "pdf_url": "https://arxiv.org/pdf/2008.06063", "subject": "Information Theory (cs.IT)"},
{"title": "Semantically Adversarial Learnable Filters", "author": "Ali Shahin Shamsabadi, Changjae Oh, Andrea Cavallaro", "pub_date": "Submitted on 13 Aug 2020", "abstract": "We present the first adversarial framework that crafts perturbations that mislead classifiers by accounting for the content of the images and the semantics of the labels. The proposed framework combines deep neural networks and traditional image processing filters, which define the type and magnitude of the adversarial perturbation. We also introduce a semantic adversarial loss that guides the training of a fully convolutional neural network to generate adversarial images that will be classified with a label that is semantically different from the label of the original (clean) image. We analyse the limitations of existing methods that do not account for the semantics of the labels and evaluate the proposed framework, FilterFool, on ImageNet and with three object classifiers, namely ResNet50, ResNet18 and AlexNet. We discuss its success rate, robustness and transferability to unseen classifiers.", "pdf_url": "https://arxiv.org/pdf/2008.06069", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Visuomotor Mechanical Search: Learning to Retrieve Target Objects in Clutter", "author": "Andrey Kurenkov, Joseph Taglic, Rohun Kulkarni, Marcus Dominguez-Kuhne, Animesh Garg, Roberto Mart\u00edn-Mart\u00edn, Silvio Savarese", "pub_date": "Submitted on 13 Aug 2020", "abstract": "When searching for objects in cluttered environments, it is often necessary to perform complex interactions in order to move occluding objects out of the way and fully reveal the object of interest and make it graspable. Due to the complexity of the physics involved and the lack of accurate models of the clutter, planning and controlling precise predefined interactions with accurate outcome is extremely hard, when not impossible. In problems where accurate (forward) models are lacking, Deep Reinforcement Learning (RL) has shown to be a viable solution to map observations (e.g. images) to good interactions in the form of close-loop visuomotor policies. However, Deep RL is sample inefficient and fails when applied directly to the problem of unoccluding objects based on images. In this work we present a novel Deep RL procedure that combines i) teacher-aided exploration, ii) a critic with privileged information, and iii) mid-level representations, resulting in sample efficient and effective learning for the problem of uncovering a target object occluded by a heap of unknown objects. Our experiments show that our approach trains faster and converges to more efficient uncovering solutions than baselines and ablations, and that our uncovering policies lead to an average improvement in the graspability of the target object, facilitating downstream retrieval applications.", "pdf_url": "https://arxiv.org/pdf/2008.06073", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Studying Dishonest Intentions in Brazilian Portuguese Texts", "author": "Francielle Alves Vargas, Thiago Alexandre Salgueiro Pardo", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Previous work in the social sciences, psychology and linguistics has show that liars have some control over the content of their stories, however their underlying state of mind may \"leak out\" through the way that they tell them. To the best of our knowledge, no previous systematic effort exists in order to describe and model deception language for Brazilian Portuguese. To fill this important gap, we carry out an initial empirical linguistic study on false statements in Brazilian news. We methodically analyze linguistic features using the corpus, which includes both fake and true news. The results show that they present substantial lexical, syntactic and semantic variations, as well as punctuation and emotion distinctions.", "pdf_url": "https://arxiv.org/pdf/2008.06079", "subject": "Computation and Language (cs.CL)"},
{"title": "Adversarial Training and Provable Robustness: A Tale of Two Objectives", "author": "Jiameng Fan, Wenchao Li", "pub_date": "Submitted on 13 Aug 2020", "abstract": "We propose a principled framework that combines adversarial training and provable robustness verification for training certifiably robust neural networks. We formulate the training problem as a joint optimization problem with both empirical and provable robustness objectives and develop a novel gradient-descent technique that can eliminate bias in stochastic multi-gradients. We perform both theoretical analysis on the convergence of the proposed technique and experimental comparison with state-of-the-arts. Results on MNIST and CIFAR-10 show that our method can match or outperform prior approaches for provable l infinity robustness.", "pdf_url": "https://arxiv.org/pdf/2008.06081", "subject": "Machine Learning (cs.LG)"},
{"title": "Push-SAGA: A decentralized stochastic algorithm with variance reduction over directed graphs", "author": "Muhammad I. Qureshi, Ran Xin, Soummya Kar, Usman A. Khan", "pub_date": "Submitted on 13 Aug 2020", "abstract": "In this paper, we propose Push-SAGA, a decentralized stochastic first-order method for finite-sum minimization over a directed network of nodes. Push-SAGA combines node-level variance reduction to remove the uncertainty caused by stochastic gradients, network-level gradient tracking to address the distributed nature of the data, and push-sum consensus to tackle the challenge of directed communication links. We show that Push-SAGA achieves linear convergence to the exact solution for smooth and strongly convex problems and is thus the first linearly-convergent stochastic algorithm over arbitrary strongly connected directed graphs. We also characterize the regimes in which Push-SAGA achieves a linear speed-up compared to its centralized counterpart and achieves a network-independent convergence rate. We illustrate the behavior and convergence properties of Push-SAGA with the help of numerical experiments on strongly convex and non-convex problems.", "pdf_url": "https://arxiv.org/pdf/2008.06082", "subject": "Machine Learning (cs.LG)"},
{"title": "Novelty Detection Through Model-Based Characterization of Neural Networks", "author": "Gukyeong Kwon, Mohit Prabhushankar, Dogancan Temel, Ghassan AlRegib", "pub_date": "Submitted on 13 Aug 2020", "abstract": "In this paper, we propose a model-based characterization of neural networks to detect novel input types and conditions. Novelty detection is crucial to identify abnormal inputs that can significantly degrade the performance of machine learning algorithms. Majority of existing studies have focused on activation-based representations to detect abnormal inputs, which limits the characterization of abnormality from a data perspective. However, a model perspective can also be informative in terms of the novelties and abnormalities. To articulate the significance of the model perspective in novelty detection, we utilize backpropagated gradients. We conduct a comprehensive analysis to compare the representation capability of gradients with that of activation and show that the gradients outperform the activation in novel class and condition detection. We validate our approach using four image recognition datasets including MNIST, Fashion-MNIST, CIFAR-10, and CURE-TSR. We achieve a significant improvement on all four datasets with an average AUROC of 0.953, 0.918, 0.582, and 0.746, respectively.", "pdf_url": "https://arxiv.org/pdf/2008.06094", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Geometric Deep Learning for Post-Menstrual Age Prediction based on the Neonatal White Matter Cortical Surface", "author": "Vitalis Vosylius, Andy Wang, Cemlyn Waters, Alexey Zakharov, Francis Ward, Loic Le Folgoc, John Cupitt, Antonios Makropoulos, Andreas Schuh, Daniel Rueckert, Amir Alansary", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Accurate estimation of the age in neonates is essential for measuring neurodevelopmental, medical, and growth outcomes. In this paper, we propose a novel approach to predict the post-menstrual age (PA) at scan, using techniques from geometric deep learning, based on the neonatal white matter cortical surface. We utilize and compare multiple specialized neural network architectures that predict the age using different geometric representations of the cortical surface; we compare MeshCNN, Pointnet++, GraphCNN, and a volumetric benchmark. The dataset is part of the Developing Human Connectome Project (dHCP), and is a cohort of healthy and premature neonates. We evaluate our approach on 650 subjects (727scans) with PA ranging from 27 to 45 weeks. Our results show accurate prediction of the estimated PA, with mean error less than one week.", "pdf_url": "https://arxiv.org/pdf/2008.06098", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Identifying Usability Issues of Software Analytics Applications in Immersive Augmented Reality", "author": "David Baum, Stefan Bechert, Ulrich Eisenecker, Isabelle Meichsner, Richard M\u00fcller", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Software analytics in augmented reality (AR) is said to have great potential. One reason why this potential is not yet fully exploited may be usability problems of the AR user interfaces. We present an iterative and qualitative usability evaluation with 15 subjects of a state-of-the-art application for software analytics in AR. We could identify and resolve numerous usability issues. Most of them were caused by applying conventional user interface elements, such as dialog windows, buttons, and scrollbars. The used city visualization, however, did not cause any usability issues. Therefore, we argue that future work should focus on making conventional user interface elements in AR obsolete by integrating their functionality into the immersive visualization.", "pdf_url": "https://arxiv.org/pdf/2008.06099", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Consistent $k$-Median: Simpler, Better and Robust", "author": "Xiangyu Guo, Janardhan Kulkarni, Shi Li, Jiayi Xian", "pub_date": "Submitted on 13 Aug 2020", "abstract": "In this paper we introduce and study the online consistent $k$-clustering with outliers problem, generalizing the non-outlier version of the problem studied in [Lattanzi-Vassilvitskii, ICML17]. We show that a simple local-search based online algorithm can give a bicriteria constant approximation for the problem with $O(k^2 \\log^2 (nD))$ swaps of medians (recourse) in total, where $D$ is the diameter of the metric. When restricted to the problem without outliers, our algorithm is simpler, deterministic and gives better approximation ratio and recourse, compared to that of [Lattanzi-Vassilvitskii, ICML17].", "pdf_url": "https://arxiv.org/pdf/2008.06101", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Development of a Web Platform for Code Peer-Testing", "author": "Manuel Maarek, L\u00e9on McGregor", "pub_date": "Submitted on 13 Aug 2020", "abstract": "As part of formative and summative assessments in programming courses, students work on developing programming artifacts following a given specification. These artifacts are evaluated by the teachers. At the end of this evaluation, the students receive feedback and marks. Providing feedback on programming artifacts is time demanding and could make feedback to arrive too late for it to be effective for the students' learning. We propose to combine software testing with peer feedback which has been praised for offering a timely and effective learning activity with program testing. In this paper we report on the development of a Web platform for peer feedback on programming artifacts through program testing. We discuss the development process of our peer-testing platform informed by teachers and students.", "pdf_url": "https://arxiv.org/pdf/2008.06102", "subject": "Software Engineering (cs.SE)"},
{"title": "Effect of Architectures and Training Methods on the Performance of Learned Video Frame Prediction", "author": "M. Akin Yilmaz, A. Murat Tekalp", "pub_date": "Submitted on 13 Aug 2020", "abstract": "We analyze the performance of feedforward vs. recurrent neural network (RNN) architectures and associated training methods for learned frame prediction. To this effect, we trained a residual fully convolutional neural network (FCNN), a convolutional RNN (CRNN), and a convolutional long short-term memory (CLSTM) network for next frame prediction using the mean square loss. We performed both stateless and stateful training for recurrent networks. Experimental results show that the residual FCNN architecture performs the best in terms of peak signal to noise ratio (PSNR) at the expense of higher training and test (inference) computational complexity. The CRNN can be trained stably and very efficiently using the stateful truncated backpropagation through time procedure, and it requires an order of magnitude less inference runtime to achieve near real-time frame prediction with an acceptable performance.", "pdf_url": "https://arxiv.org/pdf/2008.06106", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Restless bandits: indexability and computation of Whittle index", "author": "Nima Akbarzadeh, Aditya Mahajan", "pub_date": "Submitted on 13 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "Restless bandits are a class of sequential resource allocation problems concerned with allocating one or more resources among several alternative processes where the evolution of the process depends on the resource allocated to them. Such models capture the fundamental trade-offs between exploration and exploitation. In 1988, Whittle developed an index heuristic for restless bandit problems which has emerged as a popular solution approach due to its simplicity and strong empirical performance. The Whittle index heuristic is applicable if the model satisfies a technical condition known as indexability. In this paper, we present two general sufficient conditions for indexability and identify simpler to verify refinements of these conditions. We then present a general algorithm to compute Whittle index for indexable restless bandits. Finally, we present a detailed numerical study which affirms the strong performance of the Whittle index heuristic.", "pdf_url": "https://arxiv.org/pdf/2008.06111", "subject": "Systems and Control (eess.SY)"},
{"title": "Intelligent Architectures for Intelligent Machines", "author": "Onur Mutlu", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Computing is bottlenecked by data. Large amounts of application data overwhelm storage capability, communication capability, and computation capability of the modern machines we design today. As a result, many key applications' performance, efficiency and scalability are bottlenecked by data movement. In this keynote talk, we describe three major shortcomings of modern architectures in terms of 1) dealing with data, 2) taking advantage of the vast amounts of data, and 3) exploiting different semantic properties of application data. We argue that an intelligent architecture should be designed to handle data well. We show that handling data well requires designing architectures based on three key principles: 1) data-centric, 2) data-driven, 3) data-aware. We give several examples for how to exploit each of these principles to design a much more efficient and high performance computing system. We especially discuss recent research that aims to fundamentally reduce memory latency and energy, and practically enable computation close to data, with at least two promising novel directions: 1) performing massively-parallel bulk operations in memory by exploiting the analog operational properties of memory, with low-cost changes, 2) exploiting the logic layer in 3D-stacked memory technology in various ways to accelerate important data-intensive applications. We discuss how to enable adoption of such fundamentally more intelligent architectures, which we believe are key to efficiency, performance, and sustainability. We conclude with some guiding principles for future computing architecture and system designs.", "pdf_url": "https://arxiv.org/pdf/2008.06112", "subject": "Hardware Architecture (cs.AR)"},
{"title": "Can weight sharing outperform random architecture search? An investigation with TuNAS", "author": "Gabriel Bender, Hanxiao Liu, Bo Chen, Grace Chu, Shuyang Cheng, Pieter-Jan Kindermans, Quoc Le", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Efficient Neural Architecture Search methods based on weight sharing have shown good promise in democratizing Neural Architecture Search for computer vision models. There is, however, an ongoing debate whether these efficient methods are significantly better than random search. Here we perform a thorough comparison between efficient and random search methods on a family of progressively larger and more challenging search spaces for image classification and detection on ImageNet and COCO. While the efficacies of both methods are problem-dependent, our experiments demonstrate that there are large, realistic tasks where efficient search methods can provide substantial gains over random search. In addition, we propose and evaluate techniques which improve the quality of searched architectures and reduce the need for manual hyper-parameter tuning. Source code and experiment data are available at", "pdf_url": "https://arxiv.org/pdf/2008.06120", "subject": "Machine Learning (cs.LG)"},
{"title": "Explicit and recursive estimates of the Lambert W function", "author": "Lajos L\u00f3czi", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Solutions to a wide variety of transcendental equations can be expressed in terms of the Lambert $\\mathrm{W}$ function. The $\\mathrm{W}$ function, occurring frequently in applications, is a non-elementary, but now standard mathematical function implemented in all major technical computing systems. In this work, we discuss some approximations of the two real branches, $\\mathrm{W}_0$ and $\\mathrm{W}_{-1}$. On the one hand, we present some analytic lower and upper bounds on $\\mathrm{W}_0$ for large arguments that improve on some earlier results in the literature. On the other hand, we analyze two logarithmic recursions, one with linear, and the other with quadratic rate of convergence. We propose suitable starting values for the recursion with quadratic rate that ensure convergence on the whole domain of definition of both real branches. We also provide a priori, simple, explicit and uniform estimates on its convergence speed that enable guaranteed, high-precision approximations of $\\mathrm{W}_0$ and $\\mathrm{W}_{-1}$ at any point. Finally, as an application of the $\\mathrm{W}_0$ function, we settle a conjecture about the growth rate of the positive non-trivial solutions to the equation $x^y=y^x$.", "pdf_url": "https://arxiv.org/pdf/2008.06122", "subject": "Numerical Analysis (math.NA)"},
{"title": "One Size Does Not Fit All: A Study of Badge Behavior in Stack Overflow", "author": "Stav Yanovsky, Nicholas Hoernle, Omer Lev, Kobi Gal", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Badges are endemic to online interaction sites, from Question and Answer (Q&A) websites to ride sharing, as systems for rewarding participants for their contributions. This paper studies how badge design affects people's contributions and behavior over time. Past work has shown that badges \"steer\" people's behavior toward substantially increasing the amount of contributions before obtaining the badge, and immediately decreasing their contributions thereafter, returning to their baseline contribution levels. In contrast, we find that the steering effect depends on the type of user, as modeled by the rate and intensity of the user's contributions. We use these measures to distinguish between different groups of user activity, including users who are not affected by the badge system despite being significant contributors to the site. We provide a predictive model of how users change their activity group over the course of their lifetime in the system. We demonstrate our approach empirically in three different Q\\&A sites on Stack Exchange with hundreds of thousands of users, for two types of activities (editing and voting on posts).", "pdf_url": "https://arxiv.org/pdf/2008.06125", "subject": "Social and Information Networks (cs.SI)"},
{"title": "A Sum-of-Squares-Based Procedure to Approximate the Pontryagin Difference of Semialgebraic Sets", "author": "Andres Cotorruelo, Ilya Kolmanovsky, Emanuele Garone", "pub_date": "Submitted on 13 Aug 2020", "abstract": "The P-difference between two sets $\\mathcal{A}$ and $\\mathcal{B}$ is the set of all points, $\\mathcal{C}$, such that the addition of $\\mathcal{B}$ to any of the points in $\\mathcal{C}$ is contained in $\\mathcal{A}$. Such a set difference plays an important role in robust model predictive control and in set-theoretic control. In the paper we demonstrate that an inner approximation of the P-difference between two semialgebraic sets can be computed using the Sums of Squares Programming, and we illustrate the procedure using several computational examples.", "pdf_url": "https://arxiv.org/pdf/2008.06126", "subject": "Systems and Control (eess.SY)"},
{"title": "Finite element approximation of fractional Neumann problems", "author": "Francisco M. Bersetche, Juan Pablo Borthagaray", "pub_date": "Submitted on 13 Aug 2020", "abstract": "In this paper we consider approximations of Neumann problems for the integral fractional Laplacian by continuous, piecewise linear finite elements. We analyze the weak formulation of such problems, including their well-posedness and asymptotic behavior of solutions. We address the convergence of the finite element discretizations and discuss the implementation of the method. Finally, we present several numerical experiments in one- and two-dimensional domains that illustrate the method's performance as well as certain properties of solutions.", "pdf_url": "https://arxiv.org/pdf/2008.06129", "subject": "Numerical Analysis (math.NA)"},
{"title": "3D Bird Reconstruction: a Dataset, Model, and Shape Recovery from a Single View", "author": "Marc Badger, Yufu Wang, Adarsh Modh, Ammon Perkes, Nikos Kolotouros, Bernd G. Pfrommer, Marc F. Schmidt, Kostas Daniilidis", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Automated capture of animal pose is transforming how we study neuroscience and social behavior. Movements carry important social cues, but current methods are not able to robustly estimate pose and shape of animals, particularly for social animals such as birds, which are often occluded by each other and objects in the environment. To address this problem, we first introduce a model and multi-view optimization approach, which we use to capture the unique shape and pose space displayed by live birds. We then introduce a pipeline and experiments for keypoint, mask, pose, and shape regression that recovers accurate avian postures from single views. Finally, we provide extensive multi-view keypoint and mask annotations collected from a group of 15 social birds housed together in an outdoor aviary. The project website with videos, results, code, mesh model, and the Penn Aviary Dataset can be found at .", "pdf_url": "https://arxiv.org/pdf/2008.06133", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Interactive volume illumination of slice-based ray casting", "author": "Dening Luo", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Volume rendering always plays an important role in the field of medical imaging and industrial design. In recent years, the realistic and interactive volume rendering of the global illumination can improve the perception of shape and depth of volumetric datasets. In this paper, a novel and flexible performance method of slice-based ray casting is proposed to implement the volume illumination effects, such as volume shadow and other scattering effects. This benefits from the slice-based illumination attenuation buffers of the whole geometry slices at the viewpoint of the light source and the high-efficiency shadow or scattering coefficient calculation per sample in ray casting. These tests show the method can obtain much better volume illumination effects and more scalable performance in contrast to the local volume illumination in ray casting volume rendering or other similar slice-based global volume illumination.", "pdf_url": "https://arxiv.org/pdf/2008.06134", "subject": "Graphics (cs.GR)"},
{"title": "Learnability and Robustness of Shallow Neural Networks Learned With a Performance-Driven BP and a Variant PSO For Edge Decision-Making", "author": "Hongmei He, Mengyuan Chen, Gang Xu, Zhilong Zhu, Zhenhuan Zhu", "pub_date": "Submitted on 13 Aug 2020", "abstract": "In many cases, the computing resources are limited without the benefit from GPU, especially in the edge devices of IoT enabled systems. It may not be easy to implement complex AI models in edge devices. The Universal Approximation Theorem states that a shallow neural network (SNN) can represent any nonlinear function. However, how fat is an SNN enough to solve a nonlinear decision-making problem in edge devices? In this paper, we focus on the learnability and robustness of SNNs, obtained by a greedy tight force heuristic algorithm (performance driven BP) and a loose force meta-heuristic algorithm (a variant of PSO). Two groups of experiments are conducted to examine the learnability and the robustness of SNNs with Sigmoid activation, learned/optimised by KPI-PDBPs and KPI-VPSOs, where, KPIs (key performance indicators: error (ERR), accuracy (ACC) and $F_1$ score) are the objectives, driving the searching process. An incremental approach is applied to examine the impact of hidden neuron numbers on the performance of SNNs, learned/optimised by KPI-PDBPs and KPI-VPSOs. From the engineering prospective, all sensors are well justified for a specific task. Hence, all sensor readings should be strongly correlated to the target. Therefore, the structure of an SNN should depend on the dimensions of a problem space. The experimental results show that the number of hidden neurons up to the dimension number of a problem space is enough; the learnability of SNNs, produced by KPI-PDBP, is better than that of SNNs, optimized by KPI-VPSO, regarding the performance and learning time on the training data sets; the robustness of SNNs learned by KPI-PDBPs and KPI-VPSOs depends on the data sets; and comparing with other classic machine learning models, ACC-PDBPs win for almost all tested data sets.", "pdf_url": "https://arxiv.org/pdf/2008.06135", "subject": "Neural and Evolutionary Computing (cs.NE)"},
{"title": "Performance of UAV-assisted D2D Networks in the Finite Block-length Regime", "author": "Mehdi Monemi, Hina Tabassum", "pub_date": "Submitted on 13 Aug 2020", "abstract": "We develop a comprehensive framework to characterize and optimize the performance of a unmanned aerial vehicle (UAV)-assisted D2D network, where D2D transmissions underlay cellular transmissions. Different from conventional non-line-of-sight (NLoS) terrestrial transmissions, aerial transmissions are highly likely to experience line-of-sight (LoS). As such, characterizing the performance of mixed aerial-terrestrial networks with accurate fading models is critical to precise network performance characterization and resource optimization. We first characterize closed-form expressions for a variety of performance metrics such as frame decoding error probability (referred to as reliability), outage probability, and ergodic capacity of users. The terrestrial and aerial transmissions may experience either LoS Rician fading or NLoS Nakagami-m fading with a certain probability. Based on the derived expressions, we formulate a hierarchical bi-objective mixed-integer-nonlinear-programming (MINLP) problem to minimize the total transmit power of all users and maximize the aggregate throughput of D2D users subject to quality-of-service (QoS) measures (i.e., reliability and ergodic capacity) of cellular users. We model the proposed problem as a bi-partite one-to-many matching game. To solve this problem, we first obtain the optimal closed-form power allocations for each D2D and cellular user on any possible subchannel, and then incorporate them to devise efficient subchannel and power allocation algorithms. Complexity analysis of the proposed algorithms is presented. Numerical results verify the accuracy of our derived expressions and reveal the significance of aerial relays compared to ground relays in increasing the throughput of D2D pairs especially for distant D2D pairs.", "pdf_url": "https://arxiv.org/pdf/2008.06137", "subject": "Information Theory (cs.IT)"},
{"title": "Analytical bounds on the local Lipschitz constants of affine-ReLU functions", "author": "Trevor Avant, Kristi A. Morgansen", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this paper, we determine analytical bounds on the local Lipschitz constants of of affine functions composed with rectified linear units (ReLUs). Affine-ReLU functions represent a widely used layer in deep neural networks, due to the fact that convolution, fully-connected, and normalization functions are all affine, and are often followed by a ReLU activation function. Using an analytical approach, we mathematically determine upper bounds on the local Lipschitz constant of an affine-ReLU function, show how these bounds can be combined to determine a bound on an entire network, and discuss how the bounds can be efficiently computed, even for larger layers and networks. We show several examples by applying our results to AlexNet, as well as several smaller networks based on the MNIST and CIFAR-10 datasets. The results show that our method produces tighter bounds than the standard conservative bound (i.e. the product of the spectral norms of the layers' linear matrices), especially for small perturbations.", "pdf_url": "https://arxiv.org/pdf/2008.06141", "subject": "Machine Learning (cs.LG)"},
{"title": "Model Checking Software-Defined Networks with Flow Entries that Time Out", "author": "Vasileios Klimis, George Parisis, Bernhard Reus", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Software-defined networking (SDN) enables advanced operation and management of network deployments through (virtually) centralised, programmable controllers, which deploy network functionality by installing rules in the flow tables of network switches. Although this is a powerful abstraction, buggy controller functionality could lead to severe service disruption and security loopholes, motivating the need for (semi-)automated tools to find, or even verify absence of, bugs. Model checking SDNs has been proposed in the literature, but none of the existing approaches can support dynamic network deployments, where flow entries expire due to timeouts. This is necessary for automatically refreshing (and eliminating stale) state in the network (termed as soft-state in the network protocol design nomenclature), which is important for scaling up applications or recovering from failures. In this paper, we extend our model (MoCS) to deal with timeouts of flow table entries, thus supporting soft state in the network. Optimisations are proposed that are tailored to this extension. We evaluate the performance of the proposed model in UPPAAL using a load balancer and firewall in network topologies of varying size.", "pdf_url": "https://arxiv.org/pdf/2008.06149", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Consideration for effectively handling parallel workloads on public cloud system", "author": "Kazuichi Oe", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We retrieved and analyzed parallel storage workloads of the FUJITSU K5 cloud service to clarify how to build cost-effective hybrid storage systems. A hybrid storage system consists of fast but low-capacity tier (first tier) and slow but high-capacity tier (second tier). And, it typically consists of either SSDs and HDDs or NVMs and SSDs. As a result, we found that 1) regions for first tier should be assigned only if a workload includes large number of IO accesses for a whole day, 2) the regions that include a large number of IO accesses should be dynamically chosen and moved from second tier to first tier for a short interval, and 3) if a cache hit ratio is regularly low, use of the cache for the workload should be cancelled, and the whole workload region should be assigned to the region for first tier. These workloads already have been released from the SNIA web site.", "pdf_url": "https://arxiv.org/pdf/2008.06152", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Topology optimization for considering distortion in additive manufacturing", "author": "Takao Miki, Takayuki Yamada", "pub_date": "Submitted on 14 Aug 2020", "abstract": "This paper proposes a topology optimization method that takes account of distortion induced by additive manufacturing (AM). AM is a free-form manufacturing technique in which the part is built in a layer-by-layer manner. In particular, laser powder bed fusion (LPBF) is one of the most widespread technologies for metal parts. However, LPBF is known to cause residual stress and distortion during fabrication, which adversely affects the mechanical properties and dimensional accuracy of the part. Therefore, predicting and avoiding the residual stress and distortion are critical issues. Our goal is to propose a topology optimization method that considers distortion in AM and an analytical model of AM suitable for incorporation into topology optimization. First, we propose an analytical model of the AM building process by LPBF, and formulate an optimization problem. Next, a topological derivative of the objective functional is approximately derived using an adjoint variable method and is utilized to update the level set function via a time evolutionary reaction-diffusion equation. Finally, two-dimensional design examples demonstrate the validations and effectiveness of the proposed optimization methodology.", "pdf_url": "https://arxiv.org/pdf/2008.06153", "subject": "Computational Engineering, Finance, and Science (cs.CE)"},
{"title": "On Social Interactions of Merging Behaviors at Highway On-Ramps in Congested Traffic", "author": "Huanjie Wang, Wenshuo Wang, Shihua Yuan, Xueyuan Li, Lijun Sun", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Merging at highway on-ramps while interacting with other human-driven vehicles is challenging for autonomous vehicles (AVs). An efficient route to this challenge requires exploring and then exploiting knowledge of the interaction process from demonstrations by humans. However, it is unclear what information (or the environment states) is utilized by the human driver to guide their behavior over the whole merging process. This paper provides quantitative analysis and evaluation of the merging behavior at highway on-ramps with congested traffic in a volume of time and space. Two types of social interaction scenarios are considered based on the social preferences of surrounding vehicles: courteous and rude. The significant levels of environment states for characterizing the interactive merging process are empirically analyzed based on the real-world INTERACTION dataset. Experimental results reveal two fundamental mechanisms in the merging process: 1) Human driver selects different states to make sequential decisions at different moments of task execution and 2) the social preference of surrounding vehicles has an impact on variable selection for making decisions. It implies that for autonomous driving, efficient decision-making design should filter out irrelevant information while considering the social preference of the surrounding vehicles, to reach a comparable human-level performance. These essential findings shed light on developing new decision-making approaches for AVs.", "pdf_url": "https://arxiv.org/pdf/2008.06156", "subject": "Robotics (cs.RO)"},
{"title": "User Association in Coexisting RF and TeraHertz Networks in 6G", "author": "Noha Hassan, Md Tanvir Hossan, Hina Tabassum", "pub_date": "Submitted on 14 Aug 2020", "abstract": "While fifth generation (5G) networks are ready for deployment, discussions over sixth generation (6G) networks are down the road. Since high frequencies like terahertz (THz) will be central to 6G, in this paper, we propose two user association (UE) algorithms considering a coexisting RF and THz network that balances the traffic load across the network by minimizing the standard deviation of the network traffic load. Our algorithms capture the heterogeneity observed at RF and THz frequencies such as transmission bandwidth, molecular absorption, transmit powers, etc. Unlike typical unsupervised clustering algorithms (e.g. k-means, k-medoid, etc.) that search for appropriate cluster centers' locations, our algorithms identify the appropriate UEs to be associated to a certain BS such that the overall network load standard deviation (STD) can be minimized subject to users' rate constraints. In particular, our algorithms cluster UEs to every base station (BS) such that the traffic load across the network can be balanced, i.e., by minimizing the STD of network traffic load. Numerical results show that the proposed algorithms outperform the classical user association algorithms in terms of data rate, traffic load balancing, and user's fairness.", "pdf_url": "https://arxiv.org/pdf/2008.06160", "subject": "Information Theory (cs.IT)"},
{"title": "Energy-Efficient Control Adaptation with Safety Guarantees for Learning-Enabled Cyber-Physical Systems", "author": "Yixuan Wang, Chao Huang, Qi Zhu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Neural networks have been increasingly applied for control in learning-enabled cyber-physical systems (LE-CPSs) and demonstrated great promises in improving system performance and efficiency, as well as reducing the need for complex physical models. However, the lack of safety guarantees for such neural network based controllers has significantly impeded their adoption in safety-critical CPSs. In this work, we propose a controller adaptation approach that automatically switches among multiple controllers, including neural network controllers, to guarantee system safety and improve energy efficiency. Our approach includes two key components based on formal methods and machine learning. First, we approximate each controller with a Bernstein-polynomial based hybrid system model under bounded disturbance, and compute a safe invariant set for each controller based on its corresponding hybrid system. Intuitively, the invariant set of a controller defines the state space where the system can always remain safe under its control. The union of the controllers' invariants sets then define a safe adaptation space that is larger than (or equal to) that of each controller. Second, we develop a deep reinforcement learning method to learn a controller switching strategy for reducing the control/actuation energy cost, while with the help of a safety guard rule, ensuring that the system stays within the safe space. Experiments on a linear adaptive cruise control system and a non-linear Van der Pol's oscillator demonstrate the effectiveness of our approach on energy saving and safety enhancement.", "pdf_url": "https://arxiv.org/pdf/2008.06162", "subject": "Systems and Control (eess.SY)"},
{"title": "A polynomial algorithm for the maximum clique", "author": "Ioannis Avramopoulos", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this paper, we present a polynomial-time algorithm for the maximum clique problem, which implies P = NP. Our algorithm works with a continuous representation of this problem that is parametrized and uses an equilibrium computation engine that, depending on the value of the parameter, either detects a \"maximum-clique equilibrium\" or decides that such an equilibrium does not exist (for that parameter). From a technical perspective, one of our contributions is to transform an equilibrium fully polynomial-time approximation scheme to a polynomial-time equilibrium computation algorithm for the continuous representation we are working with.", "pdf_url": "https://arxiv.org/pdf/2008.06167", "subject": "Computer Science and Game Theory (cs.GT)"},
{"title": "Privacy Preserving Vertical Federated Learning for Tree-based Models", "author": "Yuncheng Wu, Shaofeng Cai, Xiaokui Xiao, Gang Chen, Beng Chin Ooi", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Federated learning (FL) is an emerging paradigm that enables multiple organizations to jointly train a model without revealing their private data to each other. This paper studies {\\it vertical} federated learning, which tackles the scenarios where (i) collaborating organizations own data of the same set of users but with disjoint features, and (ii) only one organization holds the labels. We propose Pivot, a novel solution for privacy preserving vertical decision tree training and prediction, ensuring that no intermediate information is disclosed other than those the clients have agreed to release (i.e., the final tree model and the prediction output). Pivot does not rely on any trusted third party and provides protection against a semi-honest adversary that may compromise $m-1$ out of $m$ clients. We further identify two privacy leakages when the trained decision tree model is released in plaintext and propose an enhanced protocol to mitigate them. The proposed solution can also be extended to tree ensemble models, e.g., random forest (RF) and gradient boosting decision tree (GBDT) by treating single decision trees as building blocks. Theoretical and experimental analysis suggest that Pivot is efficient for the privacy achieved.", "pdf_url": "https://arxiv.org/pdf/2008.06170", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Speech To Semantics: Improve ASR and NLU Jointly via All-Neural Interfaces", "author": "Milind Rao, Anirudh Raju, Pranav Dheram, Bach Bui, Ariya Rastrow", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We consider the problem of spoken language understanding (SLU) of extracting natural language intents and associated slot arguments or named entities from speech that is primarily directed at voice assistants. Such a system subsumes both automatic speech recognition (ASR) as well as natural language understanding (NLU). An end-to-end joint SLU model can be built to a required specification opening up the opportunity to deploy on hardware constrained scenarios like devices enabling voice assistants to work offline, in a privacy preserving manner, whilst also reducing server costs. We first present models that extract utterance intent directly from speech without intermediate text output. We then present a compositional model, which generates the transcript using the Listen Attend Spell ASR system and then extracts interpretation using a neural NLU model. Finally, we contrast these methods to a jointly trained end-to-end joint SLU model, consisting of ASR and NLU subsystems which are connected by a neural network based interface instead of text, that produces transcripts as well as NLU interpretation. We show that the jointly trained model shows improvements to ASR incorporating semantic information from NLU and also improves NLU by exposing it to ASR confusion encoded in the hidden layer.", "pdf_url": "https://arxiv.org/pdf/2008.06173", "subject": "Computation and Language (cs.CL)"},
{"title": "A Hybrid BERT and LightGBM based Model for Predicting Emotion GIF Categories on Twitter", "author": "Ye Bi, Shuo Wang, Zhongrui Fan", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The animated Graphical Interchange Format (GIF) images have been widely used on social media as an intuitive way of expression emotion. Given their expressiveness, GIFs offer a more nuanced and precise way to convey emotions. In this paper, we present our solution for the EmotionGIF 2020 challenge, the shared task of SocialNLP 2020. To recommend GIF categories for unlabeled tweets, we regarded this problem as a kind of matching tasks and proposed a learning to rank framework based on Bidirectional Encoder Representations from Transformer (BERT) and LightGBM. Our team won the 4th place with a Mean Average Precision @ 6 (MAP@6) score of 0.5394 on the round 1 leaderboard.", "pdf_url": "https://arxiv.org/pdf/2008.06176", "subject": "Information Retrieval (cs.IR)"},
{"title": "PANDA: Processing-in-MRAM Accelerated De Bruijn Graph based DNA Assembly", "author": "Shaahin Angizi, Naima Ahmed Fahmi, Wei Zhang, Deliang Fan", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Spurred by widening gap between data processing speed and data communication speed in Von-Neumann computing architectures, some bioinformatic applications have harnessed the computational power of Processing-in-Memory (PIM) platforms. However, the performance of PIMs unavoidably diminishes when dealing with such complex applications seeking bulk bit-wise comparison or addition operations. In this work, we present an efficient Processing-in-MRAM Accelerated De Bruijn Graph based DNA Assembly platform named PANDA based on an optimized and hardware-friendly genome assembly algorithm. PANDA is able to assemble large-scale DNA sequence data-set from all-pair overlaps. We first design PANDA platform that exploits MRAM as a computational memory and converts it to a potent processing unit for genome assembly. PANDA can execute not only efficient bulk bit-wise X(N)OR-based comparison/addition operations heavily required for the genome assembly task but a full-set of 2-/3-input logic operations inside MRAM chip. We then develop a highly parallel and step-by-step hardware-friendly DNA assembly algorithm for PANDA that only requires the developed in-memory logic operations. The platform is then configured with a novel data partitioning and mapping technique that provides local storage and processing to fully utilize the algorithm-level's parallelism. The cross-layer simulation results demonstrate that PANDA reduces the run time and power, respectively, by a factor of 18 and 11 compared with CPU. Besides, speed-ups of up-to 2-4x can be obtained over recent processing-in-MRAM platforms to perform the same task.", "pdf_url": "https://arxiv.org/pdf/2008.06177", "subject": "Hardware Architecture (cs.AR)"},
{"title": "A Multimodal Late Fusion Model for E-Commerce Product Classification", "author": "Ye Bi, Shuo Wang, Zhongrui Fan", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The cataloging of product listings is a fundamental problem for most e-commerce platforms. Despite promising results obtained by unimodal-based methods, it can be expected that their performance can be further boosted by the consideration of multimodal product information. In this study, we investigated a multimodal late fusion approach based on text and image modalities to categorize e-commerce products on Rakuten. Specifically, we developed modal specific state-of-the-art deep neural networks for each input modal, and then fused them at the decision level. Experimental results on Multimodal Product Classification Task of SIGIR 2020 E-Commerce Workshop Data Challenge demonstrate the superiority and effectiveness of our proposed method compared with unimodal and other multimodal methods. Our team named pa_curis won the 1st place with a macro-F1 of 0.9144 on the final leaderboard.", "pdf_url": "https://arxiv.org/pdf/2008.06179", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Distillation-Based Semi-Supervised Federated Learning for Communication-Efficient Collaborative Training with Non-IID Private Data", "author": "Sohei Itahara, Takayuki Nishio, Yusuke Koda, Masahiro Morikura, Koji Yamamoto", "pub_date": "Submitted on 14 Aug 2020", "abstract": "This study develops a federated learning (FL) framework overcoming largely incremental communication costs due to model sizes in typical frameworks without compromising model performance. To this end, based on the idea of leveraging an unlabeled open dataset, we propose a distillation-based semi-supervised FL (DS-FL) algorithm that exchanges the outputs of local models among mobile devices, instead of model parameter exchange employed by the typical frameworks. In DS-FL, the communication cost depends only on the output dimensions of the models and does not scale up according to the model size. The exchanged model outputs are used to label each sample of the open dataset, which creates an additionally labeled dataset. Based on the new dataset, local models are further trained, and model performance is enhanced owing to the data augmentation effect. We further highlight that in DS-FL, the heterogeneity of the devices' dataset leads to ambiguous of each data sample and lowing of the training convergence. To prevent this, we propose entropy reduction averaging, where the aggregated model outputs are intentionally sharpened. Moreover, extensive experiments show that DS-FL reduces communication costs up to 99% relative to those of the FL benchmark while achieving similar or higher classification accuracy.", "pdf_url": "https://arxiv.org/pdf/2008.06180", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Apparel-invariant Feature Learning for Apparel-changed Person Re-identification", "author": "Zhengxu Yu, Yilun Zhao, Bin Hong, Zhongming Jin, Jianqiang Huang, Deng Cai, Xiaofei He, Xian-Sheng Hua", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 17 Aug 2020 (this version, v2)", "abstract": "With the rise of deep learning methods, person Re-Identification (ReID) performance has been improved tremendously in many public datasets. However, most public ReID datasets are collected in a short time window in which persons' appearance rarely changes. In real-world applications such as in a shopping mall, the same person's clothing may change, and different persons may wearing similar clothes. All these cases can result in an inconsistent ReID performance, revealing a critical problem that current ReID models heavily rely on person's apparels. Therefore, it is critical to learn an apparel-invariant person representation under cases like cloth changing or several persons wearing similar clothes. In this work, we tackle this problem from the viewpoint of invariant feature representation learning. The main contributions of this work are as follows. (1) We propose the semi-supervised Apparel-invariant Feature Learning (AIFL) framework to learn an apparel-invariant pedestrian representation using images of the same person wearing different clothes. (2) To obtain images of the same person wearing different clothes, we propose an unsupervised apparel-simulation GAN (AS-GAN) to synthesize cloth changing images according to the target cloth embedding. It's worth noting that the images used in ReID tasks were cropped from real-world low-quality CCTV videos, making it more challenging to synthesize cloth changing images. We conduct extensive experiments on several datasets comparing with several baselines. Experimental results demonstrate that our proposal can improve the ReID performance of the baseline models.", "pdf_url": "https://arxiv.org/pdf/2008.06181", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "An Improved Deep Convolutional Neural Network-Based Autonomous Road Inspection Scheme Using Unmanned Aerial Vehicles", "author": "Syed Ali Hassan, Tariq Rahim, Soo Young Shin", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Advancements in artificial intelligence (AI) gives a great opportunity to develop an autonomous devices. The contribution of this work is an improved convolutional neural network (CNN) model and its implementation for the detection of road cracks, potholes, and yellow lane in the road. The purpose of yellow lane detection and tracking is to realize autonomous navigation of unmanned aerial vehicle (UAV) by following yellow lane while detecting and reporting the road cracks and potholes to the server through WIFI or 5G medium. The fabrication of own data set is a hectic and time-consuming task. The data set is created, labeled and trained using default and an improved model. The performance of both these models is benchmarked with respect to accuracy, mean average precision (mAP) and detection time. In the testing phase, it was observed that the performance of the improved model is better in respect of accuracy and mAP. The improved model is implemented in UAV using the robot operating system for the autonomous detection of potholes and cracks in roads via UAV front camera vision in real-time.", "pdf_url": "https://arxiv.org/pdf/2008.06189", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Leveraging Weakly-hard Constraints for Improving System Fault Tolerance with Functional and Timing Guarantees", "author": "Hengyi Liang, Zhilu Wang, Ruochen Jiao, Qi Zhu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Many safety-critical real-time systems operate under harsh environment and are subject to soft errors caused by transient or intermittent faults. It is critical and yet often very challenging to apply fault tolerance techniques in these systems, due to their resource limitations and stringent constraints on timing and functionality. In this work, we leverage the concept of weakly-hard constraints, which allows task deadline misses in a bounded manner, to improve system's capability to accommodate fault tolerance techniques while ensuring timing and functional correctness. In particular, we 1) quantitatively measure control cost under different deadline hit/miss scenarios and identify weak-hard constraints that guarantee control stability, 2) employ typical worst-case analysis (TWCA) to bound the number of deadline misses and approximate system control cost, 3) develop an event-based simulation method to check the task execution pattern and evaluate system control cost for any given solution and 4) develop a meta-heuristic algorithm that consists of heuristic methods and a simulated annealing procedure to explore the design space. Our experiments on an industrial case study and a set of synthetic examples demonstrate the effectiveness of our approach.", "pdf_url": "https://arxiv.org/pdf/2008.06192", "subject": "Systems and Control (eess.SY)"},
{"title": "Federated Doubly Stochastic Kernel Learning for Vertically Partitioned Data", "author": "Bin Gu, Zhiyuan Dang, Xiang Li, Heng Huang", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In a lot of real-world data mining and machine learning applications, data are provided by multiple providers and each maintains private records of different feature sets about common entities. It is challenging to train these vertically partitioned data effectively and efficiently while keeping data privacy for traditional data mining and machine learning algorithms. In this paper, we focus on nonlinear learning with kernels, and propose a federated doubly stochastic kernel learning (FDSKL) algorithm for vertically partitioned data. Specifically, we use random features to approximate the kernel mapping function and use doubly stochastic gradients to update the solutions, which are all computed federatedly without the disclosure of data. Importantly, we prove that FDSKL has a sublinear convergence rate, and can guarantee the data security under the semi-honest assumption. Extensive experimental results on a variety of benchmark datasets show that FDSKL is significantly faster than state-of-the-art federated learning methods when dealing with kernels, while retaining the similar generalization performance.", "pdf_url": "https://arxiv.org/pdf/2008.06197", "subject": "Machine Learning (cs.LG)"},
{"title": "Defending Adversarial Attacks without Adversarial Attacks in Deep Reinforcement Learning", "author": "Xinghua Qu, Yew-Soon Ong, Abhishek Gupta, Zhu Sun", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Many recent studies in deep reinforcement learning (DRL) have proposed to boost adversarial robustness through policy distillation utilizing adversarial training, where additional adversarial examples are added in the training process of the student policy; this makes the robustness improvement less flexible and more computationally expensive. In contrast, we propose an efficient policy distillation paradigm called robust policy distillation that is capable of achieving an adversarially robust student policy without relying on any adversarial example during student policy training. To this end, we devise a new policy distillation loss that consists of two terms: 1) a prescription gap maximization loss aiming at simultaneously maximizing the likelihood of the action selected by the teacher policy and the entropy over the remaining actions; 2) a Jacobian regularization loss that minimizes the magnitude of Jacobian with respect to the input state. The theoretical analysis proves that our distillation loss guarantees to increase the prescription gap and the adversarial robustness. Meanwhile, experiments on five Atari games firmly verifies the superiority of our policy distillation on boosting adversarial robustness compared to other state-of-the-arts.", "pdf_url": "https://arxiv.org/pdf/2008.06199", "subject": "Machine Learning (cs.LG)"},
{"title": "Structure-Aware Network for Lane Marker Extraction with Dynamic Vision Sensor", "author": "Wensheng Cheng, Hao Luo, Wen Yang, Lei Yu, Wei Li", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Lane marker extraction is a basic yet necessary task for autonomous driving. Although past years have witnessed major advances in lane marker extraction with deep learning models, they all aim at ordinary RGB images generated by frame-based cameras, which limits their performance in extreme cases, like huge illumination change. To tackle this problem, we introduce Dynamic Vision Sensor (DVS), a type of event-based sensor to lane marker extraction task and build a high-resolution DVS dataset for lane marker extraction. We collect the raw event data and generate 5,424 DVS images with a resolution of 1280$\\times$800 pixels, the highest one among all DVS datasets available now. All images are annotated with multi-class semantic segmentation format. We then propose a structure-aware network for lane marker extraction in DVS images. It can capture directional information comprehensively with multidirectional slice convolution. We evaluate our proposed network with other state-of-the-art lane marker extraction models on this dataset. Experimental results demonstrate that our method outperforms other competitors. The dataset is made publicly available, including the raw event data, accumulated images and labels.", "pdf_url": "https://arxiv.org/pdf/2008.06204", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Time in Blockchain-Based Process Execution", "author": "Jan Ladleif, Mathias Weske", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The traceable execution of business processes and choreographies using smart contracts is one prominent application of blockchain technology in Business Process Management (BPM). Existing approaches support a large set of patterns, modeling languages, and blockchain architectures, which cover a wide range of practical scenarios. However, they largely neglect the important aspect of time, a crucial part of process and choreography models manifested in deadlines, delays, and other temporal constraints. We argue that this deficit is due to inherent limitations of smart contracts---in particular the absence of a natural notion of measuring time---on popular blockchain platforms used in research and practice. We introduce a set of time measures available on blockchain platforms to alleviate these issues, and systematically compare their properties. We also give hints as to their suitability for facilitating various temporal constraints commonly found in process models.", "pdf_url": "https://arxiv.org/pdf/2008.06210", "subject": "Software Engineering (cs.SE)"},
{"title": "The Impact of Auto-Refactoring Code Smells on the Resource Utilization of Cloud Software", "author": "Asif Imran, Tevfik Kosar", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Cloud-based software-as-a-service (SaaS) have gained popularity due to their low cost and elasticity. However, like other software, SaaS applications suffer from code smells, which can drastically affect functionality and resource usage. Code smell is any design in the source code that indicates a deeper problem. The software community deploys automated refactoring to eliminate smells which can improve performance and also decrease the usage of critical resources. However, studies that analyze the impact of automatic refactoring smells in SaaS on resources such as CPU and memory have been conducted to a limited extent. Here, we aim to fill that gap and study the impact on resource usage of SaaS applications due to automatic refactoring of seven classic code smells: god class, feature envy, type checking, cyclic dependency, shotgun surgery, god method, and spaghetti code. We specified six real-life SaaS applications from Github called Zimbra, OneDataShare, GraphHopper, Hadoop, JENA, and JAMES which ran on Openstack cloud. Results show that refactoring smells by tools like JDeodrant and JSparrow have widely varying impacts on the CPU and memory consumption of the tested applications based on the type of smell refactored. We present the resource utilization impact of each smell and also discuss the potential reasons leading to that effect.", "pdf_url": "https://arxiv.org/pdf/2008.06214", "subject": "Software Engineering (cs.SE)"},
{"title": "Formulation of Single-Source Surface Integral Equation for Electromagnetic Analysis of Composite Penetrable Objects", "author": "Xiaochao Zhou, Zekun Zhu, Shunchuan Yang", "pub_date": "Submitted on 14 Aug 2020", "abstract": "This paper presents a new single-source surface integral equation (SS-SIE) to model composite penetrable objects. In the proposed formulation, the surface electric and magnetic fields on all interior boundaries are first eliminated through combining integral solutions inside each object. Then, by enforcing the surface electric fields in the original and equivalent configurations are equal to each other, an equivalent model with only the electric current density on the outermost boundaries is derived. Compared with other SIEs, like the PMCHWT formulation, all unknowns are residing on the outermost boundaries in the proposed formulation and therefore, less count of unknowns can be obtained. Finally, two numerical examples are carried out to validate the effectiveness of the proposed SS-SIE.", "pdf_url": "https://arxiv.org/pdf/2008.06216", "subject": "Computational Engineering, Finance, and Science (cs.CE)"},
{"title": "Towards Class Imbalance in Federated Learning", "author": "Lixu Wang, Shichao Xu, Xiao Wang, Qi Zhu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Federated learning (FL) is a promising approach for training decentralized data located on local client devices while improving efficiency and privacy. However, the distribution and quantity of the training data on the clients' side may lead to significant challenges such as data imbalance and non-IID (non-independent and identically distributed) data, which could greatly impact the performance of the common model. While much effort has been devoted to helping FL models converge when encountering non-IID data, the imbalance issue has not been sufficiently addressed. In particular, as FL training is executed by exchanging gradients in an encrypted form, the training data is not completely observable to either clients or server, and previous methods for data imbalance do not perform well for FL. Therefore, it is crucial to design new methods for detecting data imbalance in FL and mitigating its impact. In this work, we propose a monitoring scheme that can infer the composition proportion of training data for each FL round, and design a new loss function -- Ratio Loss to mitigate the impact of the imbalance. Our experiments demonstrate the importance of detecting data imbalance and taking measures as early as possible in FL training, and the effectiveness of our method in mitigating the impact. Our method is shown to significantly outperform previous methods, while maintaining client privacy.", "pdf_url": "https://arxiv.org/pdf/2008.06217", "subject": "Machine Learning (cs.LG)"},
{"title": "Which Strategies Matter for Noisy Label Classification? Insight into Loss and Uncertainty", "author": "Wonyoung Shin, Jung-Woo Ha, Shengzhe Li, Yongwoo Cho, Hoyean Song, Sunyoung Kwon", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Label noise is a critical factor that degrades the generalization performance of deep neural networks, thus leading to severe issues in real-world problems. Existing studies have employed strategies based on either loss or uncertainty to address noisy labels, and ironically some strategies contradict each other: emphasizing or discarding uncertain samples or concentrating on high or low loss samples. To elucidate how opposing strategies can enhance model performance and offer insights into training with noisy labels, we present analytical results on how loss and uncertainty values of samples change throughout the training process. From the in-depth analysis, we design a new robust training method that emphasizes clean and informative samples, while minimizing the influence of noise using both loss and uncertainty. We demonstrate the effectiveness of our method with extensive experiments on synthetic and real-world datasets for various deep learning models. The results show that our method significantly outperforms other state-of-the-art methods and can be used generally regardless of neural network architectures.", "pdf_url": "https://arxiv.org/pdf/2008.06218", "subject": "Machine Learning (cs.LG)"},
{"title": "Regularization of Inverse Problems by Filtered Diagonal Frame Decomposition", "author": "Andrea Ebner, J\u00fcrgen Frikel, Dirk Lorenz, Johannes Schwab, Markus Haltmeier", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The characteristic feature of inverse problems is their instability with respect to data perturbations. In order to stabilize the inversion process, regularization methods have to be developed and applied. In this work we introduce and analyze the concept of filtered diagonal frame decomposition which extends the standard filtered singular value decomposition to the frame case. Frames as generalized singular system allows to better adapt to a given class of potential solutions. In this paper, we show that filtered diagonal frame decomposition yield a convergent regularization method. Moreover, we derive convergence rates under source type conditions and prove order optimality under the assumption that the considered frame is a Riesz-basis.", "pdf_url": "https://arxiv.org/pdf/2008.06219", "subject": "Numerical Analysis (math.NA)"},
{"title": "Kernel Methods for Cooperative Multi-Agent Contextual Bandits", "author": "Abhimanyu Dubey, Alex Pentland", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Cooperative multi-agent decision making involves a group of agents cooperatively solving learning problems while communicating over a network with delays. In this paper, we consider the kernelised contextual bandit problem, where the reward obtained by an agent is an arbitrary linear function of the contexts' images in the related reproducing kernel Hilbert space (RKHS), and a group of agents must cooperate to collectively solve their unique decision problems. For this problem, we propose \\textsc{Coop-KernelUCB}, an algorithm that provides near-optimal bounds on the per-agent regret, and is both computationally and communicatively efficient. For special cases of the cooperative problem, we also provide variants of \\textsc{Coop-KernelUCB} that provides optimal per-agent regret. In addition, our algorithm generalizes several existing results in the multi-agent bandit setting. Finally, on a series of both synthetic and real-world multi-agent network benchmarks, we demonstrate that our algorithm significantly outperforms existing benchmarks.", "pdf_url": "https://arxiv.org/pdf/2008.06220", "subject": "Machine Learning (cs.LG)"},
{"title": "Annotating for Hate Speech: The MaNeCo Corpus and Some Input from Critical Discourse Analysis", "author": "Stavros Assimakopoulos, Rebecca Vella Muskat, Lonneke van der Plas, Albert Gatt", "pub_date": "Submitted on 14 Aug 2020", "abstract": "This paper presents a novel scheme for the annotation of hate speech in corpora of Web 2.0 commentary. The proposed scheme is motivated by the critical analysis of posts made in reaction to news reports on the Mediterranean migration crisis and LGBTIQ+ matters in Malta, which was conducted under the auspices of the EU-funded C.O.N.T.A.C.T. project. Based on the realization that hate speech is not a clear-cut category to begin with, appears to belong to a continuum of discriminatory discourse and is often realized through the use of indirect linguistic means, it is argued that annotation schemes for its detection should refrain from directly including the label 'hate speech,' as different annotators might have different thresholds as to what constitutes hate speech and what not. In view of this, we suggest a multi-layer annotation scheme, which is pilot-tested against a binary +/- hate speech classification and appears to yield higher inter-annotator agreement. Motivating the postulation of our scheme, we then present the MaNeCo corpus on which it will eventually be used; a substantial corpus of on-line newspaper comments spanning 10 years.", "pdf_url": "https://arxiv.org/pdf/2008.06222", "subject": "Computers and Society (cs.CY)"},
{"title": "Parameters Sharing Exploration and Hetero-Center based Triplet Loss for Visible-Thermal Person Re-Identification", "author": "Haijun Liu, Xiaoheng Tan", "pub_date": "Submitted on 14 Aug 2020", "abstract": "This paper focuses on the visible-thermal cross-modality person re-identification (VT Re-ID) task, whose goal is to match person images between the daytime visible modality and the nighttime thermal modality. The two-stream network is usually adopted to address the cross-modality discrepancy, the most challenging problem for VT Re-ID, by learning the multi-modality person features. In this paper, we explore how many parameters of two-stream network should share, which is still not well investigated in the existing literature. By well splitting the ResNet50 model to construct the modality-specific feature extracting network and modality-sharing feature embedding network, we experimentally demonstrate the effect of parameters sharing of two-stream network for VT Re-ID. Moreover, in the framework of part-level person feature learning, we propose the hetero-center based triplet loss to relax the strict constraint of traditional triplet loss through replacing the comparison of anchor to all the other samples by anchor center to all the other centers. With the extremely simple means, the proposed method can significantly improve the VT Re-ID performance. The experimental results on two datasets show that our proposed method distinctly outperforms the state-of-the-art methods by large margins, especially on RegDB dataset achieving superior performance, rank1/mAP/mINP 91.05%/83.28%/68.84%. It can be a new baseline for VT Re-ID, with simple but effective strategy.", "pdf_url": "https://arxiv.org/pdf/2008.06223", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "BriNet: Towards Bridging the Intra-class and Inter-class Gaps in One-Shot Segmentation", "author": "Xianghui Yang, Bairun Wang, Kaige Chen, Xinchi Zhou, Shuai Yi, Wanli Ouyang, Luping Zhou", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Few-shot segmentation focuses on the generalization of models to segment unseen object instances with limited training samples. Although tremendous improvements have been achieved, existing methods are still constrained by two factors. (1) The information interaction between query and support images is not adequate, leaving intra-class gap. (2) The object categories at the training and inference stages have no overlap, leaving the inter-class gap. Thus, we propose a framework, BriNet, to bridge these gaps. First, more information interactions are encouraged between the extracted features of the query and support images, i.e., using an Information Exchange Module to emphasize the common objects. Furthermore, to precisely localize the query objects, we design a multi-path fine-grained strategy which is able to make better use of the support feature representations. Second, a new online refinement strategy is proposed to help the trained model adapt to unseen classes, achieved by switching the roles of the query and the support images at the inference stage. The effectiveness of our framework is demonstrated by experimental results, which outperforms other competitive methods and leads to a new state-of-the-art on both PASCAL VOC and MSCOCO dataset.", "pdf_url": "https://arxiv.org/pdf/2008.06226", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Deep Atrous Guided Filter for Image Restoration in Under Display Cameras", "author": "Varun Sundar, Sumanth Hegde, Divya Kothandaraman, Kaushik Mitra", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Under Display Cameras present a promising opportunity for phone manufacturers to achieve bezel-free displays by positioning the camera behind semi-transparent OLED screens. Unfortunately, such imaging systems suffer from severe image degradation due to light attenuation and diffraction effects. In this work, we present Deep Atrous Guided Filter (DAGF), a two-stage, end-to-end approach for image restoration in UDC systems. A Low-Resolution Network first restores image quality at low-resolution, which is subsequently used by the Guided Filter Network as a filtering input to produce a high-resolution output. Besides the initial downsampling, our low-resolution network uses multiple, parallel atrous convolutions to preserve spatial resolution and emulates multi-scale processing. Our approach's ability to directly train on megapixel images results in significant performance improvement. We additionally propose a simple simulation scheme to pre-train our model and boost performance. Our overall framework ranks 2nd and 5th in the RLQ-TOD'20 UDC Challenge for POLED and TOLED displays, respectively.", "pdf_url": "https://arxiv.org/pdf/2008.06229", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Privacy-Preserving Asynchronous Federated Learning Algorithms for Multi-Party Vertically Collaborative Learning", "author": "Bin Gu, An Xu, Zhouyuan Huo, Cheng Deng, Heng Huang", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The privacy-preserving federated learning for vertically partitioned data has shown promising results as the solution of the emerging multi-party joint modeling application, in which the data holders (such as government branches, private finance and e-business companies) collaborate throughout the learning process rather than relying on a trusted third party to hold data. However, existing federated learning algorithms for vertically partitioned data are limited to synchronous computation. To improve the efficiency when the unbalanced computation/communication resources are common among the parties in the federated learning system, it is essential to develop asynchronous training algorithms for vertically partitioned data while keeping the data privacy. In this paper, we propose an asynchronous federated SGD (AFSGD-VP) algorithm and its SVRG and SAGA variants on the vertically partitioned data. Moreover, we provide the convergence analyses of AFSGD-VP and its SVRG and SAGA variants under the condition of strong convexity. We also discuss their model privacy, data privacy, computational complexities and communication costs. To the best of our knowledge, AFSGD-VP and its SVRG and SAGA variants are the first asynchronous federated learning algorithms for vertically partitioned data. Extensive experimental results on a variety of vertically partitioned datasets not only verify the theoretical results of AFSGD-VP and its SVRG and SAGA variants, but also show that our algorithms have much higher efficiency than the corresponding synchronous algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.06233", "subject": "Machine Learning (cs.LG)"},
{"title": "Language Models as Few-Shot Learner for Task-Oriented Dialogue Systems", "author": "Andrea Madotto, Zihan Liu, Zhaojiang Lin, Pascale Fung", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "Task-oriented dialogue systems use four connected modules, namely, Natural Language Understanding (NLU), a Dialogue State Tracking (DST), Dialogue Policy (DP) and Natural Language Generation (NLG). A research challenge is to learn each module with the least amount of samples (i.e., few-shots) given the high cost related to the data collection. The most common and effective technique to solve this problem is transfer learning, where large language models, either pre-trained on text or task-specific data, are fine-tuned on the few samples. These methods require fine-tuning steps and a set of parameters for each task. Differently, language models, such as GPT-2 (Radford et al., 2019) and GPT-3 (Brown et al., 2020), allow few-shot learning by priming the model with few examples. In this paper, we evaluate the priming few-shot ability of language models in the NLU, DST, DP and NLG tasks. Importantly, we highlight the current limitations of this approach, and we discuss the possible implication for future work.", "pdf_url": "https://arxiv.org/pdf/2008.06239", "subject": "Computation and Language (cs.CL)"},
{"title": "On Localized Discrepancy for Domain Adaptation", "author": "Yuchen Zhang, Mingsheng Long, Jianmin Wang, Michael I. Jordan", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We propose the discrepancy-based generalization theories for unsupervised domain adaptation. Previous theories introduced distribution discrepancies defined as the supremum over complete hypothesis space. The hypothesis space may contain hypotheses that lead to unnecessary overestimation of the risk bound. This paper studies the localized discrepancies defined on the hypothesis space after localization. First, we show that these discrepancies have desirable properties. They could be significantly smaller than the pervious discrepancies. Their values will be different if we exchange the two domains, thus can reveal asymmetric transfer difficulties. Next, we derive improved generalization bounds with these discrepancies. We show that the discrepancies could influence the rate of the sample complexity. Finally, we further extend the localized discrepancies for achieving super transfer and derive generalization bounds that could be even more sample-efficient on source domain.", "pdf_url": "https://arxiv.org/pdf/2008.06242", "subject": "Machine Learning (cs.LG)"},
{"title": "Cooperative Multi-Agent Bandits with Heavy Tails", "author": "Abhimanyu Dubey, Alex Pentland", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We study the heavy-tailed stochastic bandit problem in the cooperative multi-agent setting, where a group of agents interact with a common bandit problem, while communicating on a network with delays. Existing algorithms for the stochastic bandit in this setting utilize confidence intervals arising from an averaging-based communication protocol known as~\\textit{running consensus}, that does not lend itself to robust estimation for heavy-tailed settings. We propose \\textsc{MP-UCB}, a decentralized multi-agent algorithm for the cooperative stochastic bandit that incorporates robust estimation with a message-passing protocol. We prove optimal regret bounds for \\textsc{MP-UCB} for several problem settings, and also demonstrate its superiority to existing methods. Furthermore, we establish the first lower bounds for the cooperative bandit problem, in addition to providing efficient algorithms for robust bandit estimation of location.", "pdf_url": "https://arxiv.org/pdf/2008.06244", "subject": "Machine Learning (cs.LG)"},
{"title": "Graph Polish: A Novel Graph Generation Paradigm for Molecular Optimization", "author": "Chaojie Ji, Yijia Zheng, Ruxin Wang, Yunpeng Cai, Hongyan Wu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Molecular optimization, which transforms a given input molecule X into another Y with desirable properties, is essential in molecular drug discovery. The traditional translating approaches, generating the molecular graphs from scratch by adding some substructures piece by piece, prone to error because of the large set of candidate substructures in a large number of steps to the final target. In this study, we present a novel molecular optimization paradigm, Graph Polish, which changes molecular optimization from the traditional \"two-language translating\" task into a \"single-language polishing\" task. The key to this optimization paradigm is to find an optimization center subject to the conditions that the preserved areas around it ought to be maximized and thereafter the removed and added regions should be minimized. We then propose an effective and efficient learning framework T&S polish to capture the long-term dependencies in the optimization steps. The T component automatically identifies and annotates the optimization centers and the preservation, removal and addition of some parts of the molecule, and the S component learns these behaviors and applies these actions to a new molecule. Furthermore, the proposed paradigm can offer an intuitive interpretation for each molecular optimization result. Experiments with multiple optimization tasks are conducted on four benchmark datasets. The proposed T&S polish approach achieves significant advantage over the five state-of-the-art baseline methods on all the tasks. In addition, extensive studies are conducted to validate the effectiveness, explainability and time saving of the novel optimization paradigm.", "pdf_url": "https://arxiv.org/pdf/2008.06246", "subject": "Machine Learning (cs.LG)"},
{"title": "$C^s$-smooth isogeometric spline spaces over planar multi-patch parameterizations", "author": "Mario Kapl, Vito Vitrih", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The design of globally $C^s$-smooth ($s \\geq 1$) isogeometric spline spaces over multi-patch geometries is a current and challenging topic of research in the framework of isogeometric analysis. In this work, we extend the recent methods [25,28] and [31-33] for the construction of $C^1$-smooth and $C^2$-smooth isogeometric spline spaces over particular planar multi-patch geometries to the case of $C^s$-smooth isogeometric multi-patch spline spaces of an arbitrary selected smoothness $s \\geq 1$. More precisely, for any $s \\geq 1$, we study the space of $C^s$-smooth isogeometric spline functions defined on planar, bilinearly parameterized multi-patch domains, and generate a particular $C^s$-smooth subspace of the entire $C^s$-smooth isogeometric multi-patch spline space. We further present the construction of a basis for this $C^s$-smooth subspace, which consists of simple and locally supported functions. Moreover, we use the $C^s$-smooth spline functions to perform $L^2$ approximation on bilinearly parameterized multi-patch domains, where the obtained numerical results indicate an optimal approximation power of the constructed $C^s$-smooth subspace.", "pdf_url": "https://arxiv.org/pdf/2008.06247", "subject": "Numerical Analysis (math.NA)"},
{"title": "New schemes under coded caching placement", "author": "Mingming Zhang, Minquan Cheng, Jinyu Wang, Xi Zhong, Yishan Chen", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Coded caching schemes with low subpacketization and small transmission rate is very important in practice due to the low implementing complexities and efficient transmissions. However, many such coded caching schemes have large memory ratio. In this paper, by investigating the structure of the placement delivery array (PDA in short), which can be used to generate coded caching schemes, we find out that some schemes with low subpacketization do not fully use the users' caching contents to create multicasting opportunities. Then based on such a PDA, coded placement is used to make the caching contents fully used. As an application, based on a class of previously well known PDAs we obtain two new schemes, which have significantly advantages on the memory ratio and transmission rate compared with the original schemes.", "pdf_url": "https://arxiv.org/pdf/2008.06248", "subject": "Information Theory (cs.IT)"},
{"title": "Continuous Optimization Benchmarks by Simulation", "author": "Martin Zaefferer, Frederik Rehbach", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Benchmark experiments are required to test, compare, tune, and understand optimization algorithms. Ideally, benchmark problems closely reflect real-world problem behavior. Yet, real-world problems are not always readily available for benchmarking. For example, evaluation costs may be too high, or resources are unavailable (e.g., software or equipment). As a solution, data from previous evaluations can be used to train surrogate models which are then used for benchmarking. The goal is to generate test functions on which the performance of an algorithm is similar to that on the real-world objective function. However, predictions from data-driven models tend to be smoother than the ground-truth from which the training data is derived. This is especially problematic when the training data becomes sparse. The resulting benchmarks may not reflect the landscape features of the ground-truth, are too easy, and may lead to biased conclusions. To resolve this, we use simulation of Gaussian processes instead of estimation (or prediction). This retains the covariance properties estimated during model training. While previous research suggested a decomposition-based approach for a small-scale, discrete problem, we show that the spectral simulation method enables simulation for continuous optimization problems. In a set of experiments with an artificial ground-truth, we demonstrate that this yields more accurate benchmarks than simply predicting with the Gaussian process model.", "pdf_url": "https://arxiv.org/pdf/2008.06249", "subject": "Neural and Evolutionary Computing (cs.NE)"},
{"title": "Reasonable Machines: A Research Manifesto", "author": "Christoph Benzm\u00fcller, Bertram Lomfeld", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Future intelligent autonomous systems (IAS) are inevitably deciding on moral and legal questions, e.g. in self-driving cars, health care or human-machine collaboration. As decision processes in most modern sub-symbolic IAS are hidden, the simple political plea for transparency, accountability and governance falls short. A sound ecosystem of trust requires ways for IAS to autonomously justify their actions, that is, to learn giving and taking reasons for their decisions. Building on social reasoning models in moral psychology and legal philosophy such an idea of >>Reasonable Machines<< requires novel, hybrid reasoning tools, ethico-legal ontologies and associated argumentation technology. Enabling machines to normative communication creates trust and opens new dimensions of AI application and human-machine interaction. Keywords: Trusthworthy and Explainable AI, Ethico-Legal Governors, Social Reasoning Model, Pluralistic and Expressive Normative Reasoning", "pdf_url": "https://arxiv.org/pdf/2008.06250", "subject": "Computers and Society (cs.CY)"},
{"title": "ConsNet: Learning Consistency Graph for Zero-Shot Human-Object Interaction Detection", "author": "Ye Liu, Junsong Yuan, Chang Wen Chen", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We consider the problem of Human-Object Interaction (HOI) Detection, which aims to locate and recognize HOI instances in the form of <human, action, object> in images. Most existing works treat HOIs as individual interaction categories, thus can not handle the problem of long-tail distribution and polysemy of action labels. We argue that multi-level consistencies among objects, actions and interactions are strong cues for generating semantic representations of rare or previously unseen HOIs. Leveraging the compositional and relational peculiarities of HOI labels, we propose ConsNet, a knowledge-aware framework that explicitly encodes the relations among objects, actions and interactions into an undirected graph called consistency graph, and exploits Graph Attention Networks (GATs) to propagate knowledge among HOI categories as well as their constituents. Our model takes visual features of candidate human-object pairs and word embeddings of HOI labels as inputs, maps them into visual-semantic joint embedding space and obtains detection results by measuring their similarities. We extensively evaluate our model on the challenging V-COCO and HICO-DET datasets, and results validate that our approach outperforms state-of-the-arts under both fully-supervised and zero-shot settings.", "pdf_url": "https://arxiv.org/pdf/2008.06254", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "WAN: Watermarking Attack Network", "author": "Seung-Hun Nam, Wonhyuk Ahn, In-Jae Yu, Seung-Min Mun, Heung-Kyu Lee", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Multi-bit watermarking (MW) has been developed to improve robustness against signal processing operations and geometric distortions. To this end, several benchmark tools that simulate possible attacks on images to test robustness are available. However, limitations in these general attacks exist since they cannot exploit specific characteristics of the targeted MW. In addition, these attacks are usually devised without consideration for visual quality, which rarely occurs in the real world. To address these limitations, we propose a watermarking attack network (WAN), a fully trainable watermarking benchmark tool, that utilizes the weak points of the target MW and removes inserted watermark and inserts inverted bit information, thereby considerably reducing watermark extractability. To hinder the extraction of hidden information while ensuring high visual quality, we utilize a residual dense blocks-based architecture specialized in local and global feature learning. A novel watermarking attack loss is introduced to break the MW systems. We empirically demonstrate that the WAN can successfully fool a variety of MW systems.", "pdf_url": "https://arxiv.org/pdf/2008.06255", "subject": "Multimedia (cs.MM)"},
{"title": "Simulation Comparisons of Vehicle-based and Phase-based Traffic Control for Autonomous Vehicles at Isolated Intersections", "author": "Chen Yang, Xi Lin, Meng Li, Fang He", "pub_date": "Submitted on 14 Aug 2020", "abstract": "With the advent of autonomous driving technologies, traffic control at intersections is expected to experience revolutionary changes. Various novel intersection control methods have been proposed in the existing literature, and they can be roughly divided into two categories: vehicle-based traffic control and phase-based traffic control. Phase-based traffic control can be treated as updated versions of the current intersection signal control with the incorporation of the performance of autonomous vehicle functions. Meanwhile, vehicle-based traffic control utilizes some brand-new methods, mostly in real-time fashion, to organize traffic at intersections for safe and efficient vehicle passages. However, to date, no systematic comparison between these two control categories has been performed to suggest their advantages and disadvantages. This paper conducts a series of numerical simulations under various traffic scenarios to perform a fair comparison of their performances. Specifically, we allow trajectory adjustments of incoming vehicles under phasebased traffic control, while for its vehicle-based counterpart, we implement two strategies, i.e., the first-come-first-serve strategy and the conflict-point based rolling-horizon optimization strategy. Overall, the simulation results show that vehicle-based traffic control generally incurs a negligible delay when traffic demand is low but lead to an excessive queuing time as the traffic volume becomes high. However, performance of vehicle-based traffic control may benefit from reduction in conflicting vehicle pairs. We also discovered that when autonomous driving technologies are not mature, the advantages of phase-based traffic control are much more distinct.", "pdf_url": "https://arxiv.org/pdf/2008.06256", "subject": "Systems and Control (eess.SY)"},
{"title": "Unsupervised vs. transfer learning for multimodal one-shot matching of speech and images", "author": "Leanne Nortje, Herman Kamper", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We consider the task of multimodal one-shot speech-image matching. An agent is shown a picture along with a spoken word describing the object in the picture, e.g. cookie, broccoli and ice-cream. After observing one paired speech-image example per class, it is shown a new set of unseen pictures, and asked to pick the \"ice-cream\". Previous work attempted to tackle this problem using transfer learning: supervised models are trained on labelled background data not containing any of the one-shot classes. Here we compare transfer learning to unsupervised models trained on unlabelled in-domain data. On a dataset of paired isolated spoken and visual digits, we specifically compare unsupervised autoencoder-like models to supervised classifier and Siamese neural networks. In both unimodal and multimodal few-shot matching experiments, we find that transfer learning outperforms unsupervised training. We also present experiments towards combining the two methodologies, but find that transfer learning still performs best (despite idealised experiments showing the benefits of unsupervised learning).", "pdf_url": "https://arxiv.org/pdf/2008.06258", "subject": "Computation and Language (cs.CL)"},
{"title": "A Learning-based Method for Online Adjustment of C-arm Cone-Beam CT Source Trajectories for Artifact Avoidance", "author": "Mareike Thies, Jan-Nico Z\u00e4ch, Cong Gao, Russell Taylor, Nassir Navab, Andreas Maier, Mathias Unberath", "pub_date": "Submitted on 14 Aug 2020", "abstract": "During spinal fusion surgery, screws are placed close to critical nerves suggesting the need for highly accurate screw placement. Verifying screw placement on high-quality tomographic imaging is essential. C-arm Cone-beam CT (CBCT) provides intraoperative 3D tomographic imaging which would allow for immediate verification and, if needed, revision. However, the reconstruction quality attainable with commercial CBCT devices is insufficient, predominantly due to severe metal artifacts in the presence of pedicle screws. These artifacts arise from a mismatch between the true physics of image formation and an idealized model thereof assumed during reconstruction. Prospectively acquiring views onto anatomy that are least affected by this mismatch can, therefore, improve reconstruction quality. We propose to adjust the C-arm CBCT source trajectory during the scan to optimize reconstruction quality with respect to a certain task, i.e. verification of screw placement. Adjustments are performed on-the-fly using a convolutional neural network that regresses a quality index for possible next views given the current x-ray image. Adjusting the CBCT trajectory to acquire the recommended views results in non-circular source orbits that avoid poor images, and thus, data inconsistencies. We demonstrate that convolutional neural networks trained on realistically simulated data are capable of predicting quality metrics that enable scene-specific adjustments of the CBCT source trajectory. Using both realistically simulated data and real CBCT acquisitions of a semi-anthropomorphic phantom, we show that tomographic reconstructions of the resulting scene-specific CBCT acquisitions exhibit improved image quality particularly in terms of metal artifacts. Since the optimization objective is implicitly encoded in a neural network, the proposed approach overcomes the need for 3D information at run-time.", "pdf_url": "https://arxiv.org/pdf/2008.06262", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Towards Querying in Decentralized Environments with Privacy-Preserving Aggregation", "author": "Ruben Taelman, Simon Steyskal, Sabrina Kirrane", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The Web is a ubiquitous economic, educational, and collaborative space. However, it also serves as a haven for personal information harvesting. Existing decentralised Web-based ecosystems, such as Solid, aim to combat personal data exploitation on the Web by enabling individuals to manage their data in the personal data store of their choice. Since personal data in these decentralised ecosystems are distributed across many sources, there is a need for techniques to support efficient privacy-preserving query execution over personal data stores. Towards this end, in this position paper we present a framework for efficient privacy preserving federated querying, and highlight open research challenges and opportunities. The overarching goal being to provide a means to position future research into privacy-preserving querying within decentralised environments.", "pdf_url": "https://arxiv.org/pdf/2008.06265", "subject": "Databases (cs.DB)"},
{"title": "Optimized Deep Encoder-Decoder Methods for Crack Segmentation", "author": "Jacob K\u00f6nig, Mark Jenkins, Mike Mannion, Peter Barrie, Gordon Morison", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Continuous maintenance of concrete infrastructure is an important task which is needed to continue safe operations of these structures. One kind of defect that occurs on surfaces in these structures are cracks. Automatic detection of those cracks poses a challenging computer vision task as background, shape, colour and size of cracks vary. In this work we propose optimized deep encoder-decoder methods consisting of a combination of techniques which yield an increase in crack segmentation performance. Specifically, we propose a new design for the decoder-part in encoder-decoder based deep learning architectures for semantic segmentation. We study its composition and how to achieve increased performance by exploring components such as deep supervision and upsampling strategies. Then we examine the optimal encoder to go in conjunction with this decoder and determine that pretrained encoders lead to an increase in performance. We propose a data augmentation strategy to increase the amount of available training data and carry out the performance evaluation of the designed architecture on four publicly available crack segmentation datasets. Additionally, we introduce two techniques into the field of surface crack segmentation, previously not used there: Generating results using test-time-augmentation and performing a statistical result analysis over multiple training runs. The former approach generally yields increased performance results, whereas the latter allows for more reproducible and better representability of a methods results. Using those aforementioned strategies with our proposed encoder-decoder architecture we are able to achieve new state of the art results in all datasets.", "pdf_url": "https://arxiv.org/pdf/2008.06266", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "An Efficient Model Inference Algorithm for Learning-based Testing of Reactive Systems", "author": "Muddassar A. Sindhu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Learning-based testing (LBT) is an emerging methodology to automate iterative black-box requirements testing of software systems. The methodology involves combining model inference with model checking techniques. However, a variety of optimisations on model inference are necessary in order to achieve scalable testing for large systems. In this paper we describe the IKL learning algorithm which is an active incremental learning algorithm for deterministic Kripke structures. We formally prove the correctness of IKL. We discuss the optimisations it incorporates to achieve scalability of testing. We also evaluate a black box heuristic for test termination based on convergence of IKL learning.", "pdf_url": "https://arxiv.org/pdf/2008.06268", "subject": "Formal Languages and Automata Theory (cs.FL)"},
{"title": "Graph-based Modeling of Online Communities for Fake News Detection", "author": "Shantanu Chandra, Pushkar Mishra, Helen Yannakoudakis, Ekaterina Shutova", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Over the past few years, there has been substantial effort towards automated detection of fake news. Existing research has modeled the structure, style and content of news articles, as well as the demographic traits of users. However, no attention has been directed towards modeling the properties of online communities that interact with fake news. In this work, we propose a novel approach via graph-based modeling of online communities. Our method aggregates information with respect to: 1) the nature of the content disseminated, 2) content-sharing behavior of users, and 3) the social network of those users. We empirically demonstrate that this yields significant improvements over existing text and user-based techniques for fake news detection.", "pdf_url": "https://arxiv.org/pdf/2008.06274", "subject": "Computation and Language (cs.CL)"},
{"title": "MIMO SWIPT Systems with Power Amplifier Nonlinearities and Memory Effects", "author": "Priyadarshi Mukherjee, Souhir Lajnef, Ioannis Krikidis", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this letter, we study the impact of nonlinear high power amplifier (HPA) on simultaneous wireless information and power transfer (SWIPT), for a point-to-point multiple-input multiple-output communication system. We derive the rate-energy (RE) region by taking into account the HPA nonlinearities and its associated memory effects. We show that HPA significantly degrades the achievable RE region, and a predistortion technique is investigated for compensation. The performance of the proposed predistortion scheme is evaluated in terms of RE region enhancement. Numerical results demonstrate that approximately 24% improvement is obtained for both power-splitting and time-splitting SWIPT architectures.", "pdf_url": "https://arxiv.org/pdf/2008.06281", "subject": "Information Theory (cs.IT)"},
{"title": "Rb-PaStaNet: A Few-Shot Human-Object Interaction Detection Based on Rules and Part States", "author": "Shenyu Zhang, Zichen Zhu, Qingquan Bao", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Existing Human-Object Interaction (HOI) Detection approaches have achieved great progress on nonrare classes while rare HOI classes are still not well-detected. In this paper, we intend to apply human prior knowledge into the existing work. So we add human-labeled rules to PaStaNet and propose Rb-PaStaNet aimed at improving rare HOI classes detection. Our results show a certain improvement of the rare classes, while the non-rare classes and the overall improvement is more considerable.", "pdf_url": "https://arxiv.org/pdf/2008.06285", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "GeoLayout: Geometry Driven Room Layout Estimation Based on Depth Maps of Planes", "author": "Weidong Zhang, Wei Zhang, Yinda Zhang", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The task of room layout estimation is to locate the wall-floor, wall-ceiling, and wall-wall boundaries. Most recent methods solve this problem based on edge/keypoint detection or semantic segmentation. However, these approaches have shown limited attention on the geometry of the dominant planes and the intersection between them, which has significant impact on room layout. In this work, we propose to incorporate geometric reasoning to deep learning for layout estimation. Our approach learns to infer the depth maps of the dominant planes in the scene by predicting the pixel-level surface parameters, and the layout can be generated by the intersection of the depth maps. Moreover, we present a new dataset with pixel-level depth annotation of dominant planes. It is larger than the existing datasets and contains both cuboid and non-cuboid rooms. Experimental results show that our approach produces considerable performance gains on both 2D and 3D datasets.", "pdf_url": "https://arxiv.org/pdf/2008.06286", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A fully coupled numerical model of thermo-hydro-mechanical processes and fracture contact mechanics in porous media", "author": "Ivar Stefansson, Inga Berre, Eirik Keilegavlen", "pub_date": "Submitted on 14 Aug 2020", "abstract": "A range of phenomena in the subsurface is characterised by the interplay between coupled thermal, hydraulic and mechanical processes and deforming structures such as fractures. Modelling subsurface dynamics can provide valuable phenomenological understanding, but requires models which faithfully represent the dynamics involved; these models, therefore are themselves highly complex. This paper presents a mixed-dimensional thermo-hydro-mechanical model designed to capture the process-structure interplay using a discrete-fracture-matrix framework. It incorporates tightly coupled thermo-hydro-mechanical processes based on laws for momentum, mass and entropy in subdomains representing the matrix and the lower-dimensional fractures and fracture intersections. The deformation of explicitly represented fractures is modelled by contact mechanics relations and a Coulomb friction law, with particular attention on coupling of fracture dilation to the governing equations in both fractures and matrix. The model is discretised using multi-point finite volumes for the balance equations and a semismooth Newton scheme for the contact conditions and is implemented in the open source fracture simulation toolbox PorePy. Finally, simulation studies demonstrate the model's convergence, investigate process-structure coupling effects, explore different fracture dilation models and show an application of the model to a 3d geothermal pressure stimulation and long-term cooling scenario.", "pdf_url": "https://arxiv.org/pdf/2008.06289", "subject": "Numerical Analysis (math.NA)"},
{"title": "Free Lunch! Retrospective Uplift Modeling for Dynamic Promotions Recommendation within ROI Constraints", "author": "Dmitri Goldenberg, Javier Albert, Lucas Bernardi, Pablo Estevez", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 17 Aug 2020 (this version, v2)", "abstract": "Promotions and discounts have become key components of modern e-commerce platforms. For online travel platforms (OTPs), popular promotions include room upgrades, free meals and transportation services. By offering these promotions, customers can get more value for their money, while both the OTP and its travel partners may grow their loyal customer base. However, the promotions usually incur a cost that, if uncontrolled, can become unsustainable. Consequently, for a promotion to be viable, its associated costs must be balanced by incremental revenue within set financial constraints. Personalized treatment assignment can be used to satisfy such constraints. This paper introduces a novel uplift modeling technique, relying on the Knapsack Problem formulation, that dynamically optimizes the incremental treatment outcome subject to the required Return on Investment (ROI) constraints. The technique leverages Retrospective Estimation, a modeling approach that relies solely on data from positive outcome examples. The method also addresses training data bias, long term effects, and seasonality challenges via online-dynamic calibration. This approach was tested via offline experiments and online randomized controlled trials at Booking .com - a leading OTP with millions of customers worldwide, resulting in a significant increase in the target outcome while staying within the required financial constraints and outperforming other approaches.", "pdf_url": "https://arxiv.org/pdf/2008.06293", "subject": "Machine Learning (cs.LG)"},
{"title": "A Dynamic Deep Neural Network For Multimodal Clinical Data Analysis", "author": "Maria H\u00fcgle, Gabriel Kalweit, Thomas Huegle, Joschka Boedecker", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Clinical data from electronic medical records, registries or trials provide a large source of information to apply machine learning methods in order to foster precision medicine, e.g. by finding new disease phenotypes or performing individual disease prediction. However, to take full advantage of deep learning methods on clinical data, architectures are necessary that 1) are robust with respect to missing and wrong values, and 2) can deal with highly variable-sized lists and long-term dependencies of individual diagnosis, procedures, measurements and medication prescriptions. In this work, we elaborate limitations of fully-connected neural networks and classical machine learning methods in this context and propose AdaptiveNet, a novel recurrent neural network architecture, which can deal with multiple lists of different events, alleviating the aforementioned limitations. We employ the architecture to the problem of disease progression prediction in rheumatoid arthritis using the Swiss Clinical Quality Management registry, which contains over 10.000 patients and more than 65.000 patient visits. Our proposed approach leads to more compact representations and outperforms the classical baselines.", "pdf_url": "https://arxiv.org/pdf/2008.06294", "subject": "Machine Learning (cs.LG)"},
{"title": "Secure Data Hiding for Contact Tracing", "author": "Craig Gotsman, Kai Hormann", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Contact tracing is an effective tool in controlling the spread of infectious diseases such as COVID-19. It involves digital monitoring and recording of physical proximity between people over time with a central and trusted authority, so that when one user reports infection, it is possible to identify all other users who have been in close proximity to that person during a relevant time period in the past and alert them. One way to achieve this involves recording on the server the locations, e.g. by reading and reporting the GPS coordinates of a smartphone, of all users over time. Despite its simplicity, privacy concerns have prevented widespread adoption of this method. Technology that would enable the \"hiding\" of data could go a long way towards alleviating privacy concerns and enable contact tracing at a very large scale. In this article we describe a general method to hide data. By hiding, we mean that instead of disclosing a data value x, we would disclose an \"encoded\" version of x, namely E(x), where E(x) is easy to compute but very difficult, from a computational point of view, to invert. We propose a general construction of such a function E and show that it guarantees perfect recall, namely, all individuals who have potentially been exposed to infection are alerted, at the price of an infinitesimal number of false alarms, namely, only a negligible number of individuals who have not actually been exposed will be wrongly informed that they have.", "pdf_url": "https://arxiv.org/pdf/2008.06297", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Towards a characterization of stretchable aligned graphs", "author": "Marcel Radermacher, Ignaz Rutter, Peter Stumpf", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We consider the problem of stretching pseudolines in a planar straight-line drawing to straight lines while preserving the straightness and the combinatorial embedding of the drawing. We answer open questions by Mchedlidze et al. by showing that not all instances with two pseudolines are stretchable. On the positive side, for $k\\geq 2$ pseudolines intersecting in a single point, we prove that in case that some edge-pseudoline intersection-patterns are forbidden, all instances are stretchable. For intersection-free pseudoline arrangements we show that every aligned graph has an aligned drawing. This considerably reduces the gap between stretchable and non-stretchable instances.", "pdf_url": "https://arxiv.org/pdf/2008.06300", "subject": "Computational Geometry (cs.CG)"},
{"title": "Computation Offloading in Heterogeneous Vehicular Edge Networks: On-line and Off-policy Bandit Solutions", "author": "Arash Bozorgchenani, Setareh Maghsudi, Daniele Tarchi, Ekram Hossain", "pub_date": "Submitted on 14 Aug 2020", "abstract": "With the rapid advancement in vehicular communications and intelligent transportation systems technologies, task offloading in vehicular networking scenarios is emerging as a promising, yet challenging, paradigm in mobile edge computing. In this paper, we study the computation offloading problem from mobile vehicles/users, more specifically, the network- and base station selection problem, in a heterogeneous Vehicular Edge Computing (VEC) scenario, where networks have different traffic loads. In a fast-varying vehicular environment, the latency in computation offloading that arises as a result of network congestion (e.g. at the edge computing servers co-located with the base stations) is a key performance metric. However, due to the non-stationary property of such environments, predicting network congestion is an involved task. To address this challenge, we propose an on-line algorithm and an off-policy learning algorithm based on bandit theory. To dynamically select the least congested network in a piece-wise stationary environment, from the offloading history, these algorithms learn the latency that the offloaded tasks experience. In addition, to minimize the task loss due to the mobility of the vehicles, we develop a method for base station selection and a relaying mechanism in the chosen network based on the sojourn time of the vehicles. Through extensive numerical analysis, we demonstrate that the proposed learning-based solutions adapt to the traffic changes of the network by selecting the least congested network. Moreover, the proposed approaches improve the latency of offloaded tasks.", "pdf_url": "https://arxiv.org/pdf/2008.06302", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Improving Smart Conference Participation through Socially-Aware Recommendation", "author": "Nana Yaw Asabere, Feng Xia, Wei Wang, Joel J.P.C. Rodrigues, Filippo Basso, Jianhua Ma", "pub_date": "Submitted on 9 Aug 2020", "abstract": "This research addresses recommending presentation sessions at smart conferences to participants. We propose a venue recommendation algorithm, Socially-Aware Recommendation of Venues and Environments (SARVE). SARVE computes correlation and social characteristic information of conference participants. In order to model a recommendation process using distributed community detection, SARVE further integrates the current context of both the smart conference community and participants. SARVE recommends presentation sessions that may be of high interest to each participant. We evaluate SARVE using a real world dataset. In our experiments, we compare SARVE to two related state-of-the-art methods, namely: Context-Aware Mobile Recommendation Services (CAMRS) and Conference Navigator (Recommender) Model. Our experimental results show that in terms of the utilized evaluation metrics: precision, recall, and f-measure, SARVE achieves more reliable and favorable social (relations and context) recommendation results.", "pdf_url": "https://arxiv.org/pdf/2008.06310", "subject": "Social and Information Networks (cs.SI)"},
{"title": "DINE: A Framework for Deep Incomplete Network Embedding", "author": "Ke Hou, Jiaying Liu, Yin Peng, Bo Xu, Ivan Lee, Feng Xia", "pub_date": "Submitted on 9 Aug 2020", "abstract": "Network representation learning (NRL) plays a vital role in a variety of tasks such as node classification and link prediction. It aims to learn low-dimensional vector representations for nodes based on network structures or node attributes. While embedding techniques on complete networks have been intensively studied, in real-world applications, it is still a challenging task to collect complete networks. To bridge the gap, in this paper, we propose a Deep Incomplete Network Embedding method, namely DINE. Specifically, we first complete the missing part including both nodes and edges in a partially observable network by using the expectation-maximization framework. To improve the embedding performance, we consider both network structures and node attributes to learn node representations. Empirically, we evaluate DINE over three networks on multi-label classification and link prediction tasks. The results demonstrate the superiority of our proposed approach compared against state-of-the-art baselines.", "pdf_url": "https://arxiv.org/pdf/2008.06311", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Judging a Book by Its Cover: The Effect of Facial Perception on Centrality in Social Networks", "author": "Dongyu Zhang, Teng Guo, Hanxiao Pan, Jie Hou, Zhitao Feng, Liang Yang, Hongfei Lin, Feng Xia", "pub_date": "Submitted on 9 Aug 2020", "abstract": "Facial appearance matters in social networks. Individuals frequently make trait judgments from facial clues. Although these face-based impressions lack the evidence to determine validity, they are of vital importance, because they may relate to human network-based social behavior, such as seeking certain individuals for help, advice, dating, and cooperation, and thus they may relate to centrality in social networks. However, little to no work has investigated the apparent facial traits that influence network centrality, despite the large amount of research on attributions of the central position including personality and behavior. In this paper, we examine whether perceived traits based on facial appearance affect network centrality by exploring the initial stage of social network formation in a first-year college residential area. We took face photos of participants who are freshmen living in the same residential area, and we asked them to nominate community members linking to different networks. We then collected facial perception data by requiring other participants to rate facial images for three main attributions: dominance, trustworthiness, and attractiveness. Meanwhile, we proposed a framework to discover how facial appearance affects social networks. Our results revealed that perceived facial traits were correlated with the network centrality and that they were indicative to predict the centrality of people in different networks. Our findings provide psychological evidence regarding the interaction between faces and network centrality. Our findings also offer insights in to a combination of psychological and social network techniques, and they highlight the function of facial bias in cuing and signaling social traits. To the best of our knowledge, we are the first to explore the influence of facial perception on centrality in social networks.", "pdf_url": "https://arxiv.org/pdf/2008.06312", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Interpretable Real-Time Win Prediction for Honor of Kings, a Popular Mobile MOBA Esport", "author": "Zelong Yang, Zhufeng Pan, Yan Wang, Deng Cai, Shuming Shi, Shao-Lun Huang, Xiaojiang Liu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "With the rapid prevalence and explosive development of MOBA esports (Multiplayer Online Battle Arena electronic sports), many research efforts have been devoted to automatically predicting the game results (win predictions). While this task has great potential in various applications such as esports live streaming and game commentator AI systems, previous studies suffer from two major limitations: 1) insufficient real-time input features and high-quality training data; 2) non-interpretable inference processes of the black-box prediction models. To mitigate these issues, we collect and release a large-scale dataset that contains real-time game records with rich input features of the popular MOBA game Honor of Kings. For interpretable predictions, we propose a Two-Stage Spatial-Temporal Network (TSSTN) that can not only provide accurate real-time win predictions but also attribute the ultimate prediction results to the contributions of different features for interpretability. Experiment results and applications in real-world live streaming scenarios show that the proposed TSSTN model is effective both in prediction accuracy and interpretability.", "pdf_url": "https://arxiv.org/pdf/2008.06313", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Resilient Abstraction-Based Controller Design", "author": "Stanly Samuel, Kaushik Mallik, Anne-Kathrin Schmuck, Daniel Neider", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We consider the computation of resilient controllers for perturbed non-linear dynamical systems w.r.t. linear-time temporal logic specifications. We address this problem through the paradigm of Abstraction-Based Controller Design (ABCD) where a finite state abstraction of the perturbed system dynamics is constructed and utilized for controller synthesis. In this context, our contribution is twofold: (I) We construct abstractions which model the impact of occasional high disturbance spikes on the system via so called disturbance edges. (II) We show that the application of resilient reactive synthesis techniques to these abstract models results in closed loop systems which are optimally resilient to these occasional high disturbance spikes. We have implemented this resilient ABCD workflow on top of SCOTS and showcase our method through multiple robot planning examples.", "pdf_url": "https://arxiv.org/pdf/2008.06315", "subject": "Systems and Control (eess.SY)"},
{"title": "Not 3D Re-ID: a Simple Single Stream 2D Convolution for Robust Video Re-identification", "author": "Toby P. Breckon, Aishah Alsehaim", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 17 Aug 2020 (this version, v2)", "abstract": "Video-based person re-identification has received increasing attention recently, as it plays an important role within surveillance video analysis. Video-based Re-ID is an expansion of earlier image-based re-identification methods by learning features from a video via multiple image frames for each person. Most contemporary video Re-ID methods utilise complex CNNbased network architectures using 3D convolution or multibranch networks to extract spatial-temporal video features. By contrast, in this paper, we illustrate superior performance from a simple single stream 2D convolution network leveraging the ResNet50-IBN architecture to extract frame-level features followed by temporal attention for clip level features. These clip level features can be generalised to extract video level features by averaging without any significant additional cost. Our approach uses best video Re-ID practice and transfer learning between datasets to outperform existing state-of-the-art approaches on the MARS, PRID2011 and iLIDS-VID datasets with 89:62%, 97:75%, 97:33% rank-1 accuracy respectively and with 84:61% mAP for MARS, without reliance on complex and memory intensive 3D convolutions or multi-stream networks architectures as found in other contemporary work. Conversely, our work shows that global features extracted by the 2D convolution network are a sufficient representation for robust state of the art video Re-ID.", "pdf_url": "https://arxiv.org/pdf/2008.06318", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "OR-Gym: A Reinforcement Learning Library for Operations Research Problem", "author": "Christian D. Hubbs, Hector D. Perez, Owais Sarwar, Nikolaos V. Sahinidis, Ignacio E. Grossmann, John M. Wassick", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Reinforcement learning (RL) has been widely applied to game-playing and surpassed the best human-level performance in many domains, yet there are few use-cases in industrial or commercial settings. We introduce OR-Gym, an open-source library for developing reinforcement learning algorithms to address operations research problems. In this paper, we apply reinforcement learning to the knapsack, multi-dimensional bin packing, multi-echelon supply chain, and multi-period asset allocation model problems, as well as benchmark the RL solutions against MILP and heuristic models. These problems are used in logistics, finance, engineering, and are common in many business operation settings. We develop environments based on prototypical models in the literature and implement various optimization and heuristic models in order to benchmark the RL results. By re-framing a series of classic optimization problems as RL tasks, we seek to provide a new tool for the operations research community, while also opening those in the RL community to many of the problems and challenges in the OR field.", "pdf_url": "https://arxiv.org/pdf/2008.06319", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Feature-Extracting Functions for Neural Logic Rule Learning", "author": "Shashank Gupta, Antonio Robles-Kelly", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this paper, we present a method aimed at integrating domain knowledge abstracted as logic rules into the predictive behaviour of a neural network using feature extracting functions for visual sentiment analysis. We combine the declarative first-order logic rules which represent the human knowledge in a logically-structured format making use of feature-extracting functions. These functions are embodied as programming functions which can represent, in a straightforward manner, the applicable domain knowledge as a set of logical instructions and provide a cumulative set of probability distributions of the input data. These distributions can then be used during the training process in a mini-batch strategy. In contrast with other neural logic approaches, the programmatic nature in practice of these functions do not require any kind of special mathematical encoding, which makes our method very general in nature. We also illustrate the utility of our method for sentiment analysis and compare our results to those obtained using a number of alternatives elsewhere in the literature.", "pdf_url": "https://arxiv.org/pdf/2008.06326", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Exo-SIR: An Epidemiological Model to Analyze the Impact of Exogenous Infection of COVID-19 in India", "author": "Nirmal Kumar Sivaraman, Manas Gaur, Shivansh Baijal, Ch V Radha Sai Rupesh, Sakthi Balan Muthiah, Amit Sheth", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Epidemiological models are the mathematical models that capture the dynamics of epidemics. The spread of the virus has two routes - exogenous and endogenous. The exogenous spread is from outside the population under study, and endogenous spread is within the population under study. Although some of the models consider the exogenous source of infection, they have not studied the interplay between exogenous and endogenous spreads. In this paper, we introduce a novel model - the Exo-SIR model that captures both the exogenous and endogenous spread of the virus. We analyze to find out the relationship between endogenous and exogenous infections during the Covid19 pandemic. First, we simulate the Exo-SIR model without assuming any contact network for the population. Second, simulate it by assuming that the contact network is a scale free network. Third, we implemented the Exo-SIR model on a real dataset regarding Covid19. We found that endogenous infection is influenced by even a minimal rate of exogenous infection. Also, we found that in the presence of exogenous infection, the endogenous infection peak becomes higher, and the peak occurs earlier. This means that if we consider our response to a pandemic like Covid19, we should be prepared for an earlier and higher number of cases than the SIR model suggests if there are the exogenous source(s) of infection.", "pdf_url": "https://arxiv.org/pdf/2008.06335", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Catching a Polygonal Fish with a Minimum Net", "author": "Sepideh Aghamolaei", "pub_date": "Submitted on 11 Aug 2020", "abstract": "Given a polygon $P$ in the plane that can be translated, rotated and enlarged arbitrarily inside a unit square, the goal is to find a set of lines such that at least one of them always hits $P$ and the number of lines is minimized. We prove the solution is always a regular grid or a set of equidistant parallel lines, whose distance depends on $P$.", "pdf_url": "https://arxiv.org/pdf/2008.06337", "subject": "Computational Geometry (cs.CG)"},
{"title": "Multifunctionality in a Reservoir Computer", "author": "Andrew Flynn, Vassilios A. Tsachouridis, Andreas Amann", "pub_date": "Submitted on 10 Aug 2020", "abstract": "Multifunctionality is a well observed phenomenological feature of biological neural networks and considered to be of fundamental importance to the survival of certain species over time. These multifunctional neural networks are capable of performing more than one task without changing any network connections. In this paper we investigate how this neurological idiosyncrasy can be achieved in an artificial setting with a modern machine learning paradigm known as `Reservoir Computing'. A training technique is designed to enable a Reservoir Computer to perform tasks of a multifunctional nature. We explore the critical effects that changes in certain parameters can have on the Reservoir Computers' ability to express multifunctionality. We also expose the existence of several `untrained attractors'; attractors which dwell within the prediction state space of the Reservoir Computer that were not part of the training. We conduct a bifurcation analysis of these untrained attractors and discuss the implications of our results.", "pdf_url": "https://arxiv.org/pdf/2008.06348", "subject": "Neural and Evolutionary Computing (cs.NE)"},
{"title": "Partial Orders, Residuation, and First-Order Linear Logic", "author": "Richard Moot", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We will investigate proof-theoretic and linguistic aspects of first-order linear logic. We will show that adding partial order constraints in such a way that each sequent defines a unique linear order on the antecedent formulas of a sequent allows us to define many useful logical operators. In addition, the partial order constraints improve the efficiency of proof search.", "pdf_url": "https://arxiv.org/pdf/2008.06351", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "Survey of XAI in digital pathology", "author": "Milda Pocevi\u010di\u016bt\u0117, Gabriel Eilertsen, Claes Lundstr\u00f6m", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Artificial intelligence (AI) has shown great promise for diagnostic imaging assessments. However, the application of AI to support medical diagnostics in clinical routine comes with many challenges. The algorithms should have high prediction accuracy but also be transparent, understandable and reliable. Thus, explainable artificial intelligence (XAI) is highly relevant for this domain. We present a survey on XAI within digital pathology, a medical imaging sub-discipline with particular characteristics and needs. The review includes several contributions. Firstly, we give a thorough overview of current XAI techniques of potential relevance for deep learning methods in pathology imaging, and categorise them from three different aspects. In doing so, we incorporate uncertainty estimation methods as an integral part of the XAI landscape. We also connect the technical methods to the specific prerequisites in digital pathology and present findings to guide future research efforts. The survey is intended for both technical researchers and medical professionals, one of the objectives being to establish a common ground for cross-disciplinary discussions.", "pdf_url": "https://arxiv.org/pdf/2008.06353", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "HEX and Neurodynamic Programming", "author": "Debangshu Banerjee", "pub_date": "Submitted on 11 Aug 2020", "abstract": "Hex is a complex game with a high branching factor. For the first time Hex is being attempted to be solved without the use of game tree structures and associated methods of pruning. We also are abstaining from any heuristic information about Virtual Connections or Semi Virtual Connections which were previously used in all previous known computer versions of the game. The H-search algorithm which was the basis of finding such connections and had been used with success in previous Hex playing agents has been forgone. Instead what we use is reinforcement learning through self play and approximations through neural networks to by pass the problem of high branching factor and maintaining large tables for state-action evaluations. Our code is based primarily on NeuroHex. The inspiration is drawn from the recent success of AlphaGo Zero.", "pdf_url": "https://arxiv.org/pdf/2008.06359", "subject": "Machine Learning (cs.LG)"},
{"title": "An Overview of Deep Learning Architectures in Few-Shot Learning Domain", "author": "Shruti Jadon", "pub_date": "Submitted on 12 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v3)", "abstract": "Since 2012, Deep learning has revolutionized Artificial Intelligence and has achieved state-of-the-art outcomes in different domains, ranging from Image Classification to Speech Generation. Though it has many potentials, our current architectures come with the pre-requisite of large amounts of data. Few-Shot Learning (also known as one-shot learning) is a sub-field of machine learning that aims to create such models that can learn the desired objective with less data, similar to how humans learn. In this paper, we have reviewed some of the well-known deep learning-based approaches towards few-shot learning. We have discussed the recent achievements, challenges, and possibilities of improvement of few-shot learning based deep learning architectures. Our aim for this paper is threefold: (i) Give a brief introduction to deep learning architectures for few-shot learning with pointers to core references. (ii) Indicate how deep learning has been applied to the low-data regime, from data preparation to model training. and, (iii) Provide a starting point for people interested in experimenting and perhaps contributing to the field of few-shot learning by pointing out some useful resources and open-source code. Our code is available at Github: .", "pdf_url": "https://arxiv.org/pdf/2008.06365", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Error analysis for probabilities of rare events with approximate models", "author": "Fabian Wagner, Jonas Latz, Iason Papaioannou, Elisabeth Ullmann", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The estimation of the probability of rare events is an important task in reliability and risk assessment. We consider failure events that are expressed in terms of a limit-state function, which depends on the solution of a partial differential equation (PDE). In many applications, the PDE cannot be solved analytically. We can only evaluate an approximation of the exact PDE solution. Therefore, the probability of rare events is estimated with respect to an approximation of the limit-state function. This leads to an approximation error in the estimate of the probability of rare events. Indeed, we prove an error bound for the approximation error of the probability of failure, which behaves like the discretization accuracy of the PDE multiplied by an approximation of the probability of failure. Hence, we derive a relationship between the required accuracy of the probability of rare events estimate and the PDE discretization level. As our error bound depends on a computable approximation of the failure probability, it is applicable in practicable reliability analyses and, for instance, in multilevel methods.", "pdf_url": "https://arxiv.org/pdf/2008.06368", "subject": "Numerical Analysis (math.NA)"},
{"title": "PointMixup: Augmentation for Point Clouds", "author": "Yunlu Chen, Vincent Tao Hu, Efstratios Gavves, Thomas Mensink, Pascal Mettes, Pengwan Yang, Cees G.M. Snoek", "pub_date": "Submitted on 14 Aug 2020", "abstract": "This paper introduces data augmentation for point clouds by interpolation between examples. Data augmentation by interpolation has shown to be a simple and effective approach in the image domain. Such a mixup is however not directly transferable to point clouds, as we do not have a one-to-one correspondence between the points of two different objects. In this paper, we define data augmentation between point clouds as a shortest path linear interpolation. To that end, we introduce PointMixup, an interpolation method that generates new examples through an optimal assignment of the path function between two point clouds. We prove that our PointMixup finds the shortest path between two point clouds and that the interpolation is assignment invariant and linear. With the definition of interpolation, PointMixup allows to introduce strong interpolation-based regularizers such as mixup and manifold mixup to the point cloud domain. Experimentally, we show the potential of PointMixup for point cloud classification, especially when examples are scarce, as well as increased robustness to noise and geometric transformations to points. The code for PointMixup and the experimental details are publicly available.", "pdf_url": "https://arxiv.org/pdf/2008.06374", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "MLM: A Benchmark Dataset for Multitask Learning with Multiple Languages and Modalities", "author": "Jason Armitage, Endri Kacupaj, Golsa Tahmasebzadeh, Swati, Maria Maleshkova, Ralph Ewerth, Jens Lehmann", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 17 Aug 2020 (this version, v2)", "abstract": "In this paper, we introduce the MLM (Multiple Languages and Modalities) dataset - a new resource to train and evaluate multitask systems on samples in multiple modalities and three languages. The generation process and inclusion of semantic data provide a resource that further tests the ability for multitask systems to learn relationships between entities. The dataset is designed for researchers and developers who build applications that perform multiple tasks on data encountered on the web and in digital archives. A second version of MLM provides a geo-representative subset of the data with weighted samples for countries of the European Union. We demonstrate the value of the resource in developing novel applications in the digital humanities with a motivating use case and specify a benchmark set of tasks to retrieve modalities and locate entities in the dataset. Evaluation of baseline multitask and single task systems on the full and geo-representative versions of MLM demonstrate the challenges of generalising on diverse data. In addition to the digital humanities, we expect the resource to contribute to research in multimodal representation learning, location estimation, and scene understanding.", "pdf_url": "https://arxiv.org/pdf/2008.06376", "subject": "Machine Learning (cs.LG)"},
{"title": "Machine learning for COVID-19 detection and prognostication using chest radiographs and CT scans: a systematic methodological review", "author": "Michael Roberts, Derek Driggs, Matthew Thorpe, Julian Gilbey, Michael Yeung, Stephan Ursprung, Angelica I. Aviles-Rivero, Christian Etmann, Cathal McCague, Lucian Beer, Jonathan R. Weir-McCall, Zhongzhao Teng, James H.F. Rudd, Evis Sala, Carola-Bibiane Sch\u00f6nlieb", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Background: Machine learning methods offer great potential for fast and accurate detection and prognostication of COVID-19 from standard-of-care chest radiographs (CXR) and computed tomography (CT) images. In this systematic review we critically evaluate the machine learning methodologies employed in the rapidly growing literature. Methods: In this systematic review we reviewed EMBASE via OVID, MEDLINE via PubMed, bioRxiv, medRxiv and arXiv for published papers and preprints uploaded from Jan 1, 2020 to June 24, 2020. Studies which consider machine learning models for the diagnosis or prognosis of COVID-19 from CXR or CT images were included. A methodology quality review of each paper was performed against established benchmarks to ensure the review focusses only on high-quality reproducible papers. This study is registered with PROSPERO [CRD42020188887]. Interpretation: Our review finds that none of the developed models discussed are of potential clinical use due to methodological flaws and underlying biases. This is a major weakness, given the urgency with which validated COVID-19 models are needed. Typically, we find that the documentation of a model's development is not sufficient to make the results reproducible and therefore of 168 candidate papers only 29 are deemed to be reproducible and subsequently considered in this review. We therefore encourage authors to use established machine learning checklists to ensure sufficient documentation is made available, and to follow the PROBAST (prediction model risk of bias assessment tool) framework to determine the underlying biases in their model development process and to mitigate these where possible. This is key to safe clinical implementation which is urgently needed.", "pdf_url": "https://arxiv.org/pdf/2008.06388", "subject": "Machine Learning (cs.LG)"},
{"title": "Sample-efficient Cross-Entropy Method for Real-time Planning", "author": "Cristina Pinneri, Shambhuraj Sawant, Sebastian Blaes, Jan Achterhold, Joerg Stueckler, Michal Rolinek, Georg Martius", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Trajectory optimizers for model-based reinforcement learning, such as the Cross-Entropy Method (CEM), can yield compelling results even in high-dimensional control tasks and sparse-reward environments. However, their sampling inefficiency prevents them from being used for real-time planning and control. We propose an improved version of the CEM algorithm for fast planning, with novel additions including temporally-correlated actions and memory, requiring 2.7-22x less samples and yielding a performance increase of 1.2-10x in high-dimensional control problems.", "pdf_url": "https://arxiv.org/pdf/2008.06389", "subject": "Machine Learning (cs.LG)"},
{"title": "Deep Domain Adaptation for Ordinal Regression of Pain Intensity Estimation Using Weakly-Labelled Videos", "author": "Gnana Praveen R, Eric Granger, Patrick Cardinal", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Predicting the level of facial expression intensities based on videos allow capturing a representation of affect, which has many potential applications such as pain localisation, depression detection, etc. However, state-of-the-art DL(DL) models to predict these levels are typically formulated regression problems, and do not leverage the data distribution, nor the ordinal relationship between levels. This translates to a limited robustness to noisy and uncertain labels. Moreover, annotating expression intensity levels for video frames is a costly undertaking, involving considerable labor by domain experts, and the labels are vulnerable to subjective bias due to ambiguity among adjacent intensity levels. This paper introduces a DL model for weakly-supervised domain adaptation with ordinal regression (WSDA-OR), where videos in target domain have coarse labels representing of ordinal intensity levels that are provided on a periodic basis. In particular, the proposed model learn discriminant and domain-invariant representations by integrating multiple instance learning with deep adversarial domain adaptation, where an Inflated 3D CNN (I3D) is trained using fully supervised source domain videos, and weakly supervised target domain videos. The trained model is finally used to estimate the ordinal intensity levels of individual frames in the target operational domain. The proposed approach has been validated for pain intensity estimation on using RECOLA dataset as labeled source domain, and UNBC-McMaster dataset as weakly-labeled target domain. Experimental results shows significant improvement over the state-of-the-art models and achieves higher level of localization accuracy.", "pdf_url": "https://arxiv.org/pdf/2008.06392", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Gaining environments through shape change", "author": "Dylan S. Shah, Joshua P. Powers, Liana G. Tilton, Sam Kriegman, Josh Bongard, Rebecca Kramer-Bottiglio", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Many organisms, including various species of spiders and caterpillars, change their shape to switch gaits and adapt to different environments. Recent technological advances, ranging from stretchable circuits to highly deformable soft robots, have begun to make shape changing robots a possibility. However, it is currently unclear how and when shape change should occur, and what capabilities could be gained, leading to a wide range of unsolved design and control problems. To begin addressing these questions, here we simulate, design, and build a soft robot that utilizes shape change to achieve locomotion over both a flat and inclined surface. Modeling this robot in simulation, we explore its capabilities in two environments and demonstrate the automated discovery of environment-specific shapes and gaits that successfully transfer to the physical hardware. We found that the shape-changing robot traverses these environments better than an equivalent but non-morphing robot, in simulation and reality.", "pdf_url": "https://arxiv.org/pdf/2008.06397", "subject": "Robotics (cs.RO)"},
{"title": "Renormalization for Initialization of Rolling Shutter Visual-Inertial Odometry", "author": "Branislav Micusik, Georgios Evangelidis", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this paper we deal with the initialization problem of a visual-inertial odometry system with rolling shutter cameras. The initialization is a prerequisite to utilize inertial signals and fuse them with the visual data. We propose a novel way to solve this problem on visual and inertial data simultaneously in a statistical sense, by casting it into the renormalization scheme of Kanatani. The renormalization is an optimization scheme which intends to reduce the inherent statistical bias of common linear systems. We derive and present necessary steps and methodology specific for the initialization problem. Extensive evaluations on perfect ground truth exhibit superior performance and up to 20% accuracy gain to the originally proposed Least Squares solution. The renormalization performs similarly to the optimal Maximum Likelihood estimate, despite arriving to the solution by different means. By this, we extend the set of common Computer Vision problems which can be cast into the renormalization scheme.", "pdf_url": "https://arxiv.org/pdf/2008.06399", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "SPINN: Synergistic Progressive Inference of Neural Networks over Device and Cloud", "author": "Stefanos Laskaridis, Stylianos I. Venieris, Mario Almeida, Ilias Leontiadis, Nicholas D. Lane", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Despite the soaring use of convolutional neural networks (CNNs) in mobile applications, uniformly sustaining high-performance inference on mobile has been elusive due to the excessive computational demands of modern CNNs and the increasing diversity of deployed devices. A popular alternative comprises offloading CNN processing to powerful cloud-based servers. Nevertheless, by relying on the cloud to produce outputs, emerging mission-critical and high-mobility applications, such as drone obstacle avoidance or interactive applications, can suffer from the dynamic connectivity conditions and the uncertain availability of the cloud. In this paper, we propose SPINN, a distributed inference system that employs synergistic device-cloud computation together with a progressive inference method to deliver fast and robust CNN inference across diverse settings. The proposed system introduces a novel scheduler that co-optimises the early-exit policy and the CNN splitting at run time, in order to adapt to dynamic conditions and meet user-defined service-level requirements. Quantitative evaluation illustrates that SPINN outperforms its state-of-the-art collaborative inference counterparts by up to 2x in achieved throughput under varying network conditions, reduces the server cost by up to 6.8x and improves accuracy by 20.7% under latency constraints, while providing robust operation under uncertain connectivity conditions and significant energy savings compared to cloud-centric execution.", "pdf_url": "https://arxiv.org/pdf/2008.06402", "subject": "Machine Learning (cs.LG)"},
{"title": "A New Path to Code-based Signatures via Identification Schemes with Restricted Errors", "author": "Marco Baldi, Massimo Battaglioni, Franco Chiaraluce, Anna-Lena Horlemann-Trautmann, Edoardo Persichetti, Paolo Santini, Violetta Weger", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this paper we introduce a variant of the Syndrome Decoding Problem (SDP), that we call Restricted SDP (R-SDP), in which the entries of the searched vector are defined over a subset of the underlying finite field. We prove the NP-completeness of R-SDP, via a reduction from the canonical SDP, and describe how information set decoding algorithms can be adapted to solve this new problem. We study the properties of random codes under this new decoding perspective (in the fashion of traditional coding theory results), in order to derive the conditions upon which R-SDP has a unique solution with overwhelming probability. As a concrete application, we describe how Zero-Knowledge Identification (ZK-ID) schemes based on SDP can be tweaked to rely on R-SDP, and show that this leads to compact public keys as well as significantly reduced communication costs. Thus, these schemes offer an improved basis for the construction of code-based digital signature schemes derived from identification schemes through the well-know Fiat-Shamir transformation.", "pdf_url": "https://arxiv.org/pdf/2008.06403", "subject": "Cryptography and Security (cs.CR)"},
{"title": "ANDES at SemEval-2020 Task 12: A jointly-trained BERT multilingual model for offensive language detection", "author": "Juan Manuel P\u00e9rez, Aym\u00e9 Arango, Franco Luque", "pub_date": "Submitted on 13 Aug 2020", "abstract": "This paper describes our participation in SemEval-2020 Task 12: Multilingual Offensive Language Detection. We jointly-trained a single model by fine-tuning Multilingual BERT to tackle the task across all the proposed languages: English, Danish, Turkish, Greek and Arabic. Our single model had competitive results, with a performance close to top-performing systems in spite of sharing the same parameters across all languages. Zero-shot and few-shot experiments were also conducted to analyze the transference performance among these languages. We make our code public for further research", "pdf_url": "https://arxiv.org/pdf/2008.06408", "subject": "Computation and Language (cs.CL)"},
{"title": "Induction Models on \\mathbb{N}", "author": "A. Dileep, Kuldeep S. Meel, Ammar F. Sabili", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Mathematical induction is a fundamental tool in computer science and mathematics. Henkin initiated the study of formalization of mathematical induction restricted to the setting when the base case B is set to singleton set containing 0 and a unary generating function S. The usage of mathematical induction often involves wider set of base cases and k-ary generating functions with different structural restrictions. While subsequent studies have shown several Induction Models to be equivalent, there does not exist precise logical characterization of reduction and equivalence among different Induction Models. In this paper, we generalize the definition of Induction Model and demonstrate existence and construction of S for given B and vice versa. We then provide a formal characterization of the reduction among different Induction Models that can allow proofs in one Induction Models to be expressed as proofs in another Induction Models. The notion of reduction allows us to capture equivalence among Induction Models.", "pdf_url": "https://arxiv.org/pdf/2008.06410", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "Cannot Predict Comment Volume of a News Article before (a few) Users Read It", "author": "Lihong He, Chen Shen, Arjun Mukherjee, Slobodan Vucetic, Eduard Dragut", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Many news outlets allow users to contribute comments on topics about daily world events. News articles are the seeds that spring users' interest to contribute content, i.e., comments. An article may attract an apathetic user engagement (several tens of comments) or a spontaneous fervent user engagement (thousands of comments). In this paper, we study the problem of predicting the total number of user comments a news article will receive. Our main insight is that the early dynamics of user comments contribute the most to an accurate prediction, while news article specific factors have surprisingly little influence. This appears to be an interesting and understudied phenomenon: collective social behavior at a news outlet shapes user response and may even downplay the content of an article. We compile and analyze a large number of features, both old and novel from literature. The features span a broad spectrum of facets including news article and comment contents, temporal dynamics, sentiment/linguistic features, and user behaviors. We show that the early arrival rate of comments is the best indicator of the eventual number of comments. We conduct an in-depth analysis of this feature across several dimensions, such as news outlets and news article categories. We show that the relationship between the early rate and the final number of comments as well as the prediction accuracy vary considerably across news outlets and news article categories (e.g., politics, sports, or health).", "pdf_url": "https://arxiv.org/pdf/2008.06414", "subject": "Information Retrieval (cs.IR)"},
{"title": "On single server private information retrieval in a coding theory perspective", "author": "Gianira N. Alfarano, Karan Khathuria, Violetta Weger", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this paper, we present a new perspective of single server private information retrieval (PIR) schemes by using the notion of linear error-correcting codes. Many of the known single server schemes are based on taking linear combinations between database elements and the query elements. Using the theory of linear codes, we develop a generic framework that formalizes all such PIR schemes. Further, we describe some known PIR schemes with respect to this code-based framework, and present the weaknesses of the broken PIR schemes in a generic point of view.", "pdf_url": "https://arxiv.org/pdf/2008.06417", "subject": "Information Theory (cs.IT)"},
{"title": "Divergence--free Scott--Vogelius elements on curved domains", "author": "Michael Neilan, M. Baris Otus", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We construct and analyze an isoparametric finite element pair for the Stokes problem in two dimensions. The pair is defined by mapping the Scott-Vogelius finite element space via a Piola transform. The velocity space has the same degrees of freedom as the quadratic Lagrange finite element space, and therefore the proposed spaces reduce to the Scott-Vogelius pair in the interior of the domain. We prove that the resulting method converges with optimal order, is divergence--free, and is pressure robust. Numerical examples are provided which support the theoretical results.", "pdf_url": "https://arxiv.org/pdf/2008.06429", "subject": "Numerical Analysis (math.NA)"},
{"title": "Privacy Preserving Passive DNS", "author": "Pavlos Papadopoulos, Nikolaos Pitropakis, William J. Buchanan, Owen Lo, Sokratis Katsikas", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The Domain Name System (DNS) was created to resolve the IP addresses of the web servers to easily remembered names. When it was initially created, security was not a major concern; nowadays, this lack of inherent security and trust has exposed the global DNS infrastructure to malicious actors. The passive DNS data collection process creates a database containing various DNS data elements, some of which are personal and need to be protected to preserve the privacy of the end users. To this end, we propose the use of distributed ledger technology. We use Hyperledger Fabric to create a permissioned blockchain, which only authorized entities can access. The proposed solution supports queries for storing and retrieving data from the blockchain ledger, allowing the use of the passive DNS database for further analysis, e.g. for the identification of malicious domain names. Additionally, it effectively protects the DNS personal data from unauthorized entities, including the administrators that can act as potential malicious insiders, and allows only the data owners to perform queries over these data. We evaluated our proposed solution by creating a proof-of-concept experimental setup that passively collects DNS data from a network and then uses the distributed ledger technology to store the data in an immutable ledger, thus providing a full historical overview of all the records.", "pdf_url": "https://arxiv.org/pdf/2008.06430", "subject": "Cryptography and Security (cs.CR)"},
{"title": "RODEO: Replay for Online Object Detection", "author": "Manoj Acharya, Tyler L. Hayes, Christopher Kanan", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Humans can incrementally learn to do new visual detection tasks, which is a huge challenge for today's computer vision systems. Incrementally trained deep learning models lack backwards transfer to previously seen classes and suffer from a phenomenon known as $\"catastrophic forgetting.\"$ In this paper, we pioneer online streaming learning for object detection, where an agent must learn examples one at a time with severe memory and computational constraints. In object detection, a system must output all bounding boxes for an image with the correct label. Unlike earlier work, the system described in this paper can learn this task in an online manner with new classes being introduced over time. We achieve this capability by using a novel memory replay mechanism that efficiently replays entire scenes. We achieve state-of-the-art results on both the PASCAL VOC 2007 and MS COCO datasets.", "pdf_url": "https://arxiv.org/pdf/2008.06439", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Self-adapting confidence estimation for stereo", "author": "Matteo Poggi, Filippo Aleotti, Fabio Tosi, Giulio Zaccaroni, Stefano Mattoccia", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Estimating the confidence of disparity maps inferred by a stereo algorithm has become a very relevant task in the years, due to the increasing number of applications leveraging such cue. Although self-supervised learning has recently spread across many computer vision tasks, it has been barely considered in the field of confidence estimation. In this paper, we propose a flexible and lightweight solution enabling self-adapting confidence estimation agnostic to the stereo algorithm or network. Our approach relies on the minimum information available in any stereo setup (i.e., the input stereo pair and the output disparity map) to learn an effective confidence measure. This strategy allows us not only a seamless integration with any stereo system, including consumer and industrial devices equipped with undisclosed stereo perception methods, but also, due to its self-adapting capability, for its out-of-the-box deployment in the field. Exhaustive experimental results with different standard datasets support our claims, showing how our solution is the first-ever enabling online learning of accurate confidence estimation for any stereo system and without any requirement for the end-user.", "pdf_url": "https://arxiv.org/pdf/2008.06447", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Loghub: A Large Collection of System Log Datasets towards Automated Log Analytics", "author": "Shilin He, Jieming Zhu, Pinjia He, Michael R. Lyu", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Logs have been widely adopted in software system development and maintenance because of the rich system runtime information they contain. In recent years, the increase of software size and complexity leads to the rapid growth of the volume of logs. To handle these large volumes of logs efficiently and effectively, a line of research focuses on intelligent log analytics powered by AI (artificial intelligence) techniques. However, only a small fraction of these techniques have reached successful deployment in industry because of the lack of public log datasets and necessary benchmarking upon them. To fill this significant gap between academia and industry and also facilitate more research on AI-powered log analytics, we have collected and organized loghub, a large collection of log datasets. In particular, loghub provides 17 real-world log datasets collected from a wide range of systems, including distributed systems, supercomputers, operating systems, mobile systems, server applications, and standalone software. In this paper, we summarize the statistics of these datasets, introduce some practical log usage scenarios, and present a case study on anomaly detection to demonstrate how loghub facilitates the research and practice in this field. Up to the time of this paper writing, loghub datasets have been downloaded over 15,000 times by more than 380 organizations from both industry and academia.", "pdf_url": "https://arxiv.org/pdf/2008.06448", "subject": "Software Engineering (cs.SE)"},
{"title": "Predicting Event Time by Classifying Sub-Level Temporal Relations Induced from a Unified Representation of Time Anchors", "author": "Fei Cheng, Yusuke Miyao", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Extracting event time from news articles is a challenging but attractive task. In contrast to the most existing pair-wised temporal link annotation, Reimers et al.(2016) proposed to annotate the time anchor (a.k.a. the exact time) of each event. Their work represents time anchors with discrete representations of Single-Day/Multi-Day and Certain/Uncertain. This increases the complexity of modeling the temporal relations between two time anchors, which cannot be categorized into the relations of Allen's interval algebra (Allen, 1990). In this paper, we propose an effective method to decompose such complex temporal relations into sub-level relations by introducing a unified quadruple representation for both Single-Day/Multi-Day and Certain/Uncertain time anchors. The temporal relation classifiers are trained in a multi-label classification manner. The system structure of our approach is much simpler than the existing decision tree model (Reimers et al., 2018), which is composed by a dozen of node classifiers. Another contribution of this work is to construct a larger event time corpus (256 news documents) with a reasonable Inter-Annotator Agreement (IAA), for the purpose of overcoming the data shortage of the existing event time corpus (36 news documents). The empirical results show our approach outperforms the state-of-the-art decision tree model and the increase of data size obtained a significant improvement of performance.", "pdf_url": "https://arxiv.org/pdf/2008.06452", "subject": "Computation and Language (cs.CL)"},
{"title": "Can determinism and compositionality coexist in RML? (extended version)", "author": "Davide Ancona, Angelo Ferrando, Viviana Mascardi", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 17 Aug 2020 (this version, v2)", "abstract": "Runtime verification (RV) consists in dynamically verifying that the event traces generated by single runs of a system under scrutiny (SUS) are compliant with the formal specification of its expected properties. RML (Runtime Monitoring Language) is a simple but expressive Domain Specific Language for RV; its semantics is based on a trace calculus formalized by a deterministic rewriting system which drives the implementation of the interpreter of the monitors generated by the RML compiler from the specifications. While determinism of the trace calculus ensures better performances of the generated monitors, it makes the semantics of its operators less intuitive. In this paper we move a first step towards a compositional semantics of the RML trace calculus, by interpreting its basic operators as operations on sets of instantiated event traces and by proving that such an interpretation is equivalent to the operational semantics of the calculus.", "pdf_url": "https://arxiv.org/pdf/2008.06453", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "Mastering Rate based Curriculum Learning", "author": "Lucas Willems, Salem Lahlou, Yoshua Bengio", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Recent automatic curriculum learning algorithms, and in particular Teacher-Student algorithms, rely on the notion of learning progress, making the assumption that the good next tasks are the ones on which the learner is making the fastest progress or digress. In this work, we first propose a simpler and improved version of these algorithms. We then argue that the notion of learning progress itself has several shortcomings that lead to a low sample efficiency for the learner. We finally propose a new algorithm, based on the notion of mastering rate, that significantly outperforms learning progress-based algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.06456", "subject": "Machine Learning (cs.LG)"},
{"title": "Abstracting Deep Neural Networks into Concept Graphs for Concept Level Interpretability", "author": "Avinash Kori, Parth Natekar, Ganapathy Krishnamurthi, Balaji Srinivasan", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The black-box nature of deep learning models prevents them from being completely trusted in domains like biomedicine. Most explainability techniques do not capture the concept-based reasoning that human beings follow. In this work, we attempt to understand the behavior of trained models that perform image processing tasks in the medical domain by building a graphical representation of the concepts they learn. Extracting such a graphical representation of the model's behavior on an abstract, higher conceptual level would unravel the learnings of these models and would help us to evaluate the steps taken by the model for predictions. We show the application of our proposed implementation on two biomedical problems - brain tumor segmentation and fundus image classification. We provide an alternative graphical representation of the model by formulating a \\textit{concept level graph} as discussed above, which makes the problem of intervention to find active inference trails more tractable. Understanding these trails would provide an understanding of the hierarchy of the decision-making process followed by the model. [As well as overall nature of model]. Our framework is available at \\url{ }", "pdf_url": "https://arxiv.org/pdf/2008.06457", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Hate Speech Detection and Racial Bias Mitigation in Social Media based on BERT model", "author": "Marzieh Mozafari, Reza Farahbakhsh, Noel Crespi", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Disparate biases associated with datasets and trained classifiers in hateful and abusive content identification tasks have raised many concerns recently. Although the problem of biased datasets on abusive language detection has been addressed more frequently, biases arising from trained classifiers have not yet been a matter of concern. Here, we first introduce a transfer learning approach for hate speech detection based on an existing pre-trained language model BERT and evaluate the proposed model on two publicly available datasets that have been annotated for racism, sexism, hate or offensive content on Twitter. Next, we introduce a bias alleviation mechanism to mitigate the effect of bias in training set during the fine-tuning of our pre-trained BERT-based model for hate speech detection. Toward that end, we use a regularization method to reweight input samples, thereby decreasing the effects of high correlated training set' s n-grams with class labels, and then fine-tune our pre-trained BERT-based model with the new re-weighted samples. To evaluate our bias alleviation mechanism, we employed a cross-domain approach in which we use the trained classifiers on the aforementioned datasets to predict the labels of two new datasets from Twitter, AAE-aligned and White-aligned groups, which indicate tweets written in African-American English (AAE) and Standard American English (SAE), respectively. The results show the existence of systematic racial bias in trained classifiers, as they tend to assign tweets written in AAE from AAE-aligned group to negative classes such as racism, sexism, hate, and offensive more often than tweets written in SAE from White-aligned. However, the racial bias in our classifiers reduces significantly after our bias alleviation mechanism is incorporated. This work could institute the first step towards debiasing hate speech and abusive language detection systems.", "pdf_url": "https://arxiv.org/pdf/2008.06460", "subject": "Social and Information Networks (cs.SI)"},
{"title": "On the Sample Complexity of Super-Resolution Radar", "author": "Mohammad Mahdi Kamjoo, Saeed Razavi, Sajad Daei", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this work, we consider linear time-varying systems whose output signal is described by scaled time-frequency shifted versions of a known input with finite bandwidth $B$. The aim is to identify the time and frequency shifts by observing the received signal over a time interval with duration $T$. This problem is considered in [1] and is shown that the recovery of time-frequency pairs is possible by using an atomic norm minimization provided that the time-frequency shifts are separated by at least $2.37/B$ and $2.37/T$, respectively. For $S$ targets, we theoretically show that the number of required samples for perfect recovery is $\\mathcal{O}(S)$ up to a logarithmic factor in $BT$ instead of $\\mathcal{O}(S^2)$ which was obtained in [1].", "pdf_url": "https://arxiv.org/pdf/2008.06462", "subject": "Information Theory (cs.IT)"},
{"title": "Multi-Agent Deep Reinforcement Learning enabled Computation Resource Allocation in a Vehicular Cloud Network", "author": "Shilin Xu, Caili Guo, Rose Qingyang Hu, Yi Qian", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 17 Aug 2020 (this version, v2)", "abstract": "In this paper, we investigate the computational resource allocation problem in a distributed Ad-Hoc vehicular network with no centralized infrastructure support. To support the ever increasing computational needs in such a vehicular network, the distributed virtual cloud network (VCN) is formed, based on which a computational resource sharing scheme through offloading among nearby vehicles is proposed. In view of the time-varying computational resource in VCN, the statistical distribution characteristics for computational resource are analyzed in detail. Thereby, a resource-aware combinatorial optimization objective mechanism is proposed. To alleviate the non-stationary environment caused by the typically multi-agent environment in VCN, we adopt a centralized training and decentralized execution framework. In addition, for the objective optimization problem, we model it as a Markov game and propose a DRL based multi-agent deep deterministic reinforcement learning (MADDPG) algorithm to solve it. Interestingly, to overcome the dilemma of lacking a real central control unit in VCN, the allocation is actually completed on the vehicles in a distributed manner. The simulation results are presented to demonstrate our scheme's effectiveness.", "pdf_url": "https://arxiv.org/e-print/2008.06464", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "ALONE: A Dataset for Toxic Behavior among Adolescents on Twitter", "author": "Thilini Wijesiriwardene, Hale Inan, Ugur Kursuncu, Manas Gaur, Valerie L. Shalin, Krishnaprasad Thirunarayan, Amit Sheth, I. Budak Arpinar", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The convenience of social media has also enabled its misuse, potentially resulting in toxic behavior. Nearly 66% of internet users have observed online harassment, and 41% claim personal experience, with 18% facing severe forms of online harassment. This toxic communication has a significant impact on the well-being of young individuals, affecting mental health and, in some cases, resulting in suicide. These communications exhibit complex linguistic and contextual characteristics, making recognition of such narratives challenging. In this paper, we provide a multimodal dataset of toxic social media interactions between confirmed high school students, called ALONE (AdoLescents ON twittEr), along with descriptive explanation. Each instance of interaction includes tweets, images, emoji and related metadata. Our observations show that individual tweets do not provide sufficient evidence for toxic behavior, and meaningful use of context in interactions can enable highlighting or exonerating tweets with purported toxicity.", "pdf_url": "https://arxiv.org/pdf/2008.06465", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Self-Sampling for Neural Point Cloud Consolidation", "author": "Gal Metzer, Rana Hanocka, Raja Giryes, Daniel Cohen-Or", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this paper, we introduce a deep learning technique for consolidating and sharp feature generation of point clouds using only the input point cloud itself. Rather than explicitly define a prior that describes typical shape characteristics (i.e., piecewise-smoothness), or a heuristic policy for generating novel sharp points, we opt to learn both using a neural network with shared-weights. Instead of relying on a large collection of manually annotated data, we use the self-supervision present within a single shape, i.e., self-prior, to train the network, and learn the underlying distribution of sharp features specific to the given input point cloud. By learning to map a low-curvature subset of the input point cloud to a disjoint high-curvature subset, the network formalizes the shape-specific characteristics and infers how to generate sharp points. During test time, the network is repeatedly fed a random subset of points from the input and displaces them to generate an arbitrarily large set of novel sharp feature points. The local shared weights are optimized over the entire shape, learning non-local statistics and exploiting the recurrence of local-scale geometries. We demonstrate the ability to generate coherent sets of sharp feature points on a variety of shapes, while eliminating outliers and noise.", "pdf_url": "https://arxiv.org/pdf/2008.06471", "subject": "Graphics (cs.GR)"},
{"title": "Feedback Attention for Cell Image Segmentation", "author": "Hiroki Tsuda, Eisuke Shibuya, Kazuhiro Hotta", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this paper, we address cell image segmentation task by Feedback Attention mechanism like feedback processing. Unlike conventional neural network models of feedforward processing, we focused on the feedback processing in human brain and assumed that the network learns like a human by connecting feature maps from deep layers to shallow layers. We propose some Feedback Attentions which imitate human brain and feeds back the feature maps of output layer to close layer to the input. U-Net with Feedback Attention showed better result than the conventional methods using only feedforward processing.", "pdf_url": "https://arxiv.org/pdf/2008.06474", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Negative Confidence-Aware Weakly Supervised Binary Classification for Effective Review Helpfulness Classification", "author": "Xi Wang, Iadh Ounis, Craig Macdonald", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The incompleteness of positive labels and the presence of many unlabelled instances are common problems in binary classification applications such as in review helpfulness classification. Various studies from the classification literature consider all unlabelled instances as negative examples. However, a classification model that learns to classify binary instances with incomplete positive labels while assuming all unlabelled data to be negative examples will often generate a biased classifier. In this work, we propose a novel Negative Confidence-aware Weakly Supervised approach (NCWS), which customises a binary classification loss function by discriminating the unlabelled examples with different negative confidences during the classifier's training. We use the review helpfulness classification as a test case for examining the effectiveness of our NCWS approach. We thoroughly evaluate NCWS by using three different datasets, namely one from Yelp (venue reviews), and two from Amazon (Kindle and Electronics reviews). Our results show that NCWS outperforms strong baselines from the literature including an existing SVM-based approach (i.e. SVM-P), the positive and unlabelled learning-based approach (i.e. C-PU) and the positive confidence-based approach (i.e. P-conf) in addressing the classifier's bias problem. Moreover, we further examine the effectiveness of NCWS by using its classified helpful reviews in a state-of-the-art review-based venue recommendation model (i.e. DeepCoNN) and demonstrate the benefits of using NCWS in enhancing venue recommendation effectiveness in comparison to the baselines.", "pdf_url": "https://arxiv.org/pdf/2008.06487", "subject": "Information Retrieval (cs.IR)"},
{"title": "UAV-Assisted Attack Prevention, Detection, and Recovery of 5G Networks", "author": "Aly Sabri Abdalla, Keith Powell, Vuk Marojevic, Giovanni Geraci", "pub_date": "Submitted on 1 Jul 2020", "abstract": "Unmanned aerial vehicles (UAVs) are emerging as enablers for supporting many applications and services, such as precision agriculture, search and rescue, temporary network deployment or coverage extension, and security. UAVs are being considered for integration into emerging 5G networks as aerial users or network support nodes. We propose to leverage UAVs in 5G to assist in the prevention, detection, and recovery of attacks on 5G networks. Specifically, we consider jamming, spoofing, eavesdropping and the corresponding mitigation mechanisms that are enabled by the versatility of UAVs. We introduce the hot zone, safe zone and UAV-based secondary authorization entity, among others, to increase the resilience and confidentiality of 5G radio access networks and services. We present simulation results and discuss open issues and research directions, including the need for experimental evaluation and a research platform for prototyping and testing the proposed technologies.", "pdf_url": "https://arxiv.org/pdf/2007.00244", "subject": "Signal Processing (eess.SP)"},
{"title": "Discriminating an Arbitrary Number of Pure Quantum States by the Combined $\\mathcal{CPT}$ and Hermitian Measurements", "author": "Yaroslav Balytskyi, Sang-Yoon Chang, Anatoliy Pinchuk, Manohar Raavi", "pub_date": "Submitted on 16 Aug 2020", "abstract": "If the system is known to be in one of two non-orthogonal quantum states, $|\\psi_1\\rangle$ or $|\\psi_2\\rangle$, $\\mathcal{PT}$-symmetric quantum mechanics can discriminate them, \\textit{in principle}, by a single measurement. We extend this approach by combining $\\mathcal{PT}$-symmetric and Hermitian measurements and show that it's possible to distinguish an arbitrary number of pure quantum states by an appropriate choice of the parameters of $\\mathcal{PT}$-symmetric Hamiltonian.", "pdf_url": "https://arxiv.org/pdf/2008.06503", "subject": "Quantum Physics (quant-ph)"},
{"title": "A New Perspective on Pool-Based Active Classification and False-Discovery Control", "author": "Lalit Jain, Kevin Jamieson", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In many scientific settings there is a need for adaptive experimental design to guide the process of identifying regions of the search space that contain as many true positives as possible subject to a low rate of false discoveries (i.e. false alarms). Such regions of the search space could differ drastically from a predicted set that minimizes 0/1 error and accurate identification could require very different sampling strategies. Like active learning for binary classification, this experimental design cannot be optimally chosen a priori, but rather the data must be taken sequentially and adaptively. However, unlike classification with 0/1 error, collecting data adaptively to find a set with high true positive rate and low false discovery rate (FDR) is not as well understood. In this paper we provide the first provably sample efficient adaptive algorithm for this problem. Along the way we highlight connections between classification, combinatorial bandits, and FDR control making contributions to each.", "pdf_url": "https://arxiv.org/pdf/2008.06555", "subject": "Machine Learning (stat.ML)"},
{"title": "Performance characterization of a novel deep learning-based MR image reconstruction pipeline", "author": "R. Marc Lebel", "pub_date": "Submitted on 14 Aug 2020", "abstract": "A novel deep learning-based magnetic resonance imaging reconstruction pipeline was designed to address fundamental image quality limitations of conventional reconstruction to provide high-resolution, low-noise MR images. This pipeline's unique aims were to convert truncation artifact into improved image sharpness while jointly denoising images to improve image quality. This new approach, now commercially available at AIR Recon DL (GE Healthcare, Waukesha, WI), includes a deep convolutional neural network (CNN) to aid in the reconstruction of raw data, ultimately producing clean, sharp images. Here we describe key features of this pipeline and its CNN, characterize its performance in digital reference objects, phantoms, and in-vivo, and present sample images and protocol optimization strategies that leverage image quality improvement for reduced scan time. This new deep learning-based reconstruction pipeline represents a powerful new tool to increase the diagnostic and operational performance of an MRI scanner.", "pdf_url": "https://arxiv.org/pdf/2008.06559", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Adaptation Algorithms for Speech Recognition: An Overview", "author": "Peter Bell, Joachim Fainberg, Ondrej Klejch, Jinyu Li, Steve Renals, Pawel Swietojanski", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We present a structured overview of adaptation algorithms for neural network-based speech recognition, considering both hybrid hidden Markov model / neural network systems and end-to-end neural network systems, with a focus on speaker adaptation, domain adaptation, and accent adaptation. The overview characterizes adaptation algorithms as based on embeddings, model parameter adaptation, or data augmentation. We present a meta-analysis of the performance of speech recognition adaptation algorithms, based on relative error rate reductions as reported in the literature.", "pdf_url": "https://arxiv.org/pdf/2008.06580", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "The rising of collective forgetting and cultural selectivity in inventors and physicists communities", "author": "Cristian Candia, Brian Uzzi", "pub_date": "Submitted on 14 Aug 2020", "abstract": "How long until this paper is forgotten? Collective forgetting is the process by which the attention received by cultural pieces decays as time passes. Recent work modeled this decay as the result of two different processes, one linked to communicative memory --memories sustained by human communication-- and cultural memory --memories sustained by the physical recording of content. Yet, little is known on how the collective forgetting dynamic changes over time. Are older cultural pieces forgotten at a lower rate than newer ones? Here, we study the temporal changes of collective memory and attention by focusing on two knowledge communities: inventors and physicists. We use data on patents from the United States Patent and Trademark Office (USPTO) and physics papers published in the American Physical Society (APS) to quantify how collective forgetting has changed over time. The model enables us to distinguish between two branches of forgetting. One branch is short-lived, going directly from communicative memory to oblivion. The other one is long-lived going from communicative to cultural memory and then to oblivion. The data analysis shows an increasing forgetting rate for both communities as the information grows. Furthermore, these knowledge communities seem to be increasing their selectivity at storing valuable cultural pieces in their cultural memory. These findings provide empirical confirmation on the forgetting as an annulment hypothesis and show that knowledge communities can effectively slow down the rising of collective forgetting at improving their cultural selectivity.", "pdf_url": "https://arxiv.org/pdf/2008.06592", "subject": "Physics and Society (physics.soc-ph)"},
{"title": "Nash equilibrium structure of Cox process Hotelling games", "author": "Venkat Anantharam, Francois Baccelli", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We study an N-player game where a pure action of each player is to select a non-negative function on a Polish space supporting a finite diffuse measure, subject to a finite constraint on the integral of the function. This function is used to define the intensity of a Poisson point process on the Polish space. The processes are independent over the players, and the value to a player is the measure of the union of its open Voronoi cells in the superposition point process. Under randomized strategies, the process of points of a player is thus a Cox process, and the nature of competition between the players is akin to that in Hotelling competition games. We characterize when such a game admits Nash equilibria and prove that when a Nash equilibrium exists, it is unique and comprised of pure strategies that are proportional in the same proportions as the total intensities. We give examples of such games where Nash equilibria do not exist. A better understanding of the criterion for the existence of Nash equilibria remains an intriguing open problem.", "pdf_url": "https://arxiv.org/pdf/2008.06617", "subject": "Probability (math.PR)"},
{"title": "On the Generalization Properties of Adversarial Training", "author": "Yue Xing, Qifan Song, Guang Cheng", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Modern machine learning and deep learning models are shown to be vulnerable when testing data are slightly perturbed. Theoretical studies of adversarial training algorithms mostly focus on their adversarial training losses or local convergence properties. In contrast, this paper studies the generalization performance of a generic adversarial training algorithm. Specifically, we consider linear regression models and two-layer neural networks (with lazy training) using squared loss under both low-dimensional and high-dimensional regimes. In the former regime, the adversarial risk of the trained models will converge to the minimal adversarial risk. In the latter regime, we discover that data interpolation prevents the adversarial robust estimator from being consistent (i.e. converge in probability). Therefore, inspired by successes of the least absolute shrinkage and selection operator (LASSO), we incorporate the L1 penalty in the high dimensional adversarial learning, and show that it leads to consistent adversarial robust estimation in both theory and numerical trials.", "pdf_url": "https://arxiv.org/pdf/2008.06631", "subject": "Machine Learning (stat.ML)"},
{"title": "Dehaze-GLCGAN: Unpaired Single Image De-hazing via Adversarial Training", "author": "Zahra Anvari, Vassilis Athitsos", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Single image de-hazing is a challenging problem, and it is far from solved. Most current solutions require paired image datasets that include both hazy images and their corresponding haze-free ground-truth images. However, in reality, lighting conditions and other factors can produce a range of haze-free images that can serve as ground truth for a hazy image, and a single ground truth image cannot capture that range. This limits the scalability and practicality of paired image datasets in real-world applications. In this paper, we focus on unpaired single image de-hazing and we do not rely on the ground truth image or physical scattering model. We reduce the image de-hazing problem to an image-to-image translation problem and propose a dehazing Global-Local Cycle-consistent Generative Adversarial Network (Dehaze-GLCGAN). Generator network of Dehaze-GLCGAN combines an encoder-decoder architecture with residual blocks to better recover the haze free scene. We also employ a global-local discriminator structure to deal with spatially varying haze. Through ablation study, we demonstrate the effectiveness of different factors in the performance of the proposed network. Our extensive experiments over three benchmark datasets show that our network outperforms previous work in terms of PSNR and SSIM while being trained on smaller amount of data compared to other methods.", "pdf_url": "https://arxiv.org/pdf/2008.06632", "subject": "Image and Video Processing (eess.IV)"},
{"title": "EigenEmo: Spectral Utterance Representation Using Dynamic Mode Decomposition for Speech Emotion Classification", "author": "Shuiyang Mao, P. C. Ching, Tan Lee", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Human emotional speech is, by its very nature, a variant signal. This results in dynamics intrinsic to automatic emotion classification based on speech. In this work, we explore a spectral decomposition method stemming from fluid-dynamics, known as Dynamic Mode Decomposition (DMD), to computationally represent and analyze the global utterance-level dynamics of emotional speech. Specifically, segment-level emotion-specific representations are first learned through an Emotion Distillation process. This forms a multi-dimensional signal of emotion flow for each utterance, called Emotion Profiles (EPs). The DMD algorithm is then applied to the resultant EPs to capture the eigenfrequencies, and hence the fundamental transition dynamics of the emotion flow. Evaluation experiments using the proposed approach, which we call EigenEmo, show promising results. Moreover, due to the positive combination of their complementary properties, concatenating the utterance representations generated by EigenEmo with simple EPs averaging yields noticeable gains.", "pdf_url": "https://arxiv.org/pdf/2008.06665", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Advancing Multiple Instance Learning with Attention Modeling for Categorical Speech Emotion Recognition", "author": "Shuiyang Mao, P. C. Ching, C.-C. Jay Kuo, Tan Lee", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Categorical speech emotion recognition is typically performed as a sequence-to-label problem, i.e., to determine the discrete emotion label of the input utterance as a whole. One of the main challenges in practice is that most of the existing emotion corpora do not give ground truth labels for each segment; instead, we only have labels for whole utterances. To extract segment-level emotional information from such weakly labeled emotion corpora, we propose using multiple instance learning (MIL) to learn segment embeddings in a weakly supervised manner. Also, for a sufficiently long utterance, not all of the segments contain relevant emotional information. In this regard, three attention-based neural network models are then applied to the learned segment embeddings to attend the most salient part of a speech utterance. Experiments on the CASIA corpus and the IEMOCAP database show better or highly competitive results than other state-of-the-art approaches.", "pdf_url": "https://arxiv.org/pdf/2008.06667", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Jointly Fine-Tuning \"BERT-like\" Self Supervised Models to Improve Multimodal Speech Emotion Recognition", "author": "Shamane Siriwardhana, Andrew Reis, Rivindu Weerasekera, Suranga Nanayakkara", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Multimodal emotion recognition from speech is an important area in affective computing. Fusing multiple data modalities and learning representations with limited amounts of labeled data is a challenging task. In this paper, we explore the use of modality-specific \"BERT-like\" pretrained Self Supervised Learning (SSL) architectures to represent both speech and text modalities for the task of multimodal speech emotion recognition. By conducting experiments on three publicly available datasets (IEMOCAP, CMU-MOSEI, and CMU-MOSI), we show that jointly fine-tuning \"BERT-like\" SSL architectures achieve state-of-the-art (SOTA) results. We also evaluate two methods of fusing speech and text modalities and show that a simple fusion mechanism can outperform more complex ones when using SSL models that have similar architectural properties to BERT.", "pdf_url": "https://arxiv.org/pdf/2008.06682", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Experimental investigations of psychoacoustic characteristics of household vacuum cleaners", "author": "Sanjay Kumar, Wong Sze Wing, Teng Mingbang, Heow Pueh Lee", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Vacuum cleaners are one of the most widely used household appliances associated with unpleasant noises. Previous studies have indicated the severity of vacuum cleaner noise and its impact on the users nearby. The quantified measurements of the generated noise standalone are not sufficient for the selection or designing of vacuum cleaners. The human perception must also be included for a better assessment of the quality of sound. A hybrid approach known as psychoacoustics, which comprises subjective and objective evaluations of sounds, is widely used in recent times. This paper focuses on the experimental assessment of psychoacoustical matrices for household vacuum cleaners. Three vacuum cleaners with different specifications have been selected as test candidates, and their sound qualities have been analyzed. Besides, the annoyance index has been assessed for these vacuum cleaners.", "pdf_url": "https://arxiv.org/pdf/2008.06702", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Single image dehazing for a variety of haze scenarios using back projected pyramid network", "author": "Ayush Singh, Ajay Bhave, Dilip K. Prasad", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Learning to dehaze single hazy images, especially using a small training dataset is quite challenging. We propose a novel generative adversarial network architecture for this problem, namely back projected pyramid network (BPPNet), that gives good performance for a variety of challenging haze conditions, including dense haze and inhomogeneous haze. Our architecture incorporates learning of multiple levels of complexities while retaining spatial context through iterative blocks of UNets and structural information of multiple scales through a novel pyramidal convolution block. These blocks together for the generator and are amenable to learning through back projection. We have shown that our network can be trained without over-fitting using as few as 20 image pairs of hazy and non-hazy images. We report the state of the art performances on NTIRE 2018 homogeneous haze datasets for indoor and outdoor images, NTIRE 2019 denseHaze dataset, and NTIRE 2020 non-homogeneous haze dataset.", "pdf_url": "https://arxiv.org/pdf/2008.06713", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Deep Architectures for Modulation Recognition with Multiple Receive Antennas", "author": "Lei Li, Qihang Peng, Jun Wang", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Modulation recognition using deep neural networks has shown promising advantage over conventional algorithms. However, most existing research focuses on single receive antenna. In this paper, modulation recognition with multiple receive antennas using deep neural networks is investigated and four different architectures are introduced, including equal-gain CNN, multi-view CNN, 2-dimensional CNN and 3-dimensional CNN. Each architecture is constructed based on a ResNet and tuned to the extent that its performance does not further improve when the network size and parameters change with a given dataset. These architectures are then compared in terms of classification accuracy. Simulation results show that 3-dimensional CNN yields the overall best performance, while the equal-gain CNN leads to the lowest performance. Further, both 2-dimensional CNN and 3-dimensional CNN, which jointly extract features from multiple receive antennas with different feature encoding, outperforms either equal-gain or multi-view CNN, which fuses extracted features from each antenna. This indicates that utilizing inherent structures within deep neural networks to jointly extract features from different antennas can achieve better performance than the schemes that combine individually encoded features from each antenna, and extending the dimension of CNN from two to three can enhance feature extraction capabilities in the context of modulation recognition.", "pdf_url": "https://arxiv.org/pdf/2008.06720", "subject": "Signal Processing (eess.SP)"},
{"title": "Damage Detection in Bridge Structures: An Edge Computing Approach", "author": "Rahul Kumar Verma, K. K. Pattanaik, P. B. R. Dissanayake, A. J. Dammika, H. A. D. Samith Buddika, Mosbeh R. Kaloop", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Wireless sensor network (WSN) based SHM systems have shown significant improvement as compared to traditional wired-SHM systems in terms of cost, accuracy, and reliability of the monitoring. However, due to the resource-constrained nature of the sensor nodes, it is a challenge to process a large amount of sensed vibration data in real-time. Existing mechanisms of data processing are centralized and use cloud or remote servers to analyze the data to characterize the state of the bridge, i.e., healthy or damaged. These methods are feasible for wired-SHM systems, however, transmitting huge data-sets in WSNs has been found to be arduous. In this paper, we propose a mechanism named as ``in-network damage detection on edge (INDDE)\" which extracts the statistical features from raw acceleration measurements corresponding to the healthy condition of the bridge and use them to train a probabilistic model, i.e., estimating the probability density function (PDF) of multivariate Gaussian distribution. The trained model helps to identify the anomalous behaviour of the new data points collected from the unknown condition of the bridge in real-time. Each edge device classifies the condition of the bridge as either \"healthy\" or \"damaged\" around its deployment region depending on their respective trained model. Experimentation results showcase a promising 96-100% damage detection accuracy with the advantage of no data transmission from sensor nodes to the cloud for processing.", "pdf_url": "https://arxiv.org/pdf/2008.06724", "subject": "Signal Processing (eess.SP)"},
{"title": "FEARLESS STEPS Challenge (FS-2): Supervised Learning with Massive Naturalistic Apollo Data", "author": "Aditya Joglekar, John H.L. Hansen, Meena Chandra Shekar, Abhijeet Sangwan", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The Fearless Steps Initiative by UTDallas-CRSS led to the digitization, recovery, and diarization of 19,000 hours of original analog audio data, as well as the development of algorithms to extract meaningful information from this multi-channel naturalistic data resource. The 2020 FEARLESS STEPS (FS-2) Challenge is the second annual challenge held for the Speech and Language Technology community to motivate supervised learning algorithm development for multi-party and multi-stream naturalistic audio. In this paper, we present an overview of the challenge sub-tasks, data, performance metrics, and lessons learned from Phase-2 of the Fearless Steps Challenge (FS-2). We present advancements made in FS-2 through extensive community outreach and feedback. We describe innovations in the challenge corpus development, and present revised baseline results. We finally discuss the challenge outcome and general trends in system development across both phases (Phase FS-1 Unsupervised, and Phase FS-2 Supervised) of the challenge, and its continuation into multi-channel challenge tasks for the upcoming Fearless Steps Challenge Phase-3.", "pdf_url": "https://arxiv.org/pdf/2008.06764", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Automated Detection of Cortical Lesions in Multiple Sclerosis Patients with 7T MRI", "author": "Francesco La Rosa, Erin S Beck, Ahmed Abdulkadir, Jean-Philippe Thiran, Daniel S Reich, Pascal Sati, Meritxell Bach Cuadra", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The automated detection of cortical lesions (CLs) in patients with multiple sclerosis (MS) is a challenging task that, despite its clinical relevance, has received very little attention. Accurate detection of the small and scarce lesions requires specialized sequences and high or ultra-high field MRI. For supervised training based on multimodal structural MRI at 7T, two experts generated ground truth segmentation masks of 60 patients with 2014 CLs. We implemented a simplified 3D U-Net with three resolution levels (3D U-Net-). By increasing the complexity of the task (adding brain tissue segmentation), while randomly dropping input channels during training, we improved the performance compared to the baseline. Considering a minimum lesion size of 0.75 {\\mu}L, we achieved a lesion-wise cortical lesion detection rate of 67% and a false positive rate of 42%. However, 393 (24%) of the lesions reported as false positives were post-hoc confirmed as potential or definite lesions by an expert. This indicates the potential of the proposed method to support experts in the tedious process of CL manual segmentation.", "pdf_url": "https://arxiv.org/pdf/2008.06780", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Adversarial Filters for Secure Modulation Classification", "author": "Alex Berian, Kory Staab, Noel Teku, Gregory Ditzler, Tamal Bose, Ravi Tandon", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Modulation Classification (MC) refers to the problem of classifying the modulation class of a wireless signal. In the wireless communications pipeline, MC is the first operation performed on the received signal and is critical for reliable decoding. This paper considers the problem of secure modulation classification, where a transmitter (Alice) wants to maximize MC accuracy at a legitimate receiver (Bob) while minimizing MC accuracy at an eavesdropper (Eve). The contribution of this work is to design novel adversarial learning techniques for secure MC. In particular, we present adversarial filtering based algorithms for secure MC, in which Alice uses a carefully designed adversarial filter to mask the transmitted signal, that can maximize MC accuracy at Bob while minimizing MC accuracy at Eve. We present two filtering based algorithms, namely gradient ascent filter (GAF), and a fast gradient filter method (FGFM), with varying levels of complexity. Our proposed adversarial filtering based approaches significantly outperform additive adversarial perturbations (used in the traditional ML community and other prior works on secure MC) and also have several other desirable properties. In particular, GAF and FGFM algorithms are a) computational efficient (allow fast decoding at Bob), b) power-efficient (do not require excessive transmit power at Alice); and c) SNR efficient (i.e., perform well even at low SNR values at Bob).", "pdf_url": "https://arxiv.org/pdf/2008.06785", "subject": "Signal Processing (eess.SP)"},
{"title": "The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization", "author": "Ben Adlam, Jeffrey Pennington", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Modern deep learning models employ considerably more parameters than required to fit the training data. Whereas conventional statistical wisdom suggests such models should drastically overfit, in practice these models generalize remarkably well. An emerging paradigm for describing this unexpected behavior is in terms of a \\emph{double descent} curve, in which increasing a model's capacity causes its test error to first decrease, then increase to a maximum near the interpolation threshold, and then decrease again in the overparameterized regime. Recent efforts to explain this phenomenon theoretically have focused on simple settings, such as linear regression or kernel regression with unstructured random features, which we argue are too coarse to reveal important nuances of actual neural networks. We provide a precise high-dimensional asymptotic analysis of generalization under kernel regression with the Neural Tangent Kernel, which characterizes the behavior of wide neural networks optimized with gradient descent. Our results reveal that the test error has non-monotonic behavior deep in the overparameterized regime and can even exhibit additional peaks and descents when the number of parameters scales quadratically with the dataset size.", "pdf_url": "https://arxiv.org/pdf/2008.06786", "subject": "Machine Learning (stat.ML)"},
{"title": "Diameter Polytopes of Feasible Binary Programs", "author": "Thomas R. Cameron, Sebastian Charmot, Jonad Pulaj", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Feasible binary programs often have multiple optimal solutions, which is of interest in applications as they allow the user to choose between alternative optima without deteriorating the objective function. In this article, we present the optimal diameter of a feasible binary program as a metric for measuring the diversity among all optimal solutions. In addition, we present the diameter binary program whose optima contains two optimal solutions of the given feasible binary program that are as diverse as possible with respect to the optimal diameter. Our primary interest is in the study of the diameter polytope, i.e., the polytope underlying the diameter binary program. Under suitable conditions, we show that much of the structure of the diameter polytope is inherited from the polytope underlying the given binary program. Finally, we apply our results on the diameter binary program and diameter polytope to cases where the given binary program corresponds to the linear ordering problem and the symmetric traveling salesman problem.", "pdf_url": "https://arxiv.org/pdf/2008.06844", "subject": "Optimization and Control (math.OC)"},
{"title": "Audio Dequantization for High Fidelity Audio Generation in Flow-based Neural Vocoder", "author": "Hyun-Wook Yoon, Sang-Hoon Lee, Hyeong-Rae Noh, Seong-Whan Lee", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In recent works, a flow-based neural vocoder has shown significant improvement in real-time speech generation task. The sequence of invertible flow operations allows the model to convert samples from simple distribution to audio samples. However, training a continuous density model on discrete audio data can degrade model performance due to the topological difference between latent and actual distribution. To resolve this problem, we propose audio dequantization methods in flow-based neural vocoder for high fidelity audio generation. Data dequantization is a well-known method in image generation but has not yet been studied in the audio domain. For this reason, we implement various audio dequantization methods in flow-based neural vocoder and investigate the effect on the generated audio. We conduct various objective performance assessments and subjective evaluation to show that audio dequantization can improve audio generation quality. From our experiments, using audio dequantization produces waveform audio with better harmonic structure and fewer digital artifacts.", "pdf_url": "https://arxiv.org/pdf/2008.06867", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Unsupervised Acoustic Unit Representation Learning for Voice Conversion using WaveNet Auto-encoders", "author": "Mingjie Chen, Thomas Hain", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Unsupervised representation learning of speech has been of keen interest in recent years, which is for example evident in the wide interest of the ZeroSpeech challenges. This work presents a new method for learning frame level representations based on WaveNet auto-encoders. Of particular interest in the ZeroSpeech Challenge 2019 were models with discrete latent variable such as the Vector Quantized Variational Auto-Encoder (VQVAE). However these models generate speech with relatively poor quality. In this work we aim to address this with two approaches: first WaveNet is used as the decoder and to generate waveform data directly from the latent representation; second, the low complexity of latent representations is improved with two alternative disentanglement learning methods, namely instance normalization and sliced vector quantization. The method was developed and tested in the context of the recent ZeroSpeech challenge 2020. The system output submitted to the challenge obtained the top position for naturalness (Mean Opinion Score 4.06), top position for intelligibility (Character Error Rate 0.15), and third position for the quality of the representation (ABX test score 12.5). These and further analysis in this paper illustrates that quality of the converted speech and the acoustic units representation can be well balanced.", "pdf_url": "https://arxiv.org/pdf/2008.06892", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Automated Detection of Congenital Heart Disease in Fetal Ultrasound Screening", "author": "Jeremy Tan, Anselm Au, Qingjie Meng, Sandy FinesilverSmith, John Simpson, Daniel Rueckert, Reza Razavi, Thomas Day, David Lloyd, Bernhard Kainz", "pub_date": "Submitted on 16 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "Prenatal screening with ultrasound can lower neonatal mortality significantly for selected cardiac abnormalities. However, the need for human expertise, coupled with the high volume of screening cases, limits the practically achievable detection rates. In this paper we discuss the potential for deep learning techniques to aid in the detection of congenital heart disease (CHD) in fetal ultrasound. We propose a pipeline for automated data curation and classification. During both training and inference, we exploit an auxiliary view classification task to bias features toward relevant cardiac structures. This bias helps to improve in F1-scores from 0.72 and 0.77 to 0.87 and 0.85 for healthy and CHD classes respectively.", "pdf_url": "https://arxiv.org/pdf/2008.06966", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Real-Time Spatio-Temporal LiDAR Point Cloud Compression", "author": "Yu Feng, Shaoshan Liu, Yuhao Zhu", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Compressing massive LiDAR point clouds in real-time is critical to autonomous machines such as drones and self-driving cars. While most of the recent prior work has focused on compressing individual point cloud frames, this paper proposes a novel system that effectively compresses a sequence of point clouds. The idea to exploit both the spatial and temporal redundancies in a sequence of point cloud frames. We first identify a key frame in a point cloud sequence and spatially encode the key frame by iterative plane fitting. We then exploit the fact that consecutive point clouds have large overlaps in the physical space, and thus spatially encoded data can be (re-)used to encode the temporal stream. Temporal encoding by reusing spatial encoding data not only improves the compression rate, but also avoids redundant computations, which significantly improves the compression speed. Experiments show that our compression system achieves 40x to 90x compression rate, significantly higher than the MPEG's LiDAR point cloud compression standard, while retaining high end-to-end application accuracies. Meanwhile, our compression system has a compression speed that matches the point cloud generation rate by today LiDARs and out-performs existing compression systems, enabling real-time point cloud transmission.", "pdf_url": "https://arxiv.org/pdf/2008.06972", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Deep Learning Enables Robust and Precise Light Focusing on Treatment Needs", "author": "Changchun Yang, Hengrong Lan, Fei Gao", "pub_date": "Submitted on 16 Aug 2020", "abstract": "If light passes through the body tissues, focusing only on areas where treatment needs, such as tumors, will revolutionize many biomedical imaging and therapy technologies. So how to focus light through deep inhomogeneous tissues overcoming scattering is Holy Grail in biomedical areas. In this paper, we use deep learning to learn and accelerate the process of phase pre-compensation using wavefront shaping. We present an approach (LoftGAN, light only focuses on treatment needs) for learning the relationship between phase domain X and speckle domain Y . Our goal is not just to learn an inverse mapping F:Y->X such that we can know the corresponding X needed for imaging Y like most work, but also to make focusing that is susceptible to disturbances more robust and precise by ensuring that the phase obtained can be forward mapped back to speckle. So we introduce different constraints to enforce F(Y)=X and H(F(Y))=Y with the transmission mapping H:X->Y. Both simulation and physical experiments are performed to investigate the effects of light focusing to demonstrate the effectiveness of our method and comparative experiments prove the crucial improvement of robustness and precision. Codes are available at .", "pdf_url": "https://arxiv.org/pdf/2008.06975", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Uniform approximation by multivariate quasi-projection operators", "author": "Yurii Kolomoitsev, Maria Skopina", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Approximation properties of quasi-projection operators $Q_j(f,\\varphi, \\widetilde{\\varphi})$ are studied. Such an operator is associated with a function $\\varphi$ satisfying the Strang-Fix conditions and a tempered distribution $\\widetilde{\\varphi}$ such that compatibility conditions with $\\varphi$ hold. Error estimates in the uniform norm are obtained for a wide class of quasi-projection operators defined on the space of uniformly continuous functions and on the anisotropic Besov spaces. Under additional assumptions on $\\varphi$ and $\\widetilde{\\varphi}$, two-sided estimates in terms of realizations of the $K$-functional are also obtained.", "pdf_url": "https://arxiv.org/pdf/2008.06977", "subject": "Classical Analysis and ODEs (math.CA)"},
{"title": "Power and the Pandemic: Exploring Global Changes in Electricity Demand During COVID-19", "author": "Elizabeth Buechler, Siobhan Powell, Tao Sun, Chad Zanocco, Nicolas Astier, Jose Bolorinos, June Flora, Hilary Boudet, Ram Rajagopal", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Understanding how efforts to limit exposure to COVID-19 have altered electricity demand provides insights not only into how dramatic restrictions shape electricity demand but also about future electricity use in a post-COVID-19 world. We develop a unified modeling framework to quantify and compare electricity usage changes in 58 countries and regions around the world from January-May 2020. We find that daily electricity demand declined as much as 10% in April 2020 compared to modelled demand, controlling for weather, seasonal and temporal effects, but with significant variation. Clustering techniques show that four impact groups capture systematic differences in timing and depth of electricity usage changes, ranging from a mild decline of 2% to an extreme decline of 26%. These groupings do not align with geography, with almost every continent having at least one country or region that experienced a dramatic reduction in demand and one that did not. Instead, we find that such changes relate to government restrictions and mobility. Government restrictions have a non-linear effect on demand that generally saturates at its most restrictive levels and sustains even as restrictions ease. Mobility offers a sharper focus on electricity demand change with workplace and residential mobility strongly linked to demand changes at the daily level. Steep declines in electricity usage are associated with workday hourly load patterns that resemble pre-COVID weekend usage. Quantifying these impacts is a crucial first step in understanding the impacts of crises like the pandemic and the associated societal response on electricity demand.", "pdf_url": "https://arxiv.org/pdf/2008.06988", "subject": "Physics and Society (physics.soc-ph)"},
{"title": "Elmer FEM-Dakota: A unified open-source computational framework for electromagnetics and data analytics", "author": "Anjali Sandip", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Open-source electromagnetic design software, Elmer FEM, was interfaced with data analytics toolkit, Dakota. Furthermore, the coupled software was validated against a benchmark test. The interface developed provides a unified open-source computational framework for electromagnetics and data analytics. Its key features include uncertainty quantification, surrogate modelling and parameter studies. This framework enables a richer understanding of model predictions to better design electric machines in a time sensitive manner.", "pdf_url": "https://arxiv.org/pdf/2008.06992", "subject": "Computational Physics (physics.comp-ph)"},
{"title": "Deep Learning Predicts Cardiovascular Disease Risks from Lung Cancer Screening Low Dose Computed Tomography", "author": "Hanqing Chao, Hongming Shan, Fatemeh Homayounieh, Ramandeep Singh, Ruhani Doda Khera, Hengtao Guo, Timothy Su, Ge Wang, Mannudeep K. Kalra, Pingkun Yan", "pub_date": "Submitted on 16 Aug 2020", "abstract": "The high risk population of cardiovascular disease (CVD) is simultaneously at high risk of lung cancer. Given the dominance of low dose computed tomography (LDCT) for lung cancer screening, the feasibility of extracting information on CVD from the same LDCT scan would add major value to patients at no additional radiation dose. However, with strong noise in LDCT images and without electrocardiogram (ECG) gating, CVD risk analysis from LDCT is highly challenging. Here we present an innovative deep learning model to address this challenge. Our deep model was trained with 30,286 LDCT volumes and achieved the state-of-the-art performance (area under the curve (AUC) of 0.869) on 2,085 National Lung Cancer Screening Trial (NLST) subjects, and effectively identified patients with high CVD mortality risks (AUC of 0.768). Our deep model was further calibrated against the clinical gold standard CVD risk scores from ECG-gated dedicated cardiac CT, including coronary artery calcification (CAC) score, CAD-RADS score and MESA 10-year CHD risk score from an independent dataset of 106 subjects. In this validation study, our model achieved AUC of 0.942, 0.809 and 0.817 for CAC, CAD-RADS and MESA scores, respectively. Our deep learning model has the potential to convert LDCT for lung cancer screening into dual-screening quantitative tool for CVD risk estimation.", "pdf_url": "https://arxiv.org/pdf/2008.06997", "subject": "Image and Video Processing (eess.IV)"},
{"title": "RevPHiSeg: A Memory-Efficient Neural Network for Uncertainty Quantification in Medical Image Segmentation", "author": "Marc Gantenbein, Ertunc Erdil, Ender Konukoglu", "pub_date": "Submitted on 16 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "Quantifying segmentation uncertainty has become an important issue in medical image analysis due to the inherent ambiguity of anatomical structures and its pathologies. Recently, neural network-based uncertainty quantification methods have been successfully applied to various problems. One of the main limitations of the existing techniques is the high memory requirement during training; which limits their application to processing smaller field-of-views (FOVs) and/or using shallower architectures. In this paper, we investigate the effect of using reversible blocks for building memory-efficient neural network architectures for quantification of segmentation uncertainty. The reversible architecture achieves memory saving by exactly computing the activations from the outputs of the subsequent layers during backpropagation instead of storing the activations for each layer. We incorporate the reversible blocks into a recently proposed architecture called PHiSeg that is developed for uncertainty quantification in medical image segmentation. The reversible architecture, RevPHiSeg, allows training neural networks for quantifying segmentation uncertainty on GPUs with limited memory and processing larger FOVs. We perform experiments on the LIDC-IDRI dataset and an in-house prostate dataset, and present comparisons with PHiSeg. The results demonstrate that RevPHiSeg consumes ~30% less memory compared to PHiSeg while achieving very similar segmentation accuracy.", "pdf_url": "https://arxiv.org/pdf/2008.06999", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Spontaneous preterm birth prediction using convolutional neural networks", "author": "Tomasz W\u0142odarczyk, Szymon P\u0142otka, Przemys\u0142aw Rokita, Nicole Sochacki-W\u00f3jcicka, Jakub W\u00f3jcicki, Micha\u0142 Lipa, Tomasz Trzci\u0144ski", "pub_date": "Submitted on 16 Aug 2020", "abstract": "An estimated 15 million babies are born too early every year. Approximately 1 million children die each year due to complications of preterm birth (PTB). Many survivors face a lifetime of disability, including learning disabilities and visual and hearing problems. Although manual analysis of ultrasound images (US) is still prevalent, it is prone to errors due to its subjective component and complex variations in the shape and position of organs across patients. In this work, we introduce a conceptually simple convolutional neural network (CNN) trained for segmenting prenatal ultrasound images and classifying task for the purpose of preterm birth detection. Our method efficiently segments different types of cervixes in transvaginal ultrasound images while simultaneously predicting a preterm birth based on extracted image features without human oversight. We employed three popular network models: U-Net, Fully Convolutional Network, and Deeplabv3 for the cervix segmentation task. Based on the conducted results and model efficiency, we decided to extend U-Net by adding a parallel branch for classification task. The proposed model is trained and evaluated on a dataset consisting of 354 2D transvaginal ultrasound images and achieved a segmentation accuracy with a mean Jaccard coefficient index of 0.923 $\\pm$ 0.081 and a classification sensitivity of 0.677 $\\pm$ 0.042 with a 3.49\\% false positive rate. Our method obtained better results in the prediction of preterm birth based on transvaginal ultrasound images compared to state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2008.07000", "subject": "Image and Video Processing (eess.IV)"},
{"title": "$k$-Forrelation Optimally Separates Quantum and Classical Query Complexity", "author": "Nikhil Bansal, Makrand Sinha", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Aaronson and Ambainis (SICOMP `18) showed that any partial function on $N$ bits that can be computed with an advantage $\\delta$ over a random guess by making $q$ quantum queries, can also be computed classically with an advantage $\\delta/2$ by a randomized decision tree making ${O}_q(N^{1-\\frac{1}{2q}}\\delta^{-2})$ queries. Moreover, they conjectured the $k$-Forrelation problem -- a partial function that can be computed with $q = \\lceil k/2 \\rceil$ quantum queries -- to be a suitable candidate for exhibiting such an extremal separation. We prove their conjecture by showing a tight lower bound of $\\widetilde{\\Omega}_k(N^{1-1/k})$ for the randomized query complexity of $k$-Forrelation, where the advantage $\\delta = 1/\\mathrm{polylog}^k(N)$ and $\\widetilde{\\Omega}_k$ hides $\\mathrm{polylog}^k(N)$ factors. Our proof relies on classical Gaussian tools, in particular, Gaussian interpolation and Gaussian integration by parts, and in fact, shows a more general statement, that to prove lower bounds for $k$-Forrelation against a family of functions, it suffices to bound the $\\ell_1$-weight of the Fourier coefficients at levels $k, 2k, 3k, \\ldots, (k-1)k$ for functions in the family.", "pdf_url": "https://arxiv.org/pdf/2008.07003", "subject": "Quantum Physics (quant-ph)"},
{"title": "Training CNN Classifiers for Semantic Segmentation using Partially Annotated Images: with Application on Human Thigh and Calf MRI", "author": "Chun Kit Wong, Stephanie Marchesseau, Maria Kalimeri, Tiang Siew Yap, Serena S. H. Teo, Lingaraj Krishna, Alfredo Franco-Obreg\u00f3n, Stacey K. H. Tay, Chin Meng Khoo, Philip T. H. Lee, Melvin K. S. Leow, John J. Totman, Mary C. Stephenson", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Objective: Medical image datasets with pixel-level labels tend to have a limited number of organ or tissue label classes annotated, even when the images have wide anatomical coverage. With supervised learning, multiple classifiers are usually needed given these partially annotated datasets. In this work, we propose a set of strategies to train one single classifier in segmenting all label classes that are heterogeneously annotated across multiple datasets without moving into semi-supervised learning. Methods: Masks were first created from each label image through a process we termed presence masking. Three presence masking modes were evaluated, differing mainly in weightage assigned to the annotated and unannotated classes. These masks were then applied to the loss function during training to remove the influence of unannotated classes. Results: Evaluation against publicly available CT datasets shows that presence masking is a viable method for training class-generic classifiers. Our class-generic classifier can perform as well as multiple class-specific classifiers combined, while the training duration is similar to that required for one class-specific classifier. Furthermore, the class-generic classifier can outperform the class-specific classifiers when trained on smaller datasets. Finally, consistent results are observed from evaluations against human thigh and calf MRI datasets collected in-house. Conclusion: The evaluation outcomes show that presence masking is capable of significantly improving both training and inference efficiency across imaging modalities and anatomical regions. Improved performance may even be observed on small datasets. Significance: Presence masking strategies can reduce the computational resources and costs involved in manual medical image annotations. All codes are publicly available at .", "pdf_url": "https://arxiv.org/pdf/2008.07030", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Exploiting Fully Convolutional Network and Visualization Techniques on Spontaneous Speech for Dementia Detection", "author": "Youxiang Zhu, Xiaohui Liang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper, we exploit a Fully Convolutional Network (FCN) to analyze the audio data of spontaneous speech for dementia detection. A fully convolutional network accommodates speech samples with varying lengths, thus enabling us to analyze the speech sample without manual segmentation. Specifically, we first obtain the Mel Frequency Cepstral Coefficient (MFCC) feature map from each participant's audio data and convert the speech classification task on audio data to an image classification task on MFCC feature maps. Then, to solve the data insufficiency problem, we apply transfer learning by adopting a pre-trained backbone Convolutional Neural Network (CNN) model from the MobileNet architecture and the ImageNet dataset. We further build a convolutional layer to produce a heatmap using Otsu's method for visualization, enabling us to understand the impact of the time-series audio segments on the classification results. We demonstrate that our classification model achieves 66.7% over the testing dataset, 62.5% of the baseline model provided in the ADReSS challenge. Through the visualization technique, we can evaluate the impact of audio segments, such as filled pauses from the participants and repeated questions from the investigator, on the classification results.", "pdf_url": "https://arxiv.org/pdf/2008.07052", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "To Bag is to Prune", "author": "Philippe Goulet Coulombe", "pub_date": "Submitted on 17 Aug 2020", "abstract": "It is notoriously hard to build a bad Random Forest (RF). Concurrently, RF is perhaps the only standard ML algorithm that blatantly overfits in-sample without any consequence out-of-sample. Standard arguments cannot rationalize this paradox. I propose a new explanation: bootstrap aggregation and model perturbation as implemented by RF automatically prune a (latent) true underlying tree. More generally, there is no need to tune the stopping point of a properly randomized ensemble of greedily optimized base learners. Thus, Boosting and MARS are eligible. I empirically demonstrate the property with simulations and real data by reporting that these new ensembles yield equivalent performance to their tuned counterparts.", "pdf_url": "https://arxiv.org/pdf/2008.07063", "subject": "Machine Learning (stat.ML)"},
{"title": "Towards Cardiac Intervention Assistance: Hardware-aware Neural Architecture Exploration for Real-Time 3D Cardiac Cine MRI Segmentation", "author": "Dewen Zeng, Weiwen Jiang, Tianchen Wang, Xiaowei Xu, Haiyun Yuan, Meiping Huang, Jian Zhuang, Jingtong Hu, Yiyu Shi", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Real-time cardiac magnetic resonance imaging (MRI) plays an increasingly important role in guiding various cardiac interventions. In order to provide better visual assistance, the cine MRI frames need to be segmented on-the-fly to avoid noticeable visual lag. In addition, considering reliability and patient data privacy, the computation is preferably done on local hardware. State-of-the-art MRI segmentation methods mostly focus on accuracy only, and can hardly be adopted for real-time application or on local hardware. In this work, we present the first hardware-aware multi-scale neural architecture search (NAS) framework for real-time 3D cardiac cine MRI segmentation. The proposed framework incorporates a latency regularization term into the loss function to handle real-time constraints, with the consideration of underlying hardware. In addition, the formulation is fully differentiable with respect to the architecture parameters, so that stochastic gradient descent (SGD) can be used for optimization to reduce the computation cost while maintaining optimization quality. Experimental results on ACDC MICCAI 2017 dataset demonstrate that our hardware-aware multi-scale NAS framework can reduce the latency by up to 3.5 times and satisfy the real-time constraints, while still achieving competitive segmentation accuracy, compared with the state-of-the-art NAS segmentation framework.", "pdf_url": "https://arxiv.org/pdf/2008.07071", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Multi-Task Learning for Interpretable Weakly Labelled Sound Event Detection", "author": "Soham Deshmukh, Bhiksha Raj, Rita Singh", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Weakly Labelled learning has garnered lot of attention in recent years due to its potential to scale Sound Event Detection (SED). The paper proposes a Multi-Task Learning (MTL) framework for learning from Weakly Labelled Audio data which encompasses the traditional Multiple Instance Learning (MIL) setup. The MTL framework uses two-step attention mechanism and reconstructs Time Frequency (T-F) representation of audio as the auxiliary task. By breaking the attention into two steps, the network retains better time level information without compromising classification performance. The auxiliary task uses an auto-encoder structure to encourage the network for retaining source specific information. This indirectly de-noises internal T- F representation and improves classification performance under noisy recordings. For evaluation of proposed methodology, we remix the DCASE 2019 task 1 acoustic scene data with DCASE 2018 Task 2 sounds event data under 0, 10 and 20 db SNR. The proposed network outperforms existing benchmark models over all SNRs, specifically 22.3 %, 12.8 %, 5.9 % improvement over benchmark model on 0, 10 and 20 dB SNR respectively. The results and ablation study performed demonstrates the usefulness of auto-encoder for auxiliary task and verifies that the output of decoder portion provides a cleaned Time Frequency (T-F) representation of audio/sources which can be further used for source separation. The code is publicly released.", "pdf_url": "https://arxiv.org/pdf/2008.07085", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Semi-Supervised Learning with GANs for Device-Free Fingerprinting Indoor Localization", "author": "Kevin M. Chen, Ronald Y. Chang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Device-free wireless indoor localization is a key enabling technology for the Internet of Things (IoT). Fingerprint-based indoor localization techniques are a commonly used solution. This paper proposes a semi-supervised, generative adversarial network (GAN)-based device-free fingerprinting indoor localization system. The proposed system uses a small amount of labeled data and a large amount of unlabeled data (i.e., semi-supervised), thus considerably reducing the expensive data labeling effort. Experimental results show that, as compared to the state-of-the-art supervised scheme, the proposed semi-supervised system achieves comparable performance with equal, sufficient amount of labeled data, and significantly superior performance with equal, highly limited amount of labeled data. Besides, the proposed semi-supervised system retains its performance over a broad range of the amount of labeled data. The interactions between the generator, discriminator, and classifier models of the proposed GAN-based system are visually examined and discussed. A mathematical description of the proposed system is also presented.", "pdf_url": "https://arxiv.org/pdf/2008.07111", "subject": "Signal Processing (eess.SP)"},
{"title": "AnciNet: An Efficient Deep Learning Approach for Feedback Compression of Estimated CSI in Massive MIMO Systems", "author": "Yuyao Sun, Wei Xu, Lisheng Fan, Geoffrey Ye Li, George K. Karagiannidis", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Accurate channel state information (CSI) feedback plays a vital role in improving the performance gain of massive multiple-input multiple-output (m-MIMO) systems, where the dilemma is excessive CSI overhead versus limited feedback bandwith. By considering the noisy CSI due to imperfect channel estimation, we propose a novel deep neural network architecture, namely AnciNet, to conduct the CSI feedback with limited bandwidth. AnciNet extracts noise-free features from the noisy CSI samples to achieve effective CSI compression for the feedback. Experimental results verify that the proposed AnciNet approach outperforms the existing techniques under various conditions.", "pdf_url": "https://arxiv.org/pdf/2008.07112", "subject": "Signal Processing (eess.SP)"},
{"title": "An accurate hyper-singular boundary integral equation method for dynamic poroelasticity in two dimensions", "author": "Lu Zhang, Liwei Xu, Tao Yin", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This paper is concerned with the boundary integral equation method for solving the exterior Neumann boundary value problem of dynamic poroelasticity in two dimensions. The main contribution of this work consists of two aspescts: the proposal of a novel regularized boundary integral equation, and the presentation of new regularized formulations of the strongly-singular and hyper-singular boundary integral operators. Firstly, turning to the spectral properties of the double-layer operator and the corresponding Calder\u00f3n relation of the poroelasticity, we propose the novel low-GMRES-iteration integral equation whose eigenvalues are bounded away from zero and infinity. Secondly, with the help of the G\u00fcnter derivatives, we reformulate the strongly-singular and hyper-singular integral operators into combinations of the weakly-singular operators and the tangential derivatives. The accuracy and efficiency of the proposed methodology are demonstrated through several numerical examples.", "pdf_url": "https://arxiv.org/pdf/2008.07115", "subject": "Computational Physics (physics.comp-ph)"},
{"title": "PIANOTREE VAE: Structured Representation Learning for Polyphonic Music", "author": "Ziyu Wang, Yiyi Zhang, Yixiao Zhang, Junyan Jiang, Ruihan Yang, Junbo Zhao, Gus Xia", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The dominant approach for music representation learning involves the deep unsupervised model family variational autoencoder (VAE). However, most, if not all, viable attempts on this problem have largely been limited to monophonic music. Normally composed of richer modality and more complex musical structures, the polyphonic counterpart has yet to be addressed in the context of music representation learning. In this work, we propose the PianoTree VAE, a novel tree-structure extension upon VAE aiming to fit the polyphonic music learning. The experiments prove the validity of the PianoTree VAE via (i)-semantically meaningful latent code for polyphonic segments; (ii)-more satisfiable reconstruction aside of decent geometry learned in the latent space; (iii)-this model's benefits to the variety of the downstream music generation.", "pdf_url": "https://arxiv.org/pdf/2008.07118", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Distributed Adaptive Formation Control for Multi-UAV to Enable Connectivity", "author": "Rahim Rahmani, Ramin Firouzi, Theo Kanter", "pub_date": "Submitted on 17 Aug 2020", "abstract": "There is increasing demand for control of multi-robot and as well distributing large amounts of content to cluster of Unmanned Aerial Vehicles (UAV) on the operation. In recent years several large-scale accidents have happened. To facilitate rescue operations and gather information, the technology that can access and map inaccessible areas is needed. This paper presents a disruptive approach to address the issues with communication, data collection and data sharing for UAV units in inaccessible or dead zones and We demonstrated feasibility of the approach and evaluate its advantages over the Ad Hoc architecture involving autonomous gateways", "pdf_url": "https://arxiv.org/pdf/2008.07143", "subject": "Signal Processing (eess.SP)"},
{"title": "Binary scalar products", "author": "Andrey Kupavskii, Stefan Weltge", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Let $A,B \\subseteq \\mathbb{R}^d $ both span $\\mathbb{R}^d$ such that $\\langle a, b \\rangle \\in \\{0,1\\}$ holds for all $a \\in A$, $b \\in B$. We show that $ |A| \\cdot |B| \\le (d+1) 2^d $. This allows us to settle a conjecture by Bohn, Faenza, Fiorini, Fisikopoulos, Macchia, and Pashkovich (2015) concerning 2-level polytopes. Such polytopes have the property that for every facet-defining hyperplane $H$ there is a parallel hyperplane $H'$ such that $H \\cup H'$ contain all vertices. The authors conjectured that for every $d$-dimensional 2-level polytope $P$ the product of the number of vertices of $P$ and the number of facets of $P$ is at most $d 2^{d+1}$, which we show to be true.", "pdf_url": "https://arxiv.org/pdf/2008.07153", "subject": "Combinatorics (math.CO)"},
{"title": "Graph colorings under global structural conditions", "author": "Xuqing Bai, Xueliang Li", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v4)", "abstract": "More than ten years ago in 2008, a new kind of graph coloring appeared in graph theory, which is the {\\it rainbow connection coloring} of graphs, and then followed by some other new concepts of graph colorings, such as {\\it proper connection coloring, monochromatic connection coloring, and conflict-free connection coloring} of graphs. In about ten years of our consistent study, we found that these new concepts of graph colorings are actually quite different from the classic graph colorings. These {\\it colored connection colorings} of graphs are brand-new colorings and they need to take care of global structural properties (for example, connectivity) of a graph under the colorings; while the traditional colorings of graphs are colorings under which only local structural properties (adjacent vertices or edges) of a graph are taken care of. Both classic colorings and the new colored connection colorings can produce the so-called chromatic numbers. We call the colored connection numbers the {\\it global chromatic numbers}, and the classic or traditional chromatic numbers the {\\it local chromatic numbers}. This paper intends to clarify the difference between the colored connection colorings and the traditional colorings, and finally to propose the new concepts of global colorings under which global structural properties of the colored graph are kept, and the global chromatic numbers.", "pdf_url": "https://arxiv.org/pdf/2008.07163", "subject": "Combinatorics (math.CO)"},
{"title": "Deep Variational Generative Models for Audio-visual Speech Separation", "author": "Viet-Nhat Nguyen, Mostafa Sadeghi, Elisa Ricci, Xavier Alameda-Pineda", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper, we are interested in audio-visual speech separation given a single-channel audio recording as well as visual information (lips movements) associated with each speaker. We propose an unsupervised technique based on audio-visual generative modeling of clean speech. More specifically, during training, a latent variable generative model is learned from clean speech spectrograms using a variational auto-encoder (VAE). To better utilize the visual information, the posteriors of the latent variables are inferred from mixed speech (instead of clean speech) as well as the visual data. The visual modality also serves as a prior for latent variables, through a visual network. At test time, the learned generative model (both for speaker-independent and speaker-dependent scenarios) is combined with an unsupervised non-negative matrix factorization (NMF) variance model for background noise. All the latent variables and noise parameters are then estimated by a Monte Carlo expectation-maximization algorithm. Our experiments show that the proposed unsupervised VAE-based method yields better separation performance than NMF-based approaches as well as a supervised deep learning-based technique.", "pdf_url": "https://arxiv.org/pdf/2008.07191", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Robustness Verification of Quantum Machine Learning", "author": "Ji Guan, Wang Fang, Mingsheng Ying", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Several important models of machine learning algorithms have been successfully generalized to the quantum world, with potential applications to data analytics in quantum physics that can be implemented on the near future quantum computers. However, noise and decoherence are two major obstacles to the practical implementation of quantum machine learning. In this work, we introduce a general framework for the robustness analysis of quantum machine learning algorithms against noise and decoherence. We argue that fidelity is the only pick of measuring the robustness. A robust bound is derived and an algorithm is developed to check whether or not a quantum machine learning algorithm is robust with respect to the training data. In particular, this algorithm can help to defense attacks and improve the accuracy as it can identify useful new training data during checking. The effectiveness of our robust bound and algorithm is confirmed by the case study of quantum phase recognition. Furthermore, this experiment demonstrates a trade-off between the accuracy of quantum machine learning algorithms and their robustness.", "pdf_url": "https://arxiv.org/pdf/2008.07230", "subject": "Quantum Physics (quant-ph)"},
{"title": "StoRIR: Stochastic Room Impulse Response Generation for Audio Data Augmentation", "author": "Piotr Masztalski, Mateusz Matuszewski, Karol Piaskowski, Micha\u0142 Romaniuk", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this paper we introduce StoRIR - a stochastic room impulse response generation method dedicated to audio data augmentation in machine learning applications. This technique, in contrary to geometrical methods like image-source or ray tracing, does not require prior definition of room geometry, absorption coefficients or microphone and source placement and is dependent solely on the acoustic parameters of the room. The method is intuitive, easy to implement and allows to generate RIRs of very complicated enclosures. We show that StoRIR, when used for audio data augmentation in a speech enhancement task, allows deep learning models to achieve better results on a wide range of metrics than when using the conventional image-source method, effectively improving many of them by more than 5 %. We publish a Python implementation of StoRIR online", "pdf_url": "https://arxiv.org/pdf/2008.07231", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming Networks", "author": "Micha\u0142 Romaniuk, Piotr Masztalski, Karol Piaskowski, Mateusz Matuszewski", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We propose Mobile Audio Streaming Networks (MASnet) for efficient low-latency speech enhancement, which is particularly suitable for mobile devices and other applications where computational capacity is a limitation. MASnet processes linear-scale spectrograms, transforming successive noisy frames into complex-valued ratio masks which are then applied to the respective noisy frames. MASnet can operate in a low-latency incremental inference mode which matches the complexity of layer-by-layer batch mode. Compared to a similar fully-convolutional architecture, MASnet incorporates depthwise and pointwise convolutions for a large reduction in fused multiply-accumulate operations per second (FMA/s), at the cost of some reduction in SNR.", "pdf_url": "https://arxiv.org/pdf/2008.07244", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Deep Learning Based Open Set Acoustic Scene Classification", "author": "Zuzanna Kwiatkowska, Beniamin Kalinowski, Micha\u0142 Ko\u015bmider, Krzysztof Rykaczewski", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this work, we compare the performance of three selected techniques in open set acoustic scenes classification (ASC). We test thresholding of the softmax output of a deep network classifier, which is the most popular technique nowadays employed in ASC. Further we compare the results with the Openmax classifier which is derived from the computer vision field. As the third model, we use the Adapted Class-Conditioned Autoencoder (Adapted C2AE) which is our variation of another computer vision related technique called C2AE. Adapted C2AE encompasses a more fair comparison of the given experiments and simplifies the original inference procedure, making it more applicable in the real-life scenarios. We also analyse two training scenarios: without additional knowledge of unknown classes and another where a limited subset of examples from the unknown classes is available. We find that the C2AE based method outperforms the thresholding and Openmax, obtaining $85.5\\%$ Area Under the Receiver Operating Characteristic curve (AUROC) and $66\\%$ of open set accuracy on data used in Detection and Classification of Acoustic Scenes and Events Challenge 2019 Task 1C.", "pdf_url": "https://arxiv.org/pdf/2008.07247", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "MLBF-Net: A Multi-Lead-Branch Fusion Network for Multi-Class Arrhythmia Classification Using 12-Lead ECG", "author": "Jing Zhang, Deng Liang, Aiping Liu, Min Gao, Xiang Chen, Xu Zhang, Xun Chen", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Automatic arrhythmia detection using 12-lead electrocardiogram (ECG) signal plays a critical role in early prevention and diagnosis of cardiovascular diseases. In the previous studies on automatic arrhythmia detection, most methods concatenated 12 leads of ECG into a matrix, and then input the matrix to a variety of feature extractors or deep neural networks for extracting useful information. Under such frameworks, these methods had the ability to extract comprehensive features (known as integrity) of 12-lead ECG since the information of each lead interacts with each other during training. However, the diverse lead-specific features (known as diversity) among 12 leads were neglected, causing inadequate information learning for 12-lead ECG. To maximize the information learning of multi-lead ECG, the information fusion of comprehensive features with integrity and lead-specific features with diversity should be taken into account. In this paper, we propose a novel Multi-Lead-Branch Fusion Network (MLBF-Net) architecture for arrhythmia classification by integrating multi-loss optimization to jointly learning diversity and integrity of multi-lead ECG. MLBF-Net is composed of three components: 1) multiple lead-specific branches for learning the diversity of multi-lead ECG; 2) cross-lead features fusion by concatenating the output feature maps of all branches for learning the integrity of multi-lead ECG; 3) multi-loss co-optimization for all the individual branches and the concatenated network. We demonstrate our MLBF-Net on China Physiological Signal Challenge 2018 which is an open 12-lead ECG dataset. The experimental results show that MLBF-Net obtains an average $F_1$ score of 0.855, reaching the highest arrhythmia classification performance. The proposed method provides a promising solution for multi-lead ECG analysis from an information fusion perspective.", "pdf_url": "https://arxiv.org/pdf/2008.07263", "subject": "Signal Processing (eess.SP)"},
{"title": "On Mean Absolute Error for Deep Neural Network Based Vector-to-Vector Regression", "author": "Jun Qi, Jun Du, Sabato Marco Siniscalchi, Xiaoli Ma, Chin-Hui Lee", "pub_date": "Submitted on 12 Aug 2020", "abstract": "In this paper, we exploit the properties of mean absolute error (MAE) as a loss function for the deep neural network (DNN) based vector-to-vector regression. The goal of this work is two-fold: (i) presenting performance bounds of MAE, and (ii) demonstrating new properties of MAE that make it more appropriate than mean squared error (MSE) as a loss function for DNN based vector-to-vector regression. First, we show that a generalized upper-bound for DNN-based vector- to-vector regression can be ensured by leveraging the known Lipschitz continuity property of MAE. Next, we derive a new generalized upper bound in the presence of additive noise. Finally, in contrast to conventional MSE commonly adopted to approximate Gaussian errors for regression, we show that MAE can be interpreted as an error modeled by Laplacian distribution. Speech enhancement experiments are conducted to corroborate our proposed theorems and validate the performance advantages of MAE over MSE for DNN based regression.", "pdf_url": "https://arxiv.org/pdf/2008.07281", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "An Architectural Design for Measurement Uncertainty Evaluation in Cyber-Physical Systems", "author": "Wenzel Pilar von Pilchau, Varun Gowtham, Maximilian Gruber, Matthias Riedl, Nikolaos-Stefanos Koutrakis, Jawad Tayyub, J\u00f6rg H\u00e4hner, Sascha Eichst\u00e4dt, Eckart Uhlmann, Julian Polte, Volker Frey, Alexander Willner", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Several use cases from the areas of manufacturing and process industry, require highly accurate sensor data. As sensors always have some degree of uncertainty, methods are needed to increase their reliability. The common approach is to regularly calibrate the devices to enable traceability according to national standards and Syst\u00e8me international (SI) units - which follows costly processes. However, sensor networks can also be represented as Cyber Physical Systems (CPS) and a single sensor can have a digital representation (Digital Twin) to use its data further on. To propagate uncertainty in a reliable way in the network, we present a system architecture to communicate measurement uncertainties in sensor networks utilizing the concept of Asset Administration Shells alongside methods from the domain of Organic Computing. The presented approach contains methods for uncertainty propagation as well as concepts from the Machine Learning domain that combine the need for an accurate uncertainty estimation. The mathematical description of the metrological uncertainty of fused or propagated values can be seen as a first step towards the development of a harmonized approach for uncertainty in distributed CPSs in the context of Industrie 4.0. In this paper, we present basic use cases, conceptual ideas and an agenda of how to proceed further on.", "pdf_url": "https://arxiv.org/pdf/2008.07282", "subject": "Signal Processing (eess.SP)"},
{"title": "Estimating Causal Effects with the Neural Autoregressive Density Estimator", "author": "Sergio Garrido, Stanislav S. Borysov, Jeppe Rich, Francisco C. Pereira", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Estimation of causal effects is fundamental in situations were the underlying system will be subject to active interventions. Part of building a causal inference engine is defining how variables relate to each other, that is, defining the functional relationship between variables given conditional dependencies. In this paper, we deviate from the common assumption of linear relationships in causal models by making use of neural autoregressive density estimators and use them to estimate causal effects within the Pearl's do-calculus framework. Using synthetic data, we show that the approach can retrieve causal effects from non-linear systems without explicitly modeling the interactions between the variables.", "pdf_url": "https://arxiv.org/pdf/2008.07283", "subject": "Methodology (stat.ME)"},
{"title": "Computational timeline reconstruction of the stories surrounding Trump: Story turbulence, narrative control, and collective chronopathy", "author": "P. S. Dodds, J. R. Minot, M. V. Arnold, T. Alshaabi, J. L. Adams, A. J. Reagan, C. M. Danforth", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Measuring the specific kind, temporal ordering, diversity, and turnover rate of stories surrounding any given subject is essential to developing a complete reckoning of that subject's historical impact. Here, we use Twitter as a distributed news and opinion aggregation source to identify and track the dynamics of the dominant day-scale stories around Donald Trump, the 45th President of the United States. Working with a data set comprising around 20 billion 1-grams, we first compare each day's 1-gram and 2-gram usage frequencies to those of a year before, to create day- and week-scale timelines for Trump stories for 2016 onwards. We measure Trump's narrative control, the extent to which stories have been about Trump or put forward by Trump. We then quantify story turbulence and collective chronopathy -- the rate at which a population's stories for a subject seem to change over time. We show that 2017 was the most turbulent year for Trump, and that story generation slowed dramatically during the COVID-19 pandemic in 2020. Trump story turnover for 2 months during the COVID-19 pandemic was on par with that of 3 days in September 2017. Our methods may be applied to any well-discussed phenomenon, and have potential, in particular, to enable the computational aspects of journalism, history, and biography.", "pdf_url": "https://arxiv.org/pdf/2008.07301", "subject": "Physics and Society (physics.soc-ph)"},
{"title": "Robust Autoencoder GAN for Cryo-EM Image Denoising", "author": "Hanlin Gu, Ilona Christy Unarta, Xuhui Huang, Yuan Yao", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The cryo-electron microscopy (Cryo-EM) becomes popular for macromolecular structure determination. However, the 2D images which Cryo-EM detects are of high noise and often mixed with multiple heterogeneous conformations or contamination, imposing a challenge for denoising. Traditional image denoising methods can not remove Cryo-EM image noise well when the signal-noise-ratio (SNR) of images is meager. Thus it is desired to develop new effective denoising techniques to facilitate further research such as 3D reconstruction, 2D conformation classification, and so on. In this paper, we approach the robust image denoising problem in Cryo-EM by a joint Autoencoder and Generative Adversarial Networks (GAN) method. Equipped with robust $\\ell_1$ Autoencoder and some designs of robust $\\beta$-GANs, one can stabilize the training of GANs and achieve the state-of-the-art performance of robust denoising with low SNR data and against possible information contamination. The method is evaluated by both a heterogeneous conformational dataset on the Thermus aquaticus RNA Polymerase (RNAP) and a homogenous dataset on the Plasmodium falciparum 80S ribosome dataset (EMPIRE-10028), in terms of Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM), as well as heterogeneous conformation clustering. These results suggest that our proposed methodology provides an effective tool for Cryo-EM 2D image denoising.", "pdf_url": "https://arxiv.org/pdf/2008.07307", "subject": "Image and Video Processing (eess.IV)"},
{"title": "Bayesian deep learning: a new era for 'big data' geostatistics?", "author": "Charlie Kirkwood, Theo Economou", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "For geospatial modelling and mapping tasks, variants of kriging - the spatial interpolation technique developed by South African mining engineer Danie Krige - have long been regarded as the established geostatistical methods. However, kriging and its variants (such as regression kriging, in which auxiliary variables or derivatives of these are included as covariates) are relatively restrictive models and lack capabilities that have been afforded to us in the last decade by deep neural networks. Principal among these is feature learning - the ability to learn filters to recognise task-specific patterns in gridded data such as images. Here we demonstrate the power of feature learning in a geostatistical context, by showing how deep neural networks can automatically learn the complex relationships between point-sampled target variables and gridded auxiliary variables (such as those provided by remote sensing), and in doing so produce detailed maps of chosen target variables. At the same time, in order to cater for the needs of decision makers who require well-calibrated probabilities, we obtain uncertainty estimates via a Bayesian approximation known as Monte Carlo dropout. In our example, we produce a national-scale probabilistic geochemical map from point-sampled assay data, with auxiliary information provided by a terrain elevation grid. Unlike traditional geostatistical approaches, auxiliary variable grids are fed into our deep neural network raw. There is no need to provide terrain derivatives (e.g. slope angles, roughness, etc) because the deep neural network is capable of learning these and arbitrarily more complex derivatives as necessary to maximise predictive performance. We hope our results will raise awareness of the suitability of Bayesian deep learning - and its feature learning capabilities - for large-scale geostatistical applications where uncertainty matters.", "pdf_url": "https://arxiv.org/pdf/2008.07320", "subject": "Machine Learning (stat.ML)"},
{"title": "Optimal Posteriors for Chi-squared Divergence based PAC-Bayesian Bounds and Comparison with KL-divergence based Optimal Posteriors and Cross-Validation Procedure", "author": "Puja Sahu, Nandyala Hemachandra", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We investigate optimal posteriors for recently introduced \\cite{begin2016pac} chi-squared divergence based PAC-Bayesian bounds in terms of nature of their distribution, scalability of computations, and test set performance. For a finite classifier set, we deduce bounds for three distance functions: KL-divergence, linear and squared distances. Optimal posterior weights are proportional to deviations of empirical risks, usually with subset support. For uniform prior, it is sufficient to search among posteriors on classifier subsets ordered by these risks. We show the bound minimization for linear distance as a convex program and obtain a closed-form expression for its optimal posterior. Whereas that for squared distance is a quasi-convex program under a specific condition, and the one for KL-divergence is non-convex optimization (a difference of convex functions). To compute such optimal posteriors, we derive fast converging fixed point (FP) equations. We apply these approaches to a finite set of SVM regularization parameter values to yield stochastic SVMs with tight bounds. We perform a comprehensive performance comparison between our optimal posteriors and known KL-divergence based posteriors on a variety of UCI datasets with varying ranges and variances in risk values, etc. Chi-squared divergence based posteriors have weaker bounds and worse test errors, hinting at an underlying regularization by KL-divergence based posteriors. Our study highlights the impact of divergence function on the performance of PAC-Bayesian classifiers. We compare our stochastic classifiers with cross-validation based deterministic classifier. The latter has better test errors, but ours is more sample robust, has quantifiable generalization guarantees, and is computationally much faster.", "pdf_url": "https://arxiv.org/pdf/2008.07330", "subject": "Statistics Theory (math.ST)"},
{"title": "First U-Net Layers Contain More Domain Specific Information Than The Last Ones", "author": "Boris Shirokikh, Ivan Zakazov, Alexey Chernyavskiy, Irina Fedulova, Mikhail Belyaev", "pub_date": "Submitted on 17 Aug 2020", "abstract": "MRI scans appearance significantly depends on scanning protocols and, consequently, the data-collection institution. These variations between clinical sites result in dramatic drops of CNN segmentation quality on unseen domains. Many of the recently proposed MRI domain adaptation methods operate with the last CNN layers to suppress domain shift. At the same time, the core manifestation of MRI variability is a considerable diversity of image intensities. We hypothesize that these differences can be eliminated by modifying the first layers rather than the last ones. To validate this simple idea, we conducted a set of experiments with brain MRI scans from six domains. Our results demonstrate that 1) domain-shift may deteriorate the quality even for a simple brain extraction segmentation task (surface Dice Score drops from 0.85-0.89 even to 0.09); 2) fine-tuning of the first layers significantly outperforms fine-tuning of the last layers in almost all supervised domain adaptation setups. Moreover, fine-tuning of the first layers is a better strategy than fine-tuning of the whole network, if the amount of annotated data from the new domain is strictly limited.", "pdf_url": "https://arxiv.org/pdf/2008.07357", "subject": "Image and Video Processing (eess.IV)"},
{"title": "How little data do we need for patient-level prediction?", "author": "Luis H. John, Jan A. Kors, Jenna M. Reps, Patrick B. Ryan, Peter R. Rijnbeek", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Objective: Provide guidance on sample size considerations for developing predictive models by empirically establishing the adequate sample size, which balances the competing objectives of improving model performance and reducing model complexity as well as computational requirements. Materials and Methods: We empirically assess the effect of sample size on prediction performance and model complexity by generating learning curves for 81 prediction problems in three large observational health databases, requiring training of 17,248 prediction models. The adequate sample size was defined as the sample size for which the performance of a model equalled the maximum model performance minus a small threshold value. Results: The adequate sample size achieves a median reduction of the number of observations between 9.5% and 78.5% for threshold values between 0.001 and 0.02. The median reduction of the number of predictors in the models at the adequate sample size varied between 8.6% and 68.3%, respectively. Discussion: Based on our results a conservative, yet significant, reduction in sample size and model complexity can be estimated for future prediction work. Though, if a researcher is willing to generate a learning curve a much larger reduction of the model complexity may be possible as suggested by a large outcome-dependent variability. Conclusion: Our results suggest that in most cases only a fraction of the available data was sufficient to produce a model close to the performance of one developed on the full data set, but with a substantially reduced model complexity.", "pdf_url": "https://arxiv.org/pdf/2008.07361", "subject": "Applications (stat.AP)"},
{"title": "Informative Clusters for Multivariate Extremes", "author": "Hamid Jalalzai, R\u00e9mi Leluc", "pub_date": "Submitted on 13 Aug 2020", "abstract": "Capturing the dependence structure of multivariate extreme data is a major challenge in many fields involving the management of risks that come from multiple sources, e.g., portfolio monitoring, environmental risk management, insurance and anomaly detection. The present paper develops a novel optimization-based approach called MEXICO, standing for Multivariate EXtreme Informative Clustering by Optimization. It aims at exhibiting a sparsity pattern within the dependence structure of extremes. This is achieved by estimating some disjoint clusters of features that tend to be large simultaneously through an optimization method on the probability simplex. This dimension reduction technique can be applied to statistical learning tasks such as feature clustering and anomaly detection. Numerical experiments provide strong empirical evidence of the relevance of our approach.", "pdf_url": "https://arxiv.org/pdf/2008.07365", "subject": "Machine Learning (stat.ML)"},
{"title": "Harnessing The Multi-Stability Of Kresling Origami For Reconfigurable Articulation In Soft Robotic Arms", "author": "Joshua Kaufmann, Suyi Li", "pub_date": "Submitted on 17 Aug 2020", "abstract": "This study examines a biology-inspired approach of using reconfigurable articulation to reduce the control requirement for soft robotic arms. We construct a robotic arm by assembling Kresling origami modules that exhibit predictable bistability. Via switching between their two stable states, these origami modules can behave either like a flexible joint with low bending stiffness or like a stiff link with high stiffness, without requiring any continuous power supply. In this way, the robotic arm can exhibit pseudo-linkage kinematics with lower control requirements and improved motion accuracy. A unique advantage of using origami as the robotic arm skeleton is that its bending stiffness ratio between stable states is directly related to the underlying Kresling design. Therefore, we conduct extensive parametric analyses and experimental validations to identify the optimized Kresling pattern for articulation. The results indicate that a higher angle ratio, a smaller resting length at contracted stable state, and a large number of polygon sides can offer more significant and robust bending stiffness tuning. Based on this insight, we construct a proof-of-concept, tendon-driven robotic arm consisting of three modules, and show that it can exhibit the desired reconfigurable articulation behavior. Moreover, the deformations of this manipulator are consistent with kinematic model predictions, which validate the possibility of using simple controllers for such compliant robotic systems.", "pdf_url": "https://arxiv.org/pdf/2008.07421", "subject": "Applied Physics (physics.app-ph)"},
{"title": "Siloed Federated Learning for Multi-Centric Histopathology Datasets", "author": "Mathieu Andreux, Jean Ogier du Terrail, Constance Beguier, Eric W. Tramel", "pub_date": "Submitted on 17 Aug 2020", "abstract": "While federated learning is a promising approach for training deep learning models over distributed sensitive datasets, it presents new challenges for machine learning, especially when applied in the medical domain where multi-centric data heterogeneity is common. Building on previous domain adaptation works, this paper proposes a novel federated learning approach for deep learning architectures via the introduction of local-statistic batch normalization (BN) layers, resulting in collaboratively-trained, yet center-specific models. This strategy improves robustness to data heterogeneity while also reducing the potential for information leaks by not sharing the center-specific layer activation statistics. We benchmark the proposed method on the classification of tumorous histopathology image patches extracted from the Camelyon16 and Camelyon17 datasets. We show that our approach compares favorably to previous state-of-the-art methods, especially for transfer learning across datasets.", "pdf_url": "https://arxiv.org/pdf/2008.07424", "subject": "Image and Video Processing (eess.IV)"},
{"title": "A near-optimal stochastic gradient method for decentralized non-convex finite-sum optimization", "author": "Ran Xin, Usman A. Khan, Soummya Kar", "pub_date": "Submitted on 17 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "This paper describes a $near$-$optimal$ stochastic first-order gradient method for decentralized finite-sum minimization of smooth non-convex functions. Specifically, we propose GT-SARAH that employs a local SARAH-type variance reduction and global gradient tracking to address the stochastic and decentralized nature of the problem. Considering a total number of $N$ cost functions, equally divided over a directed network of $n$ nodes, we show that GT-SARAH finds an $\\epsilon$-accurate first-order stationary point in ${\\mathcal{O}(N^{1/2}\\epsilon^{-1})}$ gradient computations across all nodes, independent of the network topology, when ${n\\leq\\mathcal{O}(N^{1/2}(1-\\lambda)^{3})}$, where ${(1-\\lambda)}$ is the spectral gap of the network weight matrix. In this regime, GT-SARAH is thus, to the best our knowledge, the first decentralized method that achieves the algorithmic lower bound for this class of problems. Moreover, GT-SARAH achieves a $non$-$asymptotic$ $linear$ $speedup$, in that, the total number of gradient computations at each node is reduced by a factor of $1/n$ compared to the near-optimal algorithms for this problem class that process all data at a single node. We also establish the convergence rate of GT-SARAH in other regimes, in terms of the relative sizes of the number of nodes $n$, total number of functions $N$, and the network spectral gap $(1-\\lambda)$. Over infinite time horizon, we establish the almost sure and mean-squared convergence of GT-SARAH to a first-order stationary point.", "pdf_url": "https://arxiv.org/pdf/2008.07428", "subject": "Optimization and Control (math.OC)"},
{"title": "Adiabatic Quantum Optimization Fails to Solve the Knapsack Problem", "author": "Lauren Pusey-Nazzaro, Prasanna Date", "pub_date": "Submitted on 17 Aug 2020", "abstract": "In this work, we attempt to solve the integer-weight knapsack problem using the D-Wave 2000Q adiabatic quantum computer. The knapsack problem is a well-known NP-complete problem in computer science, with applications in economics, business, finance, etc. We attempt to solve a number of small knapsack problems whose optimal solutions are known; we find that adiabatic quantum optimization fails to produce solutions corresponding to optimal filling of the knapsack in all problem instances. We compare results obtained on the quantum hardware to the classical simulated annealing algorithm and two solvers employing a hybrid branch-and-bound algorithm. The simulated annealing algorithm also fails to produce the optimal filling of the knapsack, though solutions obtained by simulated and quantum annealing are no more similar to each other than to the correct solution. We discuss potential causes for this observed failure of adiabatic quantum optimization.", "pdf_url": "https://arxiv.org/pdf/2008.07456", "subject": "Quantum Physics (quant-ph)"},
{"title": "On the Suboptimality of Negative Momentum for Minimax Optimization", "author": "Guodong Zhang, Yuanhao Wang", "pub_date": "Submitted on 17 Aug 2020", "abstract": "Smooth game optimization has recently attracted great interest in machine learning as it generalizes the single-objective optimization paradigm. However, game dynamics is more complex due to the interaction between different players and is therefore fundamentally different from minimization, posing new challenges for algorithm design. Notably, it has been shown that negative momentum is preferred due to its ability of reducing oscillation in game dynamics. Nevertheless, existing analysis about negative momentum was restricted to simple bilinear games. In this paper, we extend the analysis of negative momentum to smooth and strongly-convex strongly-concave minimax games by taking the variational inequality formulation. By connecting momentum method with Chebyshev polynomials, we show that negative momentum accelerates convergence of game dynamics locally, though with a suboptimal rate. To the best of our knowledge, this is the \\emph{first work} that provides an explicit convergence rate for negative momentum in this setting.", "pdf_url": "https://arxiv.org/pdf/2008.07459", "subject": "Optimization and Control (math.OC)"},
{"title": "Bounds on the $\\mathrm{QAC}^0$ Complexity of Approximating Parity", "author": "Gregory Rosenthal", "pub_date": "Submitted on 17 Aug 2020", "abstract": "$\\mathrm{QAC}$ circuits are quantum circuits with one-qubit gates and Toffoli gates of arbitrary arity. $\\mathrm{QAC}^0$ circuits are $\\mathrm{QAC}$ circuits of constant depth, and are quantum analogues of $\\mathrm{AC}^0$ circuits. We prove the following: $\\bullet$ For all $d \\ge 7$ and $\\varepsilon>0$ there is a depth-$d$ $\\mathrm{QAC}$ circuit of size $\\exp(\\mathrm{poly}(n^{1/d}) \\log(n/\\varepsilon))$ that approximates the $n$-qubit parity function to within error $\\varepsilon$ on worst-case quantum inputs. Previously it was unknown whether $\\mathrm{QAC}$ circuits of sublogarithmic depth could approximate parity regardless of size. $\\bullet$ We introduce a class of \"mostly classical\" $\\mathrm{QAC}$ circuits, including a major component of our circuit from the above upper bound, and prove a tight lower bound on the size of low-depth, mostly classical $\\mathrm{QAC}$ circuits that approximate this component. $\\bullet$ Arbitrary depth-$d$ $\\mathrm{QAC}$ circuits require at least $\\Omega(n/d)$ multi-qubit gates to achieve a $1/2 + \\exp(-o(n/d))$ approximation of parity. When $d = \\Theta(\\log n)$ this nearly matches an easy $O(n)$ size upper bound for computing parity exactly. $\\bullet$ $\\mathrm{QAC}$ circuits with at most two layers of multi-qubit gates cannot achieve a $1/2 + \\exp(-o(n))$ approximation of parity, even non-cleanly. Previously it was known only that such circuits could not cleanly compute parity exactly for sufficiently large $n$. The proofs use a new normal form for quantum circuits which may be of independent interest, and are based on reductions to the problem of constructing certain generalizations of the cat state which we name \"nekomata\" after an analogous cat y\u014dkai.", "pdf_url": "https://arxiv.org/pdf/2008.07470", "subject": "Quantum Physics (quant-ph)"},
{"title": "Stochastic Optimization Forests", "author": "Nathan Kallus, Xiaojie Mao", "pub_date": "Submitted on 17 Aug 2020", "abstract": "We study conditional stochastic optimization problems, where we leverage rich auxiliary observations (e.g., customer characteristics) to improve decision-making with uncertain variables (e.g., demand). We show how to train forest decision policies for this problem by growing trees that choose splits to directly optimize the downstream decision quality, rather than splitting to improve prediction accuracy as in the standard random forest algorithm. We realize this seemingly computationally intractable problem by developing approximate splitting criteria that utilize optimization perturbation analysis to eschew burdensome re-optimization for every candidate split, so that our method scales to large-scale problems. Our method can accommodate both deterministic and stochastic constraints. We prove that our splitting criteria consistently approximate the true risk. We extensively validate its efficacy empirically, demonstrating the value of optimization-aware construction of forests and the success of our efficient approximations. We show that our approximate splitting criteria can reduce running time hundredfold, while achieving performance close to forest algorithms that exactly re-optimize for every candidate split.", "pdf_url": "https://arxiv.org/pdf/2008.07473", "subject": "Optimization and Control (math.OC)"},
{"title": "Do face masks introduce bias in speech technologies? The case of automated scoring of speaking proficiency", "author": "Anastassia Loukina, Keelan Evanini, Matthew Mulholland, Ian Blood, Klaus Zechner", "pub_date": "Submitted on 17 Aug 2020", "abstract": "The COVID-19 pandemic has led to a dramatic increase in the use of face masks worldwide. Face coverings can affect both acoustic properties of the signal as well as speech patterns and have unintended effects if the person wearing the mask attempts to use speech processing technologies. In this paper we explore the impact of wearing face masks on the automated assessment of English language proficiency. We use a dataset from a large-scale speaking test for which test-takers were required to wear face masks during the test administration, and we compare it to a matched control sample of test-takers who took the same test before the mask requirements were put in place. We find that the two samples differ across a range of acoustic measures and also show a small but significant difference in speech patterns. However, these differences do not lead to differences in human or automated scores of English language proficiency. Several measures of bias showed no differences in scores between the two groups.", "pdf_url": "https://arxiv.org/pdf/2008.07520", "subject": "Audio and Speech Processing (eess.AS)"},
{"title": "Manticore: A 4096-core RISC-V Chiplet Architecture for Ultra-efficient Floating-point Computing", "author": "Florian Zaruba, Fabian Schuiki, Luca Benini", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Data-parallel problems, commonly found in data analytics, machine learning, and scientific computing demand ever growing floating-point operations per second under tight area- and energy-efficiency constraints. Application-specific architectures and accelerators, while efficient at a given task, are hard to adjust to algorithmic changes. In this work, we present Manticore, a general-purpose, ultra-efficient, RISC-V, chiplet-based architecture for data-parallel floating-point workloads. We have manufactured a 9$\\text{mm}^2$ prototype of the chiplet's computational core in Globalfoundries 22nm FD-SOI process and demonstrate more than 2.5$\\times$ improvement in energy efficiency on floating-point intensive workloads compared to high performance compute engines (CPUs and GPUs), despite their more advanced FinFET process. The prototype contains two 64-bit, application-class RISC-V Ariane management cores that run a full-fledged Linux OS. The compute capability at high energy and area efficiency is provided by Snitch clusters. Each cluster contains eight small (20kGE) 32-bit integer RISC-V cores, each controlling a large double-precision floating-point unit (120kGE). Each core supports two custom RISC-V ISA extensions: FREP and SSR. The SSR extension elides explicit load and store instructions by encoding them as register reads and writes. The FREP extension mostly decouples the integer core from the FPU by allowing a sequence buffer to issue instructions to the FPU independently. Both extensions allow the tiny, single-issue, integer core to saturate the instruction bandwidth of the FPU and achieve FPU utilization above 90%, with more than 80% of core area dedicated to the FPU.", "pdf_url": "https://arxiv.org/pdf/2008.06502", "subject": "Hardware Architecture (cs.AR)"},
{"title": "Learning Gradient Fields for Shape Generation", "author": "Ruojin Cai, Guandao Yang, Hadar Averbuch-Elor, Zekun Hao, Serge Belongie, Noah Snavely, Bharath Hariharan", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "In this work, we propose a novel technique to generate shapes from point cloud data. A point cloud can be viewed as samples from a distribution of 3D points whose density is concentrated near the surface of the shape. Point cloud generation thus amounts to moving randomly sampled points to high-density areas. We generate point clouds by performing stochastic gradient ascent on an unnormalized probability density, thereby moving sampled points toward the high-likelihood regions. Our model directly predicts the gradient of the log density field and can be trained with a simple objective adapted from score-based generative models. We show that our method can reach state-of-the-art performance for point cloud auto-encoding and generation, while also allowing for extraction of a high-quality implicit surface. Code is available at .", "pdf_url": "https://arxiv.org/pdf/2008.06520", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Three Variants of Differential Privacy: Lossless Conversion and Applications", "author": "Shahab Asoodeh, Jiachun Liao, Flavio P. Calmon, Oliver Kosut, Lalitha Sankar", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We consider three different variants of differential privacy (DP), namely approximate DP, R\u00e9nyi DP (RDP), and hypothesis test DP. In the first part, we develop a machinery for optimally relating approximate DP to RDP based on the joint range of two $f$-divergences that underlie the approximate DP and RDP. In particular, this enables us to derive the optimal approximate DP parameters of a mechanism that satisfies a given level of RDP. As an application, we apply our result to the moments accountant framework for characterizing privacy guarantees of noisy stochastic gradient descent (SGD). When compared to the state-of-the-art, our bounds may lead to about 100 more stochastic gradient descent iterations for training deep learning models for the same privacy budget. In the second part, we establish a relationship between RDP and hypothesis test DP which allows us to translate the RDP constraint into a tradeoff between type I and type II error probabilities of a certain binary hypothesis test. We then demonstrate that for noisy SGD our result leads to tighter privacy guarantees compared to the recently proposed $f$-DP framework for some range of parameters.", "pdf_url": "https://arxiv.org/pdf/2008.06529", "subject": "Information Theory (cs.IT)"},
{"title": "Making Distributed Mobile Applications SAFE: Enforcing User Privacy Policies on Untrusted Applications with Secure Application Flow Enforcement", "author": "Adriana Szekeres, Irene Zhang, Katelin Bailey, Isaac Ackerman, Haichen Shen, Franziska Roesner, Dan R. K. Ports, Arvind Krishnamurthy, Henry M. Levy", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Today's mobile devices sense, collect, and store huge amounts of personal information, which users share with family and friends through a wide range of applications. Once users give applications access to their data, they must implicitly trust that the apps correctly maintain data privacy. As we know from both experience and all-too-frequent press articles, that trust is often misplaced. While users do not trust applications, they do trust their mobile devices and operating systems. Unfortunately, sharing applications are not limited to mobile clients but must also run on cloud services to share data between users. In this paper, we leverage the trust that users have in their mobile OSes to vet cloud services. To do so, we define a new Secure Application Flow Enforcement (SAFE) framework, which requires cloud services to attest to a system stack that will enforce policies provided by the mobile OS for user data. We implement a mobile OS that enforces SAFE policies on unmodified mobile apps and two systems for enforcing policies on untrusted cloud services. Using these prototypes, we demonstrate that it is possible to enforce existing user privacy policies on unmodified applications.", "pdf_url": "https://arxiv.org/pdf/2008.06536", "subject": "Cryptography and Security (cs.CR)"},
{"title": "The Relevance of Classic Fuzz Testing: Have We Solved This One?", "author": "Barton P. Miller, Mengxiao Zhang, Elisa R. Heymann", "pub_date": "Submitted on 14 Aug 2020", "abstract": "As fuzz testing has passed its 30th anniversary, and in the face of the incredible progress in fuzz testing techniques and tools, the question arises if the classic, basic fuzz technique is still useful and applicable? In that tradition, we have updated the basic fuzz tools and testing scripts and applied them to a large collection of Unix utilities on Linux, FreeBSD, and MacOS. As before, our failure criteria was whether the program crashed or hung. We found that 9 crash or hang out of 74 utilities on Linux, 15 out of 78 utilities on FreeBSD, and 12 out of 76 utilities on MacOS. A total of 24 different utilities failed across the three platforms. We note that these failure rates are somewhat higher than our in previous 1995, 2000, and 2006 studies of the reliability of command line utilities. In the basic fuzz tradition, we debugged each failed utility and categorized the causes the failures. Classic categories of failures, such as pointer and array errors and not checking return codes, were still broadly present in the current results. In addition, we found a couple of new categories of failures appearing. We present examples of these failures to illustrate the programming practices that allowed them to happen. As a side note, we tested the limited number of utilities available in a modern programming language (Rust) and found them to be of no better reliability than the standard ones.", "pdf_url": "https://arxiv.org/pdf/2008.06537", "subject": "Software Engineering (cs.SE)"},
{"title": "Efficient Low-Rank Matrix Learning by Factorizable Nonconvex Regularization", "author": "Yaqing Wang, Quanming Yao, James T. Kwok", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Matrix learning is at the core of many machine learning problems. To encourage a low-rank matrix solution, besides using the traditional convex nuclear norm regularizer, a popular recent trend is to use nonconvex regularizers that adaptively penalize singular values. They offer better recovery performance, but require computing the expensive singular value decomposition (SVD) in each iteration. To remove this bottleneck, we consider the \"nuclear norm minus Frobenius norm\" regularizer. Besides having nice theoretical properties on recovery and shrinkage as the other nonconvex regularizers, it can be reformulated into a factorized form that can be efficiently optimized by gradient-based algorithms while avoiding the SVD computations altogether. Extensive low-rank matrix completion experiments on a number of synthetic and real-world data sets show that the proposed method obtains state-of-the-art recovery performance and is much more efficient than existing low-rank convex / nonconvex regularization and matrix factorization algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.06542", "subject": "Machine Learning (cs.LG)"},
{"title": "AntiDote: Attention-based Dynamic Optimization for Neural Network Runtime Efficiency", "author": "Fuxun Yu, Chenchen Liu, Di Wang, Yanzhi Wang, Xiang Chen", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Convolutional Neural Networks (CNNs) achieved great cognitive performance at the expense of considerable computation load. To relieve the computation load, many optimization works are developed to reduce the model redundancy by identifying and removing insignificant model components, such as weight sparsity and filter pruning. However, these works only evaluate model components' static significance with internal parameter information, ignoring their dynamic interaction with external inputs. With per-input feature activation, the model component significance can dynamically change, and thus the static methods can only achieve sub-optimal results. Therefore, we propose a dynamic CNN optimization framework in this work. Based on the neural network attention mechanism, we propose a comprehensive dynamic optimization framework including (1) testing-phase channel and column feature map pruning, as well as (2) training-phase optimization by targeted dropout. Such a dynamic optimization framework has several benefits: (1) First, it can accurately identify and aggressively remove per-input feature redundancy with considering the model-input interaction; (2) Meanwhile, it can maximally remove the feature map redundancy in various dimensions thanks to the multi-dimension flexibility; (3) The training-testing co-optimization favors the dynamic pruning and helps maintain the model accuracy even with very high feature pruning ratio. Extensive experiments show that our method could bring 37.4% to 54.5% FLOPs reduction with negligible accuracy drop on various of test networks.", "pdf_url": "https://arxiv.org/pdf/2008.06543", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Targeted Interventions Reduce the Spread of COVID-19: Simulation Study on Real Mobility Data", "author": "Haotian Wang, Abhirup Ghosh, Jiaxin Ding, Rik Sarkar, Jie Gao", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Various intervention methods have been introduced worldwide to slow down the spread of the SARS-CoV-2 virus, by limiting human mobility in different ways. While large scale lockdown strategies are effective in reducing the spread rate, they come at a cost of significantly limited societal functions. We show that natural human mobility has high diversity and heterogeneity such that a small group of individuals and gathering venues play an important role in the spread of the disease. We discover that interventions that focus on protecting the most active individuals and most popular venues can significantly reduce the peak infection rate and the total number of infected people while retaining high levels of social activity overall. This trend is observed universally in multi-agent simulations using three mobility data sets of different scales, resolutions, and modalities (check-ins at seven different cities, WiFi connection events at a university, and GPS traces of electric bikes), and suggests that strategies that exploit the network effect in human mobility provide a better balance between disease control and normal social activities.", "pdf_url": "https://arxiv.org/pdf/2008.06549", "subject": "Social and Information Networks (cs.SI)"},
{"title": "Sketch-Guided Object Localization in Natural Images", "author": "Aditay Tripathi, Rajath R Dani, Anand Mishra, Anirban Chakraborty", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We introduce the novel problem of localizing all the instances of an object (seen or unseen during training) in a natural image via sketch query. We refer to this problem as sketch-guided object localization. This problem is distinctively different from the traditional sketch-based image retrieval task where the gallery set often contains images with only one object. The sketch-guided object localization proves to be more challenging when we consider the following: (i) the sketches used as queries are abstract representations with little information on the shape and salient attributes of the object, (ii) the sketches have significant variability as they are hand-drawn by a diverse set of untrained human subjects, and (iii) there exists a domain gap between sketch queries and target natural images as these are sampled from very different data distributions. To address the problem of sketch-guided object localization, we propose a novel cross-modal attention scheme that guides the region proposal network (RPN) to generate object proposals relevant to the sketch query. These object proposals are later scored against the query to obtain final localization. Our method is effective with as little as a single sketch query. Moreover, it also generalizes well to object categories not seen during training and is effective in localizing multiple object instances present in the image. Furthermore, we extend our framework to a multi-query setting using novel feature fusion and attention fusion strategies introduced in this paper. The localization performance is evaluated on publicly available object detection benchmarks, viz. MS-COCO and PASCAL-VOC, with sketch queries obtained from `Quick, Draw!'. The proposed method significantly outperforms related baselines on both single-query and multi-query localization tasks.", "pdf_url": "https://arxiv.org/pdf/2008.06551", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "On the Hardness of Massively Parallel Computation", "author": "Kai-Min Chung, Kuan-Yi Ho, Xiaorui Sun", "pub_date": "Submitted on 14 Aug 2020", "abstract": "We investigate whether there are inherent limits of parallelization in the (randomized) massively parallel computation (MPC) model by comparing it with the (sequential) RAM model. As our main result, we show the existence of hard functions that are essentially not parallelizable in the MPC model. Based on the widely-used random oracle methodology in cryptography with a cryptographic hash function $h:\\{0,1\\}^n \\rightarrow \\{0,1\\}^n$ computable in time $t_h$, we show that there exists a function that can be computed in time $O(T\\cdot t_h)$ and space $S$ by a RAM algorithm, but any MPC algorithm with local memory size $s < S/c$ for some $c>1$ requires at least $\\tilde{\\Omega}(T)$ rounds to compute the function, even in the average case, for a wide range of parameters $n \\leq S \\leq T \\leq 2^{n^{1/4}}$. Our result is almost optimal in the sense that by taking $T$ to be much larger than $t_h$, \\textit{e.g.}, $T$ to be sub-exponential in $t_h$, to compute the function, the round complexity of any MPC algorithm with small local memory size is asymptotically the same (up to a polylogarithmic factor) as the time complexity of the RAM algorithm. Our result is obtained by adapting the so-called compression argument from the data structure lower bounds and cryptography literature to the context of massively parallel computation.", "pdf_url": "https://arxiv.org/pdf/2008.06554", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "On the globalization of Riemannian Newton method", "author": "Marcio Antonio de Andrade Bortoloti, Teles Araujo Fernandes, Orizon Pereira Ferreira", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In the present paper, in order to fnd a singularity of a vector field defined on Riemannian manifolds, we present a new globalization strategy of Newton method and establish its global convergence with superlinear rate. In particular, this globalization generalizes for a general retraction the existing damped Newton's method. The presented global convergence analysis does not require any hypotesesis on singularity of the vector field. We applied the proposed method to solve the truncated singular value problem on the product of two Stiefel manifolds, the dextrous hand grasping problem on the cone of symmetric positive definite matrices and the Rayleigh quotient on the sphere. Moreover, some academic problems are solved. Numerical experiments are presented showing that the proposed algorithm has better robustness compared with the aforementioned method.", "pdf_url": "https://arxiv.org/pdf/2008.06557", "subject": "Numerical Analysis (math.NA)"},
{"title": "An Evaluation Framework of End-to-End 5G Millimeter Wave Communication for Connected Vehicle Applications", "author": "Zadid Khan, Sakib Mahmud Khan, Mashrur Chowdhury, Mizanur Rahman, Mhafuzul Islam", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The internet-of-things (IoT) environment connects different intelligent devices together and enables seamless data communication between the connected devices. Connected vehicles (CVs) are one of the primary example of the IoT, and the efficient, reliable, and safe operation of CVs demands a reliable wireless communication system, which can ensure high throughput and low communication latency. The 5G millimeter wave (5G mmWave) wireless communication network offers such benefits, which can be the enabler of CV applications, especially for dense urban areas with high number of CVs. In this study, we present a simulation-based evaluation framework of end-to-end 5G mmWave communication for CV applications. In addition, we compare the 5G mmWave with the Dedicated Short Range Communication (DSRC) technology for a CV application. The simulation framework is developed using two simulators, a network simulator and a traffic simulator. In order to develop the framework in this study, we have used Network Simulator 3 (ns-3) and SUMO, an open-source microscopic roadway traffic simulator. We have used end-to-end latency, packet loss and throughput as the performance evaluation metrics. We have found that for dense urban areas, 5G mmWave can achieve higher throughput, lower latency and lower data loss compared to DSRC. 5G mmWave can support CV applications with high throughput requirement on the downlink data flow. Through further investigation, we have found that the performance of 5G mmWave is significantly impacted by the penetration level of CVs, maximum CV speed, and CV application requirements.", "pdf_url": "https://arxiv.org/pdf/2008.06568", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Dimension Independence in Unconstrained Private ERM via Adaptive Preconditioning", "author": "Peter Kairouz, M\u00f3nica Ribero, Keith Rush, Abhradeep Thakurta", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In this paper we revisit the problem of private empirical risk minimziation (ERM) with differential privacy. We show that for unconstrained convex empirical risk minimization if the observed gradients of the objective function along the path of private gradient descent lie in a low-dimensional subspace (smaller than the ambient dimensionality of $p$), then using noisy adaptive preconditioning (a.k.a., noisy Adaptive Gradient Descent (AdaGrad)) we obtain a regret composed of two terms: a constant multiplicative factor of the original AdaGrad regret and an additional regret due to noise. In particular, we show that if the gradients lie in a constant rank subspace, then one can achieve an excess empirical risk of $ \\tilde{O}(1/\\epsilon n)$, compared to the worst-case achievable bound of $\\tilde{O}(\\sqrt{p}/\\epsilon n)$. While previous works show dimension independent excess empirical risk bounds for the restrictive setting of convex generalized linear problems optimized over unconstrained subspaces, our results operate with general convex functions in unconstrained minimization. Along the way, we do a perturbation analysis of noisy AdaGrad, which may be of independent interest.", "pdf_url": "https://arxiv.org/pdf/2008.06570", "subject": "Machine Learning (cs.LG)"},
{"title": "Toward an End-to-End Auto-tuning Framework in HPC PowerStack", "author": "Xingfu Wu, Aniruddha Marathe, Siddhartha Jana, Ondrej Vysocky, Jophin John, Andrea Bartolini, Lubomir Riha, Michael Gerndt, Valerie Taylor, Sridutt Bhalachandra", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Efficiently utilizing procured power and optimizing performance of scientific applications under power and energy constraints are challenging. The HPC PowerStack defines a software stack to manage power and energy of high-performance computing systems and standardizes the interfaces between different components of the stack. This survey paper presents the findings of a working group focused on the end-to-end tuning of the PowerStack. First, we provide a background on the PowerStack layer-specific tuning efforts in terms of their high-level objectives, the constraints and optimization goals, layer-specific telemetry, and control parameters, and we list the existing software solutions that address those challenges. Second, we propose the PowerStack end-to-end auto-tuning framework, identify the opportunities in co-tuning different layers in the PowerStack, and present specific use cases and solutions. Third, we discuss the research opportunities and challenges for collective auto-tuning of two or more management layers (or domains) in the PowerStack. This paper takes the first steps in identifying and aggregating the important R&D challenges in streamlining the optimization efforts across the layers of the PowerStack.", "pdf_url": "https://arxiv.org/pdf/2008.06571", "subject": "Performance (cs.PF)"},
{"title": "Single Board Computers (SBC): The Future of Next Generation Pedagogies in Pakistan", "author": "Saad Wazir, Hamza Ali Imran, Usama Latif, Usama Mujahid, Muhammad Bilal", "pub_date": "Submitted on 14 Aug 2020", "abstract": "ARM processors have taken over the mobile industry from a long time now. Future of data centers and the IT industry is estimated to make use of ARM Processors. Projects like Openstack on ARM are enabling use of ARM in data centers . Single board computers (SBCs) based on ARM processors have become the norm these days. Reason for their popularity lies in their cost effective and power efficient nature. There are hundreds of them available in the market having different sizes, compute power and prices. The reason for their popularity is largely due to the rise of new technology called IoT (Internet of Things) but there is another perspective where they can become handy. Low Price and Power Usage of single board computers makes them top candidate to be used for teaching many courses with hands-on experience in developing countries like Pakistan. Many boards support full Linux distributions and can be used as general-purpose computers while many of them are open hardware based. In this paper, we have reviewed the famous options available and tried to figure out which of them are better for teaching what kind of courses.", "pdf_url": "https://arxiv.org/pdf/2008.06576", "subject": "Computers and Society (cs.CY)"},
{"title": "Audio-Visual Event Localization via Recursive Fusion by Joint Co-Attention", "author": "Bin Duan, Hao Tang, Wei Wang, Ziliang Zong, Guowei Yang, Yan Yan", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The major challenge in audio-visual event localization task lies in how to fuse information from multiple modalities effectively. Recent works have shown that attention mechanism is beneficial to the fusion process. In this paper, we propose a novel joint attention mechanism with multimodal fusion methods for audio-visual event localization. Particularly, we present a concise yet valid architecture that effectively learns representations from multiple modalities in a joint manner. Initially, visual features are combined with auditory features and then turned into joint representations. Next, we make use of the joint representations to attend to visual features and auditory features, respectively. With the help of this joint co-attention, new visual and auditory features are produced, and thus both features can enjoy the mutually improved benefits from each other. It is worth noting that the joint co-attention unit is recursive meaning that it can be performed multiple times for obtaining better joint representations progressively. Extensive experiments on the public AVE dataset have shown that the proposed method achieves significantly better results than the state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2008.06581", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "COVID-Robot: Monitoring Social Distancing Constraints in Crowded Scenarios", "author": "Adarsh Jagan Sathyamoorthy, Utsav Patel, Yash Ajay Savle, Moumita Paul, Dinesh Manocha", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Maintaining social distancing norms between humans has become an indispensable precaution to slow down the transmission of COVID-19. We present a novel method to automatically detect pairs of humans in a crowded scenario who are not adhering to the social distance constraint, i.e. about 6 feet of space between them. Our approach makes no assumption about the crowd density or pedestrian walking directions. We use a mobile robot with commodity sensors, namely an RGB-D camera and a 2-D lidar to perform collision-free navigation in a crowd and estimate the distance between all detected individuals in the camera's field of view. In addition, we also equip the robot with a thermal camera that wirelessly transmits thermal images to a security/healthcare personnel who monitors if any individual exhibits a higher than normal temperature. In indoor scenarios, our mobile robot can also be combined with static mounted CCTV cameras to further improve the performance in terms of number of social distancing breaches detected, accurately pursuing walking pedestrians etc. We highlight the performance benefits of our approach in different static and dynamic indoor scenarios.", "pdf_url": "https://arxiv.org/pdf/2008.06585", "subject": "Robotics (cs.RO)"},
{"title": "An Object-Oriented Framework for Designing Reusable and Maintainable DEVS Models using Design Patterns", "author": "Maamar El, Amine Hamri", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Design patterns are well practices to share software development experiences. These patterns allow enhancing reusability, readability and maintainability of architecture and code of software applications. As simulation applies computerized models to produce traces in order to obtain results and conclusions, designers of simulation explored design patterns to make the simulation code more reusable, more readable and easy to maintain, in addition to design complex software oriented simulation modeling. In DEVS (Discrete Event System specification), the designers have successfully designed simulations, frameworks, tools, etc. However, some issues remain still open and should be explored like how a piece of code that implements a set of states, events and transitions may be reused to design a new DEVS model? How may a DEVS model be extended to a new formalism? Etc. In this paper, we address these issues and we propose a set of patterns that may serve as guidelines to designers of DEVS models and its extensions and may contribute to the design of an operational simulation framework. These patterns are inspired partly by the available designs of DEVS community and software engineering developers.", "pdf_url": "https://arxiv.org/pdf/2008.06587", "subject": "Software Engineering (cs.SE)"},
{"title": "Technical Report: Property-Directed Verified Monitoring of Signal Temporal Logic", "author": "Thomas Wright, Ian Stark", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Signal Temporal Logic monitoring over numerical simulation traces has emerged as an effective approach to approximate verification of continuous and hybrid systems. In this report we explore an exact verification procedure for STL properties based on monitoring verified traces in the form of Taylor model flowpipes as produced by the Flow* verified integrator. We explore how tight integration with Flow*'s symbolic flowpipe representation can lead to more precise and more efficient monitoring. We then show how the performance of monitoring can be increased substantially by introducing masks, a property-directed refinement of our method which restricts flowpipe monitoring to the time regions relevant to the overall truth of a complex proposition. Finally, we apply our implementation of these methods to verifying properties of a challenging continuous system, evaluating the impact of each aspect of our procedure on monitoring performance.", "pdf_url": "https://arxiv.org/pdf/2008.06589", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "New Techniques for Proving Fine-Grained Average-Case Hardness", "author": "Mina Dalirrooyfard, Andrea Lincoln, Virginia Vassilevska Williams", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The recent emergence of fine-grained cryptography strongly motivates developing an average-case analogue of Fine-Grained Complexity (FGC). This paper defines new versions of OV, $k$SUM and zero-$k$-clique that are both worst-case and average-case fine-grained hard assuming the core hypotheses of FGC. We then use these as a basis for fine-grained hardness and average-case hardness of other problems. The new problems represent their inputs in a certain ``factored'' form. We call them ``factored''-OV, ``factored''-zero-$k$-clique and ``factored''-$3$SUM. We show that factored-$k$-OV and factored $k$SUM are equivalent and are complete for a class of problems defined over Boolean functions. Factored zero-$k$-clique is also complete, for a different class of problems. Our hard factored problems are also simple enough that we can reduce them to many other problems, e.g.~to edit distance, $k$-LCS and versions of Max-Flow. We further consider counting variants of the factored problems and give WCtoACFG reductions for them for a natural distribution. Through FGC reductions we then get average-case hardness for well-studied problems like regular expression matching from standard worst-case FGC assumptions. To obtain our WCtoACFG reductions, we formalize the framework of [Boix-Adsera et al. 2019] that was used to give a WCtoACFG reduction for counting $k$-cliques. We define an explicit property of problems such that if a problem has that property one can use the framework on the problem to get a WCtoACFG self reduction. We then use the framework to slightly extend Boix-Adsera et al.'s average-case counting $k$-cliques result to average-case hardness for counting arbitrary subgraph patterns of constant size in $k$-partite graphs...", "pdf_url": "https://arxiv.org/pdf/2008.06591", "subject": "Computational Complexity (cs.CC)"},
{"title": "Decision-making at Unsignalized Intersection for Autonomous Vehicles: Left-turn Maneuver with Deep Reinforcement Learning", "author": "Teng Liu, Xingyu Mu, Bing Huang, Xiaolin Tang, Fuqing Zhao, Xiao Wang, Dongpu Cao", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Decision-making module enables autonomous vehicles to reach appropriate maneuvers in the complex urban environments, especially the intersection situations. This work proposes a deep reinforcement learning (DRL) based left-turn decision-making framework at unsignalized intersection for autonomous vehicles. The objective of the studied automated vehicle is to make an efficient and safe left-turn maneuver at a four-way unsignalized intersection. The exploited DRL methods include deep Q-learning (DQL) and double DQL. Simulation results indicate that the presented decision-making strategy could efficaciously reduce the collision rate and improve transport efficiency. This work also reveals that the constructed left-turn control structure has a great potential to be applied in real-time.", "pdf_url": "https://arxiv.org/pdf/2008.06595", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Weakly supervised cross-domain alignment with optimal transport", "author": "Siyang Yuan, Ke Bai, Liqun Chen, Yizhe Zhang, Chenyang Tao, Chunyuan Li, Guoyin Wang, Ricardo Henao, Lawrence Carin", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Cross-domain alignment between image objects and text sequences is key to many visual-language tasks, and it poses a fundamental challenge to both computer vision and natural language processing. This paper investigates a novel approach for the identification and optimization of fine-grained semantic similarities between image and text entities, under a weakly-supervised setup, improving performance over state-of-the-art solutions. Our method builds upon recent advances in optimal transport (OT) to resolve the cross-domain matching problem in a principled manner. Formulated as a drop-in regularizer, the proposed OT solution can be efficiently computed and used in combination with other existing approaches. We present empirical evidence to demonstrate the effectiveness of our approach, showing how it enables simpler model architectures to outperform or be comparable with more sophisticated designs on a range of vision-language tasks.", "pdf_url": "https://arxiv.org/pdf/2008.06597", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Wikidata on MARS", "author": "Peter F. Patel-Schneider, David Martin", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Multi-attributed relational structures (MARSs) have been proposed as a formal data model for generalized property graphs, along with multi-attributed rule-based predicate logic (MARPL) as a useful rule-based logic in which to write inference rules over property graphs. Wikidata can be modelled in an extended MARS that adds the (imprecise) datatypes of Wikidata. The rules of inference for the Wikidata ontology can be modelled as a MARPL ontology, with extensions to handle the Wikidata datatypes and functions over these datatypes. Because many Wikidata qualifiers should participate in most inference rules in Wikidata a method of implicitly handling qualifier values on a per-qualifier basis is needed to make this modelling useful. The meaning of Wikidata is then the extended MARS that is the closure of running these rules on the Wikidata data model. Wikidata constraints can be modelled as multi-attributed predicate logic (MAPL) formulae, again extended with datatypes, that are evaluated over this extended MARS. The result models Wikidata in a way that fixes several of its major problems.", "pdf_url": "https://arxiv.org/pdf/2008.06599", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Intelligent Service Selection in a Multi-dimensional Environment of Cloud Providers for IoT stream Data through cloudlets", "author": "Omid Halimi Milani, S. Ahmad Motamedi, Saeed Sharifian", "pub_date": "Submitted on 14 Aug 2020", "abstract": "The expansion of the Internet of Things(IoT) services and a huge amount of data generated by different sensors, signify the importance of cloud computing services like Storage as a Service more than ever. IoT traffic imposes such extra constraints on the cloud storage service as sensor data preprocessing capability and load-balancing between data centers and servers in each data center. Also, it should be allegiant to the Quality of Service (QoS). The hybrid MWG algorithm has been proposed in this work, which considers different objectives such as energy, processing time, transmission time, and load balancing in both Fog and Cloud Layer. The MATLAB script is used to simulate and implement our algorithms, and services of different servers, e.g. Amazon, Dropbox, Google Drive, etc. have been considered. The MWG has 7%, 13%, and 25% improvement in comparison with MOWCA, KGA, and NSGAII in metric of spacing, respectively. Moreover, the MWG has 4%, 4.7%, and 7.3% optimization in metric of quality in comparison to MOWCA, KGA, and NSGAII, respectively. The overall optimization shows that the MWG algorithm has 7.8%, 17%, and 21.6% better performance in comparison with MOWCA, KGA, and NSGAII in the obtained best result by considering different objectives, respectively.", "pdf_url": "https://arxiv.org/pdf/2008.06601", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"},
{"title": "Model-Free Optimal Control of Linear Multi-Agent Systems via Decomposition and Hierarchical Approximation", "author": "Gangshan Jing, He Bai, Jemin George, Aranya Chakrabortty", "pub_date": "Submitted on 14 Aug 2020", "abstract": "Designing the optimal linear quadratic regulator (LQR) for a large-scale multi-agent system (MAS) is time-consuming since it involves solving a large-size matrix Riccati equation. The situation is further exasperated when the design needs to be done in a model-free way using schemes such as reinforcement learning (RL). To reduce this computational complexity, we decompose the large-scale LQR design problem into multiple sets of smaller-size LQR design problems. We consider the objective function to be specified over an undirected graph, and cast the decomposition as a graph clustering problem. The graph is decomposed into two parts, one consisting of multiple decoupled subgroups of connected components, and the other containing edges that connect the different subgroups. Accordingly, the resulting controller has a hierarchical structure, consisting of two components. The first component optimizes the performance of each decoupled subgroup by solving the smaller-size LQR design problem in a model-free way using an RL algorithm. The second component accounts for the objective coupling different subgroups, which is achieved by solving a least squares problem in one shot. Although suboptimal, the hierarchical controller adheres to a particular structure as specified by the inter-agent coupling in the objective function and by the decomposition strategy. Mathematical formulations are established to find a decomposition that minimizes required communication links or reduces the optimality gap. Numerical simulations are provided to highlight the pros and cons of the proposed designs.", "pdf_url": "https://arxiv.org/pdf/2008.06604", "subject": "Systems and Control (eess.SY)"},
{"title": "Quantification of BERT Diagnosis Generalizability Across Medical Specialties Using Semantic Dataset Distance", "author": "Mihir P. Khambete, William Su, Juan Garcia, Joseph Lehar, Martin Kang, Marcus A. Badgeley", "pub_date": "Submitted on 14 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "Deep learning models in healthcare may fail to generalize on data from unseen corpora. Additionally, no quantitative metric exists to tell how existing models will perform on new data. Previous studies demonstrated that NLP models of medical notes generalize variably between institutions, but ignored other levels of healthcare organization. We measured SciBERT diagnosis sentiment classifier generalizability between medical specialties using EHR sentences from MIMIC-III. Models trained on one specialty performed better on internal test sets than mixed or external test sets (mean AUCs 0.92, 0.87, and 0.83, respectively; p = 0.016). When models are trained on more specialties, they have better test performances (p < 1e-4). Model performance on new corpora is directly correlated to the similarity between train and test sentence content (p < 1e-4). Future studies should assess additional axes of generalization to ensure deep learning models fulfil their intended purpose across institutions, specialties, and practices.", "pdf_url": "https://arxiv.org/pdf/2008.06606", "subject": "Computation and Language (cs.CL)"},
{"title": "Self-supervised Contrastive Video-Speech Representation Learning for Ultrasound", "author": "Jianbo Jiao, Yifan Cai, Mohammad Alsharid, Lior Drukker, Aris T.Papageorghiou, J. Alison Noble", "pub_date": "Submitted on 14 Aug 2020", "abstract": "In medical imaging, manual annotations can be expensive to acquire and sometimes infeasible to access, making conventional deep learning-based models difficult to scale. As a result, it would be beneficial if useful representations could be derived from raw data without the need for manual annotations. In this paper, we propose to address the problem of self-supervised representation learning with multi-modal ultrasound video-speech raw data. For this case, we assume that there is a high correlation between the ultrasound video and the corresponding narrative speech audio of the sonographer. In order to learn meaningful representations, the model needs to identify such correlation and at the same time understand the underlying anatomical features. We designed a framework to model the correspondence between video and audio without any kind of human annotations. Within this framework, we introduce cross-modal contrastive learning and an affinity-aware self-paced learning scheme to enhance correlation modelling. Experimental evaluations on multi-modal fetal ultrasound video and audio show that the proposed approach is able to learn strong representations and transfers well to downstream tasks of standard plane detection and eye-gaze prediction.", "pdf_url": "https://arxiv.org/pdf/2008.06607", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Are Smart Home Devices Abandoning IPV Victims?", "author": "Ahmed Alshehri, Malek Ben Salem, Lei Ding", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Smart home devices have brought us many benefits such as advanced security, convenience, and entertainment. However, these devices also have made unintended consequences like giving ultimate power for devices' owners over their intimate partners in the same household which might lead to tech-facilitated domestic abuse (tech-abuse) as recent research has shown. In this paper, we systematize findings on tech-abuse in smart homes. We show that domestic abuse and Intimate Partner Violence (IPV) in smart homes is more effective and less risky for abusers. Victims find it more harmful and more challenging to protect themselves from. We articulate a comprehensive analysis of all the phases of abuse in smart homes and categorize risks and needs in each phase. Technical analysis of current smart home technologies is conducted to shed light upon their limitations. We also summarize recent recommendations to combat tech-abuse in smart homes and focus on their potentials and shortcomings. Unsurprisingly, we find that many recommendations conflict with each other due to a lack of understanding of phases of abuse in smart homes. Desirable properties to design abuse-resistant smart home devices are proposed for all the phases of abuse. The research community benefits from our analysis and recommendations to move forward with a focus on filling the blind spots of existing smart home devices' safety measures and building appropriate safety measures that consider tech-abuse threats in smart homes.", "pdf_url": "https://arxiv.org/pdf/2008.06612", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Object Detection with a Unified Label Space from Multiple Datasets", "author": "Xiangyun Zhao, Samuel Schulter, Gaurav Sharma, Yi-Hsuan Tsai, Manmohan Chandraker, Ying Wu", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Given multiple datasets with different label spaces, the goal of this work is to train a single object detector predicting over the union of all the label spaces. The practical benefits of such an object detector are obvious and significant application-relevant categories can be picked and merged form arbitrary existing datasets. However, naive merging of datasets is not possible in this case, due to inconsistent object annotations. Consider an object category like faces that is annotated in one dataset, but is not annotated in another dataset, although the object itself appears in the latter images. Some categories, like face here, would thus be considered foreground in one dataset, but background in another. To address this challenge, we design a framework which works with such partial annotations, and we exploit a pseudo labeling approach that we adapt for our specific case. We propose loss functions that carefully integrate partial but correct annotations with complementary but noisy pseudo labels. Evaluation in the proposed novel setting requires full annotation on the test set. We collect the required annotations and define a new challenging experimental setup for this task based one existing public datasets. We show improved performances compared to competitive baselines and appropriate adaptations of existing work.", "pdf_url": "https://arxiv.org/pdf/2008.06614", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Maps, Mirrors, and Participants: Design Lenses for Sociomateriality in Engineering Organizations", "author": "Edward Burnell, Priya P. Pillai, Maria C. Yang", "pub_date": "Submitted on 15 Aug 2020", "abstract": "When you use a computer it also uses you, and in that relationship forms a new entity of melded agencies, a \"centaur\" inseparably human and nonhuman. Networks of interaction in an organization similarly form \"organizational centaurs\", melding humans, technologies, and organizations into an inseparable sociomateriality. By developing a convex optimization toolkit for conceptual engineering we sought to shape these centaurs. How do organizations go from a high-level concept (\"let's make an airplane\") to a \"design\", and in that process what blurred lines between humans and computers bring opportunities for research? We present three metaphors that have been useful lenses across our field sites: considering design models as maps shows how centaurs apportioned legitimacy; looking at design models as mirrors illuminates how they sought validation in their perspectives; and treating design models as participants recognizes their opinions and agency as equivalent to other entities in these centaurs.", "pdf_url": "https://arxiv.org/pdf/2008.06616", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Cautious Adaptation For Reinforcement Learning in Safety-Critical Settings", "author": "Jesse Zhang, Brian Cheung, Chelsea Finn, Sergey Levine, Dinesh Jayaraman", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Reinforcement learning (RL) in real-world safety-critical target settings like urban driving is hazardous, imperiling the RL agent, other agents, and the environment. To overcome this difficulty, we propose a \"safety-critical adaptation\" task setting: an agent first trains in non-safety-critical \"source\" environments such as in a simulator, before it adapts to the target environment where failures carry heavy costs. We propose a solution approach, CARL, that builds on the intuition that prior experience in diverse environments equips an agent to estimate risk, which in turn enables relative safety through risk-averse, cautious adaptation. CARL first employs model-based RL to train a probabilistic model to capture uncertainty about transition dynamics and catastrophic states across varied source environments. Then, when exploring a new safety-critical environment with unknown dynamics, the CARL agent plans to avoid actions that could lead to catastrophic states. In experiments on car driving, cartpole balancing, half-cheetah locomotion, and robotic object manipulation, CARL successfully acquires cautious exploration behaviors, yielding higher rewards with fewer failures than strong RL adaptation baselines. Website at .", "pdf_url": "https://arxiv.org/pdf/2008.06622", "subject": "Machine Learning (cs.LG)"},
{"title": "Safe Reinforcement Learning in Constrained Markov Decision Processes", "author": "Akifumi Wachi, Yanan Sui", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Safe reinforcement learning has been a promising approach for optimizing the policy of an agent that operates in safety-critical applications. In this paper, we propose an algorithm, SNO-MDP, that explores and optimizes Markov decision processes under unknown safety constraints. Specifically, we take a stepwise approach for optimizing safety and cumulative reward. In our method, the agent first learns safety constraints by expanding the safe region, and then optimizes the cumulative reward in the certified safe region. We provide theoretical guarantees on both the satisfaction of the safety constraint and the near-optimality of the cumulative reward under proper regularity assumptions. In our experiments, we demonstrate the effectiveness of SNO-MDP through two experiments: one uses a synthetic data in a new, openly-available environment named GP-SAFETY-GYM, and the other simulates Mars surface exploration by using real observation data.", "pdf_url": "https://arxiv.org/pdf/2008.06626", "subject": "Machine Learning (cs.LG)"},
{"title": "Practical Volume-Based Attacks on Encrypted Databases", "author": "Rishabh Poddar, Stephanie Wang, Jianan Lu, Raluca Ada Popa", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Recent years have seen an increased interest towards strong security primitives for encrypted databases (such as oblivious protocols), that hide the access patterns of query execution, and reveal only the volume of results. However, recent work has shown that even volume leakage can enable the reconstruction of entire columns in the database. Yet, existing attacks rely on a set of assumptions that are unrealistic in practice: for example, they (i) require a large number of queries to be issued by the user, or (ii) assume certain distributions on the queries or underlying data (e.g., that the queries are distributed uniformly at random, or that the database does not contain missing values). In this work, we present new attacks for recovering the content of individual user queries, assuming no leakage from the system except the number of results and avoiding the limiting assumptions above. Unlike prior attacks, our attacks require only a single query to be issued by the user for recovering the keyword. Furthermore, our attacks make no assumptions about the distribution of issued queries or the underlying data. Instead, our key insight is to exploit the behavior of real-world applications. We start by surveying 11 applications to identify two key characteristics that can be exploited by attackers: (i) file injection, and (ii) automatic query replay. We present attacks that leverage these two properties in concert with volume leakage, independent of the details of any encrypted database system. Subsequently, we perform an attack on the real Gmail web client by simulating a server-side adversary. Our attack on Gmail completes within a matter of minutes, demonstrating the feasibility of our techniques. We also present three ancillary attacks for situations when certain mitigation strategies are employed.", "pdf_url": "https://arxiv.org/pdf/2008.06627", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Neural Ray Surfaces for Self-Supervised Learning of Depth and Ego-motion", "author": "Igor Vasiljevic, Vitor Guizilini, Rares Ambrus, Sudeep Pillai, Wolfram Burgard, Greg Shakhnarovich, Adrien Gaidon", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Self-supervised learning has emerged as a powerful tool for depth and ego-motion estimation, leading to state-of-the-art results on benchmark datasets. However, one significant limitation shared by current methods is the assumption of a known parametric camera model -- usually the standard pinhole geometry -- leading to failure when applied to imaging systems that deviate significantly from this assumption (e.g., catadioptric cameras or underwater imaging). In this work, we show that self-supervision can be used to learn accurate depth and ego-motion estimation without prior knowledge of the camera model. Inspired by the geometric model of Grossberg and Nayar, we introduce Neural Ray Surfaces (NRS), convolutional networks that represent pixel-wise projection rays, approximating a wide range of cameras. NRS are fully differentiable and can be learned end-to-end from unlabeled raw videos. We demonstrate the use of NRS for self-supervised learning of visual odometry and depth estimation from raw videos obtained using a wide variety of camera systems, including pinhole, fisheye, and catadioptric.", "pdf_url": "https://arxiv.org/pdf/2008.06630", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Evolving Deep Convolutional Neural Networks for Hyperspectral Image Denoising", "author": "Yuqiao Liu, Yanan Sun, Bing Xue, Mengjie Zhang", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Hyperspectral images (HSIs) are susceptible to various noise factors leading to the loss of information, and the noise restricts the subsequent HSIs object detection and classification tasks. In recent years, learning-based methods have demonstrated their superior strengths in denoising the HSIs. Unfortunately, most of the methods are manually designed based on the extensive expertise that is not necessarily available to the users interested. In this paper, we propose a novel algorithm to automatically build an optimal Convolutional Neural Network (CNN) to effectively denoise HSIs. Particularly, the proposed algorithm focuses on the architectures and the initialization of the connection weights of the CNN. The experiments of the proposed algorithm have been well-designed and compared against the state-of-the-art peer competitors, and the experimental results demonstrate the competitive performance of the proposed algorithm in terms of the different evaluation metrics, visual assessments, and the computational complexity.", "pdf_url": "https://arxiv.org/pdf/2008.06634", "subject": "Neural and Evolutionary Computing (cs.NE)"},
{"title": "Orthogonalized SGD and Nested Architectures for Anytime Neural Networks", "author": "Chengcheng Wan, Henry Hoffmann, Shan Lu, Michael Maire", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We propose a novel variant of SGD customized for training network architectures that support anytime behavior: such networks produce a series of increasingly accurate outputs over time. Efficient architectural designs for these networks focus on re-using internal state; subnetworks must produce representations relevant for both immediate prediction as well as refinement by subsequent network stages. We consider traditional branched networks as well as a new class of recursively nested networks. Our new optimizer, Orthogonalized SGD, dynamically re-balances task-specific gradients when training a multitask network. In the context of anytime architectures, this optimizer projects gradients from later outputs onto a parameter subspace that does not interfere with those from earlier outputs. Experiments demonstrate that training with Orthogonalized SGD significantly improves generalization accuracy of anytime networks.", "pdf_url": "https://arxiv.org/pdf/2008.06635", "subject": "Machine Learning (cs.LG)"},
{"title": "Automatic Storage Structure Selection for hybrid Workload", "author": "Hongzhi Wang, Yan Wei, Hao Yan", "pub_date": "Submitted on 15 Aug 2020", "abstract": "In the use of database systems, the design of the storage engine and data model directly affects the performance of the database when performing queries. Therefore, the users of the database need to select the storage engine and design data model according to the workload encountered. However, in a hybrid workload, the query set of the database is dynamically changing, and the design of its optimal storage structure is also changing. Motivated by this, we propose an automatic storage structure selection system based on learning cost, which is used to dynamically select the optimal storage structure of the database under hybrid workloads. In the system, we introduce a machine learning method to build a cost model for the storage engine, and a column-oriented data layout generation algorithm. Experimental results show that the proposed system can choose the optimal combination of storage engine and data model according to the current workload, which greatly improves the performance of the default storage structure. And the system is designed to be compatible with different storage engines for easy use in practical applications.", "pdf_url": "https://arxiv.org/pdf/2008.06640", "subject": "Databases (cs.DB)"},
{"title": "Vehicle Speed Aware Computing Task Offloading and Resource Allocation Based on Multi-Agent Reinforcement Learning in a Vehicular Edge Computing Network", "author": "Xinyu Huang, Lijun He, Wanyue Zhang", "pub_date": "Submitted on 15 Aug 2020 ( ), last revised 19 Aug 2020 (this version, v2)", "abstract": "For in-vehicle application, the vehicles with different speeds have different delay requirements. However, vehicle speeds have not been extensively explored, which may cause mismatching between vehicle speed and its allocated computation and wireless resource. In this paper, we propose a vehicle speed aware task offloading and resource allocation strategy, to decrease the energy cost of executing tasks without exceeding the delay constraint. First, we establish the vehicle speed aware delay constraint model based on different speeds and task types. Then, the delay and energy cost of task execution in VEC server and local terminal are calculated. Next, we formulate a joint optimization of task offloading and resource allocation to minimize vehicles' energy cost subject to delay constraints. MADDPG method is employed to obtain offloading and resource allocation strategy. Simulation results show that our algorithm can achieve superior performance on energy cost and task completion delay.", "pdf_url": "https://arxiv.org/pdf/2008.06641", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Correspondence between neuroevolution and gradient descent", "author": "Stephen Whitelam, Viktor Selin, Sang-Won Park, Isaac Tamblyn", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We show analytically that training a neural network by stochastic mutation or \"neuroevolution\" of its weights is equivalent, in the limit of small mutations, to gradient descent on the loss function in the presence of Gaussian white noise. Averaged over independent realizations of the learning process, neuroevolution is equivalent to gradient descent on the loss function. We use numerical simulation to show that this correspondence can be observed for finite mutations. Our results provide a connection between two distinct types of neural-network training, and provide justification for the empirical success of neuroevolution.", "pdf_url": "https://arxiv.org/pdf/2008.06643", "subject": "Neural and Evolutionary Computing (cs.NE)"},
{"title": "A Two-Stage Optimal Bidding Algorithm for Incentive-based Aggregation of Electric Vehicles in Workplace Parking Lots", "author": "Zhongyang Zhao, Caisheng Wang", "pub_date": "Submitted on 15 Aug 2020", "abstract": "This paper proposes an incentive-based aggregator for electric vehicles (EVs) in workplace parking lots to participate in the energy and regulation markets. With the implementation of seasonal Autoregressive Integrated Moving Average (ARIMA) model to predict the market information, a Day-Ahead (DA) planning model coordinated with the EV's responses to the incentive is formulated to determine the days to activate the aggregation program and the optimal incentives that are broadcasted to the EV owners in the first stage. Given the determined incentives and EV's responses, an real-time (RT) optimal bidding algorithm complying with EVs' energy demand in the second stage is designed to maximize the aggregator's profits in the markets. The proposed models are tested using the data collected from PJM's energy and regulation markets. The results show the incentive-based aggregator can benefit both the EV owners and the aggregator from the credits obtained from the markets. Meanwhile, the results also indicate the proposed optimal bidding algorithm is capable of handling the uncertainty of regulation signals and following the signals with high precision.", "pdf_url": "https://arxiv.org/pdf/2008.06644", "subject": "Systems and Control (eess.SY)"},
{"title": "PPContactTracing: A Privacy-Preserving Contact Tracing Protocol for COVID-19 Pandemic", "author": "Priyanka Singh, Abhishek Singh, Gabriel Cojocaru, Praneeth Vepakomma, Ramesh Raskar", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Several contact tracing solutions have been proposed and implemented all around the globe to combat the spread of COVID-19 pandemic. But, most of these solutions endanger the privacy rights of the individuals and hinder their widespread adoption. We propose a privacy-preserving contact tracing protocol for the efficient tracing of the spread of the global pandemic. It is based on the private set intersection (PSI) protocol and utilizes the homomorphic properties to preserve the privacy at the individual level. A hierarchical model for the representation of landscapes and rate-limiting factor on the number of queries have been adopted to maintain the efficiency of the protocol.", "pdf_url": "https://arxiv.org/pdf/2008.06648", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Graph Edit Distance Reward: Learning to Edit Scene Graph", "author": "Lichang Chen, Guosheng Lin, Shijie Wang, Qingyao Wu", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Scene Graph, as a vital tool to bridge the gap between language domain and image domain, has been widely adopted in the cross-modality task like VQA. In this paper, we propose a new method to edit the scene graph according to the user instructions, which has never been explored. To be specific, in order to learn editing scene graphs as the semantics given by texts, we propose a Graph Edit Distance Reward, which is based on the Policy Gradient and Graph Matching algorithm, to optimize neural symbolic model. In the context of text-editing image retrieval, we validate the effectiveness of our method in CSS and CRIR dataset. Besides, CRIR is a new synthetic dataset generated by us, which we will publish it soon for future use.", "pdf_url": "https://arxiv.org/pdf/2008.06651", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Evaluating Lossy Compression Rates of Deep Generative Models", "author": "Sicong Huang, Alireza Makhzani, Yanshuai Cao, Roger Grosse", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The field of deep generative modeling has succeeded in producing astonishingly realistic-seeming images and audio, but quantitative evaluation remains a challenge. Log-likelihood is an appealing metric due to its grounding in statistics and information theory, but it can be challenging to estimate for implicit generative models, and scalar-valued metrics give an incomplete picture of a model's quality. In this work, we propose to use rate distortion (RD) curves to evaluate and compare deep generative models. While estimating RD curves is seemingly even more computationally demanding than log-likelihood estimation, we show that we can approximate the entire RD curve using nearly the same computations as were previously used to achieve a single log-likelihood estimate. We evaluate lossy compression rates of VAEs, GANs, and adversarial autoencoders (AAEs) on the MNIST and CIFAR10 datasets. Measuring the entire RD curve gives a more complete picture than scalar-valued metrics, and we arrive at a number of insights not obtainable from log-likelihoods alone.", "pdf_url": "https://arxiv.org/pdf/2008.06653", "subject": "Machine Learning (cs.LG)"},
{"title": "Object Detection in the Context of Mobile Augmented Reality", "author": "Xiang Li, Yuan Tian, Fuyao Zhang, Shuxue Quan, Yi Xu", "pub_date": "Submitted on 15 Aug 2020", "abstract": "In the past few years, numerous Deep Neural Network (DNN) models and frameworks have been developed to tackle the problem of real-time object detection from RGB images. Ordinary object detection approaches process information from the images only, and they are oblivious to the camera pose with regard to the environment and the scale of the environment. On the other hand, mobile Augmented Reality (AR) frameworks can continuously track a camera's pose within the scene and can estimate the correct scale of the environment by using Visual-Inertial Odometry (VIO). In this paper, we propose a novel approach that combines the geometric information from VIO with semantic information from object detectors to improve the performance of object detection on mobile devices. Our approach includes three components: (1) an image orientation correction method, (2) a scale-based filtering approach, and (3) an online semantic map. Each component takes advantage of the different characteristics of the VIO-based AR framework. We implemented the AR-enhanced features using ARCore and the SSD Mobilenet model on Android phones. To validate our approach, we manually labeled objects in image sequences taken from 12 room-scale AR sessions. The results show that our approach can improve on the accuracy of generic object detectors by 12% on our dataset.", "pdf_url": "https://arxiv.org/pdf/2008.06655", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Compositional Generalization via Neural-Symbolic Stack Machines", "author": "Xinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song, Denny Zhou", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Despite achieving tremendous success, existing deep learning models have exposed limitations in compositional generalization, the capability to learn compositional rules and apply them to unseen cases in a systematic manner. To tackle this issue, we propose the Neural-Symbolic Stack Machine (NeSS). It contains a neural network to generate traces, which are then executed by a symbolic stack machine enhanced with sequence manipulation operations. NeSS combines the expressive power of neural sequence models with the recursion supported by the symbolic stack machine. Without training supervision on execution traces, NeSS achieves 100% generalization performance in three domains: the SCAN benchmark of language-driven navigation tasks, the compositional machine translation benchmark, and context-free grammar parsing tasks.", "pdf_url": "https://arxiv.org/pdf/2008.06662", "subject": "Machine Learning (cs.LG)"},
{"title": "Accountable Off-Policy Evaluation With Kernel Bellman Statistics", "author": "Yihao Feng, Tongzheng Ren, Ziyang Tang, Qiang Liu", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We consider off-policy evaluation (OPE), which evaluates the performance of a new policy from observed data collected from previous experiments, without requiring the execution of the new policy. This finds important applications in areas with high execution cost or safety concerns, such as medical diagnosis, recommendation systems and robotics. In practice, due to the limited information from off-policy data, it is highly desirable to construct rigorous confidence intervals, not just point estimation, for the policy performance. In this work, we propose a new variational framework which reduces the problem of calculating tight confidence bounds in OPE into an optimization problem on a feasible set that catches the true state-action value function with high probability. The feasible set is constructed by leveraging statistical properties of a recently proposed kernel Bellman loss (Feng et al., 2019). We design an efficient computational approach for calculating our bounds, and extend it to perform post-hoc diagnosis and correction for existing estimators. Empirical results show that our method yields tight confidence intervals in different settings.", "pdf_url": "https://arxiv.org/pdf/2008.06668", "subject": "Machine Learning (cs.LG)"},
{"title": "ECG beats classification via online sparse dictionary and time pyramid matching", "author": "Nanyu Li, Yujuan Si, Duo Deng, Chunyu Yuan", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Recently, the Bag-Of-Word (BOW) algorithm provides efficient features and promotes the accuracy of the ECG classification system. However, BOW algorithm has two shortcomings: (1). it has large quantization errors and poor reconstruction performance; (2). it loses heart beat's time information, and may provide confusing features for different kinds of heart beats. Furthermore, ECG classification system can be used for long time monitoring and analysis of cardiovascular patients, while a huge amount of data will be produced, so we urgently need an efficient compression algorithm. In view of the above problems, we use the wavelet feature to construct the sparse dictionary, which lower the quantization error to a minimum. In order to reduce the complexity of our algorithm and adapt to large-scale heart beats operation, we combine the Online Dictionary Learning with Feature-sign algorithm to update the dictionary and coefficients. Coefficients matrix is used to represent ECG beats, which greatly reduces the memory consumption, and solve the problem of quantitative error simultaneously. Finally, we construct the pyramid to match coefficients of each ECG beat. Thus, we obtain the features that contain the beat time information by time stochastic pooling. It is efficient to solve the problem of losing time information. The experimental results show that: on the one hand, the proposed algorithm has advantages of high reconstruction performance for BOW, this storage method is high fidelity and low memory consumption; on the other hand, our algorithm yields highest accuracy in ECG beats classification; so this method is more suitable for large-scale heart beats data storage and classification.", "pdf_url": "https://arxiv.org/pdf/2008.06672", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "BroadFace: Looking at Tens of Thousands of People at Once for Face Recognition", "author": "Yonghyun Kim, Wonpyo Park, Jongju Shin", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The datasets of face recognition contain an enormous number of identities and instances. However, conventional methods have difficulty in reflecting the entire distribution of the datasets because a mini-batch of small size contains only a small portion of all identities. To overcome this difficulty, we propose a novel method called BroadFace, which is a learning process to consider a massive set of identities, comprehensively. In BroadFace, a linear classifier learns optimal decision boundaries among identities from a large number of embedding vectors accumulated over past iterations. By referring more instances at once, the optimality of the classifier is naturally increased on the entire datasets. Thus, the encoder is also globally optimized by referring the weight matrix of the classifier. Moreover, we propose a novel compensation method to increase the number of referenced instances in the training stage. BroadFace can be easily applied on many existing methods to accelerate a learning process and obtain a significant improvement in accuracy without extra computational burden at inference stage. We perform extensive ablation studies and experiments on various datasets to show the effectiveness of BroadFace, and also empirically prove the validity of our compensation method. BroadFace achieves the state-of-the-art results with significant improvements on nine datasets in 1:1 face verification and 1:N face identification tasks, and is also effective in image retrieval.", "pdf_url": "https://arxiv.org/pdf/2008.06674", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Evaluation of Three Nonlinear Control Methods to Reject the Constant Bounded Disturbance for Robotic Manipulators", "author": "Amir.A. Ghavifekr, Saeed Pezeshki, Arash Arjmandi", "pub_date": "Submitted on 15 Aug 2020", "abstract": "In this paper, we consider the tracking control problem for robot manipulators which are affected by constant bounded disturbances. Three control schemes are applied for the problem, which composed of integral action and tracking controllers. The goal is improving the accuracy of tracking procedure for a robot manipulator to track a specified reference signal in the presence of constant bounded disturbances. Inverse dynamics controller, improved Lyapunov-based controller with integral action and discontinuous Lyapunov-based controller are three schemes that are evaluated in this paper. Third one is a novel controller that achieves trajectory following without requiring exact knowledge of the nonlinear dynamics. Based on the disturbance rejection scheme, tracking controllers are constructed which are asymptotically stabilizing in the sense of Lyapunov. Furthermore the closed loop system has strong disturbance rejection property. It is shown that how under proper assumptions, the proposed schemes succeed in achieving disturbance rejection at the input of a nonlinear system. Computer simulation results given for a two degree of freedom manipulator with a large payload and fast maneuver, demonstrate that accurate trajectory tracking can be achieved by using the proposed controllers.", "pdf_url": "https://arxiv.org/pdf/2008.06676", "subject": "Systems and Control (eess.SY)"},
{"title": "Preferential Bayesian optimisation with Skew Gaussian Processes", "author": "Alessio Benavoli, Dario Azzimonti, Dario Piga", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Bayesian optimisation (BO) is a very effective approach for sequential black-box optimization where direct queries of the objective function are expensive. However, there are cases where the objective function can only be accessed via preference judgments, such as \"this is better than that\" between two candidate solutions (like in A/B tests or recommender systems). The state-of-the-art approach to Preferential Bayesian Optimization (PBO) uses a Gaussian process to model the preference function and a Bernoulli likelihood to model the observed pairwise comparisons. Laplace's method is then employed to compute posterior inferences and, in particular, to build an appropriate acquisition function. In this paper, we prove that the true posterior distribution of the preference function is a Skew Gaussian Process (SkewGP), with highly skewed pairwise marginals and, thus, show that Laplace's method usually provides a very poor approximation. We then derive an efficient method to compute the exact SkewGP posterior and use it as surrogate model for PBO employing standard acquisition functions (Upper Credible Bound, etc.). We illustrate the benefits of our exact PBO-SkewGP in a variety of experiments, by showing that it consistently outperforms PBO based on Laplace's approximation both in terms of convergence speed and computational time. We also show that our framework can be extended to deal with mixed preferential-categorical BO, typical for instance in smart manufacturing, where binary judgments (valid or non-valid) together with preference judgments are available.", "pdf_url": "https://arxiv.org/pdf/2008.06677", "subject": "Machine Learning (cs.LG)"},
{"title": "MobileVisFixer: Tailoring Web Visualizations for Mobile Phones Leveraging an Explainable Reinforcement Learning Framework", "author": "Aoyu Wu, Wai Tong, Tim Dwyer, Bongshin Lee, Petra Isenberg, Huamin Qu", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view Cartesian visualizations with linear or discrete scales by a Markov Decision Process model that is both generalizable across various visualizations and fully explainable. MobileVisFixer deconstructs charts into declarative formats, and uses a greedy heuristic based on Policy Gradient methods to find solutions to this difficult, multi-criteria optimization problem in reasonable time. In addition, MobileVisFixer can be easily extended with the incorporation of optimization algorithms for data visualizations. Quantitative evaluation on two real-world datasets demonstrates the effectiveness and generalizability of our method.", "pdf_url": "https://arxiv.org/pdf/2008.06678", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Stability analysis of the linear discrete teleoperation systems with stochastic sampling and data dropout", "author": "Amir A Ghavifekr, Amir R Ghiasi, Mohammad A Badamchizadeh, Farzad Hashemzadeh, Paolo Fiorini", "pub_date": "Submitted on 15 Aug 2020", "abstract": "This paper addresses the stability conditions of the sampled-data teleoperation systems consisting continuous time master, slave, operator, and environment with discrete time controllers over general communication networks. The output signals of the slave and master robots are quantized with stochastic sampling periods which are modeled as being from a finite set. By applying an input delay method, the probabilistic sampling system is converted into a continuous-time system including stochastic parameters in the system matrices. The main contribution of this paper is the derivation of the less conservative stability conditions for linear discrete teleoperation systems taking into account the challenges such as the stochastic sampling rate, constant time delay and the possibility of data packet dropout. The numbers of dropouts are driven by a finite state Markov chain. First, the problem of finding a lower bound on the maximum sampling period that preserves the stability is formulated. This problem is constructed as a convex optimization program in terms of linear matrix inequalities (LMI). Next, Lyapunov Krasovskii based approaches are applied to propose sufficient conditions for stochastic and exponential stability of closed-loop sampled-data bilateral teleoperation system. The proposed criterion notifies the effect of sampling time on the stability transparency trade-off and imposes bounds on the sampling time, control gains and the damping of robots. Neglecting this study undermines both the stability and transparency of teleoperation systems. Numerical simulation results are used to verify the proposed stability criteria and illustrate the effectiveness of the sampling architecture.", "pdf_url": "https://arxiv.org/pdf/2008.06683", "subject": "Systems and Control (eess.SY)"},
{"title": "Discrete-time control of bilateral teleoperation systems: a review", "author": "Amir Aminzadeh Ghavifekr, Amir Rikhtehgar Ghiasi, Mohammad Ali Badamchizadeh", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The possibility of operating in remote environments using teleoperation systems has been considered widely in the control literature. This paper presents a review on the discrete-time teleoperation systems, including issues such as stability, passivity and time delays. Using discrete-time methods for a master-slave teleoperation system can simplify control implementation. Varieties of control schemes have been proposed for these systems and major concerns such as passivity, stability and transparency have been studied. Recently, unreliable communication networks affected by packet loss and variable transmission delays have been received much attention. Thus, it is worth considering discrete-time theories for bilateral teleoperation architectures, which are formulated on the same lines as the continuous-time systems. Despite the extensive amount of researches concerning continuous-time teleoperation systems, only a few papers have been published on the analysis and controller design for discrete bilateral forms. This paper takes into account the challenges for the discrete structure of bilateral teleoperation systems and notifies the recent contributions in this area. The effect of sampling time on the stability-transparency trade-off and the task performance is taken into consideration in this review. These studies can help to design guidelines to have better transparency and stable teleoperation systems.", "pdf_url": "https://arxiv.org/pdf/2008.06685", "subject": "Systems and Control (eess.SY)"},
{"title": "Crossing The Gap: A Deep Dive into Zero-Shot Sim-to-Real Transfer for Dynamics", "author": "Eugene Valassakis, Zihan Ding, Edward Johns", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Zero-shot sim-to-real transfer of tasks with complex dynamics is a highly challenging and unsolved problem. A number of solutions have been proposed in recent years, but we have found that many works do not present a thorough evaluation in the real world, or underplay the significant engineering effort and task-specific fine tuning that is required to achieve the published results. In this paper, we dive deeper into the sim-to-real transfer challenge, investigate why this is such a difficult problem, and present objective evaluations of a number of transfer methods across a range of real-world tasks. Surprisingly, we found that a method which simply injects random forces into the simulation performs just as well as more complex methods, such as those which randomise the simulator's dynamics parameters, or adapt a policy online using recurrent network architectures.", "pdf_url": "https://arxiv.org/pdf/2008.06686", "subject": "Robotics (cs.RO)"},
{"title": "Natural Wake-Sleep Algorithm", "author": "Csongor V\u00e1rady, Riccardo Volpi, Luigi Malag\u00f2, Nihat Ay", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The benefits of using the natural gradient are well known in a wide range of optimization problems. However, for the training of common neural networks the resulting increase in computational complexity sets a limitation to its practical application. Helmholtz Machines are a particular type of generative model composed of two Sigmoid Belief Networks (SBNs), acting as an encoder and a decoder, commonly trained using the Wake-Sleep (WS) algorithm and its reweighted version RWS. For SBNs, it has been shown how the locality of the connections in the graphical structure induces sparsity in the Fisher information matrix. The resulting block diagonal structure can be efficiently exploited to reduce the computational complexity of the Fisher matrix inversion and thus compute the natural gradient exactly, without the need of approximations. We present a geometric adaptation of well-known methods from the literature, introducing the Natural Wake-Sleep (NWS) and the Natural Reweighted Wake-Sleep (NRWS) algorithms. We present an experimental analysis of the novel geometrical algorithms based on the convergence speed and the value of the log-likelihood, both with respect to the number of iterations and the time complexity and demonstrating improvements on these aspects over their respective non-geometric baselines.", "pdf_url": "https://arxiv.org/pdf/2008.06687", "subject": "Machine Learning (cs.LG)"},
{"title": "Iterative Detection for Orthogonal Time Frequency Space Modulation Using Approximate Message Passing with Unitary Transformation", "author": "Zhengdao Yuan, Fei Liu, Weijie Yuan, Qinghua Guo, Zhongyong Wang, Jinhong Yuan", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The orthogonal time frequency space (OTFS) modulation has emerged as a promising modulation scheme for high mobility wireless communications. To harvest the time and frequency diversity promised by OTFS, some promising detectors, especially message passing based ones, have been developed by taking advantage of the sparsity of the channel in the delay-Doppler domain. However, when the number of channel paths is relatively large or fractional Doppler shift has to be considered, the complexity of existing detectors is a concern, and the message passing based detectors may suffer from performance loss due to the short loops involved in message passing. In this work, we investigate the design of OTFS detectors based on the approximate message passing (AMP) algorithm. In particular, AMP with unitary transformation (UTAMP) based detectors are developed, which enjoy the structure of the channel matrix and allow efficient implementation, e.g., by exploiting the property of block circulant matrix with circulant block (BCCB), the complexity of the UTAMP-based detector per symbol is in the order of the logarithm of OTFS block length. In addition, the estimation of noise variance is incorporated into the UTAMP-based detectors (while existing detectors assume perfect noise variance). Thanks to the robustness of UTAMP relative to AMP, the UTAMP-based detectors are able to deliver much better performance, and outperform state-of-the-art detectors significantly. The investigations are also extended to iterative joint detection and decoding in a coded OTFS system, where the OTFS detectors are integrated into a powerful turbo receiver, leading to a considerable performance gain.", "pdf_url": "https://arxiv.org/pdf/2008.06688", "subject": "Information Theory (cs.IT)"},
{"title": "How to build your own ASP-based system?!", "author": "Roland Kaminski, Javier Romero, Torsten Schaub, Philipp Wanko", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Answer Set Programming (ASP) has become a popular and quite sophisticated approach to declarative problem solving. This is arguably due to its attractive modeling-grounding-solving workflow that provides an easy approach to problem solving, even for laypersons outside computer science. Unlike this, the high degree of sophistication of the underlying technology makes it increasingly hard for ASP experts to put ideas into practice. For addressing this issue, this tutorial aims at enabling users to build their own ASP-based systems. More precisely, we show how the ASP system CLINGO can be used for extending ASP and for implementing customized special-purpose systems. To this end, we propose two alternatives. We begin with a traditional AI technique and show how meta programming can be used for extending ASP. This is a rather light approach that relies on CLINGO's reification feature to use ASP itself for expressing new functionalities. Unlike this, the major part of this tutorial uses traditional programming (in PYTHON) for manipulating CLINGO via its application programming interface. This approach allows for changing and controlling the entire model-ground-solve workflow of ASP. Central to this is CLINGO's new Application class that allows us to draw on CLINGO's infrastructure by customizing processes similar to the one in CLINGO. For instance, we may engage manipulations to programs' abstract syntax trees, control various forms of multi-shot solving, and set up theory propagators for foreign inferences. Another cross-sectional structure, spanning meta as well as application programming, is CLINGO's intermediate format, ASPIF, that specifies the interface among the underlying grounder and solver. We illustrate the aforementioned concepts and techniques throughout this tutorial by means of examples and several non-trivial case-studies.", "pdf_url": "https://arxiv.org/pdf/2008.06692", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Explainability in Deep Reinforcement Learning", "author": "Alexandre Heuillet, Fabien Couthouis, Natalia D\u00edaz-Rodr\u00edguez", "pub_date": "Submitted on 15 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "A large set of the explainable Artificial Intelligence (XAI) literature is emerging on feature relevance techniques to explain a deep neural network (DNN) output or explaining models that ingest image source data. However, assessing how XAI techniques can help understand models beyond classification tasks, e.g. for reinforcement learning (RL), has not been extensively studied. We review recent works in the direction to attain Explainable Reinforcement Learning (XRL), a relatively new subfield of Explainable Artificial Intelligence, intended to be used in general public applications, with diverse audiences, requiring ethical, responsible and trustable algorithms. In critical situations where it is essential to justify and explain the agent's behaviour, better explainability and interpretability of RL models could help gain scientific insight on the inner workings of what is still considered a black box. We evaluate mainly studies directly linking explainability to RL, and split these into two categories according to the way the explanations are generated: transparent algorithms and post-hoc explainaility. We also review the most prominent XAI works from the lenses of how they could potentially enlighten the further deployment of the latest advances in RL, in the demanding present and future of everyday problems.", "pdf_url": "https://arxiv.org/pdf/2008.06693", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Providing reliability and auditability to the IoT LwM2M protocol through Blockchain", "author": "Cristian Mart\u00edn, Iv\u00e1n Alba, Joaqu\u00edn Trillo, Enrique Soler, Bartolom\u00e9 Rubio, Manuel D\u00edaz", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Blockchain has come to provide transparency, reliability as well as to increase the security in computer systems, especially in distributed ones like the Internet of Things (IoT). A few integrations have been proposed in this context so far; however, most of these solutions do not pay special attention to the interoperability of the IoT, one of the biggest challenges in this field. In this paper, a Blockchain solution has been integrated into the OMA Lightweight M2M (LwM2M), a promising industry IoT protocol for global interoperability. This integration provides reliability and auditability to the LwM2M protocol enabling IoT devices (LwM2M clients) to transparently interact with the protocol. Furthermore, a missing reliable API to allow users and applications to securely interact with the system and an interface to store critical information like anomalies for auditability have been defined.", "pdf_url": "https://arxiv.org/pdf/2008.06694", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Label-Wise Document Pre-Training for Multi-Label Text Classification", "author": "Han Liu, Caixia Yuan, Xiaojie Wang", "pub_date": "Submitted on 15 Aug 2020", "abstract": "A major challenge of multi-label text classification (MLTC) is to stimulatingly exploit possible label differences and label correlations. In this paper, we tackle this challenge by developing Label-Wise Pre-Training (LW-PT) method to get a document representation with label-aware information. The basic idea is that, a multi-label document can be represented as a combination of multiple label-wise representations, and that, correlated labels always cooccur in the same or similar documents. LW-PT implements this idea by constructing label-wise document classification tasks and trains label-wise document encoders. Finally, the pre-trained label-wise encoder is fine-tuned with the downstream MLTC task. Extensive experimental results validate that the proposed method has significant advantages over the previous state-of-the-art models and is able to discover reasonable label relationship. The code is released to facilitate other researchers.", "pdf_url": "https://arxiv.org/pdf/2008.06695", "subject": "Computation and Language (cs.CL)"},
{"title": "Autonomous Braking and Throttle System: A Deep Reinforcement Learning Approach for Naturalistic Driving", "author": "Varshit S. Dubey, Ruhshad Kasad, Karan Agrawal", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Autonomous Braking and Throttle control is key in developing safe driving systems for the future. There exists a need for autonomous vehicles to negotiate a multi-agent environment while ensuring safety and comfort. A Deep Reinforcement Learning based autonomous throttle and braking system is presented. For each time step, the proposed system makes a decision to apply the brake or throttle. The throttle and brake are modelled as continuous action space values. We demonstrate 2 scenarios where there is a need for a sophisticated braking and throttle system, i.e when there is a static obstacle in front of our agent like a car, stop sign. The second scenario consists of 2 vehicles approaching an intersection. The policies for brake and throttle control are learned through computer simulation using Deep deterministic policy gradients. The experiment shows that the system not only avoids a collision, but also it ensures that there is smooth change in the values of throttle/brake as it gets out of the emergency situation and abides by the speed regulations, i.e the system resembles human driving.", "pdf_url": "https://arxiv.org/pdf/2008.06696", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Curriculum Learning for Recurrent Video Object Segmentation", "author": "Maria Gonzalez-i-Calabuig, Carles Ventura, Xavier Gir\u00f3-i-Nieto", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Video object segmentation can be understood as a sequence-to-sequence task that can benefit from the curriculum learning strategies for better and faster training of deep neural networks. This work explores different schedule sampling and frame skipping variations to significantly improve the performance of a recurrent architecture. Our results on the car class of the KITTI-MOTS challenge indicate that, surprisingly, an inverse schedule sampling is a better option than a classic forward one. Also, that a progressive skipping of frames during training is beneficial, but only when training with the ground truth masks instead of the predicted ones. Source code and trained models are available at .", "pdf_url": "https://arxiv.org/pdf/2008.06698", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Joint fan-beam CT and Compton scattering tomography: analysis and image reconstruction", "author": "Lorenz Kuger, Gael Rigaud", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The recent development of energy-resolving cameras opens the way to new types of applications and imaging systems. In this work, we consider computerized tomography (CT) with fan-beam geometry and equipped with such cameras. The measured radiation is then a function of the positions of the source and detectors and of the energy of the incoming photons. Due to the Compton effect, the variations in energy (or spectrum) of the measurement are modeled in terms of scattering events leading to the so-called Compton scattering tomography (CST). We propose an analysis of the spectral data in terms of modelling and mapping properties which results in a general reconstruction strategy. Thanks to the supplementary information given by the energy, this joint CT-CST scanner makes accurate reconstructions of characteristics of the sought-for object possible for very few source positions and a small number of detectors. The general reconstruction strategy is finally validated on synthetic data via a total variation iterative scheme. Also illustrative, this work motivates the potential of combining conventional CT and Compton scattering imaging (CSI) with various architectures in 2D and 3D.", "pdf_url": "https://arxiv.org/pdf/2008.06699", "subject": "Numerical Analysis (math.NA)"},
{"title": "On Efficient Low Distortion Ultrametric Embedding", "author": "Vincent Cohen-Addad, Karthik C. S., Guillaume Lagarde", "pub_date": "Submitted on 15 Aug 2020", "abstract": "A classic problem in unsupervised learning and data analysis is to find simpler and easy-to-visualize representations of the data that preserve its essential properties. A widely-used method to preserve the underlying hierarchical structure of the data while reducing its complexity is to find an embedding of the data into a tree or an ultrametric. The most popular algorithms for this task are the classic linkage algorithms (single, average, or complete). However, these methods on a data set of $n$ points in $\\Omega(\\log n)$ dimensions exhibit a quite prohibitive running time of $\\Theta(n^2)$. In this paper, we provide a new algorithm which takes as input a set of points $P$ in $\\mathbb{R}^d$, and for every $c\\ge 1$, runs in time $n^{1+\\frac{\\rho}{c^2}}$ (for some universal constant $\\rho>1$) to output an ultrametric $\\Delta$ such that for any two points $u,v$ in $P$, we have $\\Delta(u,v)$ is within a multiplicative factor of $5c$ to the distance between $u$ and $v$ in the \"best\" ultrametric representation of $P$. Here, the best ultrametric is the ultrametric $\\tilde\\Delta$ that minimizes the maximum distance distortion with respect to the $\\ell_2$ distance, namely that minimizes $\\underset{u,v \\in P}{\\max}\\ \\frac{\\tilde\\Delta(u,v)}{\\|u-v\\|_2}$. We complement the above result by showing that under popular complexity theoretic assumptions, for every constant $\\varepsilon>0$, no algorithm with running time $n^{2-\\varepsilon}$ can distinguish between inputs in $\\ell_\\infty$-metric that admit isometric embedding and those that incur a distortion of $\\frac{3}{2}$. Finally, we present empirical evaluation on classic machine learning datasets and show that the output of our algorithm is comparable to the output of the linkage algorithms while achieving a much faster running time.", "pdf_url": "https://arxiv.org/pdf/2008.06700", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Description and Technical specification of Cybernetic Transportation Systems: an urban transportation concept", "author": "Luis Rold\u00e3o, Joshue P\u00e9rez, David Gonz\u00e1lez, and Vicente Milan\u00e9s", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The Cybernetic Transportation Systems (CTS) is an urban mobility concept based on two ideas: the car sharing and the automation of dedicated systems with door-to-door capabilities. In the last decade, many European projects have been developed in this context, where some of the most important are: Cybercars, Cybercars2, CyberMove, CyberC3 and CityMobil. Different companies have developed a first fleet of CTSs in collaboration with research centers around Europe, Asia and America. Considering these previous works, the FP7 project CityMobil2 is on progress since 2012. Its goal is to solve some of the limitations found so far, including the definition of the legal framework for autonomous vehicles on urban environment. This work describes the different improvements, adaptation and instrumentation of the CTS prototypes involved in European cities. Results show tests in our facilities at INRIA-Rocquencourt (France) and the first showcase at Le\u00f3n (Spain)", "pdf_url": "https://arxiv.org/pdf/2008.06703", "subject": "Robotics (cs.RO)"},
{"title": "On the Relationship Between Network Topology and Throughput in Mesh Optical Networks", "author": "Daniel Semrau, Shahzaib Durrani, Georgios Zervas, Robert I. Killey, Polina Bayvel", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The relationship between topology and network throughput of arbitrarily-connected mesh networks is studied. Taking into account nonlinear channel properties, it is shown that throughput decreases logarithmically with physical network size with minor dependence on network ellipticity.", "pdf_url": "https://arxiv.org/pdf/2008.06708", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Performance of Hyperbolic Geometry Models on Top-N Recommendation Tasks", "author": "Leyla Mirvakhabova, Evgeny Frolov, Valentin Khrulkov, Ivan Oseledets, Alexander Tuzhilin", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We introduce a simple autoencoder based on hyperbolic geometry for solving standard collaborative filtering problem. In contrast to many modern deep learning techniques, we build our solution using only a single hidden layer. Remarkably, even with such a minimalistic approach, we not only outperform the Euclidean counterpart but also achieve a competitive performance with respect to the current state-of-the-art. We additionally explore the effects of space curvature on the quality of hyperbolic models and propose an efficient data-driven method for estimating its optimal value.", "pdf_url": "https://arxiv.org/pdf/2008.06716", "subject": "Information Retrieval (cs.IR)"},
{"title": "Site Reliability Engineering: Application of Item Response Theory to Application Deployment Practices and Controls", "author": "Kiran Mahesh ND", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Reliability of an application or solution in production environment is one of the fundamental features where every SRE team is critically focused upon. At the same time achieving extreme reliability comes with the cost which include but not limited to slow pace of new feature deployments, operations cost and opportunity cost. One such earlier effort in giving an objective metric to strike the fine balance between acceptable reliability and product velocity is error budget and its associated policy. There are also contemporary deployment guidelines and controls per organization to ascertain the reliability of an application deployment version into customer facing or production environments. This work proposes new objective metrics called Application Deployment Score estimated using dichotomous Item Response Theory model. This score is used to assess the improvement trend of each application version deployed into customer facing environment, identify the improvement scope for each application deployment in each area of deployment guidelines and controls, adjust the error budget i.e. soft error budget of a interdependent application in application mesh by giving soft collective responsibility and finally defines a new metric called deployment index which helps to assess the effectiveness of these contemporary deployment guidelines and controls in upholding the agreed SLOs of the application in customer facing environments. This study opens a new field of research in developing new underlying latent indexes (i.e. new objective metrics) in SRE and DevOps space.", "pdf_url": "https://arxiv.org/pdf/2008.06717", "subject": "Software Engineering (cs.SE)"},
{"title": "A Deep Convolutional Neural Network for the Detection of Polyps in Colonoscopy Images", "author": "Tariq Rahim, Syed Ali Hassan, Soo Young Shin", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Computerized detection of colonic polyps remains an unsolved issue because of the wide variation in the appearance, texture, color, size, and presence of the multiple polyp-like imitators during colonoscopy. In this paper, we propose a deep convolutional neural network based model for the computerized detection of polyps within colonoscopy images. The proposed model comprises 16 convolutional layers with 2 fully connected layers, and a Softmax layer, where we implement a unique approach using different convolutional kernels within the same hidden layer for deeper feature extraction. We applied two different activation functions, MISH and rectified linear unit activation functions for deeper propagation of information and self regularized smooth non-monotonicity. Furthermore, we used a generalized intersection of union, thus overcoming issues such as scale invariance, rotation, and shape. Data augmentation techniques such as photometric and geometric distortions are adapted to overcome the obstacles faced in polyp detection. Detailed benchmarked results are provided, showing better performance in terms of precision, sensitivity, F1- score, F2- score, and dice-coefficient, thus proving the efficacy of the proposed model.", "pdf_url": "https://arxiv.org/pdf/2008.06721", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Primary-Space Adaptive Control Variates using Piecewise-Polynomial Approximations", "author": "Miguel Crespo, Felix Bernal, Adrian Jarabo, Adolfo Mu\u00f1oz", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We present an unbiased numerical integration algorithm that handles both low-frequency regions and high frequency details of multidimensional integrals. It combines quadrature and Monte Carlo integration, by using a quadrature-base approximation as a control variate of the signal. We adaptively build the control variate constructed as a piecewise polynomial, which can be analytically integrated, and accurately reconstructs the low frequency regions of the integrand. We then recover the high-frequency details missed by the control variate by using Monte Carlo integration of the residual. Our work leverages importance sampling techniques by working in primary space, allowing the combination of multiple mappings; this enables multiple importance sampling in quadrature-based integration. Our algorithm is generic, and can be applied to any complex multidimensional integral. We demonstrate its effectiveness with four applications with low dimensionality: transmittance estimation in heterogeneous participating media, low-order scattering in homogeneous media, direct illumination computation, and rendering of distributed effects. Finally, we show how our technique is extensible to integrands of higher dimensionality, by computing the control variate on Monte Carlo estimates of the high-dimensional signal, and accounting for such additional dimensionality on the residual as well. In all cases, we show accurate results and faster convergence compared to previous approaches.", "pdf_url": "https://arxiv.org/pdf/2008.06722", "subject": "Graphics (cs.GR)"},
{"title": "Personality in Healthcare Human Robot Interaction (H-HRI): A Literature Review and Brief Critique", "author": "Connor Esterwood, Lionel P. Robert", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Robots are becoming an important way to deliver health care, and personality is vital to understanding their effectiveness. Despite this, there is a lack of a systematic overarching understanding of personality in health care human robot interaction (H-HRI). To address this, the authors conducted a review that identified 18 studies on personality in H-HRI. This paper presents the results of that systematic literature review. Insights are derived from this review regarding the methodologies, outcomes, and samples utilized. The authors of this review discuss findings across this literature while identifying several gaps worthy of attention. Overall, this paper is an important starting point in understanding personality in H-HRI.", "pdf_url": "https://arxiv.org/pdf/2008.06723", "subject": "Computers and Society (cs.CY)"},
{"title": "A Review on Drivers Red Light Running and Turning Behaviour Prediction", "author": "Md Mostafizur Rahman Komol, Mohammed Elhenawy, Shamsunnahar Yasmin, Mahmoud Masoud, Andry Rakotonirainy", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Drivers behaviour prediction has been an unceasing concern for transportation safety divisions all over the world. A massive amount of lives and properties losses due to the adversities at intersections and pedestrian crossings. Especially for countries with poor road safety technologies, this toll knows no bounds. A myriad of research and studies have been mastered for technological evaluation and model representation over this issue. Instead, little comprehensive review has been made on the drivers behaviour prediction at signalised intersections on red-light running and turning. This Paper aims at incorporating previous researches on drivers behaviour prediction and the prediction parameters leading to traffic violation like red-light running and turning at intersection and pedestrian crossing. The review also covers the probable crash scenarios by red-light running and turning and analyses the innovation of counter-crash technologies with future research directions.", "pdf_url": "https://arxiv.org/pdf/2008.06727", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Reliable Uncertainties for Bayesian Neural Networks using Alpha-divergences", "author": "Hector J. Hortua, Luigi Malago, Riccardo Volpi", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Bayesian Neural Networks (BNNs) often result uncalibrated after training, usually tending towards overconfidence. Devising effective calibration methods with low impact in terms of computational complexity is thus of central interest. In this paper we present calibration methods for BNNs based on the alpha divergences from Information Geometry. We compare the use of alpha divergence in training and in calibration, and we show how the use in calibration provides better calibrated uncertainty estimates for specific choices of alpha and is more efficient especially for complex network architectures. We empirically demonstrate the advantages of alpha calibration in regression problems involving parameter estimation and inferred correlations between output uncertainties.", "pdf_url": "https://arxiv.org/pdf/2008.06729", "subject": "Machine Learning (cs.LG)"},
{"title": "An asymptotic-preserving IMEX method for nonlinear radiative transfer equation", "author": "Weiming Li, Peng Song, Yanli Wang", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We present an asymptotic preserving method for the radiative transfer equations in the framework of PN method. An implicit and explicit method is proposed to solve the P N system based on the order analysis of the expansion coefficients of the distribution function. The order of each coefficient expanded in the Knudsen number is found through the process of Maxwellian iteration, and the coefficients of high order are treated explicitly while that of low order are treated implicitly in each equation of P N system. Energy inequality is proved for this numerical scheme. Several numerical examples validate this new AP scheme in both optical thick and thin regions.", "pdf_url": "https://arxiv.org/pdf/2008.06730", "subject": "Numerical Analysis (math.NA)"},
{"title": "The parameter-uniform convergence of a fitted operator method on non-uniform meshes for a singularly perturbed initial value problem", "author": "John J. H. Miller", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The parameter-uniform convergence of a fitted operator method for a singularly perturbed differential equation is normally available only for uniform meshes. Here we establish the parameter-uniform convergence of a fitted operator method on a non-uniform mesh for a singularly perturbed initial value problem. This is obtained by a new method of proof.", "pdf_url": "https://arxiv.org/pdf/2008.06732", "subject": "Numerical Analysis (math.NA)"},
{"title": "Reducing Sampling Error in Batch Temporal Difference Learning", "author": "Brahma Pavse, Ishan Durugkar, Josiah Hanna, Peter Stone", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Temporal difference (TD) learning is one of the main foundations of modern reinforcement learning. This paper studies the use of TD(0), a canonical TD algorithm, to estimate the value function of a given policy from a batch of data. In this batch setting, we show that TD(0) may converge to an inaccurate value function because the update following an action is weighted according to the number of times that action occurred in the batch -- not the true probability of the action under the given policy. To address this limitation, we introduce \\textit{policy sampling error corrected}-TD(0) (PSEC-TD(0)). PSEC-TD(0) first estimates the empirical distribution of actions in each state in the batch and then uses importance sampling to correct for the mismatch between the empirical weighting and the correct weighting for updates following each action. We refine the concept of a certainty-equivalence estimate and argue that PSEC-TD(0) is a more data efficient estimator than TD(0) for a fixed batch of data. Finally, we conduct an empirical evaluation of PSEC-TD(0) on three batch value function learning tasks, with a hyperparameter sensitivity analysis, and show that PSEC-TD(0) produces value function estimates with lower mean squared error than TD(0).", "pdf_url": "https://arxiv.org/pdf/2008.06738", "subject": "Machine Learning (cs.LG)"},
{"title": "Finding a Shortest Even Hole in Polynomial Time", "author": "Hou-Teng Cheong, Hsueh-I Lu", "pub_date": "Submitted on 15 Aug 2020", "abstract": "An even (respectively, odd) hole in a graph is an induced cycle with even (respectively, odd) length that is at least four. Bienstock [DM 1991 and 1992] proved that detecting an even (respectively, odd) hole containing a given vertex is NP-complete. Conforti, Chornu\u00e9jols, Kappor, and Vu\u0161kovi\u0107 [FOCS 1997] gave the first known polynomial-time algorithm to determine whether a graph contains even holes. Chudnovsky, Kawarabayashi, and Seymour [JGT 2005] estimated that Conforti et al.'s algorithm runs in $O(n^{40})$ time on an $n$-vertex graph and reduced the required time to $O(n^{31})$. Subsequently, da~Silva and Vu\u0161kovi\u0107~[JCTB 2013], Chang and Lu [JCTB 2017], and Lai, Lu, and Thorup [STOC 2020] improved the time to $O(n^{19})$, $O(n^{11})$, and $O(n^9)$, respectively. The tractability of determining whether a graph contains odd holes has been open for decades until the algorithm of Chudnovsky, Scott, Seymour, and Spirkl [JACM 2020] that runs in $O(n^9)$ time, which Lai et al. also reduced to $O(n^8)$. By extending Chudnovsky et al.'s techniques for detecting odd holes, Chudnovsky, Scott, and Seymour [Combinatorica 2020 to appear] (respectively, [arXiv 2020]) ensured the tractability of finding a long (respectively, shortest) odd hole. They also ensured the NP-hardness of finding a longest odd hole, whose reduction also works for finding a longest even hole. Recently, Cook and Seymour ensured the tractability of finding a long even hole. An intriguing missing piece is the tractability of finding a shortest even hole, left open for at least 15 years by, e.g., Chudnovsky et al. [JGT 2005] and Johnson [TALG 2005]. We resolve this long-standing open problem by giving the first known polynomial-time algorithm, running in $O(n^{31})$ time, for finding a shortest even hole in an $n$-vertex graph that contains even holes.", "pdf_url": "https://arxiv.org/pdf/2008.06740", "subject": "Data Structures and Algorithms (cs.DS)"},
{"title": "Breaking Barriers: Maximizing Array Utilization for Compute In-Memory Fabrics", "author": "Brian Crafton, Samuel Spetalnick, Gauthaman Murali, Tushar Krishna, Sung-Kyu Lim, Arijit Raychowdhury", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Compute in-memory (CIM) is a promising technique that minimizes data transport, the primary performance bottleneck and energy cost of most data intensive applications. This has found wide-spread adoption in accelerating neural networks for machine learning applications. Utilizing a crossbar architecture with emerging non-volatile memories (eNVM) such as dense resistive random access memory (RRAM) or phase change random access memory (PCRAM), various forms of neural networks can be implemented to greatly reduce power and increase on chip memory capacity. However, compute in-memory faces its own limitations at both the circuit and the device levels. Although compute in-memory using the crossbar architecture can greatly reduce data transport, the rigid nature of these large fixed weight matrices forfeits the flexibility of traditional CMOS and SRAM based designs. In this work, we explore the different synchronization barriers that occur from the CIM constraints. Furthermore, we propose a new allocation algorithm and data flow based on input data distributions to maximize utilization and performance for compute-in memory based designs. We demonstrate a 7.47$\\times$ performance improvement over a naive allocation method for CIM accelerators on ResNet18.", "pdf_url": "https://arxiv.org/pdf/2008.06741", "subject": "Hardware Architecture (cs.AR)"},
{"title": "Cubature rules based on bivariate spline quasi-interpolation for weakly singular integrals", "author": "A. Falini, T. Kandu\u010d, M. L. Sampoli, A. Sestini", "pub_date": "Submitted on 15 Aug 2020", "abstract": "In this paper we present a new class of cubature rules with the aim of accurately integrating weakly singular double integrals. In particular we focus on those integrals coming from the discretization of Boundary Integral Equations for 3D Laplace boundary value problems, using a collocation method within the Isogeometric Analysis paradigm. In such setting the regular part of the integrand can be defined as the product of a tensor product B-spline and a general function. The rules are derived by using first the spline quasi-interpolation approach to approximate such function and then the extension of a well known algorithm for spline product to the bivariate setting. In this way efficiency is ensured, since the locality of any spline quasi-interpolation scheme is combined with the capability of an ad--hoc treatment of the B-spline factor. The numerical integration is performed on the whole support of the B-spline factor by exploiting inter-element continuity of the integrands", "pdf_url": "https://arxiv.org/pdf/2008.06746", "subject": "Numerical Analysis (math.NA)"},
{"title": "Smart Voltage Monitoring: Centralised and Blockchain-based Decentralised Approach", "author": "Shailesh Mishra, Shivam Kumar", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Voltage controls the majority of the processes around us, starting from lighting an incandescent lamp to running huge machines in industries. Therefore, voltage monitoring becomes essential, which demands efficient measurement and storage of voltage data. However, there is hardly any system till date that fulfils both the goals of voltage monitoring and voltage data storage. To achieve this goal, we propose the application of the Internet of Things along with the server-based framework and Distributed Ledger Technology to build systems for smart voltage monitoring. Two models - a centralised model and a decentralised model have been presented and analysed thoroughly in this paper. The centralised model is built on client-server architecture, whereas the decentralised model is based on a peer-to-peer architecture. Blockchain and InterPlanetary File System have been used for the implementation of the decentralised system. Potential improvements to make these systems robust have also been discussed. The methods proposed in this paper for voltage monitoring are novel; ensure efficient data storage and can be used for IoT data storage of any form.", "pdf_url": "https://arxiv.org/pdf/2008.06747", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Tackling COVID-19 through Responsible AI Innovation: Five Steps in the Right Direction", "author": "David Leslie", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Innovations in data science and AI/ML have a central role to play in supporting global efforts to combat COVID-19. The versatility of AI/ML technologies enables scientists and technologists to address an impressively broad range of biomedical, epidemiological, and socioeconomic challenges. This wide-reaching scientific capacity, however, also raises a diverse array of ethical challenges. The need for researchers to act quickly and globally in tackling SARS-CoV-2 demands unprecedented practices of open research and responsible data sharing at a time when innovation ecosystems are hobbled by proprietary protectionism, inequality, and a lack of public trust. Moreover, societally impactful interventions like digital contact tracing are raising fears of surveillance creep and are challenging widely held commitments to privacy, autonomy, and civil liberties. Prepandemic concerns that data-driven innovations may function to reinforce entrenched dynamics of societal inequity have likewise intensified given the disparate impact of the virus on vulnerable social groups and the life-and-death consequences of biased and discriminatory public health outcomes. To address these concerns, I offer five steps that need to be taken to encourage responsible research and innovation. These provide a practice-based path to responsible AI/ML design and discovery centered on open, accountable, equitable, and democratically governed processes and products. When taken from the start, these steps will not only enhance the capacity of innovators to tackle COVID-19 responsibly, they will, more broadly, help to better equip the data science and AI/ML community to cope with future pandemics and to support a more humane, rational, and just society.", "pdf_url": "https://arxiv.org/pdf/2008.06755", "subject": "Computers and Society (cs.CY)"},
{"title": "Deep Search Query Intent Understanding", "author": "Xiaowei Liu, Weiwei Guo, Huiji Gao, Bo Long", "pub_date": "Submitted on 15 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "Understanding a user's query intent behind a search is critical for modern search engine success. Accurate query intent prediction allows the search engine to better serve the user's need by rendering results from more relevant categories. This paper aims to provide a comprehensive learning framework for modeling query intent under different stages of a search. We focus on the design for 1) predicting users' intents as they type in queries on-the-fly in typeahead search using character-level models; and 2) accurate word-level intent prediction models for complete queries. Various deep learning components for query text understanding are experimented. Offline evaluation and online A/B test experiments show that the proposed methods are effective in understanding query intent and efficient to scale for online search systems.", "pdf_url": "https://arxiv.org/pdf/2008.06759", "subject": "Computation and Language (cs.CL)"},
{"title": "SklCoin: Toward a Scalable Proof-of-Stake and Collective Signature Based Consensus Protocol for Strong Consistency in Blockchain", "author": "Zakwan Jaroucheh, Baraq Ghaleb, William J Buchanan", "pub_date": "Submitted on 15 Aug 2020", "abstract": "The proof-of-work consensus protocol suffers from two main limitations: waste of energy and offering only probabilistic guarantees about the status of the blockchain. This paper introduces SklCoin, a new Byzantine consensus protocol and its corresponding software architecture. This protocol leverages two ideas: 1) the proof-of-stake concept to dynamically form stake proportionate consensus groups that represent block miners (stakeholders), and 2) scalable collective signing to efficiently commit transactions irreversibly. SklCoin has immediate finality characteristic where all miners instantly agree on the validity of blocks. In addition, SklCoin supports high transaction rate because of its fast miner election mechanism", "pdf_url": "https://arxiv.org/pdf/2008.06763", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Heterogeneous Federated Learning", "author": "Fuxun Yu, Weishan Zhang, Zhuwei Qin, Zirui Xu, Di Wang, Chenchen Liu, Zhi Tian, Xiang Chen", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Federated learning learns from scattered data by fusing collaborative models from local nodes. However, due to chaotic information distribution, the model fusion may suffer from structural misalignment with regard to unmatched parameters. In this work, we propose a novel federated learning framework to resolve this issue by establishing a firm structure-information alignment across collaborative models. Specifically, we design a feature-oriented regulation method ({$\\Psi$-Net}) to ensure explicit feature information allocation in different neural network structures. Applying this regulating method to collaborative models, matchable structures with similar feature information can be initialized at the very early training stage. During the federated learning process under either IID or non-IID scenarios, dedicated collaboration schemes further guarantee ordered information distribution with definite structure matching, so as the comprehensive model alignment. Eventually, this framework effectively enhances the federated learning applicability to extensive heterogeneous settings, while providing excellent convergence speed, accuracy, and computation/communication efficiency.", "pdf_url": "https://arxiv.org/pdf/2008.06767", "subject": "Machine Learning (cs.LG)"},
{"title": "Model Patching: Closing the Subgroup Performance Gap with Data Augmentation", "author": "Karan Goel, Albert Gu, Yixuan Li, Christopher R\u00e9", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Classifiers in machine learning are often brittle when deployed. Particularly concerning are models with inconsistent performance on specific subgroups of a class, e.g., exhibiting disparities in skin cancer classification in the presence or absence of a spurious bandage. To mitigate these performance differences, we introduce model patching, a two-stage framework for improving robustness that encourages the model to be invariant to subgroup differences, and focus on class information shared by subgroups. Model patching first models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate subgroup features. We instantiate model patching with CAMEL, which (1) uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and (2) balances subgroup performance using a theoretically-motivated subgroup consistency regularizer, accompanied by a new robust objective. We demonstrate CAMEL's effectiveness on 3 benchmark datasets, with reductions in robust error of up to 33% relative to the best baseline. Lastly, CAMEL successfully patches a model that fails due to spurious features on a real-world skin cancer dataset.", "pdf_url": "https://arxiv.org/pdf/2008.06775", "subject": "Machine Learning (cs.LG)"},
{"title": "The Evaluation of Rating Systems in Online Free-for-All Games", "author": "Arman Dehpanah, Muheeb Faizan Ghori, Jonathan Gemmell, Bamshad Mobasher", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Online competitive games have become increasingly popular. To ensure an exciting and competitive environment, these games routinely attempt to match players with similar skill levels. Matching players is often accomplished through a rating system. There has been an increasing amount of research on developing such rating systems. However, less attention has been given to the evaluation metrics of these systems. In this paper, we present an exhaustive analysis of six metrics for evaluating rating systems in online competitive games. We compare traditional metrics such as accuracy. We then introduce other metrics adapted from the field of information retrieval. We evaluate these metrics against several well-known rating systems on a large real-world dataset of over 100,000 free-for-all matches. Our results show stark differences in their utility. Some metrics do not consider deviations between two ranks. Others are inordinately impacted by new players. Many do not capture the importance of distinguishing between errors in higher ranks and lower ranks. Among all metrics studied, we recommend Normalized Discounted Cumulative Gain (NDCG) because not only does it resolve the issues faced by other metrics, but it also offers flexibility to adjust the evaluations based on the goals of the system", "pdf_url": "https://arxiv.org/pdf/2008.06787", "subject": "Information Retrieval (cs.IR)"},
{"title": "Is Supervised Syntactic Parsing Beneficial for Language Understanding? An Empirical Investigation", "author": "Goran Glava\u0161, Ivan Vuli\u0107", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Traditional NLP has long held (supervised) syntactic parsing necessary for successful higher-level language understanding. The recent advent of end-to-end neural language learning, self-supervised via language modeling (LM), and its success on a wide range of language understanding tasks, however, questions this belief. In this work, we empirically investigate the usefulness of supervised parsing for semantic language understanding in the context of LM-pretrained transformer networks. Relying on the established fine-tuning paradigm, we first couple a pretrained transformer with a biaffine parsing head, aiming to infuse explicit syntactic knowledge from Universal Dependencies (UD) treebanks into the transformer. We then fine-tune the model for language understanding (LU) tasks and measure the effect of the intermediate parsing training (IPT) on downstream LU performance. Results from both monolingual English and zero-shot language transfer experiments (with intermediate target-language parsing) show that explicit formalized syntax, injected into transformers through intermediate supervised parsing, has very limited and inconsistent effect on downstream LU performance. Our results, coupled with our analysis of transformers' representation spaces before and after intermediate parsing, make a significant step towards providing answers to an essential question: how (un)availing is supervised parsing for high-level semantic language understanding in the era of large neural models?", "pdf_url": "https://arxiv.org/pdf/2008.06788", "subject": "Computation and Language (cs.CL)"},
{"title": "On the Power of Automata Minimization in Temporal Synthesis", "author": "Shufang Zhu, Lucas M. Tabajara, Geguang Pu, Moshe Y. Vardi", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Reactive synthesis is the problem of automatically constructing a reactive system from a formal specification, with the guarantee that the executions of the system align with the specification. The specification is often described in temporal logic. Some types of specifications can be converted into deterministic finite automata (DFA) as an intermediate step in synthesis, thus benefiting from the fact that DFAs can be fully minimized in polynomial time. In this work we investigate DFA-minimization algorithms in the context of temporal synthesis. In particular, we compare between the Hopcroft and Brzozowski minimization algorithms, adapting them to start from temporal-logic formulas and integrating them into an existing temporal synthesis framework. While earlier studies comparing the two algorithms for randomly-generated automata concluded that neither algorithm dominates, our results suggest that in the context of temporal-synthesis, Hopcroft's algorithm is the best choice. Analyzing the results, we observe that the reason for the poor performance of Brzozowski's algorithm is a discrepancy between theory and practice. This algorithm first constructs a DFA for the reverse language of the specification and then performs a series of operations to transform it into a minimal DFA for the specification itself. In theory, the DFA for the reverse language can be exponentially smaller, which would potentially make this algorithm more efficient than directly constructing the DFA for the original specification. In practice, however, we find that the reverse DFA is often of comparable size or even larger, which cancels the advantage that this approach could have.", "pdf_url": "https://arxiv.org/pdf/2008.06790", "subject": "Formal Languages and Automata Theory (cs.FL)"},
{"title": "Skyline: Interactive In-Editor Computational Performance Profiling for Deep Neural Network Training", "author": "Geoffrey X. Yu, Tovi Grossman, Gennady Pekhimenko", "pub_date": "Submitted on 15 Aug 2020 ( ), last revised 20 Aug 2020 (this version, v2)", "abstract": "Training a state-of-the-art deep neural network (DNN) is a computationally-expensive and time-consuming process, which incentivizes deep learning developers to debug their DNNs for computational performance. However, effectively performing this debugging requires intimate knowledge about the underlying software and hardware systems---something that the typical deep learning developer may not have. To help bridge this gap, we present Skyline: a new interactive tool for DNN training that supports in-editor computational performance profiling, visualization, and debugging. Skyline's key contribution is that it leverages special computational properties of DNN training to provide (i) interactive performance predictions and visualizations, and (ii) directly manipulatable visualizations that, when dragged, mutate the batch size in the code. As an in-editor tool, Skyline allows users to leverage these diagnostic features to debug the performance of their DNNs during development. An exploratory qualitative user study of Skyline produced promising results; all the participants found Skyline to be useful and easy to use.", "pdf_url": "https://arxiv.org/pdf/2008.06798", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Chrome Dino Run using Reinforcement Learning", "author": "Divyanshu Marwah, Sneha Srivastava, Anusha Gupta, Shruti Verma", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Reinforcement Learning is one of the most advanced set of algorithms known to mankind which can compete in games and perform at par or even better than humans. In this paper we study most popular model free reinforcement learning algorithms along with convolutional neural network to train the agent for playing the game of Chrome Dino Run. We have used two of the popular temporal difference approaches namely Deep Q-Learning, and Expected SARSA and also implemented Double DQN model to train the agent and finally compare the scores with respect to the episodes and convergence of algorithms with respect to timesteps.", "pdf_url": "https://arxiv.org/pdf/2008.06799", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "On Partial Differential Encodings, with Application to Boolean Circuits", "author": "Edinah K. Gnang", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We argue that a better understanding of arithmetic circuit complexity is central to Boolean circuit complexity and not merely a first step. We do this by showing that Boolean circuit complexity upperbound the Kolomogorov complexity of certain partial derivative incarnations of Turing machines.", "pdf_url": "https://arxiv.org/pdf/2008.06801", "subject": "Computational Complexity (cs.CC)"},
{"title": "Stronger Lower Bounds for Polynomial Time Problems", "author": "Andr\u00e1s Z. Salamon, Michael Wehar", "pub_date": "Submitted on 15 Aug 2020", "abstract": "We reinvestigate the classical topic of limited nondeterminism, to prove stronger conditional lower bounds for polynomial time problems. In particular, we show that CircuitSAT for circuits with m gates and log(m) inputs (denoted by log-CircuitSAT) is not solvable in quasilinear time unless the exponential time hypothesis (ETH) is false. In other words, a polynomial time improvement for log-CircuitSAT would lead to an exponential time improvement for NP-complete problems.", "pdf_url": "https://arxiv.org/pdf/2008.06805", "subject": "Computational Complexity (cs.CC)"},
{"title": "Finding Fast Transformers: One-Shot Neural Architecture Search by Component Composition", "author": "Henry Tsai, Jayden Ooi, Chun-Sung Ferng, Hyung Won Chung, Jason Riesa", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Transformer-based models have achieved stateof-the-art results in many tasks in natural language processing. However, such models are usually slow at inference time, making deployment difficult. In this paper, we develop an efficient algorithm to search for fast models while maintaining model quality. We describe a novel approach to decompose the Transformer architecture into smaller components, and propose a sampling-based one-shot architecture search method to find an optimal model for inference. The model search process is more efficient than alternatives, adding only a small overhead to training time. By applying our methods to BERT-base architectures, we achieve 10% to 30% speedup for pre-trained BERT and 70% speedup on top of a previous state-of-the-art distilled BERT model on Cloud TPU-v2 with a generally acceptable drop in performance.", "pdf_url": "https://arxiv.org/pdf/2008.06808", "subject": "Machine Learning (cs.LG)"},
{"title": "How Search Engine Advertising Affects Sales over Time: An Empirical Investigation", "author": "Yanwu Yang, Kang Zhao, Daniel Zeng, Bernard Jim Jansen", "pub_date": "Submitted on 15 Aug 2020", "abstract": "As a mainstream marketing channel on the Internet, Search Engine Advertising (SEA) has a huge business impact and attracts a plethora of attention from both academia and industry. One important goal of advertising is to increase sales. Nevertheless, while previous research has studied multiple factors that are potentially related to the outcome of SEA campaigns, effects of these factors on actual sales generated by SEA remain understudied. It is also unclear whether and how such effects change over time in highly dynamic SEA campaigns. As the first empirical investigation of the dynamic advertisement-sales relationship in SEA, this study builds an advertising response model within a time-varying coefficient (TVC) modeling framework, and estimates the model using a unique dataset from a large E-Commerce retailer in the United States. Results reveal the effects of the advertising expenditure, consumer behaviors and advertisement characteristics on realized sales, and demonstrate that such effects on sales do change over time in non-linear ways. More importantly, we find that carryover has a stronger effect in generating sales than direct response does, conversion rate is much more important than click-through rate, and ad position does not have significant effects on sales. These findings have direct implications for advertisers to launch more effective SEA campaigns.", "pdf_url": "https://arxiv.org/pdf/2008.06809", "subject": "Computers and Society (cs.CY)"},
{"title": "Cluster-level Feature Alignment for Person Re-identification", "author": "Qiuyu Chen, Wei Zhang, Jianping Fan", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Instance-level alignment is widely exploited for person re-identification, e.g. spatial alignment, latent semantic alignment and triplet alignment. This paper probes another feature alignment modality, namely cluster-level feature alignment across whole dataset, where the model can see not only the sampled images in local mini-batch but the global feature distribution of the whole dataset from distilled anchors. Towards this aim, we propose anchor loss and investigate many variants of cluster-level feature alignment, which consists of iterative aggregation and alignment from the overview of dataset. Our extensive experiments have demonstrated that our methods can provide consistent and significant performance improvement with small training efforts after the saturation of traditional training. In both theoretical and experimental aspects, our proposed methods can result in more stable and guided optimization towards better representation and generalization for well-aligned embedding.", "pdf_url": "https://arxiv.org/pdf/2008.06810", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Quantum Hoare logic with classical variables", "author": "Yuan Feng, Mingsheng Ying", "pub_date": "Submitted on 15 Aug 2020", "abstract": "Hoare logic provides a syntax-oriented method to reason about program correctness, and has been proven effective in the verification of classical and probabilistic programs. Existing proposals for quantum Hoare logic either lack completeness or support only quantum variables, thus limiting their capability in practical use. In this paper, we propose a quantum Hoare logic for a simple while language which involves both classical and quantum variables. Its soundness and relative completeness are proven for both partial and total correctness of quantum programs written in the language. Remarkably, with novel definitions of classical-quantum states and corresponding assertions, the logic system is quite simple and similar to the traditional Hoare logic for classical programs. Furthermore, to simplify reasoning in real applications, auxiliary proof rules are provided which support the introduction of disjunction and quantifiers in the classical part of assertions, and of super-operator application and superposition in the quantum part. Finally, a series of practical quantum algorithms, in particular the whole algorithm of Shor's factorisation, are formally verified to show the effectiveness of the logic.", "pdf_url": "https://arxiv.org/pdf/2008.06812", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "Attributes affecting user decision to adopt a Virtual Private Network (VPN) app", "author": "Nissy Sombatruang, Tan Omiya, Daisuke Miyamoto, M. Angela Sasse, Youki Kadobayashi, Michelle Baddeley", "pub_date": "Submitted on 16 Aug 2020", "abstract": "A Virtual Private Network (VPN) helps to mitigate security and privacy risks of data transmitting on unsecured network such as public Wi-Fi. However, despite awareness of public Wi-Fi risks becoming increasingly common, the use of VPN when using public Wi-Fi is low. To increase adoption, understanding factors driving user decision to adopt a VPN app is an important first step. This study is the first to achieve this objective using discrete choice experiments (DCEs) to elicit individual preferences of specific attributes of a VPN app. The experiments were run in the United Kingdom (UK) and Japan (JP). We first interviewed participants (15 UK, 17 JP) to identify common attributes of a VPN app which they considered important. The results were used to design and run a DCE in each country. Participants (149 UK, 94 JP) were shown a series of two hypothetical VPN apps, varying in features, and were asked to choose one which they preferred. Customer review rating, followed by price of a VPN app, significantly affected the decision to choose which VPN app to download and install. A change from a rating of 3 to 4-5 stars increased the probability of choosing an app by 33% in the UK and 14% in Japan. Unsurprisingly, price was a deterrent. Recommendations by friends, source of product reviews, and the presence of in-app ads also played a role but to a lesser extent. To actually use a VPN app, participants considered Internet speed, connection stability, battery level on mobile devices, and the presence of in-app ads as key drivers. Participants in the UK and in Japan prioritized these attributes differently, suggesting possible influences from cultural differences.", "pdf_url": "https://arxiv.org/pdf/2008.06813", "subject": "Cryptography and Security (cs.CR)"},
{"title": "Cascaded channel pruning using hierarchical self-distillation", "author": "Roy Miles, Krystian Mikolajczyk", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In this paper, we propose an approach for filter-level pruning with hierarchical knowledge distillation based on the teacher, teaching-assistant, and student framework. Our method makes use of teaching assistants at intermediate pruning levels that share the same architecture and weights as the target student. We propose to prune each model independently using the gradient information from its corresponding teacher. By considering the relative sizes of each student-teacher pair, this formulation provides a natural trade-off between the capacity gap for knowledge distillation and the bias of the filter saliency updates. Our results show improvements in the attainable accuracy and model compression across the CIFAR10 and ImageNet classification tasks using the VGG16and ResNet50 architectures. We provide an extensive evaluation that demonstrates the benefits of using a varying number of teaching assistant models at different sizes.", "pdf_url": "https://arxiv.org/pdf/2008.06814", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Attack on Multi-Node Attention for Object Detection", "author": "Sizhe Chen, Fan He, Xiaolin Huang, Kun Zhang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "This paper focuses on high-transferable adversarial attacks on detection networks, which are crucial for life-concerning systems such as autonomous driving and security surveillance. Detection networks are hard to attack in a black-box manner, because of their multiple-output property and diversity across architectures. To pursue a high attacking transferability, one needs to find a common property shared by different models. Multi-node attention heat map obtained by our newly proposed method is such a property. Based on it, we design the ATTACk on multi-node attenTION for object detecTION (ATTACTION). ATTACTION achieves a state-of-the-art transferability in numerical experiments. On MS COCO, the detection mAP for all 7 tested black-box architectures is halved and the performance of semantic segmentation is greatly influenced. Given the great transferability of ATTACTION, we generate Adversarial Objects in COntext (AOCO), the first adversarial dataset on object detection networks, which could help designers to quickly evaluate and improve the robustness of detection networks.", "pdf_url": "https://arxiv.org/pdf/2008.06822", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Conjunctive Queries: Unique Characterizations and Exact Learnability", "author": "Balder ten Cate, Victor Dalmau", "pub_date": "Submitted on 16 Aug 2020", "abstract": "We answer the question which conjunctive queries are uniquely characterized by polynomially many positive and negative examples, and how to construct such examples efficiently. As a consequence, we obtain a new efficient exact learning algorithm for a class of conjunctive queries. At the core of our contributions lie two new polynomial-time algorithms for constructing frontiers in the homomorphism lattice of finite structures. We also discuss implications for the unique characterizability and learnability of schema mappings and of description logic concepts.", "pdf_url": "https://arxiv.org/pdf/2008.06824", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "Faster Person Re-Identification", "author": "Guan'an Wang, Shaogang Gong, Jian Cheng, Zengguang Hou", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Fast person re-identification (ReID) aims to search person images quickly and accurately. The main idea of recent fast ReID methods is the hashing algorithm, which learns compact binary codes and performs fast Hamming distance and counting sort. However, a very long code is needed for high accuracy (e.g. 2048), which compromises search speed. In this work, we introduce a new solution for fast ReID by formulating a novel Coarse-to-Fine (CtF) hashing code search strategy, which complementarily uses short and long codes, achieving both faster speed and better accuracy. It uses shorter codes to coarsely rank broad matching similarities and longer codes to refine only a few top candidates for more accurate instance ReID. Specifically, we design an All-in-One (AiO) framework together with a Distance Threshold Optimization (DTO) algorithm. In AiO, we simultaneously learn and enhance multiple codes of different lengths in a single model. It learns multiple codes in a pyramid structure, and encourage shorter codes to mimic longer codes by self-distillation. DTO solves a complex threshold search problem by a simple optimization process, and the balance between accuracy and speed is easily controlled by a single parameter. It formulates the optimization target as a $F_{\\beta}$ score that can be optimised by Gaussian cumulative distribution functions. Experimental results on 2 datasets show that our proposed method (CtF) is not only 8% more accurate but also 5x faster than contemporary hashing ReID methods. Compared with non-hashing ReID methods, CtF is $50\\times$ faster with comparable accuracy. Code is available at .", "pdf_url": "https://arxiv.org/pdf/2008.06826", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "A novel approach to remove foreign objects from chest X-ray images", "author": "Hieu X. Le, Phuong D. Nguyen, Thang H. Nguyen, Khanh N.Q. Le, Thanh T. Nguyen", "pub_date": "Submitted on 16 Aug 2020", "abstract": "We initially proposed a deep learning approach for foreign objects inpainting in smartphone-camera captured chest radiographs utilizing the cheXphoto dataset. Foreign objects which can significantly affect the quality of a computer-aided diagnostic prediction are captured under various settings. In this paper, we used multi-method to tackle both removal and inpainting chest radiographs. Firstly, an object detection model is trained to separate the foreign objects from the given image. Subsequently, the binary mask of each object is extracted utilizing a segmentation model. Each pair of the binary mask and the extracted object are then used for inpainting purposes. Finally, the in-painted regions are now merged back to the original image, resulting in a clean and non-foreign-object-existing output. To conclude, we achieved state-of-the-art accuracy. The experimental results showed a new approach to the possible applications of this method for chest X-ray images detection.", "pdf_url": "https://arxiv.org/pdf/2008.06828", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "DeepSampling: Selectivity Estimation with Predicted Error and Response Time", "author": "Tin Vu, Ahmed Eldawy", "pub_date": "Submitted on 16 Aug 2020", "abstract": "The rapid growth of spatial data urges the research community to find efficient processing techniques for interactive queries on large volumes of data. Approximate Query Processing (AQP) is the most prominent technique that can provide real-time answer for ad-hoc queries based on a random sample. Unfortunately, existing AQP methods provide an answer without providing any accuracy metrics due to the complex relationship between the sample size, the query parameters, the data distribution, and the result accuracy. This paper proposes DeepSampling, a deep-learning-based model that predicts the accuracy of a sample-based AQP algorithm, specially selectivity estimation, given the sample size, the input distribution, and query parameters. The model can also be reversed to measure the sample size that would produce a desired accuracy. DeepSampling is the first system that provides a reliable tool for existing spatial databases to control the accuracy of AQP.", "pdf_url": "https://arxiv.org/pdf/2008.06831", "subject": "Databases (cs.DB)"},
{"title": "Differentially Private Multi-Agent Planning for Logistic-like Problems", "author": "Dayong Ye, Tianqing Zhu, Sheng Shen, Wanlei Zhou, Philip S. Yu", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Planning is one of the main approaches used to improve agents' working efficiency by making plans beforehand. However, during planning, agents face the risk of having their private information leaked. This paper proposes a novel strong privacy-preserving planning approach for logistic-like problems. This approach outperforms existing approaches by addressing two challenges: 1) simultaneously achieving strong privacy, completeness and efficiency, and 2) addressing communication constraints. These two challenges are prevalent in many real-world applications including logistics in military environments and packet routing in networks. To tackle these two challenges, our approach adopts the differential privacy technique, which can both guarantee strong privacy and control communication overhead. To the best of our knowledge, this paper is the first to apply differential privacy to the field of multi-agent planning as a means of preserving the privacy of agents for logistic-like problems. We theoretically prove the strong privacy and completeness of our approach and empirically demonstrate its efficiency. We also theoretically analyze the communication overhead of our approach and illustrate how differential privacy can be used to control it.", "pdf_url": "https://arxiv.org/pdf/2008.06832", "subject": "Artificial Intelligence (cs.AI)"},
{"title": "Benchmarking database performance for genomic data", "author": "Matloob Khushi", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Genomic regions represent features such as gene annotations, transcription factor binding sites and epigenetic modifications. Performing various genomic operations such as identifying overlapping/non-overlapping regions or nearest gene annotations are common research needs. The data can be saved in a database system for easy management, however, there is no comprehensive database built-in algorithm at present to identify overlapping regions. Therefore I have developed a region-mapping (RegMap) SQL-based algorithm to perform genomic operations and have benchmarked the performance of different databases. Benchmarking identified that PostgreSQL extracts overlapping regions much faster than MySQL. Insertion and data uploads in PostgreSQL were also better, although general searching capability of both databases was almost equivalent. In addition, using the algorithm pair-wise, overlaps of >1000 datasets of transcription factor binding sites and histone marks, collected from previous publications, were reported and it was found that HNF4G significantly co-locates with cohesin subunit STAG1 (SA1).", "pdf_url": "https://arxiv.org/pdf/2008.06835", "subject": "Databases (cs.DB)"},
{"title": "Open source tools for management and archiving of digital microscopy data to allow integration with patient pathology and treatment information", "author": "Matloob Khushi, Georgina Edwards, Diego Alonso de Marcos, Jane E Carpenter, J Dinny Graham, Christine L Clarke", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Virtual microscopy includes digitisation of histology slides and the use of computer technologies for complex investigation of diseases such as cancer. However, automated image analysis, or website publishing of such digital images, is hampered by their large file sizes. We have developed two Java based open source tools: Snapshot Creator and NDPI-Splitter. Snapshot Creator converts a portion of a large digital slide into a desired quality JPEG image. The image is linked to the patients clinical and treatment information in a customised open source cancer data management software (Caisis) in use at the Australian Breast Cancer Tissue Bank (ABCTB) and then published on the ABCTB website using Deep Zoom open source technology. Using the ABCTB online search engine, digital images can be searched by defining various criteria such as cancer type, or biomarkers expressed. NDPI-Splitter splits a large image file into smaller sections of TIFF images so that they can be easily analysed by image analysis software such as Metamorph or Matlab. NDPI-Splitter also has the capacity to filter out empty images. Snapshot Creator and NDPI-Splitter are novel open source Java tools. They convert digital slides into files of smaller size for further processing. In conjunction with other open source tools such as Deep Zoom and Caisis, this suite of tools is used for the management and archiving of digital microscopy images, enabling digitised images to be explored and zoomed online. Our online image repository also has the capacity to be used as a teaching resource. These tools also enable large files to be sectioned for image analysis.", "pdf_url": "https://arxiv.org/pdf/2008.06837", "subject": "Image and Video Processing (eess.IV)"},
{"title": "We Learn Better Road Pothole Detection: from Attention Aggregation to Adversarial Domain Adaptation", "author": "Rui Fan, Hengli Wang, Mohammud J. Bocus, Ming Liu", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Manual visual inspection performed by certified inspectors is still the main form of road pothole detection. This process is, however, not only tedious, time-consuming and costly, but also dangerous for the inspectors. Furthermore, the road pothole detection results are always subjective, because they depend entirely on the individual experience. Our recently introduced disparity (or inverse depth) transformation algorithm allows better discrimination between damaged and undamaged road areas, and it can be easily deployed to any semantic segmentation network for better road pothole detection results. To boost the performance, we propose a novel attention aggregation (AA) framework, which takes the advantages of different types of attention modules. In addition, we develop an effective training set augmentation technique based on adversarial domain adaptation, where the synthetic road RGB images and transformed road disparity (or inverse depth) images are generated to enhance the training of semantic segmentation networks. The experimental results demonstrate that, firstly, the transformed disparity (or inverse depth) images become more informative; secondly, AA-UNet and AA-RTFNet, our best performing implementations, respectively outperform all other state-of-the-art single-modal and data-fusion networks for road pothole detection; and finally, the training set augmentation technique based on adversarial domain adaptation not only improves the accuracy of the state-of-the-art semantic segmentation networks, but also accelerates their convergence.", "pdf_url": "https://arxiv.org/pdf/2008.06840", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Wavelet Denoising and Attention-based RNN-ARIMA Model to Predict Forex Price", "author": "Zhiwen Zeng, Matloob Khushi", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Every change of trend in the forex market presents a great opportunity as well as a risk for investors. Accurate forecasting of forex prices is a crucial element in any effective hedging or speculation strategy. However, the complex nature of the forex market makes the predicting problem challenging, which has prompted extensive research from various academic disciplines. In this paper, a novel approach that integrates the wavelet denoising, Attention-based Recurrent Neural Network (ARNN), and Autoregressive Integrated Moving Average (ARIMA) are proposed. Wavelet transform removes the noise from the time series to stabilize the data structure. ARNN model captures the robust and non-linear relationships in the sequence and ARIMA can well fit the linear correlation of the sequential information. By hybridization of the three models, the methodology is capable of modelling dynamic systems such as the forex market. Our experiments on USD/JPY five-minute data outperforms the baseline methods. Root-Mean-Squared-Error (RMSE) of the hybrid approach was found to be 1.65 with a directional accuracy of ~76%.", "pdf_url": "https://arxiv.org/pdf/2008.06841", "subject": "Computational Engineering, Finance, and Science (cs.CE)"},
{"title": "Learning Flow-based Feature Warping for Face Frontalization with Illumination Inconsistent Supervision", "author": "Yuxiang Wei, Ming Liu, Haolin Wang, Ruifeng Zhu, Guosheng Hu, Wangmeng Zuo", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Despite recent advances in deep learning-based face frontalization methods, photo-realistic and illumination preserving frontal face synthesis is still challenging due to large pose and illumination discrepancy during training. We propose a novel Flow-based Feature Warping Model (FFWM) which can learn to synthesize photo-realistic and illumination preserving frontal images with illumination inconsistent supervision. Specifically, an Illumination Preserving Module (IPM) is proposed to learn illumination preserving image synthesis from illumination inconsistent image pairs. IPM includes two pathways which collaborate to ensure the synthesized frontal images are illumination preserving and with fine details. Moreover, a Warp Attention Module (WAM) is introduced to reduce the pose discrepancy in the feature level, and hence to synthesize frontal images more effectively and preserve more details of profile images. The attention mechanism in WAM helps reduce the artifacts caused by the displacements between the profile and the frontal images. Quantitative and qualitative experimental results show that our FFWM can synthesize photo-realistic and illumination preserving frontal images and performs favorably against the state-of-the-art results.", "pdf_url": "https://arxiv.org/pdf/2008.06843", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "New Schemes for Solving the Principal Eigenvalue Problems of Perron-like Matrices via Polynomial Approximations of Matrix Exponentials", "author": "Desheng Li, Ruijing Wang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "A real square matrix is Perron-like if it has a real eigenvalue $s$, called the principal eigenvalue of the matrix, and $\\mbox{Re}\\,\\mu<s$ for any other eigenvalue $\\mu$. Nonnegative matrices and symmetric ones are typical examples of this class of matrices. The main purpose of this paper is to develop a set of new schemes to compute the principal eigenvalues of Perron-like matrices and the associated generalized eigenspaces by using polynomial approximations of matrix exponentials. Numerical examples show that these schemes are effective in practice.", "pdf_url": "https://arxiv.org/pdf/2008.06850", "subject": "Numerical Analysis (math.NA)"},
{"title": "An efficient numerical method for condition number constrained covariance matrix approximation", "author": "Shaoxin Wang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In high-dimensional data setting, the sample covariance matrix is singular. In order to get a numerical stable and positive definite modification of the sample covariance matrix in the high-dimensional data setting, we in this paper consider the condition number constrained covariance matrix approximation problem and present its explicit solution with respect to Frobenius norm. The condition number constraint guarantees the numerical stability and positive definiteness of the approximation form simultaneously. By exploiting the special structure of the data matrix in high-dimensional data setting, we also propose some new algorithms based on efficient matrix decomposition techniques. Numerical experiments are also given to show the computational efficiency of the proposed algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.06851", "subject": "Numerical Analysis (math.NA)"},
{"title": "Geometric Foundations of Data Reduction", "author": "Ce Ju", "pub_date": "Submitted on 16 Aug 2020", "abstract": "The purpose of this paper is to write a complete survey of the (spectral) manifold learning methods and nonlinear dimensionality reduction (NLDR) in data reduction. The first two NLDR methods in history were respectively published in Science in 2000 in which they solve the similar reduction problem of high-dimensional data endowed with the intrinsic nonlinear structure. The intrinsic nonlinear structure is always interpreted as a concept in manifolds from geometry and topology in theoretical mathematics by computer scientists and theoretical physicists. In 2001, the concept of Manifold Learning first appears as an NLDR method called Laplacian Eigenmaps purposed by Belkin and Niyogi. In the typical manifold learning setup, the data set, also called the observation set, is distributed on or near a low dimensional manifold $M$ embedded in $\\mathbb{R}^D$, which yields that each observation has a $D$-dimensional representation. The goal of (spectral) manifold learning is to reduce these observations as a compact lower-dimensional representation based on the geometric information. The reduction procedure is called the (spectral) manifold learning method. In this paper, we derive each (spectral) manifold learning method with the matrix and operator representation, and we then discuss the convergence behavior of each method in a geometric uniform language. Hence, we name the survey Geometric Foundations of Data Reduction.", "pdf_url": "https://arxiv.org/pdf/2008.06853", "subject": "Machine Learning (cs.LG)"},
{"title": "SGG: Spinbot, Grammarly and GloVe based Fake News Detection", "author": "Akansha Gautam, Koteswar Rao Jerripothula", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Recently, news consumption using online news portals has increased exponentially due to several reasons, such as low cost and easy accessibility. However, such online platforms inadvertently also become the cause of spreading false information across the web. They are being misused quite frequently as a medium to disseminate misinformation and hoaxes. Such malpractices call for a robust automatic fake news detection system that can keep us at bay from such misinformation and hoaxes. We propose a robust yet simple fake news detection system, leveraging the tools for paraphrasing, grammar-checking, and word-embedding. In this paper, we try to the potential of these tools in jointly unearthing the authenticity of a news article. Notably, we leverage Spinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for word-embedding) tools for this purpose. Using these tools, we were able to extract novel features that could yield state-of-the-art results on the Fake News AMT dataset and comparable results on Celebrity datasets when combined with some of the essential features. More importantly, the proposed method is found to be more robust empirically than the existing ones, as revealed in our cross-domain analysis and multi-domain analysis.", "pdf_url": "https://arxiv.org/pdf/2008.06854", "subject": "Computation and Language (cs.CL)"},
{"title": "GLOD: Gaussian Likelihood Out of Distribution Detector", "author": "Guy Amit, Moshe Levy, Ishai Rosenberg, Asaf Shabtai, Yuval Elovici", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Discriminative deep neural networks (DNNs) do well at classifying input associated with the classes they have been trained on. However, out-of-distribution (OOD) input poses a great challenge to such models and consequently represents a major risk when these models are used in safety-critical systems. In the last two years, extensive research has been performed in the domain of OOD detection. This research has relied mainly on training the model with OOD data or using an auxiliary (external) model for OOD detection. Such methods have limited capability in detecting OOD samples and may not be applicable in many real world use cases. In this paper, we propose GLOD - Gaussian likelihood out of distribution detector - an extended DNN classifier capable of efficiently detecting OOD samples without relying on OOD training data or an external detection model. GLOD uses a layer that models the Gaussian density function of the trained classes. The layer outputs are used to estimate a Log-Likelihood Ratio which is employed to detect OOD samples. We evaluate GLOD's detection performance on three datasets: SVHN, CIFAR-10, and CIFAR-100. Our results show that GLOD surpasses state-of-the-art OOD detection techniques in detection performance by a large margin.", "pdf_url": "https://arxiv.org/pdf/2008.06856", "subject": "Machine Learning (cs.LG)"},
{"title": "TextDecepter: Hard Label Black Box Attack on Text Classifiers", "author": "Sachin Saxena", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Machine learning has been proven to be susceptible to carefully crafted samples, known as adversarialexamples. The generation of these adversarial examples helps to make the models more robust and give as an insight of the underlying decision making of these models. Over the years, researchers have successfully attacked image classifiers in, both, white and black-box setting. Although, these methods are not directly applicable to texts as text data is discrete in nature. In recent years, research on crafting adversarial examples against textual applications has been on the rise. In this paper, we present a novel approach for hard label black-box attacks against Natural Language Processing (NLP) classifiers, where no model information is disclosed, and an attacker can only query the model to get final decision of the classifier, without confidence scores of the classes involved. Such attack scenario is applicable to real world black-box models being used for security-sensitive applications such as sentiment analysis and toxic content detection", "pdf_url": "https://arxiv.org/pdf/2008.06860", "subject": "Computation and Language (cs.CL)"},
{"title": "Detection of Gait Abnormalities caused by Neurological Disorders", "author": "Daksh Goyal, Koteswar Rao Jerripothula, Ankush Mittal", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In this paper, we leverage gait to potentially detect some of the important neurological disorders, namely Parkinson's disease, Diplegia, Hemiplegia, and Huntington's Chorea. Persons with these neurological disorders often have a very abnormal gait, which motivates us to target gait for their potential detection. Some of the abnormalities involve the circumduction of legs, forward-bending, involuntary movements, etc. To detect such abnormalities in gait, we develop gait features from the key-points of the human pose, namely shoulders, elbows, hips, knees, ankles, etc. To evaluate the effectiveness of our gait features in detecting the abnormalities related to these diseases, we build a synthetic video dataset of persons mimicking the gait of persons with such disorders, considering the difficulty in finding a sufficient number of people with these disorders. We name it \\textit{NeuroSynGait} video dataset. Experiments demonstrated that our gait features were indeed successful in detecting these abnormalities.", "pdf_url": "https://arxiv.org/pdf/2008.06861", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Discovering Lexical Similarity Through Articulatory Feature-based Phonetic Edit Distance", "author": "Tafseer Ahmed, Muhammad Suffian Nizami, Muhammad Yaseen Khan", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Lexical Similarity (LS) between two languages uncovers many interesting linguistic insights such as genetic relationship, mutual intelligibility, and the usage of one's vocabulary into other. There are various methods through which LS is evaluated. In the same regard, this paper presents a method of Phonetic Edit Distance (PED) that uses a soft comparison of letters using the articulatory features associated with them. The system converts the words into the corresponding International Phonetic Alphabet (IPA), followed by the conversion of IPA into its set of articulatory features. Later, the lists of the set of articulatory features are compared using the proposed method. As an example, PED gives edit distance of German word vater and Persian word pidar as 0.82; and similarly, Hebrew word shalom and Arabic word salaam as 0.93, whereas for a juxtapose comparison, their IPA based edit distances are 4 and 2 respectively. Experiments are performed with six languages (Arabic, Hindi, Marathi, Persian, Sanskrit, and Urdu). In this regard, we extracted part of speech wise word-lists from the Universal Dependency corpora and evaluated the LS for every pair of language. Thus, with the proposed approach, we find the genetic affinity, similarity, and borrowing/loan-words despite having script differences and sound variation phenomena among these languages.", "pdf_url": "https://arxiv.org/pdf/2008.06865", "subject": "Computation and Language (cs.CL)"},
{"title": "KutralNet: A Portable Deep Learning Model for Fire Recognition", "author": "Angel Ayala, Bruno Fernandes, Francisco Cruz, David Mac\u00eado, Adriano L. I. Oliveira, Cleber Zanchettin", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Most of the automatic fire alarm systems detect the fire presence through sensors like thermal, smoke, or flame. One of the new approaches to the problem is the use of images to perform the detection. The image approach is promising since it does not need specific sensors and can be easily embedded in different devices. However, besides the high performance, the computational cost of the used deep learning methods is a challenge to their deployment in portable devices. In this work, we propose a new deep learning architecture that requires fewer floating-point operations (flops) for fire recognition. Additionally, we propose a portable approach for fire recognition and the use of modern techniques such as inverted residual block, convolutions like depth-wise, and octave, to reduce the model's computational cost. The experiments show that our model keeps high accuracy while substantially reducing the number of parameters and flops. One of our models presents 71\\% fewer parameters than FireNet, while still presenting competitive accuracy and AUROC performance. The proposed methods are evaluated on FireNet and FiSmo datasets. The obtained results are promising for the implementation of the model in a mobile device, considering the reduced number of flops and parameters acquired.", "pdf_url": "https://arxiv.org/pdf/2008.06866", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "SECODA: Segmentation- and Combination-Based Detection of Anomalies", "author": "Ralph Foorthuis", "pub_date": "Submitted on 16 Aug 2020", "abstract": "This study introduces SECODA, a novel general-purpose unsupervised non-parametric anomaly detection algorithm for datasets containing continuous and categorical attributes. The method is guaranteed to identify cases with unique or sparse combinations of attribute values. Continuous attributes are discretized repeatedly in order to correctly determine the frequency of such value combinations. The concept of constellations, exponentially increasing weights and discretization cut points, as well as a pruning heuristic are used to detect anomalies with an optimal number of iterations. Moreover, the algorithm has a low memory imprint and its runtime performance scales linearly with the size of the dataset. An evaluation with simulated and real-life datasets shows that this algorithm is able to identify many different types of anomalies, including complex multidimensional instances. An evaluation in terms of a data quality use case with a real dataset demonstrates that SECODA can bring relevant and practical value to real-world settings.", "pdf_url": "https://arxiv.org/pdf/2008.06869", "subject": "Databases (cs.DB)"},
{"title": "Attractive Ellipsoid Sliding Mode Observer Design for State of Charge Estimation of Lithium-ion Cells", "author": "Anirudh Nath, Raghvendra Gupta, Rohit Mehta, Supreet Singh Bahga, Amit Gupta, Shubhendu Bhasin", "pub_date": "Submitted on 16 Aug 2020", "abstract": "This work investigates the real-time estimation of the state-of-charge (SoC) of Lithium-ion (Li-ion) cells for reliable, safe and efficient utilization. A novel attractive ellipsoid based sliding-mode observer (AESMO) algorithm is designed to estimate the SoC in real-time. The algorithm utilizes standard equivalent circuit model of a Li-ion cell and provides reliable and efficient SoC estimate in the presence of bounded uncertainties in the battery parameters as well as exogenous disturbances. The theoretical framework of the observer design is not limited to the SoC estimation problem of Li-ion cell but applicable to a wider class of nonlinear systems with both matched and mismatched uncertainties. The main advantage of the proposed observer is to provide a fast and optimal SoC estimate based on minimization over the uncertainty bound. The proposed method is experimentally tested and evaluated using the hybrid pulse power characterization test (HPPC)and urban dynamometer driving schedule (UDDS) test data, which demonstrate its effectiveness and feasibility.", "pdf_url": "https://arxiv.org/pdf/2008.06871", "subject": "Systems and Control (eess.SY)"},
{"title": "SMPLpix: Neural Avatars from 3D Human Models", "author": "Sergey Prokudin, Michael J. Black, Javier Romero", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Recent advances in deep generative models have led to an unprecedented level of realism for synthetically generated images of humans. However, one of the remaining fundamental limitations of these models is the ability to flexibly control the generative process, e.g. change the camera and human pose while retaining the subject identity. At the same time, deformable human body models like SMPL and its successors provide full control over pose and shape, but rely on classic computer graphics pipelines for rendering. Such rendering pipelines require explicit mesh rasterization that (a) does not have the potential to fix artifacts or lack of realism in the original 3D geometry and (b) until recently, were not fully incorporated into deep learning frameworks. In this work, we propose to bridge the gap between classic geometry-based rendering and the latest generative networks operating in pixel space by introducing a neural rasterizer, a trainable neural network module that directly \"renders\" a sparse set of 3D mesh vertices as photorealistic images, avoiding any hardwired logic in pixel colouring and occlusion reasoning. We train our model on a large corpus of human 3D models and corresponding real photos, and show the advantage over conventional differentiable renderers both in terms of the level of photorealism and rendering efficiency.", "pdf_url": "https://arxiv.org/pdf/2008.06872", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "TopicBERT: A Transformer transfer learning based memory-graph approach for multimodal streaming social media topic detection", "author": "Meysam Asgari-Chenaghlu, Mohammad-Reza Feizi-Derakhshi, Leili farzinvash, Mohammad-Ali Balafar, Cina Motamed", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Real time nature of social networks with bursty short messages and their respective large data scale spread among vast variety of topics are research interest of many researchers. These properties of social networks which are known as 5'Vs of big data has led to many unique and enlightenment algorithms and techniques applied to large social networking datasets and data streams. Many of these researches are based on detection and tracking of hot topics and trending social media events that help revealing many unanswered questions. These algorithms and in some cases software products mostly rely on the nature of the language itself. Although, other techniques such as unsupervised data mining methods are language independent but many requirements for a comprehensive solution are not met. Many research issues such as noisy sentences that adverse grammar and new online user invented words are challenging maintenance of a good social network topic detection and tracking methodology; The semantic relationship between words and in most cases, synonyms are also ignored by many of these researches. In this research, we use Transformers combined with an incremental community detection algorithm. Transformer in one hand, provides the semantic relation between words in different contexts. On the other hand, the proposed graph mining technique enhances the resulting topics with aid of simple structural rules. Named entity recognition from multimodal data, image and text, labels the named entities with entity type and the extracted topics are tuned using them. All operations of proposed system has been applied with big social data perspective under NoSQL technologies. In order to present a working and systematic solution, we combined MongoDB with Neo4j as two major database systems of our work. The proposed system shows higher precision and recall compared to other methods in three different datasets.", "pdf_url": "https://arxiv.org/pdf/2008.06877", "subject": "Computation and Language (cs.CL)"},
{"title": "Poet: Product-oriented Video Captioner for E-commerce", "author": "Shengyu Zhang, Ziqi Tan, Jin Yu, Zhou Zhao, Kun Kuang, Jie Liu, Jingren Zhou, Hongxia Yang, Fei Wu", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In e-commerce, a growing number of user-generated videos are used for product promotion. How to generate video descriptions that narrate the user-preferred product characteristics depicted in the video is vital for successful promoting. Traditional video captioning methods, which focus on routinely describing what exists and happens in a video, are not amenable for product-oriented video captioning. To address this problem, we propose a product-oriented video captioner framework, abbreviated as Poet. Poet firstly represents the videos as product-oriented spatial-temporal graphs. Then, based on the aspects of the video-associated product, we perform knowledge-enhanced spatial-temporal inference on those graphs for capturing the dynamic change of fine-grained product-part characteristics. The knowledge leveraging module in Poet differs from the traditional design by performing knowledge filtering and dynamic memory modeling. We show that Poet achieves consistent performance improvement over previous methods concerning generation quality, product aspects capturing, and lexical diversity. Experiments are performed on two product-oriented video captioning datasets, buyer-generated fashion video dataset (BFVD) and fan-generated fashion video dataset (FFVD), collected from Mobile Taobao. We will release the desensitized datasets to promote further investigations on both video captioning and general video analysis problems.", "pdf_url": "https://arxiv.org/pdf/2008.06880", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "DeVLBert: Learning Deconfounded Visio-Linguistic Representations", "author": "Shengyu Zhang, Tan Jiang, Tan Wang, Kun Kuang, Zhou Zhao, Jianke Zhu, Jin Yu, Hongxia Yang, Fei Wu", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In this paper, we propose to investigate the problem of out-of-domain visio-linguistic pretraining, where the pretraining data distribution differs from that of downstream data on which the pretrained model will be fine-tuned. Existing methods for this problem are purely likelihood-based, leading to the spurious correlations and hurt the generalization ability when transferred to out-of-domain downstream tasks. By spurious correlation, we mean that the conditional probability of one token (object or word) given another one can be high (due to the dataset biases) without robust (causal) relationships between them. To mitigate such dataset biases, we propose a Deconfounded Visio-Linguistic Bert framework, abbreviated as DeVLBert, to perform intervention-based learning. We borrow the idea of the backdoor adjustment from the research field of causality and propose several neural-network based architectures for Bert-style out-of-domain pretraining. The quantitative results on three downstream tasks, Image Retrieval (IR), Zero-shot IR, and Visual Question Answering, show the effectiveness of DeVLBert by boosting generalization ability.", "pdf_url": "https://arxiv.org/pdf/2008.06884", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Adaptive Signal Variances: CNN Initialization Through Modern Architectures", "author": "Takahiko Henmi, Esmeraldo Ronnie Rey Zara, Yoshihiro Hirohashi, Tsuyoshi Kato", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Deep convolutional neural networks (CNN) have achieved the unwavering confidence in its performance on image processing tasks. The CNN architecture constitutes a variety of different types of layers including the convolution layer and the max-pooling layer. CNN practitioners widely understandthe fact that the stability of learning depends on how to initialize the model parameters in each layer. Nowadays, no one doubts that the de facto standard scheme for initialization is the so-called Kaiming initialization that has been developed by He et al. The Kaiming scheme was derived from a much simpler model than the currently used CNN structure having evolved since the emergence of the Kaiming scheme. The Kaiming model consists only of the convolution and fully connected layers, ignoring the max-pooling layer and the global average pooling layer. In this study, we derived the initialization scheme again not from the simplified Kaiming model, but precisely from the modern CNN architectures.", "pdf_url": "https://arxiv.org/pdf/2008.06885", "subject": "Machine Learning (cs.LG)"},
{"title": "Efficient, Flexible and Secure Group Key Management Protocol for Dynamic IoT Settings", "author": "Adhirath Kabra, Sumit Kumar, Gaurav S. Kasbekar", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Many Internet of Things (IoT) scenarios require communication to and data acquisition from multiple devices with similar functionalities. For such scenarios, group communication in the form of multicasting and broadcasting has proven to be effective. Group Key Management (GKM) involves the handling, revocation, updation and distribution of cryptographic keys to members of various groups. Classical GKM schemes perform inefficiently in dynamic IoT environments, which are those wherein nodes frequently leave or join a network or migrate from one group to another over time. Recently, the `GroupIt' scheme has been proposed for GKM in dynamic IoT environments. However, this scheme has several limitations such as vulnerability to collusion attacks, the use of computationally expensive asymmetric encryption and threats to the backward secrecy of the system. In this paper, we present a highly efficient and secure GKM protocol for dynamic IoT settings, which maintains forward and backward secrecy at all times. Our proposed protocol uses only symmetric encryption, and is completely resistant to collusion attacks. Also, our protocol is highly flexible and can handle several new scenarios in which device or user dynamics may take place, e.g., allowing a device group to join or leave the network or creation or dissolution of a user group, which are not handled by schemes proposed in prior literature. We evaluate the performance of the proposed protocol via extensive mathematical analysis and numerical computations, and show that it outperforms the GroupIt scheme in terms of the communication and computation costs incurred by users and devices.", "pdf_url": "https://arxiv.org/pdf/2008.06890", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Context-aware Feature Generation for Zero-shot Semantic Segmentation", "author": "Zhangxuan Gu, Siyuan Zhou, Li Niu, Zihan Zhao, Liqing Zhang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Existing semantic segmentation models heavily rely on dense pixel-wise annotations. To reduce the annotation pressure, we focus on a challenging task named zero-shot semantic segmentation, which aims to segment unseen objects with zero annotations. This task can be accomplished by transferring knowledge across categories via semantic word embeddings. In this paper, we propose a novel context-aware feature generation method for zero-shot segmentation named CaGNet. In particular, with the observation that a pixel-wise feature highly depends on its contextual information, we insert a contextual module in a segmentation network to capture the pixel-wise contextual information, which guides the process of generating more diverse and context-aware features from semantic word embeddings. Our method achieves state-of-the-art results on three benchmark datasets for zero-shot segmentation. Codes are available at: .", "pdf_url": "https://arxiv.org/pdf/2008.06893", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "From Lost to Found: Discover Missing UI Design Semantics through Recovering Missing Tags", "author": "Chunyang Chen, Sidong Feng, Zhengyang Liu, Zhenchang Xing, Shengdong Zhao", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Design sharing sites provide UI designers with a platform to share their works and also an opportunity to get inspiration from others' designs. To facilitate management and search of millions of UI design images, many design sharing sites adopt collaborative tagging systems by distributing the work of categorization to the community. However, designers often do not know how to properly tag one design image with compact textual description, resulting in unclear, incomplete, and inconsistent tags for uploaded examples which impede retrieval, according to our empirical study and interview with four professional designers. Based on a deep neural network, we introduce a novel approach for encoding both the visual and textual information to recover the missing tags for existing UI examples so that they can be more easily found by text queries. We achieve 82.72% accuracy in the tag prediction. Through a simulation test of 5 queries, our system on average returns hundreds more results than the default Dribbble search, leading to better relatedness, diversity and satisfaction.", "pdf_url": "https://arxiv.org/pdf/2008.06895", "subject": "Human-Computer Interaction (cs.HC)"},
{"title": "Adaptive Shape Servoing of Elastic Rods using Parameterized Regression Features and Auto-Tuning Motion Controls", "author": "Jiaming Qi, Wanyu Ma, David Navarro-Alarcon, Han Gao, Guangfu Ma", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In this paper, we present a new vision-based method to control the shape of elastic rods with robot manipulators. Our new method computes parameterized regression features from online sensor measurements that enable to automatically quantify the object's configuration and establish an explicit shape servo-loop. To automatically deform the rod into a desired shape, our adaptive controller iteratively estimates the differential transformation between the robot's motion and the relative shape changes; This valuable capability allows to effectively manipulate objects with unknown mechanical models. An auto-tuning algorithm is introduced to adjust the robot's shaping motion in real-time based on optimal performance criteria. To validate the proposed theory, we present a detailed numerical and experimental study with vision-guided robotic manipulators.", "pdf_url": "https://arxiv.org/pdf/2008.06896", "subject": "Robotics (cs.RO)"},
{"title": "Structure-Preserving Numerical Methods for Nonlinear Fokker--Planck Equations with Nonlocal Interactions by an Energetic Variational Approach", "author": "Chenghua Duan, Wenbin Chen, Chun Liu, Xingye Yue, Shenggao Zhou", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In this work, we develop novel structure-preserving numerical schemes for a class of nonlinear Fokker--Planck equations with nonlocal interactions. Such equations can cover many cases of importance, such as porous medium equations with external potentials, optimal transport problems, and aggregation-diffusion models. Based on the Energetic Variational Approach, a trajectory equation is first derived by using the balance between the maximal dissipation principle and least action principle. By a convex-splitting technique, we propose energy dissipating numerical schemes for the trajectory equation. Rigorous numerical analysis reveals that the nonlinear numerical schemes are uniquely solvable, naturally respect mass conservation and positivity at fully discrete level, and preserve steady states. Under certain smoothness assumptions, the numerical schemes are shown to be second order accurate in space and first order accurate in time. Extensive numerical simulations are performed to demonstrate several valuable features of the proposed schemes. In addition to the preservation of physical structures, such as positivity, mass conservation, discrete energy dissipation, blue and steady states, numerical simulations further reveal that our numerical schemes are capable of solving \\emph{degenerate} cases of the Fokker--Planck equations effectively and robustly. It is shown that the developed numerical schemes have convergence order even in degenerate cases with the presence of solutions having compact support, can accurately and robustly compute the waiting time of free boundaries without any oscillation, and can approximate blow-up singularity up to machine precision.", "pdf_url": "https://arxiv.org/pdf/2008.06903", "subject": "Numerical Analysis (math.NA)"},
{"title": "A Biomimetic Tactile Fingerprint Induces Incipient Slip", "author": "Jasper W. James, Stephen J. Redmond, Nathan F. Lepora", "pub_date": "Submitted on 16 Aug 2020", "abstract": "We present a modified TacTip biomimetic optical tactile sensor design which demonstrates the ability to induce and detect incipient slip, as confirmed by recording the movement of markers on the sensor's external surface. Incipient slip is defined as slippage of part, but not all, of the contact surface between the sensor and object. The addition of ridges - which mimic the friction ridges in the human fingertip - in a concentric ring pattern allowed for localised shear deformation to occur on the sensor surface for a significant duration prior to the onset of gross slip. By detecting incipient slip we were able to predict when several differently shaped objects were at risk of falling and prevent them from doing so. Detecting incipient slip is useful because a corrective action can be taken before slippage occurs across the entire contact area thus minimising the risk of objects been dropped.", "pdf_url": "https://arxiv.org/pdf/2008.06904", "subject": "Robotics (cs.RO)"},
{"title": "Visually Aware Skip-Gram for Image Based Recommendations", "author": "Parth Tiwari, Yash Jain, Shivansh Mundra, Jenny Harding, Manoj Kumar Tiwari", "pub_date": "Submitted on 16 Aug 2020", "abstract": "The visual appearance of a product significantly influences purchase decisions on e-commerce websites. We propose a novel framework VASG (Visually Aware Skip-Gram) for learning user and product representations in a common latent space using product image features. Our model is an amalgamation of the Skip-Gram architecture and a deep neural network based Decoder. Here the Skip-Gram attempts to capture user preference by optimizing user-product co-occurrence in a Heterogeneous Information Network while the Decoder simultaneously learns a mapping to transform product image features to the Skip-Gram embedding space. This architecture is jointly optimized in an end-to-end, multitask fashion. The proposed framework enables us to make personalized recommendations for cold-start products which have no purchase history. Experiments conducted on large real-world datasets show that the learned embeddings can generate effective recommendations using nearest neighbour searches.", "pdf_url": "https://arxiv.org/pdf/2008.06908", "subject": "Information Retrieval (cs.IR)"},
{"title": "Geodesic Paths for Image Segmentation with Implicit Region-based Homogeneity Enhancement", "author": "Da Chen, Jian Zhu, Xinxin Zhang, Minglei Shu, Laurent D. Cohen", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Minimal paths are considered as a powerful and efficient tool for boundary detection and image segmentation due to its global optimality and well-established numerical solutions such as fast marching algorithm. In this paper, we introduce a flexible interactive image segmentation model based on the minimal geodesic framework in conjunction with region-based homogeneity enhancement. A key ingredient in our model is the construction of Finsler geodesic metrics, which are capable of integrating anisotropic and asymmetric edge features, region-based homogeneity and/or curvature regularization. This is done by exploiting an implicit method to incorporate the region-based homogeneity information to the metrics used. Moreover, we also introduce a way to build objective simple closed contours, each of which is treated as the concatenation of two disjoint open paths. Experimental results prove that the proposed model indeed outperforms state-of-the-art minimal paths-based image segmentation approaches.", "pdf_url": "https://arxiv.org/pdf/2008.06909", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "Neural Descent for Visual 3D Human Pose and Shape", "author": "Andrei Zanfir, Eduard Gabriel Bazavan, Mihai Zanfir, William T. Freeman, Rahul Sukthankar, Cristian Sminchisescu", "pub_date": "Submitted on 16 Aug 2020", "abstract": "We present deep neural network methodology to reconstruct the 3d pose and shape of people, given an input RGB image. We rely on a recently introduced, expressivefull body statistical 3d human model, GHUM, trained end-to-end, and learn to reconstruct its pose and shape state in a self-supervised regime. Central to our methodology, is a learning to learn and optimize approach, referred to as HUmanNeural Descent (HUND), which avoids both second-order differentiation when training the model parameters,and expensive state gradient descent in order to accurately minimize a semantic differentiable rendering loss at test time. Instead, we rely on novel recurrent stages to update the pose and shape parameters such that not only losses are minimized effectively, but the process is meta-regularized in order to ensure end-progress. HUND's symmetry between training and testing makes it the first 3d human sensing architecture to natively support different operating regimes including self-supervised ones. In diverse tests, we show that HUND achieves very competitive results in datasets like H3.6M and 3DPW, aswell as good quality 3d reconstructions for complex imagery collected in-the-wild.", "pdf_url": "https://arxiv.org/pdf/2008.06910", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "SoK: Why Johnny Can't Fix PGP Standardization", "author": "Harry Halpin", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Pretty Good Privacy (PGP) has long been the primary IETF standard for encrypting email, but suffers from widespread usability and security problems that have limited its adoption. As time has marched on, the underlying cryptographic protocol has fallen out of date insofar as PGP is unauthenticated on a per message basis and compresses before encryption. There have been an increasing number of attacks on the increasingly outdated primitives and complex clients used by the PGP eco-system. However, attempts to update the OpenPGP standard have failed at the IETF except for adding modern cryptographic primitives. Outside of official standardization, Autocrypt is a \"bottom-up\" community attempt to fix PGP, but still falls victim to attacks on PGP involving authentication. The core reason for the inability to \"fix\" PGP is the lack of a simple AEAD interface which in turn requires a decentralized public key infrastructure to work with email. Yet even if standards like MLS replace PGP, the deployment of a decentralized PKI remains an open issue.", "pdf_url": "https://arxiv.org/pdf/2008.06913", "subject": "Cryptography and Security (cs.CR)"},
{"title": "DCR-Net: A Deep Co-Interactive Relation Network for Joint Dialog Act Recognition and Sentiment Classification", "author": "Libo Qin, Wanxiang Che, Yangming Li, Minheng Ni, Ting Liu", "pub_date": "Submitted on 16 Aug 2020", "abstract": "In dialog system, dialog act recognition and sentiment classification are two correlative tasks to capture speakers intentions, where dialog act and sentiment can indicate the explicit and the implicit intentions separately. Most of the existing systems either treat them as separate tasks or just jointly model the two tasks by sharing parameters in an implicit way without explicitly modeling mutual interaction and relation. To address this problem, we propose a Deep Co-Interactive Relation Network (DCR-Net) to explicitly consider the cross-impact and model the interaction between the two tasks by introducing a co-interactive relation layer. In addition, the proposed relation layer can be stacked to gradually capture mutual knowledge with multiple steps of interaction. Especially, we thoroughly study different relation layers and their effects. Experimental results on two public datasets (Mastodon and Dailydialog) show that our model outperforms the state-of-the-art joint model by 4.3% and 3.4% in terms of F1 score on dialog act recognition task, 5.7% and 12.4% on sentiment classification respectively. Comprehensive analysis empirically verifies the effectiveness of explicitly modeling the relation between the two tasks and the multi-steps interaction mechanism. Finally, we employ the Bidirectional Encoder Representation from Transformer (BERT) in our framework, which can further boost our performance in both tasks.", "pdf_url": "https://arxiv.org/pdf/2008.06914", "subject": "Computation and Language (cs.CL)"},
{"title": "Association and Caching in Relay-Assisted mmWave Networks: From A Stochastic Geometry Perspective", "author": "Zhuojia Gu, Hancheng Lu, Ming Zhang, Haizhou Sun, Chang Wen Chen", "pub_date": "Submitted on 16 Aug 2020 ( ), last revised 18 Aug 2020 (this version, v2)", "abstract": "Limited backhaul bandwidth and blockage effects are two main factors limiting the practical deployment of millimeter wave (mmWave) networks. To tackle these issues, we study the feasibility of relaying as well as caching in mmWave networks. A user association and relaying (UAR) criterion dependent on both caching status and maximum biased received power is proposed by considering the spatial correlation caused by the coexistence of base stations (BSs) and relay nodes (RNs). A joint UAR and caching placement problem is then formulated to maximize the backhaul offloading traffic. Using stochastic geometry tools, we decouple the joint UAR and caching placement problem by analyzing the relationship between UAR probabilities and caching placement probabilities. We then optimize the transformed caching placement problem based on polyblock outer approximation by exploiting the monotonic property in the general case and utilizing convex optimization in the noise-limited case. Accordingly, we propose a BS and RN selection algorithm where caching status at BSs and maximum biased received power are jointly considered. Experimental results demonstrate a significant enhancement of backhaul offloading using the proposed algorithms, and show that deploying more RNs and increasing cache size in mmWave networks is a more cost-effective alternative than increasing BS density to achieve similar backhaul offloading performance.", "pdf_url": "https://arxiv.org/pdf/2008.06915", "subject": "Networking and Internet Architecture (cs.NI)"},
{"title": "Discouraging Pool Block Withholding Attacks in Bitcoins", "author": "Zhihuai Chen, Bo Li, Xiaohan Shan, Xiaoming Sun, Jialin Zhang", "pub_date": "Submitted on 16 Aug 2020", "abstract": "The arisen of Bitcoin has led to much enthusiasm for blockchain research and block mining, and the extensive existence of mining pools helps its participants (i.e., miners) gain reward more frequently. Recently, the mining pools are proved to be vulnerable for several possible attacks, and pool block withholding attack is one of them: one strategic pool manager sends some of her miners to other pools and these miners pretend to work on the puzzles but actually do nothing. And these miners still get reward since the pool manager can not recognize these malicious miners. In this work, we revisit the game-theoretic model for pool block withholding attacks and propose a revised approach to reallocate the reward to the miners. Fortunately, in the new model, the pool managers have strong incentive to not launch such attacks. We show that for any number of mining pools, no-pool-attacks is always a Nash equilibrium. Moreover, with only two minority mining pools participating, no-pool-attacks is actually the unique Nash equilibrium.", "pdf_url": "https://arxiv.org/pdf/2008.06923", "subject": "Computer Science and Game Theory (cs.GT)"},
{"title": "Inverse Reinforcement Learning with Natural Language Goals", "author": "Li Zhou, Kevin Small", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Humans generally use natural language to communicate task requirements amongst each other. It is desirable that this would be similar for autonomous machines (e.g. robots) such that humans can convey goals or assign tasks more easily. However, understanding natural language goals and mapping them to sequences of states and actions is challenging. Previous research has encountered difficulty generalizing learned policies to new natural language goals and environments. In this paper, we propose an adversarial inverse reinforcement learning algorithm that learns a language-conditioned policy and reward function. To improve the generalization of the learned policy and reward function, we use a variational goal generator that relabels trajectories and samples diverse goals during training. Our algorithm outperforms baselines by a large margin on a vision-based natural language instruction following dataset, demonstrating a promising advance in providing natural language instructions to agents without reliance on instruction templates.", "pdf_url": "https://arxiv.org/pdf/2008.06924", "subject": "Machine Learning (cs.LG)"},
{"title": "A Survey of Machine Learning Methods for Detecting False Data Injection Attacks in Power Systems", "author": "Ali Sayghe, Yaodan Hu, Ioannis Zografopoulos, XiaoRui Liu, Raj Gautam Dutta, Yier Jin, Charalambos Konstantinou", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Over the last decade, the number of cyberattacks targeting power systems and causing physical and economic damages has increased rapidly. Among them, False Data Injection Attacks (FDIAs) is a class of cyberattacks against power grid monitoring systems. Adversaries can successfully perform FDIAs in order to manipulate the power system State Estimation (SE) by compromising sensors or modifying system data. SE is an essential process performed by the Energy Management System (EMS) towards estimating unknown state variables based on system redundant measurements and network topology. SE routines include Bad Data Detection (BDD) algorithms to eliminate errors from the acquired measurements, e.g., in case of sensor failures. FDIAs can bypass BDD modules to inject malicious data vectors into a subset of measurements without being detected, and thus manipulate the results of the SE process. In order to overcome the limitations of traditional residual-based BDD approaches, data-driven solutions based on machine learning algorithms have been widely adopted for detecting malicious manipulation of sensor data due to their fast execution times and accurate results. This paper provides a comprehensive review of the most up-to-date machine learning methods for detecting FDIAs against power system SE algorithms.", "pdf_url": "https://arxiv.org/pdf/2008.06926", "subject": "Systems and Control (eess.SY)"},
{"title": "The reinforcement learning-based multi-agent cooperative approach for the adaptive speed regulation on a metallurgical pickling line", "author": "Anna Bogomolova, Kseniia Kingsep, Boris Voskresenskii", "pub_date": "Submitted on 16 Aug 2020", "abstract": "We present a holistic data-driven approach to the problem of productivity increase on the example of a metallurgical pickling line. The proposed approach combines mathematical modeling as a base algorithm and a cooperative Multi-Agent Reinforcement Learning (MARL) system implemented such as to enhance the performance by multiple criteria while also meeting safety and reliability requirements and taking into account the unexpected volatility of certain technological processes. We demonstrate how Deep Q-Learning can be applied to a real-life task in a heavy industry, resulting in significant improvement of previously existing automation systems.The problem of input data scarcity is solved by a two-step combination of LSTM and CGAN, which helps to embrace both the tabular representation of the data and its sequential properties. Offline RL training, a necessity in this setting, has become possible through the sophisticated probabilistic kinematic environment.", "pdf_url": "https://arxiv.org/pdf/2008.06933", "subject": "Machine Learning (cs.LG)"},
{"title": "Automatic Translation of tock-CSP into Timed Automata", "author": "Abdulrazaq Abba, Ana Cavalcanti, Jeremy Jacob", "pub_date": "Submitted on 16 Aug 2020", "abstract": "The process algebra tock-CSP provides textual notations for modelling discrete-time behaviours, with the support of various tools for verification. Similarly, automatic verification of Timed Automata (TA) is supported by the real-time verification toolbox UPPAAL. TA and tock-CSP differ in both modelling and verification approaches. For instance, liveness requirements are difficult to specify with the constructs of tock-CSP, but they are easy to verify in UPPAAL. In this work, we translate tock-CSP into TA to take advantage of UPPAAL. We have developed a translation technique and tool; our work uses rules for translating tock-CSP into a network of small TA, which address the complexity of capturing the compositionality of tock-CSP . For validation, we use an experimental approach based on finite approximations to trace sets. We plan to use mathematical proof to establish the correctness of the rules that will cover an infinite set of traces.", "pdf_url": "https://arxiv.org/pdf/2008.06935", "subject": "Logic in Computer Science (cs.LO)"},
{"title": "Supervised Learning with First-to-Spike Decoding in Multilayer Spiking Neural Networks", "author": "Brian Gardner, Andr\u00e9 Gr\u00fcning", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Experimental studies support the notion of spike-based neuronal information processing in the brain, with neural circuits exhibiting a wide range of temporally-based coding strategies to rapidly and efficiently represent sensory stimuli. Accordingly, it would be desirable to apply spike-based computation to tackling real-world challenges, and in particular transferring such theory to neuromorphic systems for low-power embedded applications. Motivated by this, we propose a new supervised learning method that can train multilayer spiking neural networks to solve classification problems based on a rapid, first-to-spike decoding strategy. The proposed learning rule supports multiple spikes fired by stochastic hidden neurons, and yet is stable by relying on first-spike responses generated by a deterministic output layer. In addition to this, we also explore several distinct, spike-based encoding strategies in order to form compact representations of presented input data. We demonstrate the classification performance of the learning rule as applied to several benchmark datasets, including MNIST. The learning rule is capable of generalising from the data, and is successful even when used with constrained network architectures containing few input and hidden layer neurons. Furthermore, we highlight a novel encoding strategy, termed `scanline encoding', that can transform image data into compact spatiotemporal patterns for subsequent network processing. Designing constrained, but optimised, network structures and performing input dimensionality reduction has strong implications for neuromorphic applications.", "pdf_url": "https://arxiv.org/pdf/2008.06937", "subject": "Neural and Evolutionary Computing (cs.NE)"},
{"title": "Successive Cancellation Decoding of Single Parity-Check Product Codes: Analysis and Improved Decoding", "author": "Mustafa Cemil Co\u015fkun, Gianluigi Liva, Alexandre Graell i Amat, Michael Lentmaier, Henry D. Pfister", "pub_date": "Submitted on 16 Aug 2020", "abstract": "A product code with single parity-check component codes can be seen as a special instance of a multi-kernel polar code, where the rows of the generator matrix are chosen according to the constraints imposed by the product code construction. Following this observation, successive cancellation decoding of such codes is introduced. In particular, the error probability of single parity-check product codes over the binary erasure channel under successive cancellation decoding is characterized. A bridge with the analysis of product codes introduced by Elias is also established. Successive cancellation list decoding of single parity-check product codes is then described. For the provided example, it is shown that successive cancellation list decoding outperforms belief propagation decoding performed on the code graph over the binary input additive white Gaussian channel. Finally, the performance of the concatenation of a product code with a high-rate outer code is investigated via distance spectrum analysis.", "pdf_url": "https://arxiv.org/pdf/2008.06938", "subject": "Information Theory (cs.IT)"},
{"title": "Visual stream connectivity predicts assessments of image quality", "author": "Elijah Bowen, Antonio Rodriguez, Damian Sowinski, Richard Granger", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Some biological mechanisms of early vision are comparatively well understood, but they have yet to be evaluated for their ability to accurately predict and explain human judgments of image similarity. From well-studied simple connectivity patterns in early vision, we derive a novel formalization of the psychophysics of similarity, showing the differential geometry that provides accurate and explanatory accounts of perceptual similarity judgments. These predictions then are further improved via simple regression on human behavioral reports, which in turn are used to construct more elaborate hypothesized neural connectivity patterns. Both approaches outperform standard successful measures of perceived image fidelity from the literature, as well as providing explanatory principles of similarity perception.", "pdf_url": "https://arxiv.org/pdf/2008.06939", "subject": "Computer Vision and Pattern Recognition (cs.CV)"},
{"title": "TempNodeEmb:Temporal Node Embedding considering temporal edge influence matrix", "author": "Khushnood Abbas, Alireza Abbasi, Dong Shi, Niu Ling, Mingsheng Shang, Chen Liong, Bolun Chen", "pub_date": "Submitted on 16 Aug 2020", "abstract": "Understanding the evolutionary patterns of real-world evolving complex systems such as human interactions, transport networks, biological interactions, and computer networks has important implications in our daily lives. Predicting future links among the nodes in such networks reveals an important aspect of the evolution of temporal networks. To analyse networks, they are mapped to adjacency matrices, however, a single adjacency matrix cannot represent complex relationships (e.g. temporal pattern), and therefore, some approaches consider a simplified representation of temporal networks but in high-dimensional and generally sparse matrices. As a result, adjacency matrices cannot be directly used by machine learning models for making network or node level predictions. To overcome this problem, automated frameworks are proposed for learning low-dimensional vectors for nodes or edges, as state-of-the-art techniques in predicting temporal patterns in networks such as link prediction. However, these models fail to consider temporal dimensions of the networks. This gap motivated us to propose in this research a new node embedding technique which exploits the evolving nature of the networks considering a simple three-layer graph neural network at each time step, and extracting node orientation by Given's angle method. To prove our proposed algorithm's efficiency, we evaluated the efficiency of our proposed algorithm against six state-of-the-art benchmark network embedding models, on four real temporal networks data, and the results show our model outperforms other methods in predicting future links in temporal networks.", "pdf_url": "https://arxiv.org/pdf/2008.06940", "subject": "Machine Learning (cs.LG)"}
]